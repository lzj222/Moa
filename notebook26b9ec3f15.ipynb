{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249ac894",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-15T01:33:59.903002Z",
     "iopub.status.busy": "2025-03-15T01:33:59.902690Z",
     "iopub.status.idle": "2025-03-15T01:34:05.445186Z",
     "shell.execute_reply": "2025-03-15T01:34:05.444208Z"
    },
    "papermill": {
     "duration": 5.552363,
     "end_time": "2025-03-15T01:34:05.446767",
     "exception": false,
     "start_time": "2025-03-15T01:33:59.894404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting iterative-stratification\r\n",
      "  Downloading iterative_stratification-0.1.9-py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from iterative-stratification) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from iterative-stratification) (1.13.1)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from iterative-stratification) (1.2.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->iterative-stratification) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->iterative-stratification) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->iterative-stratification) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->iterative-stratification) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->iterative-stratification) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->iterative-stratification) (2.4.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->iterative-stratification) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->iterative-stratification) (3.5.0)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->iterative-stratification) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->iterative-stratification) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->iterative-stratification) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->iterative-stratification) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->iterative-stratification) (2024.2.0)\r\n",
      "Downloading iterative_stratification-0.1.9-py3-none-any.whl (8.5 kB)\r\n",
      "Installing collected packages: iterative-stratification\r\n",
      "Successfully installed iterative-stratification-0.1.9\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#sys.path.append('../input/iterativestratification')\n",
    "!pip install iterative-stratification\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b73cdb",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2025-03-15T01:34:05.461377Z",
     "iopub.status.busy": "2025-03-15T01:34:05.461019Z",
     "iopub.status.idle": "2025-03-15T01:34:10.330296Z",
     "shell.execute_reply": "2025-03-15T01:34:10.329570Z"
    },
    "papermill": {
     "duration": 4.878139,
     "end_time": "2025-03-15T01:34:10.331888",
     "exception": false,
     "start_time": "2025-03-15T01:34:05.453749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA,FactorAnalysis\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e56d451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:34:10.346129Z",
     "iopub.status.busy": "2025-03-15T01:34:10.345733Z",
     "iopub.status.idle": "2025-03-15T01:34:10.349120Z",
     "shell.execute_reply": "2025-03-15T01:34:10.348487Z"
    },
    "papermill": {
     "duration": 0.011572,
     "end_time": "2025-03-15T01:34:10.350271",
     "exception": false,
     "start_time": "2025-03-15T01:34:10.338699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62f1edd5",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-03-15T01:34:10.363383Z",
     "iopub.status.busy": "2025-03-15T01:34:10.363180Z",
     "iopub.status.idle": "2025-03-15T01:34:10.368691Z",
     "shell.execute_reply": "2025-03-15T01:34:10.368081Z"
    },
    "papermill": {
     "duration": 0.013201,
     "end_time": "2025-03-15T01:34:10.369776",
     "exception": false,
     "start_time": "2025-03-15T01:34:10.356575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_targets_scored.csv',\n",
       " 'sample_submission.csv',\n",
       " 'train_drug.csv',\n",
       " 'train_targets_nonscored.csv',\n",
       " 'train_features.csv',\n",
       " 'test_features.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/lish-moa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ebdbdf7",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-03-15T01:34:10.383093Z",
     "iopub.status.busy": "2025-03-15T01:34:10.382883Z",
     "iopub.status.idle": "2025-03-15T01:34:16.572242Z",
     "shell.execute_reply": "2025-03-15T01:34:16.571282Z"
    },
    "papermill": {
     "duration": 6.197852,
     "end_time": "2025-03-15T01:34:16.573941",
     "exception": false,
     "start_time": "2025-03-15T01:34:10.376089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "sample_submission = pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54023b73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:34:16.588775Z",
     "iopub.status.busy": "2025-03-15T01:34:16.588524Z",
     "iopub.status.idle": "2025-03-15T01:34:16.593843Z",
     "shell.execute_reply": "2025-03-15T01:34:16.593009Z"
    },
    "papermill": {
     "duration": 0.013966,
     "end_time": "2025-03-15T01:34:16.595090",
     "exception": false,
     "start_time": "2025-03-15T01:34:16.581124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772 100\n"
     ]
    }
   ],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]\n",
    "print(len(GENES),len(CELLS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48b09fd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:34:16.608616Z",
     "iopub.status.busy": "2025-03-15T01:34:16.608394Z",
     "iopub.status.idle": "2025-03-15T01:34:16.611448Z",
     "shell.execute_reply": "2025-03-15T01:34:16.610771Z"
    },
    "papermill": {
     "duration": 0.011039,
     "end_time": "2025-03-15T01:34:16.612511",
     "exception": false,
     "start_time": "2025-03-15T01:34:16.601472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IS_TRAIN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72c1e529",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:34:16.626140Z",
     "iopub.status.busy": "2025-03-15T01:34:16.625906Z",
     "iopub.status.idle": "2025-03-15T01:55:47.854324Z",
     "shell.execute_reply": "2025-03-15T01:55:47.853369Z"
    },
    "papermill": {
     "duration": 1291.243697,
     "end_time": "2025-03-15T01:55:47.862721",
     "exception": false,
     "start_time": "2025-03-15T01:34:16.619024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 876)\n",
      "(3982, 876)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for col in (GENES + CELLS):\n",
    "\n",
    "  #  transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n",
    "    vec_len = len(train_features[col].values)\n",
    "    vec_len_test = len(test_features[col].values)\n",
    "    raw_vec = train_features[col].values.reshape(vec_len, 1)\n",
    "    if IS_TRAIN:\n",
    "        transformer = QuantileTransformer(n_quantiles=100, random_state=0, output_distribution=\"normal\")\n",
    "        transformer.fit(raw_vec)\n",
    "        pd.to_pickle(transformer, f'{col}_quantile_transformer.pkl')\n",
    "    else:\n",
    "        transformer = pd.read_pickle(f'{col}_quantile_transformer.pkl')        \n",
    "\n",
    "\n",
    "    train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]\n",
    "    test_train_features=np.array(train_features)\n",
    "    test_test_feature=np.array(test_features)\n",
    "print(test_train_features.shape)\n",
    "print(test_test_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d9bc6f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:55:47.876543Z",
     "iopub.status.busy": "2025-03-15T01:55:47.876295Z",
     "iopub.status.idle": "2025-03-15T01:55:47.884400Z",
     "shell.execute_reply": "2025-03-15T01:55:47.883804Z"
    },
    "papermill": {
     "duration": 0.016296,
     "end_time": "2025-03-15T01:55:47.885584",
     "exception": false,
     "start_time": "2025-03-15T01:55:47.869288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b332f9db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:55:47.900086Z",
     "iopub.status.busy": "2025-03-15T01:55:47.899708Z",
     "iopub.status.idle": "2025-03-15T01:55:54.869642Z",
     "shell.execute_reply": "2025-03-15T01:55:54.868969Z"
    },
    "papermill": {
     "duration": 6.978695,
     "end_time": "2025-03-15T01:55:54.871212",
     "exception": false,
     "start_time": "2025-03-15T01:55:47.892517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GENES\n",
    "n_comp = 90  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "#data2 = (FactorAnalysis(n_components=n_comp, random_state=42).fit_transform(data[GENES]))\n",
    "if IS_TRAIN:\n",
    "    fa = FactorAnalysis(n_components=n_comp, random_state=1903).fit(data[GENES])\n",
    "    pd.to_pickle(fa, f'factor_analysis_g.pkl')\n",
    "    #umap = UMAP(n_components=n_dim, random_state=1903).fit(data[GENES])\n",
    "    #pd.to_pickle(umap, f'{MODEL_DIR}/{NB}_umap_g.pkl')\n",
    "else:\n",
    "    fa = pd.read_pickle(f'factor_analysis_g.pkl')\n",
    "    #umap = pd.read_pickle(f'{MODEL_DIR}/{NB}_umap_g.pkl')\n",
    "data2 = fa.transform(data[GENES])\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d879700f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:55:54.886225Z",
     "iopub.status.busy": "2025-03-15T01:55:54.885981Z",
     "iopub.status.idle": "2025-03-15T01:55:56.605865Z",
     "shell.execute_reply": "2025-03-15T01:55:56.605123Z"
    },
    "papermill": {
     "duration": 1.729313,
     "end_time": "2025-03-15T01:55:56.607575",
     "exception": false,
     "start_time": "2025-03-15T01:55:54.878262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CELLS\n",
    "n_comp = 50  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "if IS_TRAIN:\n",
    "    fa = FactorAnalysis(n_components=n_comp, random_state=1903).fit(data[CELLS])\n",
    "    pd.to_pickle(fa, f'factor_analysis_c.pkl')\n",
    "    #umap = UMAP(n_components=n_dim, random_state=1903).fit(data[GENES])\n",
    "    #pd.to_pickle(umap, f'{MODEL_DIR}/{NB}_umap_g.pkl')\n",
    "else:\n",
    "    fa = pd.read_pickle(f'factor_analysis_c.pkl')\n",
    "    #umap = pd.read_pickle(f'{MODEL_DIR}/{NB}_umap_g.pkl')\n",
    "data2 = fa.transform(data[CELLS])\n",
    "#data2 = (FactorAnalysis(n_components=n_comp, random_state=42).fit_transform(data[CELLS]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdf82255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:55:56.622145Z",
     "iopub.status.busy": "2025-03-15T01:55:56.621913Z",
     "iopub.status.idle": "2025-03-15T01:55:56.626583Z",
     "shell.execute_reply": "2025-03-15T01:55:56.625783Z"
    },
    "papermill": {
     "duration": 0.012975,
     "end_time": "2025-03-15T01:55:56.627748",
     "exception": false,
     "start_time": "2025-03-15T01:55:56.614773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sig_id', 'cp_type', 'cp_time', 'cp_dose', 'g-0', 'g-1', 'g-2', 'g-3',\n",
       "       'g-4', 'g-5',\n",
       "       ...\n",
       "       'pca_C-40', 'pca_C-41', 'pca_C-42', 'pca_C-43', 'pca_C-44', 'pca_C-45',\n",
       "       'pca_C-46', 'pca_C-47', 'pca_C-48', 'pca_C-49'],\n",
       "      dtype='object', length=1016)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape\n",
    "train_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1811ff2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:55:56.641616Z",
     "iopub.status.busy": "2025-03-15T01:55:56.641385Z",
     "iopub.status.idle": "2025-03-15T01:56:03.710427Z",
     "shell.execute_reply": "2025-03-15T01:56:03.709523Z"
    },
    "papermill": {
     "duration": 7.077347,
     "end_time": "2025-03-15T01:56:03.711776",
     "exception": false,
     "start_time": "2025-03-15T01:55:56.634429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23814, 1015)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "#var_thresh = VarianceThreshold(0.8)  #<-- Update\n",
    "var_thresh = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n",
    "\n",
    "data = pd.concat([train_features, test_features], ignore_index=True)\n",
    "if IS_TRAIN:\n",
    "    transformer = QuantileTransformer(n_quantiles=100, random_state=123, output_distribution=\"normal\")\n",
    "    transformer.fit(data.iloc[:,5:])\n",
    "    pd.to_pickle(transformer, f'{col}_quantile_transformer2.pkl')\n",
    "else:\n",
    "    transformer = pd.read_pickle(f'{col}_quantile_transformer2.pkl')  \n",
    "data_transformed = transformer.transform(data.iloc[:, 5:])\n",
    "\n",
    "train_features_transformed = data_transformed[ : train_features.shape[0]]\n",
    "test_features_transformed = data_transformed[-test_features.shape[0] : ]\n",
    "\n",
    "\n",
    "train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n",
    "\n",
    "\n",
    "test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n",
    "\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83845887",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:03.726321Z",
     "iopub.status.busy": "2025-03-15T01:56:03.726069Z",
     "iopub.status.idle": "2025-03-15T01:56:03.758212Z",
     "shell.execute_reply": "2025-03-15T01:56:03.757397Z"
    },
    "papermill": {
     "duration": 0.040778,
     "end_time": "2025-03-15T01:56:03.759660",
     "exception": false,
     "start_time": "2025-03-15T01:56:03.718882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>1001</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>1007</th>\n",
       "      <th>1008</th>\n",
       "      <th>1009</th>\n",
       "      <th>1010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.890073</td>\n",
       "      <td>-0.412189</td>\n",
       "      <td>-0.944830</td>\n",
       "      <td>-0.261746</td>\n",
       "      <td>-1.019905</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564399</td>\n",
       "      <td>-0.264961</td>\n",
       "      <td>2.052781</td>\n",
       "      <td>0.725427</td>\n",
       "      <td>2.004088</td>\n",
       "      <td>-0.538631</td>\n",
       "      <td>-0.391831</td>\n",
       "      <td>0.118504</td>\n",
       "      <td>1.139026</td>\n",
       "      <td>-0.492681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.666238</td>\n",
       "      <td>0.291031</td>\n",
       "      <td>0.094330</td>\n",
       "      <td>1.230592</td>\n",
       "      <td>0.663497</td>\n",
       "      <td>0.298448</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.317965</td>\n",
       "      <td>-0.490015</td>\n",
       "      <td>0.581155</td>\n",
       "      <td>0.757636</td>\n",
       "      <td>0.642792</td>\n",
       "      <td>0.302269</td>\n",
       "      <td>0.285574</td>\n",
       "      <td>1.135923</td>\n",
       "      <td>0.514133</td>\n",
       "      <td>0.889294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.928918</td>\n",
       "      <td>1.434467</td>\n",
       "      <td>-0.107724</td>\n",
       "      <td>-0.007338</td>\n",
       "      <td>1.469665</td>\n",
       "      <td>0.224107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232821</td>\n",
       "      <td>-0.269213</td>\n",
       "      <td>-1.666802</td>\n",
       "      <td>1.578149</td>\n",
       "      <td>-0.288255</td>\n",
       "      <td>0.206113</td>\n",
       "      <td>-0.813300</td>\n",
       "      <td>0.671201</td>\n",
       "      <td>0.840813</td>\n",
       "      <td>-0.571809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.281437</td>\n",
       "      <td>-0.437950</td>\n",
       "      <td>0.769865</td>\n",
       "      <td>2.327620</td>\n",
       "      <td>-0.850179</td>\n",
       "      <td>-2.326113</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.907963</td>\n",
       "      <td>0.201992</td>\n",
       "      <td>-0.597280</td>\n",
       "      <td>0.377508</td>\n",
       "      <td>-0.195342</td>\n",
       "      <td>-0.193072</td>\n",
       "      <td>0.343032</td>\n",
       "      <td>0.159275</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.231893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.496357</td>\n",
       "      <td>0.982277</td>\n",
       "      <td>0.987313</td>\n",
       "      <td>1.487840</td>\n",
       "      <td>-0.861976</td>\n",
       "      <td>-0.388252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317295</td>\n",
       "      <td>-1.804858</td>\n",
       "      <td>0.495281</td>\n",
       "      <td>-0.030676</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-0.895828</td>\n",
       "      <td>-2.334076</td>\n",
       "      <td>-0.251194</td>\n",
       "      <td>1.490739</td>\n",
       "      <td>0.997273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.033938</td>\n",
       "      <td>-0.234157</td>\n",
       "      <td>-0.765638</td>\n",
       "      <td>-0.702918</td>\n",
       "      <td>0.894022</td>\n",
       "      <td>0.725918</td>\n",
       "      <td>...</td>\n",
       "      <td>1.291270</td>\n",
       "      <td>0.614803</td>\n",
       "      <td>0.880556</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>-0.183727</td>\n",
       "      <td>0.949953</td>\n",
       "      <td>-0.887562</td>\n",
       "      <td>-0.628253</td>\n",
       "      <td>-0.303959</td>\n",
       "      <td>-0.925261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.574460</td>\n",
       "      <td>-0.584423</td>\n",
       "      <td>1.313386</td>\n",
       "      <td>-1.009899</td>\n",
       "      <td>0.827632</td>\n",
       "      <td>-0.317398</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.232952</td>\n",
       "      <td>1.464645</td>\n",
       "      <td>0.562763</td>\n",
       "      <td>1.259711</td>\n",
       "      <td>-0.983095</td>\n",
       "      <td>1.576557</td>\n",
       "      <td>-0.832365</td>\n",
       "      <td>-0.055082</td>\n",
       "      <td>-0.990865</td>\n",
       "      <td>-1.913727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.616060</td>\n",
       "      <td>0.307320</td>\n",
       "      <td>-1.124344</td>\n",
       "      <td>0.780588</td>\n",
       "      <td>-0.018413</td>\n",
       "      <td>-0.351035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.363167</td>\n",
       "      <td>-0.569549</td>\n",
       "      <td>2.009670</td>\n",
       "      <td>1.083905</td>\n",
       "      <td>-0.939400</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>-1.168008</td>\n",
       "      <td>1.222020</td>\n",
       "      <td>-0.427585</td>\n",
       "      <td>0.688047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.404122</td>\n",
       "      <td>0.452794</td>\n",
       "      <td>0.313924</td>\n",
       "      <td>1.089796</td>\n",
       "      <td>-0.041223</td>\n",
       "      <td>0.040732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.843405</td>\n",
       "      <td>0.226004</td>\n",
       "      <td>-1.963314</td>\n",
       "      <td>-0.509632</td>\n",
       "      <td>-1.475090</td>\n",
       "      <td>-0.732285</td>\n",
       "      <td>1.396649</td>\n",
       "      <td>0.453370</td>\n",
       "      <td>0.310334</td>\n",
       "      <td>1.618901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.544298</td>\n",
       "      <td>-0.265196</td>\n",
       "      <td>1.103513</td>\n",
       "      <td>-0.527464</td>\n",
       "      <td>-2.120578</td>\n",
       "      <td>-1.619244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647490</td>\n",
       "      <td>-0.836719</td>\n",
       "      <td>-0.407389</td>\n",
       "      <td>0.130110</td>\n",
       "      <td>0.200374</td>\n",
       "      <td>-0.360941</td>\n",
       "      <td>-0.399136</td>\n",
       "      <td>0.578968</td>\n",
       "      <td>-0.431915</td>\n",
       "      <td>-0.769602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 1015 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id      cp_type cp_time cp_dose         0         1  \\\n",
       "0      id_000644bb2       trt_cp      24      D1  0.890073 -0.412189   \n",
       "1      id_000779bfc       trt_cp      72      D1  0.666238  0.291031   \n",
       "2      id_000a6266a       trt_cp      48      D1  0.928918  1.434467   \n",
       "3      id_0015fd391       trt_cp      48      D1 -0.281437 -0.437950   \n",
       "4      id_001626bd3       trt_cp      72      D2 -0.496357  0.982277   \n",
       "...             ...          ...     ...     ...       ...       ...   \n",
       "23809  id_fffb1ceed       trt_cp      24      D2 -0.033938 -0.234157   \n",
       "23810  id_fffb70c0c       trt_cp      24      D2  0.574460 -0.584423   \n",
       "23811  id_fffc1c3f4  ctl_vehicle      48      D2  0.616060  0.307320   \n",
       "23812  id_fffcb9e7c       trt_cp      24      D1  0.404122  0.452794   \n",
       "23813  id_ffffdd77b       trt_cp      72      D1  1.544298 -0.265196   \n",
       "\n",
       "              2         3         4         5  ...      1001      1002  \\\n",
       "0     -0.944830 -0.261746 -1.019905 -1.357832  ...  0.564399 -0.264961   \n",
       "1      0.094330  1.230592  0.663497  0.298448  ... -0.317965 -0.490015   \n",
       "2     -0.107724 -0.007338  1.469665  0.224107  ...  0.232821 -0.269213   \n",
       "3      0.769865  2.327620 -0.850179 -2.326113  ... -0.907963  0.201992   \n",
       "4      0.987313  1.487840 -0.861976 -0.388252  ...  0.317295 -1.804858   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "23809 -0.765638 -0.702918  0.894022  0.725918  ...  1.291270  0.614803   \n",
       "23810  1.313386 -1.009899  0.827632 -0.317398  ... -3.232952  1.464645   \n",
       "23811 -1.124344  0.780588 -0.018413 -0.351035  ... -0.363167 -0.569549   \n",
       "23812  0.313924  1.089796 -0.041223  0.040732  ... -0.843405  0.226004   \n",
       "23813  1.103513 -0.527464 -2.120578 -1.619244  ...  0.647490 -0.836719   \n",
       "\n",
       "           1003      1004      1005      1006      1007      1008      1009  \\\n",
       "0      2.052781  0.725427  2.004088 -0.538631 -0.391831  0.118504  1.139026   \n",
       "1      0.581155  0.757636  0.642792  0.302269  0.285574  1.135923  0.514133   \n",
       "2     -1.666802  1.578149 -0.288255  0.206113 -0.813300  0.671201  0.840813   \n",
       "3     -0.597280  0.377508 -0.195342 -0.193072  0.343032  0.159275  0.547945   \n",
       "4      0.495281 -0.030676 -1.087009 -0.895828 -2.334076 -0.251194  1.490739   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "23809  0.880556  0.002841 -0.183727  0.949953 -0.887562 -0.628253 -0.303959   \n",
       "23810  0.562763  1.259711 -0.983095  1.576557 -0.832365 -0.055082 -0.990865   \n",
       "23811  2.009670  1.083905 -0.939400 -0.000248 -1.168008  1.222020 -0.427585   \n",
       "23812 -1.963314 -0.509632 -1.475090 -0.732285  1.396649  0.453370  0.310334   \n",
       "23813 -0.407389  0.130110  0.200374 -0.360941 -0.399136  0.578968 -0.431915   \n",
       "\n",
       "           1010  \n",
       "0     -0.492681  \n",
       "1      0.889294  \n",
       "2     -0.571809  \n",
       "3      0.231893  \n",
       "4      0.997273  \n",
       "...         ...  \n",
       "23809 -0.925261  \n",
       "23810 -1.913727  \n",
       "23811  0.688047  \n",
       "23812  1.618901  \n",
       "23813 -0.769602  \n",
       "\n",
       "[23814 rows x 1015 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2c949ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:03.774910Z",
     "iopub.status.busy": "2025-03-15T01:56:03.774650Z",
     "iopub.status.idle": "2025-03-15T01:56:03.777636Z",
     "shell.execute_reply": "2025-03-15T01:56:03.777002Z"
    },
    "papermill": {
     "duration": 0.011887,
     "end_time": "2025-03-15T01:56:03.778924",
     "exception": false,
     "start_time": "2025-03-15T01:56:03.767037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pickle import load,dump\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "114dc6c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:03.793449Z",
     "iopub.status.busy": "2025-03-15T01:56:03.793211Z",
     "iopub.status.idle": "2025-03-15T01:56:47.654320Z",
     "shell.execute_reply": "2025-03-15T01:56:47.653334Z"
    },
    "papermill": {
     "duration": 43.870166,
     "end_time": "2025-03-15T01:56:47.656047",
     "exception": false,
     "start_time": "2025-03-15T01:56:03.785881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def fe_cluster_genes(train, test, n_clusters_g = 45, SEED = 123):\n",
    "    \n",
    "    #features_g = GENES\n",
    "    #features_c = CELLS\n",
    "    features_g = list(train.columns[4:776])\n",
    "    \n",
    "    def create_cluster(train, test, features, kind = 'g', n_clusters = n_clusters_g):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans_genes = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_genes, open('kmeans_genes.pkl', 'wb'))\n",
    "        train[f'clusters_{kind}'] = kmeans_genes.predict(train_.values)\n",
    "        test[f'clusters_{kind}'] = kmeans_genes.predict(test_.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "    train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "   # train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features ,test_features=fe_cluster_genes(train_features,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd6ce28c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:47.671424Z",
     "iopub.status.busy": "2025-03-15T01:56:47.671182Z",
     "iopub.status.idle": "2025-03-15T01:56:52.692268Z",
     "shell.execute_reply": "2025-03-15T01:56:52.691576Z"
    },
    "papermill": {
     "duration": 5.030238,
     "end_time": "2025-03-15T01:56:52.693825",
     "exception": false,
     "start_time": "2025-03-15T01:56:47.663587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_cluster_cells(train, test, n_clusters_c = 15, SEED = 123):\n",
    "    \n",
    "    #features_g = GENES\n",
    "    #features_c = CELLS\n",
    "    features_c = list(train.columns[776:876])\n",
    "\n",
    "    def create_cluster(train, test, features, kind = 'c', n_clusters = n_clusters_c):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans_cells = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_cells, open('kmeans_cells.pkl', 'wb'))\n",
    "        train[f'clusters_{kind}'] = kmeans_cells.predict(train_.values)\n",
    "        test[f'clusters_{kind}'] = kmeans_cells.predict(test_.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "   # train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "    train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features ,test_features=fe_cluster_cells(train_features,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f2866f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:52.710002Z",
     "iopub.status.busy": "2025-03-15T01:56:52.709724Z",
     "iopub.status.idle": "2025-03-15T01:56:55.481241Z",
     "shell.execute_reply": "2025-03-15T01:56:55.480144Z"
    },
    "papermill": {
     "duration": 2.781531,
     "end_time": "2025-03-15T01:56:55.483139",
     "exception": false,
     "start_time": "2025-03-15T01:56:52.701608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_stats(train, test):\n",
    "    \n",
    "    features_g = list(train.columns[4:776])\n",
    "    features_c = list(train.columns[776:876])\n",
    "    \n",
    "    for df in train, test:\n",
    "        df['g_sum'] = df[features_g].sum(axis = 1)\n",
    "        df['g_mean'] = df[features_g].mean(axis = 1)\n",
    "        df['g_std'] = df[features_g].std(axis = 1)\n",
    "        df['g_kurt'] = df[features_g].kurtosis(axis = 1)\n",
    "        df['g_skew'] = df[features_g].skew(axis = 1)\n",
    "        df['c_sum'] = df[features_c].sum(axis = 1)\n",
    "        df['c_mean'] = df[features_c].mean(axis = 1)\n",
    "        df['c_std'] = df[features_c].std(axis = 1)\n",
    "        df['c_kurt'] = df[features_c].kurtosis(axis = 1)\n",
    "        df['c_skew'] = df[features_c].skew(axis = 1)\n",
    "        df['gc_sum'] = df[features_g + features_c].sum(axis = 1)\n",
    "        df['gc_mean'] = df[features_g + features_c].mean(axis = 1)\n",
    "        df['gc_std'] = df[features_g + features_c].std(axis = 1)\n",
    "        df['gc_kurt'] = df[features_g + features_c].kurtosis(axis = 1)\n",
    "        df['gc_skew'] = df[features_g + features_c].skew(axis = 1)\n",
    "        \n",
    "    return train, test\n",
    "\n",
    "train_features,test_features=fe_stats(train_features,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26f247ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:55.498918Z",
     "iopub.status.busy": "2025-03-15T01:56:55.498627Z",
     "iopub.status.idle": "2025-03-15T01:56:55.837346Z",
     "shell.execute_reply": "2025-03-15T01:56:55.836387Z"
    },
    "papermill": {
     "duration": 0.347958,
     "end_time": "2025-03-15T01:56:55.839044",
     "exception": false,
     "start_time": "2025-03-15T01:56:55.491086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c9b725a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:55.854172Z",
     "iopub.status.busy": "2025-03-15T01:56:55.853908Z",
     "iopub.status.idle": "2025-03-15T01:56:55.911732Z",
     "shell.execute_reply": "2025-03-15T01:56:55.910693Z"
    },
    "papermill": {
     "duration": 0.067009,
     "end_time": "2025-03-15T01:56:55.913413",
     "exception": false,
     "start_time": "2025-03-15T01:56:55.846404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c627cb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:55.928629Z",
     "iopub.status.busy": "2025-03-15T01:56:55.928337Z",
     "iopub.status.idle": "2025-03-15T01:56:55.949499Z",
     "shell.execute_reply": "2025-03-15T01:56:55.948689Z"
    },
    "papermill": {
     "duration": 0.029921,
     "end_time": "2025-03-15T01:56:55.950712",
     "exception": false,
     "start_time": "2025-03-15T01:56:55.920791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.890073</td>\n",
       "      <td>-0.412189</td>\n",
       "      <td>-0.944830</td>\n",
       "      <td>-0.261746</td>\n",
       "      <td>-1.019905</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>-0.029436</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.666238</td>\n",
       "      <td>0.291031</td>\n",
       "      <td>0.094330</td>\n",
       "      <td>1.230592</td>\n",
       "      <td>0.663497</td>\n",
       "      <td>0.298448</td>\n",
       "      <td>0.570563</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.928918</td>\n",
       "      <td>1.434467</td>\n",
       "      <td>-0.107724</td>\n",
       "      <td>-0.007338</td>\n",
       "      <td>1.469665</td>\n",
       "      <td>0.224107</td>\n",
       "      <td>0.365146</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.281437</td>\n",
       "      <td>-0.437950</td>\n",
       "      <td>0.769865</td>\n",
       "      <td>2.327620</td>\n",
       "      <td>-0.850179</td>\n",
       "      <td>-2.326113</td>\n",
       "      <td>0.310265</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.496357</td>\n",
       "      <td>0.982277</td>\n",
       "      <td>0.987313</td>\n",
       "      <td>1.487840</td>\n",
       "      <td>-0.861976</td>\n",
       "      <td>-0.388252</td>\n",
       "      <td>-0.215173</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.247670</td>\n",
       "      <td>0.232367</td>\n",
       "      <td>-0.333729</td>\n",
       "      <td>-0.336437</td>\n",
       "      <td>0.544847</td>\n",
       "      <td>-0.161153</td>\n",
       "      <td>-0.261668</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.033938</td>\n",
       "      <td>-0.234157</td>\n",
       "      <td>-0.765638</td>\n",
       "      <td>-0.702918</td>\n",
       "      <td>0.894022</td>\n",
       "      <td>0.725918</td>\n",
       "      <td>0.519715</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.574460</td>\n",
       "      <td>-0.584423</td>\n",
       "      <td>1.313386</td>\n",
       "      <td>-1.009899</td>\n",
       "      <td>0.827632</td>\n",
       "      <td>-0.317398</td>\n",
       "      <td>-0.710768</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.404122</td>\n",
       "      <td>0.452794</td>\n",
       "      <td>0.313924</td>\n",
       "      <td>1.089796</td>\n",
       "      <td>-0.041223</td>\n",
       "      <td>0.040732</td>\n",
       "      <td>0.096359</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.544298</td>\n",
       "      <td>-0.265196</td>\n",
       "      <td>1.103513</td>\n",
       "      <td>-0.527464</td>\n",
       "      <td>-2.120578</td>\n",
       "      <td>-1.619244</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 1295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose         0         1         2         3  \\\n",
       "0      id_000644bb2      24      D1  0.890073 -0.412189 -0.944830 -0.261746   \n",
       "1      id_000779bfc      72      D1  0.666238  0.291031  0.094330  1.230592   \n",
       "2      id_000a6266a      48      D1  0.928918  1.434467 -0.107724 -0.007338   \n",
       "3      id_0015fd391      48      D1 -0.281437 -0.437950  0.769865  2.327620   \n",
       "4      id_001626bd3      72      D2 -0.496357  0.982277  0.987313  1.487840   \n",
       "...             ...     ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444      72      D1 -1.247670  0.232367 -0.333729 -0.336437   \n",
       "21944  id_fffb1ceed      24      D2 -0.033938 -0.234157 -0.765638 -0.702918   \n",
       "21945  id_fffb70c0c      24      D2  0.574460 -0.584423  1.313386 -1.009899   \n",
       "21946  id_fffcb9e7c      24      D1  0.404122  0.452794  0.313924  1.089796   \n",
       "21947  id_ffffdd77b      72      D1  1.544298 -0.265196  1.103513 -0.527464   \n",
       "\n",
       "              4         5         6  ...  \\\n",
       "0     -1.019905 -1.357832 -0.029436  ...   \n",
       "1      0.663497  0.298448  0.570563  ...   \n",
       "2      1.469665  0.224107  0.365146  ...   \n",
       "3     -0.850179 -2.326113  0.310265  ...   \n",
       "4     -0.861976 -0.388252 -0.215173  ...   \n",
       "...         ...       ...       ...  ...   \n",
       "21943  0.544847 -0.161153 -0.261668  ...   \n",
       "21944  0.894022  0.725918  0.519715  ...   \n",
       "21945  0.827632 -0.317398 -0.710768  ...   \n",
       "21946 -0.041223  0.040732  0.096359  ...   \n",
       "21947 -2.120578 -1.619244  1.422976  ...   \n",
       "\n",
       "       tropomyosin_receptor_kinase_inhibitor  trpv_agonist  trpv_antagonist  \\\n",
       "0                                          0             0                0   \n",
       "1                                          0             0                0   \n",
       "2                                          0             0                0   \n",
       "3                                          0             0                0   \n",
       "4                                          0             0                0   \n",
       "...                                      ...           ...              ...   \n",
       "21943                                      0             0                0   \n",
       "21944                                      0             0                0   \n",
       "21945                                      0             0                0   \n",
       "21946                                      0             0                0   \n",
       "21947                                      0             0                0   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "...                  ...                        ...   \n",
       "21943                  0                          0   \n",
       "21944                  0                          0   \n",
       "21945                  0                          0   \n",
       "21946                  0                          0   \n",
       "21947                  0                          0   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                          0                0          0   \n",
       "1                                          0                0          0   \n",
       "2                                          0                0          0   \n",
       "3                                          0                0          0   \n",
       "4                                          0                0          0   \n",
       "...                                      ...              ...        ...   \n",
       "21943                                      0                0          0   \n",
       "21944                                      0                0          0   \n",
       "21945                                      0                0          0   \n",
       "21946                                      0                0          0   \n",
       "21947                                      0                0          0   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                               0              0  \n",
       "1                               0              0  \n",
       "2                               0              0  \n",
       "3                               0              0  \n",
       "4                               0              0  \n",
       "...                           ...            ...  \n",
       "21943                           0              0  \n",
       "21944                           0              0  \n",
       "21945                           0              0  \n",
       "21946                           0              0  \n",
       "21947                           0              0  \n",
       "\n",
       "[21948 rows x 1295 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dfa8e6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:55.966138Z",
     "iopub.status.busy": "2025-03-15T01:56:55.965893Z",
     "iopub.status.idle": "2025-03-15T01:56:55.977234Z",
     "shell.execute_reply": "2025-03-15T01:56:55.976381Z"
    },
    "papermill": {
     "duration": 0.020408,
     "end_time": "2025-03-15T01:56:55.978526",
     "exception": false,
     "start_time": "2025-03-15T01:56:55.958118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2bf5886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:55.994011Z",
     "iopub.status.busy": "2025-03-15T01:56:55.993736Z",
     "iopub.status.idle": "2025-03-15T01:56:58.213451Z",
     "shell.execute_reply": "2025-03-15T01:56:58.212613Z"
    },
    "papermill": {
     "duration": 2.228676,
     "end_time": "2025-03-15T01:56:58.214741",
     "exception": false,
     "start_time": "2025-03-15T01:56:55.986065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.890073</td>\n",
       "      <td>-0.412189</td>\n",
       "      <td>-0.944830</td>\n",
       "      <td>-0.261746</td>\n",
       "      <td>-1.019905</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>-0.029436</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.666238</td>\n",
       "      <td>0.291031</td>\n",
       "      <td>0.094330</td>\n",
       "      <td>1.230592</td>\n",
       "      <td>0.663497</td>\n",
       "      <td>0.298448</td>\n",
       "      <td>0.570563</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.928918</td>\n",
       "      <td>1.434467</td>\n",
       "      <td>-0.107724</td>\n",
       "      <td>-0.007338</td>\n",
       "      <td>1.469665</td>\n",
       "      <td>0.224107</td>\n",
       "      <td>0.365146</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.281437</td>\n",
       "      <td>-0.437950</td>\n",
       "      <td>0.769865</td>\n",
       "      <td>2.327620</td>\n",
       "      <td>-0.850179</td>\n",
       "      <td>-2.326113</td>\n",
       "      <td>0.310265</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.496357</td>\n",
       "      <td>0.982277</td>\n",
       "      <td>0.987313</td>\n",
       "      <td>1.487840</td>\n",
       "      <td>-0.861976</td>\n",
       "      <td>-0.388252</td>\n",
       "      <td>-0.215173</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.247670</td>\n",
       "      <td>0.232367</td>\n",
       "      <td>-0.333729</td>\n",
       "      <td>-0.336437</td>\n",
       "      <td>0.544847</td>\n",
       "      <td>-0.161153</td>\n",
       "      <td>-0.261668</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.033938</td>\n",
       "      <td>-0.234157</td>\n",
       "      <td>-0.765638</td>\n",
       "      <td>-0.702918</td>\n",
       "      <td>0.894022</td>\n",
       "      <td>0.725918</td>\n",
       "      <td>0.519715</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.574460</td>\n",
       "      <td>-0.584423</td>\n",
       "      <td>1.313386</td>\n",
       "      <td>-1.009899</td>\n",
       "      <td>0.827632</td>\n",
       "      <td>-0.317398</td>\n",
       "      <td>-0.710768</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.404122</td>\n",
       "      <td>0.452794</td>\n",
       "      <td>0.313924</td>\n",
       "      <td>1.089796</td>\n",
       "      <td>-0.041223</td>\n",
       "      <td>0.040732</td>\n",
       "      <td>0.096359</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.544298</td>\n",
       "      <td>-0.265196</td>\n",
       "      <td>1.103513</td>\n",
       "      <td>-0.527464</td>\n",
       "      <td>-2.120578</td>\n",
       "      <td>-1.619244</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 1296 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose         0         1         2         3  \\\n",
       "0      id_000644bb2      24      D1  0.890073 -0.412189 -0.944830 -0.261746   \n",
       "1      id_000779bfc      72      D1  0.666238  0.291031  0.094330  1.230592   \n",
       "2      id_000a6266a      48      D1  0.928918  1.434467 -0.107724 -0.007338   \n",
       "3      id_0015fd391      48      D1 -0.281437 -0.437950  0.769865  2.327620   \n",
       "4      id_001626bd3      72      D2 -0.496357  0.982277  0.987313  1.487840   \n",
       "...             ...     ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444      72      D1 -1.247670  0.232367 -0.333729 -0.336437   \n",
       "21944  id_fffb1ceed      24      D2 -0.033938 -0.234157 -0.765638 -0.702918   \n",
       "21945  id_fffb70c0c      24      D2  0.574460 -0.584423  1.313386 -1.009899   \n",
       "21946  id_fffcb9e7c      24      D1  0.404122  0.452794  0.313924  1.089796   \n",
       "21947  id_ffffdd77b      72      D1  1.544298 -0.265196  1.103513 -0.527464   \n",
       "\n",
       "              4         5         6  ...  trpv_agonist  trpv_antagonist  \\\n",
       "0     -1.019905 -1.357832 -0.029436  ...             0                0   \n",
       "1      0.663497  0.298448  0.570563  ...             0                0   \n",
       "2      1.469665  0.224107  0.365146  ...             0                0   \n",
       "3     -0.850179 -2.326113  0.310265  ...             0                0   \n",
       "4     -0.861976 -0.388252 -0.215173  ...             0                0   \n",
       "...         ...       ...       ...  ...           ...              ...   \n",
       "21943  0.544847 -0.161153 -0.261668  ...             0                0   \n",
       "21944  0.894022  0.725918  0.519715  ...             0                0   \n",
       "21945  0.827632 -0.317398 -0.710768  ...             0                0   \n",
       "21946 -0.041223  0.040732  0.096359  ...             0                0   \n",
       "21947 -2.120578 -1.619244  1.422976  ...             0                0   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "...                  ...                        ...   \n",
       "21943                  0                          0   \n",
       "21944                  0                          0   \n",
       "21945                  0                          0   \n",
       "21946                  0                          0   \n",
       "21947                  0                          0   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                          0                0          0   \n",
       "1                                          0                0          0   \n",
       "2                                          0                0          0   \n",
       "3                                          0                0          0   \n",
       "4                                          0                0          0   \n",
       "...                                      ...              ...        ...   \n",
       "21943                                      0                0          0   \n",
       "21944                                      0                0          0   \n",
       "21945                                      0                0          0   \n",
       "21946                                      0                0          0   \n",
       "21947                                      0                0          0   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  kfold  \n",
       "0                               0              0      0  \n",
       "1                               0              0      2  \n",
       "2                               0              0      1  \n",
       "3                               0              0      2  \n",
       "4                               0              0      2  \n",
       "...                           ...            ...    ...  \n",
       "21943                           0              0      0  \n",
       "21944                           0              0      4  \n",
       "21945                           0              0      0  \n",
       "21946                           0              0      1  \n",
       "21947                           0              0      2  \n",
       "\n",
       "[21948 rows x 1296 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=5)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a451579a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:58.232982Z",
     "iopub.status.busy": "2025-03-15T01:56:58.232664Z",
     "iopub.status.idle": "2025-03-15T01:56:58.237968Z",
     "shell.execute_reply": "2025-03-15T01:56:58.237108Z"
    },
    "papermill": {
     "duration": 0.01562,
     "end_time": "2025-03-15T01:56:58.239336",
     "exception": false,
     "start_time": "2025-03-15T01:56:58.223716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1295)\n",
      "(21948, 1296)\n",
      "(3624, 1089)\n",
      "(21948, 207)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d53e3d",
   "metadata": {
    "papermill": {
     "duration": 0.007355,
     "end_time": "2025-03-15T01:56:58.254419",
     "exception": false,
     "start_time": "2025-03-15T01:56:58.247064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1633c87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:58.270486Z",
     "iopub.status.busy": "2025-03-15T01:56:58.270217Z",
     "iopub.status.idle": "2025-03-15T01:56:58.275761Z",
     "shell.execute_reply": "2025-03-15T01:56:58.274949Z"
    },
    "papermill": {
     "duration": 0.014987,
     "end_time": "2025-03-15T01:56:58.277043",
     "exception": false,
     "start_time": "2025-03-15T01:56:58.262056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features.astype(np.float32)\n",
    "        self.targets = targets.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26f20569",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:58.293282Z",
     "iopub.status.busy": "2025-03-15T01:56:58.293043Z",
     "iopub.status.idle": "2025-03-15T01:56:58.299376Z",
     "shell.execute_reply": "2025-03-15T01:56:58.298780Z"
    },
    "papermill": {
     "duration": 0.015677,
     "end_time": "2025-03-15T01:56:58.300560",
     "exception": false,
     "start_time": "2025-03-15T01:56:58.284883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "#         print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13941e9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:58.317273Z",
     "iopub.status.busy": "2025-03-15T01:56:58.317037Z",
     "iopub.status.idle": "2025-03-15T01:56:58.322513Z",
     "shell.execute_reply": "2025-03-15T01:56:58.321860Z"
    },
    "papermill": {
     "duration": 0.015253,
     "end_time": "2025-03-15T01:56:58.323791",
     "exception": false,
     "start_time": "2025-03-15T01:56:58.308538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4afb9e76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:58.339974Z",
     "iopub.status.busy": "2025-03-15T01:56:58.339752Z",
     "iopub.status.idle": "2025-03-15T01:56:58.344984Z",
     "shell.execute_reply": "2025-03-15T01:56:58.344157Z"
    },
    "papermill": {
     "duration": 0.014623,
     "end_time": "2025-03-15T01:56:58.346272",
     "exception": false,
     "start_time": "2025-03-15T01:56:58.331649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):      # <-- Update\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.dense2 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.leaky_relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.leaky_relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f27aedbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:58.362421Z",
     "iopub.status.busy": "2025-03-15T01:56:58.362212Z",
     "iopub.status.idle": "2025-03-15T01:56:58.365381Z",
     "shell.execute_reply": "2025-03-15T01:56:58.364763Z"
    },
    "papermill": {
     "duration": 0.012307,
     "end_time": "2025-03-15T01:56:58.366458",
     "exception": false,
     "start_time": "2025-03-15T01:56:58.354151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8105eec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:58.382679Z",
     "iopub.status.busy": "2025-03-15T01:56:58.382479Z",
     "iopub.status.idle": "2025-03-15T01:56:58.567707Z",
     "shell.execute_reply": "2025-03-15T01:56:58.566828Z"
    },
    "papermill": {
     "duration": 0.194891,
     "end_time": "2025-03-15T01:56:58.569129",
     "exception": false,
     "start_time": "2025-03-15T01:56:58.374238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1091"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e10b7229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:58.586136Z",
     "iopub.status.busy": "2025-03-15T01:56:58.585879Z",
     "iopub.status.idle": "2025-03-15T01:56:58.639416Z",
     "shell.execute_reply": "2025-03-15T01:56:58.638719Z"
    },
    "papermill": {
     "duration": 0.063229,
     "end_time": "2025-03-15T01:56:58.640659",
     "exception": false,
     "start_time": "2025-03-15T01:56:58.577430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 5e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 5            #<-- Update\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=2048\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "555afb8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:58.657876Z",
     "iopub.status.busy": "2025-03-15T01:56:58.657610Z",
     "iopub.status.idle": "2025-03-15T01:56:58.666757Z",
     "shell.execute_reply": "2025-03-15T01:56:58.666167Z"
    },
    "papermill": {
     "duration": 0.018711,
     "end_time": "2025-03-15T01:56:58.667879",
     "exception": false,
     "start_time": "2025-03-15T01:56:58.649168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-3, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"SEED: {seed} ,FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"SEED{seed}_FOLD{fold}_.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"SEED{seed}_FOLD{fold}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16137c47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:58.684922Z",
     "iopub.status.busy": "2025-03-15T01:56:58.684665Z",
     "iopub.status.idle": "2025-03-15T01:56:58.688317Z",
     "shell.execute_reply": "2025-03-15T01:56:58.687714Z"
    },
    "papermill": {
     "duration": 0.013333,
     "end_time": "2025-03-15T01:56:58.689414",
     "exception": false,
     "start_time": "2025-03-15T01:56:58.676081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db626875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T01:56:58.706127Z",
     "iopub.status.busy": "2025-03-15T01:56:58.705912Z",
     "iopub.status.idle": "2025-03-15T02:13:24.962006Z",
     "shell.execute_reply": "2025-03-15T02:13:24.961248Z"
    },
    "papermill": {
     "duration": 986.266275,
     "end_time": "2025-03-15T02:13:24.963687",
     "exception": false,
     "start_time": "2025-03-15T01:56:58.697412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 940, FOLD: 0, EPOCH: 0, train_loss: 0.4710014884940524\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 0, valid_loss: 0.023523257193820816\n",
      "SEED: 940, FOLD: 0, EPOCH: 1, train_loss: 0.023648104508933815\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 1, valid_loss: 0.018759854723300252\n",
      "SEED: 940, FOLD: 0, EPOCH: 2, train_loss: 0.02179516255315663\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 2, valid_loss: 0.017789908551744053\n",
      "SEED: 940, FOLD: 0, EPOCH: 3, train_loss: 0.02124146609634593\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 3, valid_loss: 0.01728952806442976\n",
      "SEED: 940, FOLD: 0, EPOCH: 4, train_loss: 0.02030121396039275\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017331369301038128\n",
      "SEED: 940, FOLD: 0, EPOCH: 5, train_loss: 0.02047741726256799\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 5, valid_loss: 0.01734606054212366\n",
      "SEED: 940, FOLD: 0, EPOCH: 6, train_loss: 0.02021799275678569\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017249195863093647\n",
      "SEED: 940, FOLD: 0, EPOCH: 7, train_loss: 0.020195152381084103\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017209224668996676\n",
      "SEED: 940, FOLD: 0, EPOCH: 8, train_loss: 0.020205059007782\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017046885405267987\n",
      "SEED: 940, FOLD: 0, EPOCH: 9, train_loss: 0.020156528854715652\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017288648683045593\n",
      "SEED: 940, FOLD: 0, EPOCH: 10, train_loss: 0.02015985765804847\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017093356273003988\n",
      "SEED: 940, FOLD: 0, EPOCH: 11, train_loss: 0.020036208065415638\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 11, valid_loss: 0.017144494876265525\n",
      "SEED: 940, FOLD: 0, EPOCH: 12, train_loss: 0.02002012965849776\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 12, valid_loss: 0.017129433846899442\n",
      "SEED: 940, FOLD: 0, EPOCH: 13, train_loss: 0.019997494241249733\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01688494011759758\n",
      "SEED: 940, FOLD: 0, EPOCH: 14, train_loss: 0.019686631844851418\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016970001480409076\n",
      "SEED: 940, FOLD: 0, EPOCH: 15, train_loss: 0.019552895461843498\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016695975086518697\n",
      "SEED: 940, FOLD: 0, EPOCH: 16, train_loss: 0.01937392595615508\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01656330826559237\n",
      "SEED: 940, FOLD: 0, EPOCH: 17, train_loss: 0.01913273126642773\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 17, valid_loss: 0.0164726014648165\n",
      "SEED: 940, FOLD: 0, EPOCH: 18, train_loss: 0.018799208813225447\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 18, valid_loss: 0.01628383712044784\n",
      "SEED: 940, FOLD: 0, EPOCH: 19, train_loss: 0.018353998094149258\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016158683598041533\n",
      "SEED: 940, FOLD: 0, EPOCH: 20, train_loss: 0.017840709712734257\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016155844527695862\n",
      "SEED: 940, FOLD: 0, EPOCH: 21, train_loss: 0.017311321335264307\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016029928837503704\n",
      "SEED: 940, FOLD: 0, EPOCH: 22, train_loss: 0.016730185645375994\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01604124770632812\n",
      "SEED: 940, FOLD: 0, EPOCH: 23, train_loss: 0.01627579257837024\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 23, valid_loss: 0.016050762284014905\n",
      "SEED: 940, FOLD: 0, EPOCH: 24, train_loss: 0.016037665428998676\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 24, valid_loss: 0.016109686344861984\n",
      "SEED: 940, FOLD: 1, EPOCH: 0, train_loss: 0.4722805485345315\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 0, valid_loss: 0.023859903269580433\n",
      "SEED: 940, FOLD: 1, EPOCH: 1, train_loss: 0.023601809435564537\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 1, valid_loss: 0.019166276923247745\n",
      "SEED: 940, FOLD: 1, EPOCH: 2, train_loss: 0.022171437483874783\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 2, valid_loss: 0.01907728894480637\n",
      "SEED: 940, FOLD: 1, EPOCH: 3, train_loss: 0.020802925651272137\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 3, valid_loss: 0.018096173953797135\n",
      "SEED: 940, FOLD: 1, EPOCH: 4, train_loss: 0.020207421638179516\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017584697396627495\n",
      "SEED: 940, FOLD: 1, EPOCH: 5, train_loss: 0.02018038454749014\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017488416151276658\n",
      "SEED: 940, FOLD: 1, EPOCH: 6, train_loss: 0.020226849229547424\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017244946637323923\n",
      "SEED: 940, FOLD: 1, EPOCH: 7, train_loss: 0.020186762176993965\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01707700166319098\n",
      "SEED: 940, FOLD: 1, EPOCH: 8, train_loss: 0.02023015746279903\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017502883289541516\n",
      "SEED: 940, FOLD: 1, EPOCH: 9, train_loss: 0.020188350459911686\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 9, valid_loss: 0.017091515713504382\n",
      "SEED: 940, FOLD: 1, EPOCH: 10, train_loss: 0.020140111068452614\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01731598491647414\n",
      "SEED: 940, FOLD: 1, EPOCH: 11, train_loss: 0.020078422731139522\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017123708873987196\n",
      "SEED: 940, FOLD: 1, EPOCH: 12, train_loss: 0.020087008661442043\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 12, valid_loss: 0.017119820176490715\n",
      "SEED: 940, FOLD: 1, EPOCH: 13, train_loss: 0.019902124380071957\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016915500057595116\n",
      "SEED: 940, FOLD: 1, EPOCH: 14, train_loss: 0.019746979725533638\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016750291202749526\n",
      "SEED: 940, FOLD: 1, EPOCH: 15, train_loss: 0.019577609105170635\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016646800749003886\n",
      "SEED: 940, FOLD: 1, EPOCH: 16, train_loss: 0.019383582165059837\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 16, valid_loss: 0.01661947633006743\n",
      "SEED: 940, FOLD: 1, EPOCH: 17, train_loss: 0.019076537691812584\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016547327462051595\n",
      "SEED: 940, FOLD: 1, EPOCH: 18, train_loss: 0.018755701330044994\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016293824650347233\n",
      "SEED: 940, FOLD: 1, EPOCH: 19, train_loss: 0.018384130698615227\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01626503701720919\n",
      "SEED: 940, FOLD: 1, EPOCH: 20, train_loss: 0.017866881226823814\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016128316574863025\n",
      "SEED: 940, FOLD: 1, EPOCH: 21, train_loss: 0.01727400420476561\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01606932513947998\n",
      "SEED: 940, FOLD: 1, EPOCH: 22, train_loss: 0.016712515608178102\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 22, valid_loss: 0.016000951799963203\n",
      "SEED: 940, FOLD: 1, EPOCH: 23, train_loss: 0.01626222717670211\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01603019405156374\n",
      "SEED: 940, FOLD: 1, EPOCH: 24, train_loss: 0.016077807787265898\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 24, valid_loss: 0.016008805909327097\n",
      "SEED: 940, FOLD: 2, EPOCH: 0, train_loss: 0.47011388086484396\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 0, valid_loss: 0.024073853663035803\n",
      "SEED: 940, FOLD: 2, EPOCH: 1, train_loss: 0.023823268603587498\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 1, valid_loss: 0.019071323850325176\n",
      "SEED: 940, FOLD: 2, EPOCH: 2, train_loss: 0.02181675206815851\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018496058136224746\n",
      "SEED: 940, FOLD: 2, EPOCH: 3, train_loss: 0.020838995558628136\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017617323196360044\n",
      "SEED: 940, FOLD: 2, EPOCH: 4, train_loss: 0.020350349149194317\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 4, valid_loss: 0.01722237363989864\n",
      "SEED: 940, FOLD: 2, EPOCH: 5, train_loss: 0.02030685808563578\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01729101857968739\n",
      "SEED: 940, FOLD: 2, EPOCH: 6, train_loss: 0.020238450755351696\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017177968685116087\n",
      "SEED: 940, FOLD: 2, EPOCH: 7, train_loss: 0.020158932908721592\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017422201564269407\n",
      "SEED: 940, FOLD: 2, EPOCH: 8, train_loss: 0.02020547534946514\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017215248809329103\n",
      "SEED: 940, FOLD: 2, EPOCH: 9, train_loss: 0.02019970043413881\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 9, valid_loss: 0.016991134599915574\n",
      "SEED: 940, FOLD: 2, EPOCH: 10, train_loss: 0.020099834215057934\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017279223299452237\n",
      "SEED: 940, FOLD: 2, EPOCH: 11, train_loss: 0.020101658959427605\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 11, valid_loss: 0.017453538626432417\n",
      "SEED: 940, FOLD: 2, EPOCH: 12, train_loss: 0.02012361573946217\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01711676155350038\n",
      "SEED: 940, FOLD: 2, EPOCH: 13, train_loss: 0.019886937424324562\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016847327990191324\n",
      "SEED: 940, FOLD: 2, EPOCH: 14, train_loss: 0.019754245431850784\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016925621644726822\n",
      "SEED: 940, FOLD: 2, EPOCH: 15, train_loss: 0.01955983550220296\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016659288853406905\n",
      "SEED: 940, FOLD: 2, EPOCH: 16, train_loss: 0.019322750590525677\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016562603121357305\n",
      "SEED: 940, FOLD: 2, EPOCH: 17, train_loss: 0.01906107106934423\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016565859876573087\n",
      "SEED: 940, FOLD: 2, EPOCH: 18, train_loss: 0.018792744105060894\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016465836656945093\n",
      "SEED: 940, FOLD: 2, EPOCH: 19, train_loss: 0.01836234497824225\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01630113303129162\n",
      "SEED: 940, FOLD: 2, EPOCH: 20, train_loss: 0.01791371691270151\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 20, valid_loss: 0.016126766268696104\n",
      "SEED: 940, FOLD: 2, EPOCH: 21, train_loss: 0.017422712954652052\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01608825743730579\n",
      "SEED: 940, FOLD: 2, EPOCH: 22, train_loss: 0.01690454204040377\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01598263199308089\n",
      "SEED: 940, FOLD: 2, EPOCH: 23, train_loss: 0.016470805883569563\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01603211819061211\n",
      "SEED: 940, FOLD: 2, EPOCH: 24, train_loss: 0.016262996752840885\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01604032013565302\n",
      "SEED: 940, FOLD: 3, EPOCH: 0, train_loss: 0.4705053523884735\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 0, valid_loss: 0.02497671406183924\n",
      "SEED: 940, FOLD: 3, EPOCH: 1, train_loss: 0.023680464216116547\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 1, valid_loss: 0.021801588843975747\n",
      "SEED: 940, FOLD: 3, EPOCH: 2, train_loss: 0.02202840961947821\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018272418528795242\n",
      "SEED: 940, FOLD: 3, EPOCH: 3, train_loss: 0.02090983185917139\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 3, valid_loss: 0.017675888910889625\n",
      "SEED: 940, FOLD: 3, EPOCH: 4, train_loss: 0.02023978767565627\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 4, valid_loss: 0.01756035712148462\n",
      "SEED: 940, FOLD: 3, EPOCH: 5, train_loss: 0.020182113689572914\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017260003834962845\n",
      "SEED: 940, FOLD: 3, EPOCH: 6, train_loss: 0.020078192154566448\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017447111276643616\n",
      "SEED: 940, FOLD: 3, EPOCH: 7, train_loss: 0.02019817978683589\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017188436617808684\n",
      "SEED: 940, FOLD: 3, EPOCH: 8, train_loss: 0.020114623023655968\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017838242437158314\n",
      "SEED: 940, FOLD: 3, EPOCH: 9, train_loss: 0.02008980713730705\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 9, valid_loss: 0.017477127031556197\n",
      "SEED: 940, FOLD: 3, EPOCH: 10, train_loss: 0.020104741326708725\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017366774034287248\n",
      "SEED: 940, FOLD: 3, EPOCH: 11, train_loss: 0.0200751151052722\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01720959421779428\n",
      "SEED: 940, FOLD: 3, EPOCH: 12, train_loss: 0.019961568122000797\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 12, valid_loss: 0.0170134859425681\n",
      "SEED: 940, FOLD: 3, EPOCH: 13, train_loss: 0.019782969566143078\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 13, valid_loss: 0.017340129534048693\n",
      "SEED: 940, FOLD: 3, EPOCH: 14, train_loss: 0.01965193005035753\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01688144677983863\n",
      "SEED: 940, FOLD: 3, EPOCH: 15, train_loss: 0.01942586068711851\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016802123188972472\n",
      "SEED: 940, FOLD: 3, EPOCH: 16, train_loss: 0.019214883352211422\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 16, valid_loss: 0.01669385191053152\n",
      "SEED: 940, FOLD: 3, EPOCH: 17, train_loss: 0.01894978622811428\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016474428666489464\n",
      "SEED: 940, FOLD: 3, EPOCH: 18, train_loss: 0.018648100267771795\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016436442892466274\n",
      "SEED: 940, FOLD: 3, EPOCH: 19, train_loss: 0.018204368084021236\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016350595466792583\n",
      "SEED: 940, FOLD: 3, EPOCH: 20, train_loss: 0.01765222713837157\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016237180520381245\n",
      "SEED: 940, FOLD: 3, EPOCH: 21, train_loss: 0.017043149355205074\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016243361149515426\n",
      "SEED: 940, FOLD: 3, EPOCH: 22, train_loss: 0.01643187944790807\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01620818323322705\n",
      "SEED: 940, FOLD: 3, EPOCH: 23, train_loss: 0.01602652067642497\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01621205128197159\n",
      "SEED: 940, FOLD: 3, EPOCH: 24, train_loss: 0.015792468292773632\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016242898282195842\n",
      "SEED: 940, FOLD: 4, EPOCH: 0, train_loss: 0.4698299863578185\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 0, valid_loss: 0.02314047318484102\n",
      "SEED: 940, FOLD: 4, EPOCH: 1, train_loss: 0.02364226732996927\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 1, valid_loss: 0.01894268308367048\n",
      "SEED: 940, FOLD: 4, EPOCH: 2, train_loss: 0.0219224554527065\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 2, valid_loss: 0.017981359335993017\n",
      "SEED: 940, FOLD: 4, EPOCH: 3, train_loss: 0.020859186591553516\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01766908344413553\n",
      "SEED: 940, FOLD: 4, EPOCH: 4, train_loss: 0.02026199210651111\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017231247095125062\n",
      "SEED: 940, FOLD: 4, EPOCH: 5, train_loss: 0.020262247288896553\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017403749376535417\n",
      "SEED: 940, FOLD: 4, EPOCH: 6, train_loss: 0.02011988453728997\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01723526969019856\n",
      "SEED: 940, FOLD: 4, EPOCH: 7, train_loss: 0.020143405210388744\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01722336576453277\n",
      "SEED: 940, FOLD: 4, EPOCH: 8, train_loss: 0.020093521832124046\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017009673081338404\n",
      "SEED: 940, FOLD: 4, EPOCH: 9, train_loss: 0.02012932866109886\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017023634245353084\n",
      "SEED: 940, FOLD: 4, EPOCH: 10, train_loss: 0.020099102006550285\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017018212218369758\n",
      "SEED: 940, FOLD: 4, EPOCH: 11, train_loss: 0.02006692539198675\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01712296743478094\n",
      "SEED: 940, FOLD: 4, EPOCH: 12, train_loss: 0.019875601122992626\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016870397169675144\n",
      "SEED: 940, FOLD: 4, EPOCH: 13, train_loss: 0.01982583656259205\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016889048660440106\n",
      "SEED: 940, FOLD: 4, EPOCH: 14, train_loss: 0.019726375549815704\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016921098131154264\n",
      "SEED: 940, FOLD: 4, EPOCH: 15, train_loss: 0.019544904538686726\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016671273431607656\n",
      "SEED: 940, FOLD: 4, EPOCH: 16, train_loss: 0.019372836943121925\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016475015319883823\n",
      "SEED: 940, FOLD: 4, EPOCH: 17, train_loss: 0.019046781368661617\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016407281000699315\n",
      "SEED: 940, FOLD: 4, EPOCH: 18, train_loss: 0.018726064432142437\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01629202485616718\n",
      "SEED: 940, FOLD: 4, EPOCH: 19, train_loss: 0.01831982651239504\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016154818502920016\n",
      "SEED: 940, FOLD: 4, EPOCH: 20, train_loss: 0.01784966657937005\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016044764327151434\n",
      "SEED: 940, FOLD: 4, EPOCH: 21, train_loss: 0.017305767865500588\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01594336639557566\n",
      "SEED: 940, FOLD: 4, EPOCH: 22, train_loss: 0.016737095437997927\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 22, valid_loss: 0.01596398994858776\n",
      "SEED: 940, FOLD: 4, EPOCH: 23, train_loss: 0.016284045520360054\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01591901079352413\n",
      "SEED: 940, FOLD: 4, EPOCH: 24, train_loss: 0.01602839738589482\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015916618225829942\n",
      "SEED: 1513, FOLD: 0, EPOCH: 0, train_loss: 0.4703520646696721\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 0, valid_loss: 0.02468744856970651\n",
      "SEED: 1513, FOLD: 0, EPOCH: 1, train_loss: 0.023763856027221333\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 1, valid_loss: 0.01872725510703666\n",
      "SEED: 1513, FOLD: 0, EPOCH: 2, train_loss: 0.0228827941244927\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 2, valid_loss: 0.018076472144041743\n",
      "SEED: 1513, FOLD: 0, EPOCH: 3, train_loss: 0.02106351995219787\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017333313157515868\n",
      "SEED: 1513, FOLD: 0, EPOCH: 4, train_loss: 0.020384670883093193\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017269115921642098\n",
      "SEED: 1513, FOLD: 0, EPOCH: 5, train_loss: 0.020282141283910343\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017424349885966098\n",
      "SEED: 1513, FOLD: 0, EPOCH: 6, train_loss: 0.02032620732443056\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01729874805148159\n",
      "SEED: 1513, FOLD: 0, EPOCH: 7, train_loss: 0.020258009082813194\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01731123990778412\n",
      "SEED: 1513, FOLD: 0, EPOCH: 8, train_loss: 0.020188179393501385\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01761786158063582\n",
      "SEED: 1513, FOLD: 0, EPOCH: 9, train_loss: 0.020240676508325596\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01733983143099717\n",
      "SEED: 1513, FOLD: 0, EPOCH: 10, train_loss: 0.02010371783019408\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017195072663681848\n",
      "SEED: 1513, FOLD: 0, EPOCH: 11, train_loss: 0.020085257977463196\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01720097347029618\n",
      "SEED: 1513, FOLD: 0, EPOCH: 12, train_loss: 0.020003433244815773\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01697427989648921\n",
      "SEED: 1513, FOLD: 0, EPOCH: 13, train_loss: 0.01979947380343641\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 13, valid_loss: 0.017099094577133656\n",
      "SEED: 1513, FOLD: 0, EPOCH: 14, train_loss: 0.019765281671847122\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016852353167321\n",
      "SEED: 1513, FOLD: 0, EPOCH: 15, train_loss: 0.019576745958107968\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01684199587575027\n",
      "SEED: 1513, FOLD: 0, EPOCH: 16, train_loss: 0.019385214287625706\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01656383621905531\n",
      "SEED: 1513, FOLD: 0, EPOCH: 17, train_loss: 0.019046806406391704\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016420705510037287\n",
      "SEED: 1513, FOLD: 0, EPOCH: 18, train_loss: 0.01878823494484675\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016358348141823496\n",
      "SEED: 1513, FOLD: 0, EPOCH: 19, train_loss: 0.018378736235309338\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016179548230554376\n",
      "SEED: 1513, FOLD: 0, EPOCH: 20, train_loss: 0.01785685620068208\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016112873596804484\n",
      "SEED: 1513, FOLD: 0, EPOCH: 21, train_loss: 0.017284751626784386\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015954802078860148\n",
      "SEED: 1513, FOLD: 0, EPOCH: 22, train_loss: 0.016777333749485188\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01593536428575005\n",
      "SEED: 1513, FOLD: 0, EPOCH: 23, train_loss: 0.016289474321124348\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01596553030290774\n",
      "SEED: 1513, FOLD: 0, EPOCH: 24, train_loss: 0.01606145559175723\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015951366829020635\n",
      "SEED: 1513, FOLD: 1, EPOCH: 0, train_loss: 0.47082636786111887\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 0, valid_loss: 0.02380216813513211\n",
      "SEED: 1513, FOLD: 1, EPOCH: 1, train_loss: 0.023727129510455372\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 1, valid_loss: 0.01888812759092876\n",
      "SEED: 1513, FOLD: 1, EPOCH: 2, train_loss: 0.021719961724095585\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 2, valid_loss: 0.02021299685750689\n",
      "SEED: 1513, FOLD: 1, EPOCH: 3, train_loss: 0.020711453995950844\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 3, valid_loss: 0.018538251519203186\n",
      "SEED: 1513, FOLD: 1, EPOCH: 4, train_loss: 0.02024381752193406\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017500084399112634\n",
      "SEED: 1513, FOLD: 1, EPOCH: 5, train_loss: 0.020125367206291878\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017227294562118394\n",
      "SEED: 1513, FOLD: 1, EPOCH: 6, train_loss: 0.020139929217596848\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 6, valid_loss: 0.01716949338359492\n",
      "SEED: 1513, FOLD: 1, EPOCH: 7, train_loss: 0.020091887995384743\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017350693845323156\n",
      "SEED: 1513, FOLD: 1, EPOCH: 8, train_loss: 0.020102715322180935\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017098316576864038\n",
      "SEED: 1513, FOLD: 1, EPOCH: 9, train_loss: 0.020090294502459576\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01715701368770429\n",
      "SEED: 1513, FOLD: 1, EPOCH: 10, train_loss: 0.02013549621662368\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01702342727886779\n",
      "SEED: 1513, FOLD: 1, EPOCH: 11, train_loss: 0.019986241853431515\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017065735374178204\n",
      "SEED: 1513, FOLD: 1, EPOCH: 12, train_loss: 0.019953514030878094\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 12, valid_loss: 0.017055253604693073\n",
      "SEED: 1513, FOLD: 1, EPOCH: 13, train_loss: 0.019842416358490784\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01691500996904714\n",
      "SEED: 1513, FOLD: 1, EPOCH: 14, train_loss: 0.019755971523514694\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016715731019420282\n",
      "SEED: 1513, FOLD: 1, EPOCH: 15, train_loss: 0.019537392193856445\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016568847160254207\n",
      "SEED: 1513, FOLD: 1, EPOCH: 16, train_loss: 0.019360759794928024\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016587458444493157\n",
      "SEED: 1513, FOLD: 1, EPOCH: 17, train_loss: 0.019103448298098385\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 17, valid_loss: 0.01647712194493839\n",
      "SEED: 1513, FOLD: 1, EPOCH: 18, train_loss: 0.018705150470191587\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01631604270743472\n",
      "SEED: 1513, FOLD: 1, EPOCH: 19, train_loss: 0.018325656956142706\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01620901221675532\n",
      "SEED: 1513, FOLD: 1, EPOCH: 20, train_loss: 0.017788866798028997\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016143732597785336\n",
      "SEED: 1513, FOLD: 1, EPOCH: 21, train_loss: 0.017191030247055965\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 21, valid_loss: 0.016047183477452823\n",
      "SEED: 1513, FOLD: 1, EPOCH: 22, train_loss: 0.016606460089214903\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 22, valid_loss: 0.016077075978474957\n",
      "SEED: 1513, FOLD: 1, EPOCH: 23, train_loss: 0.016171774698718302\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01606351610805307\n",
      "SEED: 1513, FOLD: 1, EPOCH: 24, train_loss: 0.015948897335624348\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 24, valid_loss: 0.016054626234940122\n",
      "SEED: 1513, FOLD: 2, EPOCH: 0, train_loss: 0.46958023585055186\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 0, valid_loss: 0.0244343103574855\n",
      "SEED: 1513, FOLD: 2, EPOCH: 1, train_loss: 0.023957832297985104\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 1, valid_loss: 0.01951797663101128\n",
      "SEED: 1513, FOLD: 2, EPOCH: 2, train_loss: 0.02183892837037211\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 2, valid_loss: 0.017851122867848193\n",
      "SEED: 1513, FOLD: 2, EPOCH: 3, train_loss: 0.020711365803752258\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017353205436042376\n",
      "SEED: 1513, FOLD: 2, EPOCH: 4, train_loss: 0.020170060850247955\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017234175971576147\n",
      "SEED: 1513, FOLD: 2, EPOCH: 5, train_loss: 0.02012510441135669\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017273364535399845\n",
      "SEED: 1513, FOLD: 2, EPOCH: 6, train_loss: 0.02016784570625295\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01718881627810853\n",
      "SEED: 1513, FOLD: 2, EPOCH: 7, train_loss: 0.020267071688304775\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017322644644549915\n",
      "SEED: 1513, FOLD: 2, EPOCH: 8, train_loss: 0.02020138557460429\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01735017259738275\n",
      "SEED: 1513, FOLD: 2, EPOCH: 9, train_loss: 0.02017199145495028\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 9, valid_loss: 0.017008180171251296\n",
      "SEED: 1513, FOLD: 2, EPOCH: 10, train_loss: 0.02010443594738625\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017104422886456763\n",
      "SEED: 1513, FOLD: 2, EPOCH: 11, train_loss: 0.020017868015861164\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 11, valid_loss: 0.017337099223264627\n",
      "SEED: 1513, FOLD: 2, EPOCH: 12, train_loss: 0.019993874392863632\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01682927901191371\n",
      "SEED: 1513, FOLD: 2, EPOCH: 13, train_loss: 0.01986033157647952\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 13, valid_loss: 0.01690915479723896\n",
      "SEED: 1513, FOLD: 2, EPOCH: 14, train_loss: 0.019744347969906918\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016721067151853015\n",
      "SEED: 1513, FOLD: 2, EPOCH: 15, train_loss: 0.019574055542656475\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016685535359595504\n",
      "SEED: 1513, FOLD: 2, EPOCH: 16, train_loss: 0.019360045969918156\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016525694036058018\n",
      "SEED: 1513, FOLD: 2, EPOCH: 17, train_loss: 0.019062562643185905\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016467339944626604\n",
      "SEED: 1513, FOLD: 2, EPOCH: 18, train_loss: 0.018749260465088097\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016297020709940366\n",
      "SEED: 1513, FOLD: 2, EPOCH: 19, train_loss: 0.018331986042144505\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016239062856350628\n",
      "SEED: 1513, FOLD: 2, EPOCH: 20, train_loss: 0.01785505869412336\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01608028837612697\n",
      "SEED: 1513, FOLD: 2, EPOCH: 21, train_loss: 0.017292863068481285\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 21, valid_loss: 0.015998178347945213\n",
      "SEED: 1513, FOLD: 2, EPOCH: 22, train_loss: 0.016714002309448046\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01596547860120024\n",
      "SEED: 1513, FOLD: 2, EPOCH: 23, train_loss: 0.016239147154155417\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015952681244484016\n",
      "SEED: 1513, FOLD: 2, EPOCH: 24, train_loss: 0.01604088868918842\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 24, valid_loss: 0.015974046502794537\n",
      "SEED: 1513, FOLD: 3, EPOCH: 0, train_loss: 0.4702085381427753\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 0, valid_loss: 0.024361002179128784\n",
      "SEED: 1513, FOLD: 3, EPOCH: 1, train_loss: 0.023700966783191845\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 1, valid_loss: 0.01974916851946286\n",
      "SEED: 1513, FOLD: 3, EPOCH: 2, train_loss: 0.021921215659898262\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 2, valid_loss: 0.01853981518319675\n",
      "SEED: 1513, FOLD: 3, EPOCH: 3, train_loss: 0.020737489860882793\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 3, valid_loss: 0.017487863823771477\n",
      "SEED: 1513, FOLD: 3, EPOCH: 4, train_loss: 0.02017549195907254\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 4, valid_loss: 0.01754270073558603\n",
      "SEED: 1513, FOLD: 3, EPOCH: 5, train_loss: 0.02008653630543014\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017342186266822473\n",
      "SEED: 1513, FOLD: 3, EPOCH: 6, train_loss: 0.020046820945065956\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017640368826687337\n",
      "SEED: 1513, FOLD: 3, EPOCH: 7, train_loss: 0.020162760927949264\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01747000954513039\n",
      "SEED: 1513, FOLD: 3, EPOCH: 8, train_loss: 0.02009718657295773\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017392355895468167\n",
      "SEED: 1513, FOLD: 3, EPOCH: 9, train_loss: 0.020137298663241276\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01717250131602798\n",
      "SEED: 1513, FOLD: 3, EPOCH: 10, train_loss: 0.02006039393228897\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017448050289281775\n",
      "SEED: 1513, FOLD: 3, EPOCH: 11, train_loss: 0.0200098504487803\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 11, valid_loss: 0.0176701051316091\n",
      "SEED: 1513, FOLD: 3, EPOCH: 12, train_loss: 0.019949316735500874\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 12, valid_loss: 0.01709080154874495\n",
      "SEED: 1513, FOLD: 3, EPOCH: 13, train_loss: 0.019850748469648155\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 13, valid_loss: 0.017168747766741686\n",
      "SEED: 1513, FOLD: 3, EPOCH: 14, train_loss: 0.0196218263303888\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01711331656468766\n",
      "SEED: 1513, FOLD: 3, EPOCH: 15, train_loss: 0.019482541856342468\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01690653719540153\n",
      "SEED: 1513, FOLD: 3, EPOCH: 16, train_loss: 0.019251171998895596\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016799530839281422\n",
      "SEED: 1513, FOLD: 3, EPOCH: 17, train_loss: 0.018969520852239668\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016926178123269763\n",
      "SEED: 1513, FOLD: 3, EPOCH: 18, train_loss: 0.018665743600307167\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 18, valid_loss: 0.01656260908182178\n",
      "SEED: 1513, FOLD: 3, EPOCH: 19, train_loss: 0.01821761580346071\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016353318893483706\n",
      "SEED: 1513, FOLD: 3, EPOCH: 20, train_loss: 0.017724287095547155\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016344075969287327\n",
      "SEED: 1513, FOLD: 3, EPOCH: 21, train_loss: 0.017129739570984806\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016226124869925636\n",
      "SEED: 1513, FOLD: 3, EPOCH: 22, train_loss: 0.01652261557435428\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01624036394059658\n",
      "SEED: 1513, FOLD: 3, EPOCH: 23, train_loss: 0.01611705104806933\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016254329468522753\n",
      "SEED: 1513, FOLD: 3, EPOCH: 24, train_loss: 0.015884977387453335\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016236722362892968\n",
      "SEED: 1513, FOLD: 4, EPOCH: 0, train_loss: 0.4705649203742328\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 0, valid_loss: 0.02504995891026088\n",
      "SEED: 1513, FOLD: 4, EPOCH: 1, train_loss: 0.0238266765423443\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 1, valid_loss: 0.0189557459205389\n",
      "SEED: 1513, FOLD: 4, EPOCH: 2, train_loss: 0.022485272621438988\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018776918681604523\n",
      "SEED: 1513, FOLD: 4, EPOCH: 3, train_loss: 0.021081524806610054\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01830321986760412\n",
      "SEED: 1513, FOLD: 4, EPOCH: 4, train_loss: 0.020568547486934975\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017632988201720375\n",
      "SEED: 1513, FOLD: 4, EPOCH: 5, train_loss: 0.02028906319722317\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 5, valid_loss: 0.018837807061416762\n",
      "SEED: 1513, FOLD: 4, EPOCH: 6, train_loss: 0.020415828914206097\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017461665852793625\n",
      "SEED: 1513, FOLD: 4, EPOCH: 7, train_loss: 0.020209871569945328\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017348332170929227\n",
      "SEED: 1513, FOLD: 4, EPOCH: 8, train_loss: 0.02031364991073159\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017273143120110034\n",
      "SEED: 1513, FOLD: 4, EPOCH: 9, train_loss: 0.020251272286733856\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 9, valid_loss: 0.01710092108696699\n",
      "SEED: 1513, FOLD: 4, EPOCH: 10, train_loss: 0.020242943495943928\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017084522758211408\n",
      "SEED: 1513, FOLD: 4, EPOCH: 11, train_loss: 0.02012933567976174\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 11, valid_loss: 0.017052598616906573\n",
      "SEED: 1513, FOLD: 4, EPOCH: 12, train_loss: 0.02006802255746679\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016953422129154204\n",
      "SEED: 1513, FOLD: 4, EPOCH: 13, train_loss: 0.01999666046459174\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01685408598610333\n",
      "SEED: 1513, FOLD: 4, EPOCH: 14, train_loss: 0.019783189088322113\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016817503635372433\n",
      "SEED: 1513, FOLD: 4, EPOCH: 15, train_loss: 0.019602840050946976\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016560345302735056\n",
      "SEED: 1513, FOLD: 4, EPOCH: 16, train_loss: 0.019444227380597073\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01654053365013429\n",
      "SEED: 1513, FOLD: 4, EPOCH: 17, train_loss: 0.01916345627303573\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016432522636439118\n",
      "SEED: 1513, FOLD: 4, EPOCH: 18, train_loss: 0.018854319090968456\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01629689397024257\n",
      "SEED: 1513, FOLD: 4, EPOCH: 19, train_loss: 0.018381132595780968\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01618473638913461\n",
      "SEED: 1513, FOLD: 4, EPOCH: 20, train_loss: 0.01798383711391817\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016098404595894473\n",
      "SEED: 1513, FOLD: 4, EPOCH: 21, train_loss: 0.017353738651381456\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 21, valid_loss: 0.016021342096584183\n",
      "SEED: 1513, FOLD: 4, EPOCH: 22, train_loss: 0.01682041264206603\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 22, valid_loss: 0.016004260443150998\n",
      "SEED: 1513, FOLD: 4, EPOCH: 23, train_loss: 0.01639097646229725\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01597626664276634\n",
      "SEED: 1513, FOLD: 4, EPOCH: 24, train_loss: 0.016116796668780888\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01598264511142458\n",
      "SEED: 1269, FOLD: 0, EPOCH: 0, train_loss: 0.47258509650988423\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 0, valid_loss: 0.0254850943173681\n",
      "SEED: 1269, FOLD: 0, EPOCH: 1, train_loss: 0.023802423917189026\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 1, valid_loss: 0.019256007352045603\n",
      "SEED: 1269, FOLD: 0, EPOCH: 2, train_loss: 0.02245258986679972\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 2, valid_loss: 0.02085249647498131\n",
      "SEED: 1269, FOLD: 0, EPOCH: 3, train_loss: 0.021760463147707607\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017582333726542335\n",
      "SEED: 1269, FOLD: 0, EPOCH: 4, train_loss: 0.020568448145860348\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 4, valid_loss: 0.01775532564414399\n",
      "SEED: 1269, FOLD: 0, EPOCH: 5, train_loss: 0.02024786757386249\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017825311954532352\n",
      "SEED: 1269, FOLD: 0, EPOCH: 6, train_loss: 0.020281252734687016\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 6, valid_loss: 0.0173838201378073\n",
      "SEED: 1269, FOLD: 0, EPOCH: 7, train_loss: 0.020252272014276707\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017396143158631666\n",
      "SEED: 1269, FOLD: 0, EPOCH: 8, train_loss: 0.020262368131374966\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01727404429444245\n",
      "SEED: 1269, FOLD: 0, EPOCH: 9, train_loss: 0.020204674493035545\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017578965558537416\n",
      "SEED: 1269, FOLD: 0, EPOCH: 10, train_loss: 0.02016360358591529\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 10, valid_loss: 0.01712294215602534\n",
      "SEED: 1269, FOLD: 0, EPOCH: 11, train_loss: 0.020101818984941296\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01745588614472321\n",
      "SEED: 1269, FOLD: 0, EPOCH: 12, train_loss: 0.020026447021982807\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 12, valid_loss: 0.017045878831829342\n",
      "SEED: 1269, FOLD: 0, EPOCH: 13, train_loss: 0.019889252759732197\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016852356387036187\n",
      "SEED: 1269, FOLD: 0, EPOCH: 14, train_loss: 0.01973396719203911\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016821962728032044\n",
      "SEED: 1269, FOLD: 0, EPOCH: 15, train_loss: 0.019576901920895645\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016673296317458154\n",
      "SEED: 1269, FOLD: 0, EPOCH: 16, train_loss: 0.019346901957971462\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016685322299599646\n",
      "SEED: 1269, FOLD: 0, EPOCH: 17, train_loss: 0.01907033355825621\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01645796000957489\n",
      "SEED: 1269, FOLD: 0, EPOCH: 18, train_loss: 0.018761231496498203\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016464684158563614\n",
      "SEED: 1269, FOLD: 0, EPOCH: 19, train_loss: 0.018410695109354412\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016273470329386846\n",
      "SEED: 1269, FOLD: 0, EPOCH: 20, train_loss: 0.017919097136220207\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016107454550053392\n",
      "SEED: 1269, FOLD: 0, EPOCH: 21, train_loss: 0.017324297014029995\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015995057273123947\n",
      "SEED: 1269, FOLD: 0, EPOCH: 22, train_loss: 0.016716822630901268\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01592772946293865\n",
      "SEED: 1269, FOLD: 0, EPOCH: 23, train_loss: 0.016308101177539513\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015903937523918492\n",
      "SEED: 1269, FOLD: 0, EPOCH: 24, train_loss: 0.016099186263222626\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015901206832911286\n",
      "SEED: 1269, FOLD: 1, EPOCH: 0, train_loss: 0.47105829498690105\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 0, valid_loss: 0.0266524360116039\n",
      "SEED: 1269, FOLD: 1, EPOCH: 1, train_loss: 0.02392630207527807\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 1, valid_loss: 0.018915835289018496\n",
      "SEED: 1269, FOLD: 1, EPOCH: 2, train_loss: 0.0218659534888423\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 2, valid_loss: 0.018303314915725163\n",
      "SEED: 1269, FOLD: 1, EPOCH: 3, train_loss: 0.020717025154094765\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 3, valid_loss: 0.017371039810989586\n",
      "SEED: 1269, FOLD: 1, EPOCH: 4, train_loss: 0.0204121892111025\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017480012827685902\n",
      "SEED: 1269, FOLD: 1, EPOCH: 5, train_loss: 0.0202234396306069\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017297110493694035\n",
      "SEED: 1269, FOLD: 1, EPOCH: 6, train_loss: 0.020242446601606796\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017393219524196216\n",
      "SEED: 1269, FOLD: 1, EPOCH: 7, train_loss: 0.020203075844092644\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017451683485082217\n",
      "SEED: 1269, FOLD: 1, EPOCH: 8, train_loss: 0.020191011423973934\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 8, valid_loss: 0.01715436838567257\n",
      "SEED: 1269, FOLD: 1, EPOCH: 9, train_loss: 0.020170280642375565\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 9, valid_loss: 0.017163172151361192\n",
      "SEED: 1269, FOLD: 1, EPOCH: 10, train_loss: 0.020108395849988945\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 10, valid_loss: 0.017247655881302698\n",
      "SEED: 1269, FOLD: 1, EPOCH: 11, train_loss: 0.020120684286930424\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017145087915871826\n",
      "SEED: 1269, FOLD: 1, EPOCH: 12, train_loss: 0.02008284527160551\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01704272712979998\n",
      "SEED: 1269, FOLD: 1, EPOCH: 13, train_loss: 0.019919039924507557\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016861397214233874\n",
      "SEED: 1269, FOLD: 1, EPOCH: 14, train_loss: 0.01975516148208492\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016916797789079802\n",
      "SEED: 1269, FOLD: 1, EPOCH: 15, train_loss: 0.01957091790340517\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01682284924068621\n",
      "SEED: 1269, FOLD: 1, EPOCH: 16, train_loss: 0.019363219795775585\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 16, valid_loss: 0.01665597789521728\n",
      "SEED: 1269, FOLD: 1, EPOCH: 17, train_loss: 0.01913200522624496\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 17, valid_loss: 0.01658847906759807\n",
      "SEED: 1269, FOLD: 1, EPOCH: 18, train_loss: 0.018833032559495474\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01637789173317807\n",
      "SEED: 1269, FOLD: 1, EPOCH: 19, train_loss: 0.01840963031745691\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016202884939100062\n",
      "SEED: 1269, FOLD: 1, EPOCH: 20, train_loss: 0.01792544176451106\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016089499395872866\n",
      "SEED: 1269, FOLD: 1, EPOCH: 21, train_loss: 0.01738209024314647\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 21, valid_loss: 0.016033451152699333\n",
      "SEED: 1269, FOLD: 1, EPOCH: 22, train_loss: 0.016866213864768328\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015969982131251267\n",
      "SEED: 1269, FOLD: 1, EPOCH: 23, train_loss: 0.016411700009273878\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 23, valid_loss: 0.016019154100545815\n",
      "SEED: 1269, FOLD: 1, EPOCH: 24, train_loss: 0.016217781041843304\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 24, valid_loss: 0.01598901783249208\n",
      "SEED: 1269, FOLD: 2, EPOCH: 0, train_loss: 0.47087701142806077\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 0, valid_loss: 0.025248308533004353\n",
      "SEED: 1269, FOLD: 2, EPOCH: 1, train_loss: 0.02371261127131141\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 1, valid_loss: 0.018945961498788425\n",
      "SEED: 1269, FOLD: 2, EPOCH: 2, train_loss: 0.022244743260460487\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 2, valid_loss: 0.04750065164906638\n",
      "SEED: 1269, FOLD: 2, EPOCH: 3, train_loss: 0.020884673759017303\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017483447013156756\n",
      "SEED: 1269, FOLD: 2, EPOCH: 4, train_loss: 0.020366607571317665\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 4, valid_loss: 0.0177231599177633\n",
      "SEED: 1269, FOLD: 2, EPOCH: 5, train_loss: 0.020209765169715534\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01733121975724186\n",
      "SEED: 1269, FOLD: 2, EPOCH: 6, train_loss: 0.020269977536214435\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017209983244538308\n",
      "SEED: 1269, FOLD: 2, EPOCH: 7, train_loss: 0.020233843246123928\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017126796740506378\n",
      "SEED: 1269, FOLD: 2, EPOCH: 8, train_loss: 0.02024662014150965\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017162848955818585\n",
      "SEED: 1269, FOLD: 2, EPOCH: 9, train_loss: 0.02020725652413524\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01714084539562464\n",
      "SEED: 1269, FOLD: 2, EPOCH: 10, train_loss: 0.020139855427154595\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017065365905208248\n",
      "SEED: 1269, FOLD: 2, EPOCH: 11, train_loss: 0.020062031224370003\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 11, valid_loss: 0.01707664430141449\n",
      "SEED: 1269, FOLD: 2, EPOCH: 12, train_loss: 0.019980123968444008\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016984039252357825\n",
      "SEED: 1269, FOLD: 2, EPOCH: 13, train_loss: 0.019892840794679047\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016974469779857566\n",
      "SEED: 1269, FOLD: 2, EPOCH: 14, train_loss: 0.019735927450592102\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016788944069828306\n",
      "SEED: 1269, FOLD: 2, EPOCH: 15, train_loss: 0.01954714346515096\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01676917334220239\n",
      "SEED: 1269, FOLD: 2, EPOCH: 16, train_loss: 0.019384065791424633\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016486896388232707\n",
      "SEED: 1269, FOLD: 2, EPOCH: 17, train_loss: 0.019080464606699737\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016456241000975882\n",
      "SEED: 1269, FOLD: 2, EPOCH: 18, train_loss: 0.018771925752145657\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016362897173634598\n",
      "SEED: 1269, FOLD: 2, EPOCH: 19, train_loss: 0.01841916664220069\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016166649412895952\n",
      "SEED: 1269, FOLD: 2, EPOCH: 20, train_loss: 0.017923872850403404\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 20, valid_loss: 0.016003540344536306\n",
      "SEED: 1269, FOLD: 2, EPOCH: 21, train_loss: 0.017339783761164417\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016036383834268364\n",
      "SEED: 1269, FOLD: 2, EPOCH: 22, train_loss: 0.01674054297146158\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 22, valid_loss: 0.016044916452041695\n",
      "SEED: 1269, FOLD: 2, EPOCH: 23, train_loss: 0.016307281397714996\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 23, valid_loss: 0.016014749902699674\n",
      "SEED: 1269, FOLD: 2, EPOCH: 24, train_loss: 0.01613865657777026\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 24, valid_loss: 0.016002334601112774\n",
      "SEED: 1269, FOLD: 3, EPOCH: 0, train_loss: 0.4719382741124086\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 0, valid_loss: 0.0256246344851596\n",
      "SEED: 1269, FOLD: 3, EPOCH: 1, train_loss: 0.02380364795849807\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 1, valid_loss: 0.022078601164477213\n",
      "SEED: 1269, FOLD: 3, EPOCH: 2, train_loss: 0.021981300367717293\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018500378515039172\n",
      "SEED: 1269, FOLD: 3, EPOCH: 3, train_loss: 0.020807369612157345\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 3, valid_loss: 0.017947907612792083\n",
      "SEED: 1269, FOLD: 3, EPOCH: 4, train_loss: 0.020368426579280174\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017434403539768287\n",
      "SEED: 1269, FOLD: 3, EPOCH: 5, train_loss: 0.02043706669971563\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 5, valid_loss: 0.01744518144322293\n",
      "SEED: 1269, FOLD: 3, EPOCH: 6, train_loss: 0.02015732795647953\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017729350472135204\n",
      "SEED: 1269, FOLD: 3, EPOCH: 7, train_loss: 0.020149793921281463\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01736321050141539\n",
      "SEED: 1269, FOLD: 3, EPOCH: 8, train_loss: 0.020177051816405594\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017286600385393414\n",
      "SEED: 1269, FOLD: 3, EPOCH: 9, train_loss: 0.02015527254105478\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 9, valid_loss: 0.017552608491054604\n",
      "SEED: 1269, FOLD: 3, EPOCH: 10, train_loss: 0.020075099556234436\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 10, valid_loss: 0.01734310926071235\n",
      "SEED: 1269, FOLD: 3, EPOCH: 11, train_loss: 0.020107028830418552\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 11, valid_loss: 0.017199876558567796\n",
      "SEED: 1269, FOLD: 3, EPOCH: 12, train_loss: 0.019911731876756832\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 12, valid_loss: 0.01713481196867568\n",
      "SEED: 1269, FOLD: 3, EPOCH: 13, train_loss: 0.019872911085469135\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01722454210477216\n",
      "SEED: 1269, FOLD: 3, EPOCH: 14, train_loss: 0.019728800119913143\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016843389134321894\n",
      "SEED: 1269, FOLD: 3, EPOCH: 15, train_loss: 0.019505016478723373\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016801390424370767\n",
      "SEED: 1269, FOLD: 3, EPOCH: 16, train_loss: 0.019310816919997982\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 16, valid_loss: 0.01667405856507165\n",
      "SEED: 1269, FOLD: 3, EPOCH: 17, train_loss: 0.01907769998913442\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01658285805689437\n",
      "SEED: 1269, FOLD: 3, EPOCH: 18, train_loss: 0.01868808770255334\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016526736691594122\n",
      "SEED: 1269, FOLD: 3, EPOCH: 19, train_loss: 0.018369786151131426\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016447135673037596\n",
      "SEED: 1269, FOLD: 3, EPOCH: 20, train_loss: 0.017843817455181175\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016301356442272662\n",
      "SEED: 1269, FOLD: 3, EPOCH: 21, train_loss: 0.017248925098312506\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016241837106645108\n",
      "SEED: 1269, FOLD: 3, EPOCH: 22, train_loss: 0.01670182589441538\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 22, valid_loss: 0.016195829665022237\n",
      "SEED: 1269, FOLD: 3, EPOCH: 23, train_loss: 0.016222563835427813\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016220374165901115\n",
      "SEED: 1269, FOLD: 3, EPOCH: 24, train_loss: 0.016029469689111345\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 24, valid_loss: 0.01623233963868448\n",
      "SEED: 1269, FOLD: 4, EPOCH: 0, train_loss: 0.4709199544015354\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 0, valid_loss: 0.024815865659288\n",
      "SEED: 1269, FOLD: 4, EPOCH: 1, train_loss: 0.023656316209530483\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 1, valid_loss: 0.018737326402749332\n",
      "SEED: 1269, FOLD: 4, EPOCH: 2, train_loss: 0.022043919001800426\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 2, valid_loss: 0.017831380612083843\n",
      "SEED: 1269, FOLD: 4, EPOCH: 3, train_loss: 0.020670009533996166\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 3, valid_loss: 0.0172396560598697\n",
      "SEED: 1269, FOLD: 4, EPOCH: 4, train_loss: 0.020797966183095738\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017337478244943277\n",
      "SEED: 1269, FOLD: 4, EPOCH: 5, train_loss: 0.020260332975590576\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017336020884769304\n",
      "SEED: 1269, FOLD: 4, EPOCH: 6, train_loss: 0.02027905925406494\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017165684460529258\n",
      "SEED: 1269, FOLD: 4, EPOCH: 7, train_loss: 0.020233859861458557\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017246934425617966\n",
      "SEED: 1269, FOLD: 4, EPOCH: 8, train_loss: 0.020198821198141228\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017123155854642393\n",
      "SEED: 1269, FOLD: 4, EPOCH: 9, train_loss: 0.020166983962922855\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017307597478585585\n",
      "SEED: 1269, FOLD: 4, EPOCH: 10, train_loss: 0.020184945598568604\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01758922774876867\n",
      "SEED: 1269, FOLD: 4, EPOCH: 11, train_loss: 0.020124276209136715\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 11, valid_loss: 0.017128145561686584\n",
      "SEED: 1269, FOLD: 4, EPOCH: 12, train_loss: 0.020011424937325974\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016943858510681562\n",
      "SEED: 1269, FOLD: 4, EPOCH: 13, train_loss: 0.0198893117165004\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016878105806452888\n",
      "SEED: 1269, FOLD: 4, EPOCH: 14, train_loss: 0.019766929856353047\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016792972279446466\n",
      "SEED: 1269, FOLD: 4, EPOCH: 15, train_loss: 0.019628452272086903\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016533624061516355\n",
      "SEED: 1269, FOLD: 4, EPOCH: 16, train_loss: 0.01939024195830891\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016667961409049376\n",
      "SEED: 1269, FOLD: 4, EPOCH: 17, train_loss: 0.019149969561376434\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01632245403847524\n",
      "SEED: 1269, FOLD: 4, EPOCH: 18, train_loss: 0.01879422444904196\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016165946663490364\n",
      "SEED: 1269, FOLD: 4, EPOCH: 19, train_loss: 0.018395666451449844\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016218596936336586\n",
      "SEED: 1269, FOLD: 4, EPOCH: 20, train_loss: 0.01792904393126567\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016013154839830738\n",
      "SEED: 1269, FOLD: 4, EPOCH: 21, train_loss: 0.017323083946130413\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01602154097386769\n",
      "SEED: 1269, FOLD: 4, EPOCH: 22, train_loss: 0.016754579008219465\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 22, valid_loss: 0.01596181783825159\n",
      "SEED: 1269, FOLD: 4, EPOCH: 23, train_loss: 0.016354711888277012\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01590621378272772\n",
      "SEED: 1269, FOLD: 4, EPOCH: 24, train_loss: 0.016088415807841913\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015948001721075602\n",
      "SEED: 1392, FOLD: 0, EPOCH: 0, train_loss: 0.46942387406538794\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 0, valid_loss: 0.0247997023165226\n",
      "SEED: 1392, FOLD: 0, EPOCH: 1, train_loss: 0.023712535469752292\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 1, valid_loss: 0.018706350401043893\n",
      "SEED: 1392, FOLD: 0, EPOCH: 2, train_loss: 0.021971328872377457\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 2, valid_loss: 0.019522871316543646\n",
      "SEED: 1392, FOLD: 0, EPOCH: 3, train_loss: 0.020938100657709267\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 3, valid_loss: 0.01849158935781036\n",
      "SEED: 1392, FOLD: 0, EPOCH: 4, train_loss: 0.020511151102465996\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017338794443224156\n",
      "SEED: 1392, FOLD: 0, EPOCH: 5, train_loss: 0.020232783832951733\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017333705377365862\n",
      "SEED: 1392, FOLD: 0, EPOCH: 6, train_loss: 0.020199156163827232\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017179516330361366\n",
      "SEED: 1392, FOLD: 0, EPOCH: 7, train_loss: 0.020158112656487072\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01718168742954731\n",
      "SEED: 1392, FOLD: 0, EPOCH: 8, train_loss: 0.020224772704144318\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017151805731867042\n",
      "SEED: 1392, FOLD: 0, EPOCH: 9, train_loss: 0.020178178473767162\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01731215888368232\n",
      "SEED: 1392, FOLD: 0, EPOCH: 10, train_loss: 0.020102438489919987\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017396489770284723\n",
      "SEED: 1392, FOLD: 0, EPOCH: 11, train_loss: 0.020062016161239666\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 11, valid_loss: 0.017381312538470542\n",
      "SEED: 1392, FOLD: 0, EPOCH: 12, train_loss: 0.020068232536963795\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 12, valid_loss: 0.017088669911026956\n",
      "SEED: 1392, FOLD: 0, EPOCH: 13, train_loss: 0.019930046497155792\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 13, valid_loss: 0.017017987689801624\n",
      "SEED: 1392, FOLD: 0, EPOCH: 14, train_loss: 0.019763131484227335\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 14, valid_loss: 0.01696788149752787\n",
      "SEED: 1392, FOLD: 0, EPOCH: 15, train_loss: 0.019589271018470543\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016748605242797306\n",
      "SEED: 1392, FOLD: 0, EPOCH: 16, train_loss: 0.0193339372323691\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 16, valid_loss: 0.0165072341848697\n",
      "SEED: 1392, FOLD: 0, EPOCH: 17, train_loss: 0.0190707352552293\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016344962348895414\n",
      "SEED: 1392, FOLD: 0, EPOCH: 18, train_loss: 0.01868629948222551\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016265436155455452\n",
      "SEED: 1392, FOLD: 0, EPOCH: 19, train_loss: 0.01824700593462457\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 19, valid_loss: 0.01610216237604618\n",
      "SEED: 1392, FOLD: 0, EPOCH: 20, train_loss: 0.017843312320663877\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01606462254588093\n",
      "SEED: 1392, FOLD: 0, EPOCH: 21, train_loss: 0.01719346489298387\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015978721289762427\n",
      "SEED: 1392, FOLD: 0, EPOCH: 22, train_loss: 0.016612887099061325\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01596632386956896\n",
      "SEED: 1392, FOLD: 0, EPOCH: 23, train_loss: 0.016181633639000895\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015997401970837797\n",
      "SEED: 1392, FOLD: 0, EPOCH: 24, train_loss: 0.0159479890126681\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015986199118196966\n",
      "SEED: 1392, FOLD: 1, EPOCH: 0, train_loss: 0.4701697213602239\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 0, valid_loss: 0.025926682938422475\n",
      "SEED: 1392, FOLD: 1, EPOCH: 1, train_loss: 0.025232990393820015\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 1, valid_loss: 0.019470704240458353\n",
      "SEED: 1392, FOLD: 1, EPOCH: 2, train_loss: 0.022190053083434486\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 2, valid_loss: 0.019648880405085428\n",
      "SEED: 1392, FOLD: 1, EPOCH: 3, train_loss: 0.02104213901296042\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 3, valid_loss: 0.017634083862815585\n",
      "SEED: 1392, FOLD: 1, EPOCH: 4, train_loss: 0.020304914550396843\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01731063521334103\n",
      "SEED: 1392, FOLD: 1, EPOCH: 5, train_loss: 0.02014064011366471\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017313043267599176\n",
      "SEED: 1392, FOLD: 1, EPOCH: 6, train_loss: 0.02016430630254141\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017352160518722876\n",
      "SEED: 1392, FOLD: 1, EPOCH: 7, train_loss: 0.02013972435362529\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01748556425528867\n",
      "SEED: 1392, FOLD: 1, EPOCH: 8, train_loss: 0.02018169103109318\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017248957630779063\n",
      "SEED: 1392, FOLD: 1, EPOCH: 9, train_loss: 0.020126144320744534\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 9, valid_loss: 0.017157618568411897\n",
      "SEED: 1392, FOLD: 1, EPOCH: 10, train_loss: 0.020155184159892193\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 10, valid_loss: 0.017342579205121313\n",
      "SEED: 1392, FOLD: 1, EPOCH: 11, train_loss: 0.020047110923822376\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017118384928575585\n",
      "SEED: 1392, FOLD: 1, EPOCH: 12, train_loss: 0.01995350254456634\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016964277252554893\n",
      "SEED: 1392, FOLD: 1, EPOCH: 13, train_loss: 0.01987562879272129\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01708402109465429\n",
      "SEED: 1392, FOLD: 1, EPOCH: 14, train_loss: 0.0197214484349757\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 14, valid_loss: 0.01691995643611465\n",
      "SEED: 1392, FOLD: 1, EPOCH: 15, train_loss: 0.019563478647150856\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016719427944294044\n",
      "SEED: 1392, FOLD: 1, EPOCH: 16, train_loss: 0.01938853582934193\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016621136904827187\n",
      "SEED: 1392, FOLD: 1, EPOCH: 17, train_loss: 0.019076726709802944\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016443537761058127\n",
      "SEED: 1392, FOLD: 1, EPOCH: 18, train_loss: 0.018689419561322185\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 18, valid_loss: 0.0164377204275557\n",
      "SEED: 1392, FOLD: 1, EPOCH: 19, train_loss: 0.018306916417635006\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016257564590445587\n",
      "SEED: 1392, FOLD: 1, EPOCH: 20, train_loss: 0.017732890754722168\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016222788340279033\n",
      "SEED: 1392, FOLD: 1, EPOCH: 21, train_loss: 0.017167330280864153\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 21, valid_loss: 0.016145097703805993\n",
      "SEED: 1392, FOLD: 1, EPOCH: 22, train_loss: 0.01660637456950718\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 22, valid_loss: 0.016085513973874706\n",
      "SEED: 1392, FOLD: 1, EPOCH: 23, train_loss: 0.016158843325262053\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01609057044344289\n",
      "SEED: 1392, FOLD: 1, EPOCH: 24, train_loss: 0.015920226819867243\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 24, valid_loss: 0.016135492974093984\n",
      "SEED: 1392, FOLD: 2, EPOCH: 0, train_loss: 0.47153712501344475\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 0, valid_loss: 0.02447243912943772\n",
      "SEED: 1392, FOLD: 2, EPOCH: 1, train_loss: 0.023683403443167175\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 1, valid_loss: 0.019311516093356268\n",
      "SEED: 1392, FOLD: 2, EPOCH: 2, train_loss: 0.021977332542124\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 2, valid_loss: 0.023091089352965354\n",
      "SEED: 1392, FOLD: 2, EPOCH: 3, train_loss: 0.0207606451180966\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017386839086455958\n",
      "SEED: 1392, FOLD: 2, EPOCH: 4, train_loss: 0.02027978551020657\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017991811116891247\n",
      "SEED: 1392, FOLD: 2, EPOCH: 5, train_loss: 0.020243752525066553\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01721400238041367\n",
      "SEED: 1392, FOLD: 2, EPOCH: 6, train_loss: 0.02017392936176148\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017364450996475562\n",
      "SEED: 1392, FOLD: 2, EPOCH: 7, train_loss: 0.020254060153619968\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01728608775883913\n",
      "SEED: 1392, FOLD: 2, EPOCH: 8, train_loss: 0.020178497957902542\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017230012480701717\n",
      "SEED: 1392, FOLD: 2, EPOCH: 9, train_loss: 0.020158645764425182\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 9, valid_loss: 0.017134514903383597\n",
      "SEED: 1392, FOLD: 2, EPOCH: 10, train_loss: 0.020156289180875687\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017236450500786305\n",
      "SEED: 1392, FOLD: 2, EPOCH: 11, train_loss: 0.020020530127204846\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 11, valid_loss: 0.0170333399570414\n",
      "SEED: 1392, FOLD: 2, EPOCH: 12, train_loss: 0.020030478366475174\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01694974529423884\n",
      "SEED: 1392, FOLD: 2, EPOCH: 13, train_loss: 0.0198745458940233\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016930629605693477\n",
      "SEED: 1392, FOLD: 2, EPOCH: 14, train_loss: 0.01975805408226839\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01682802169982876\n",
      "SEED: 1392, FOLD: 2, EPOCH: 15, train_loss: 0.019528759117035763\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01671659419579165\n",
      "SEED: 1392, FOLD: 2, EPOCH: 16, train_loss: 0.01939767493825892\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016521133854985236\n",
      "SEED: 1392, FOLD: 2, EPOCH: 17, train_loss: 0.019089676345280117\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01635557043233088\n",
      "SEED: 1392, FOLD: 2, EPOCH: 18, train_loss: 0.018741557185632595\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 18, valid_loss: 0.01635759440915925\n",
      "SEED: 1392, FOLD: 2, EPOCH: 19, train_loss: 0.018374922658330288\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016234563131417547\n",
      "SEED: 1392, FOLD: 2, EPOCH: 20, train_loss: 0.017829020035223686\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 20, valid_loss: 0.016099563666752408\n",
      "SEED: 1392, FOLD: 2, EPOCH: 21, train_loss: 0.017301270562777485\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016081297477441175\n",
      "SEED: 1392, FOLD: 2, EPOCH: 22, train_loss: 0.01674887743792024\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 22, valid_loss: 0.016026927530765532\n",
      "SEED: 1392, FOLD: 2, EPOCH: 23, train_loss: 0.016278316455798737\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015998449016894612\n",
      "SEED: 1392, FOLD: 2, EPOCH: 24, train_loss: 0.016060414460852095\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 24, valid_loss: 0.016015365560139928\n",
      "SEED: 1392, FOLD: 3, EPOCH: 0, train_loss: 0.4716439625869195\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 0, valid_loss: 0.02430701819913728\n",
      "SEED: 1392, FOLD: 3, EPOCH: 1, train_loss: 0.023921569363902443\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 1, valid_loss: 0.020037527116281647\n",
      "SEED: 1392, FOLD: 3, EPOCH: 2, train_loss: 0.02196520927321652\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 2, valid_loss: 0.019163598226649422\n",
      "SEED: 1392, FOLD: 3, EPOCH: 3, train_loss: 0.02068714609882538\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018130413203367165\n",
      "SEED: 1392, FOLD: 3, EPOCH: 4, train_loss: 0.020360600149285965\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 4, valid_loss: 0.018173612042197158\n",
      "SEED: 1392, FOLD: 3, EPOCH: 5, train_loss: 0.020071635738123154\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017644732871225904\n",
      "SEED: 1392, FOLD: 3, EPOCH: 6, train_loss: 0.020076431388008423\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01738294738211802\n",
      "SEED: 1392, FOLD: 3, EPOCH: 7, train_loss: 0.020120600022483563\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01734862213156053\n",
      "SEED: 1392, FOLD: 3, EPOCH: 8, train_loss: 0.020110263043771618\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017527581857783452\n",
      "SEED: 1392, FOLD: 3, EPOCH: 9, train_loss: 0.020111912078615547\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01733402745532138\n",
      "SEED: 1392, FOLD: 3, EPOCH: 10, train_loss: 0.020082435381693253\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 10, valid_loss: 0.01731167430324214\n",
      "SEED: 1392, FOLD: 3, EPOCH: 11, train_loss: 0.01999579849180536\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01736648662814072\n",
      "SEED: 1392, FOLD: 3, EPOCH: 12, train_loss: 0.019941652949521507\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 12, valid_loss: 0.017414820274072033\n",
      "SEED: 1392, FOLD: 3, EPOCH: 13, train_loss: 0.01990920540107333\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01706276017108134\n",
      "SEED: 1392, FOLD: 3, EPOCH: 14, train_loss: 0.01971716229952332\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016970016860536168\n",
      "SEED: 1392, FOLD: 3, EPOCH: 15, train_loss: 0.019504669459833614\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016792987952274935\n",
      "SEED: 1392, FOLD: 3, EPOCH: 16, train_loss: 0.019319595215653164\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 16, valid_loss: 0.01669974752834865\n",
      "SEED: 1392, FOLD: 3, EPOCH: 17, train_loss: 0.018980426038952843\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016519867868295738\n",
      "SEED: 1392, FOLD: 3, EPOCH: 18, train_loss: 0.01861481198474117\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016404872174773898\n",
      "SEED: 1392, FOLD: 3, EPOCH: 19, train_loss: 0.01816627165923516\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016336328057306154\n",
      "SEED: 1392, FOLD: 3, EPOCH: 20, train_loss: 0.01771473956118891\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016284660143511636\n",
      "SEED: 1392, FOLD: 3, EPOCH: 21, train_loss: 0.01710015168224556\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01624022690313203\n",
      "SEED: 1392, FOLD: 3, EPOCH: 22, train_loss: 0.016517166864882776\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01621401783611093\n",
      "SEED: 1392, FOLD: 3, EPOCH: 23, train_loss: 0.01602197803583914\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01618215409772737\n",
      "SEED: 1392, FOLD: 3, EPOCH: 24, train_loss: 0.015785701579643763\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 24, valid_loss: 0.0161674153059721\n",
      "SEED: 1392, FOLD: 4, EPOCH: 0, train_loss: 0.469678016676419\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 0, valid_loss: 0.02500185828123774\n",
      "SEED: 1392, FOLD: 4, EPOCH: 1, train_loss: 0.02424666524419318\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 1, valid_loss: 0.01940356870847089\n",
      "SEED: 1392, FOLD: 4, EPOCH: 2, train_loss: 0.021964977481874867\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018131006908203875\n",
      "SEED: 1392, FOLD: 4, EPOCH: 3, train_loss: 0.0206796210664122\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 3, valid_loss: 0.017852565087378026\n",
      "SEED: 1392, FOLD: 4, EPOCH: 4, train_loss: 0.020540897532001785\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 4, valid_loss: 0.0182838324457407\n",
      "SEED: 1392, FOLD: 4, EPOCH: 5, train_loss: 0.020344671293877174\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 5, valid_loss: 0.01735125229294811\n",
      "SEED: 1392, FOLD: 4, EPOCH: 6, train_loss: 0.02022176823052375\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017332517488726547\n",
      "SEED: 1392, FOLD: 4, EPOCH: 7, train_loss: 0.02027391253606133\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017248387315443585\n",
      "SEED: 1392, FOLD: 4, EPOCH: 8, train_loss: 0.020195322381197544\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017722255789807864\n",
      "SEED: 1392, FOLD: 4, EPOCH: 9, train_loss: 0.020123833115550056\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017459546348878315\n",
      "SEED: 1392, FOLD: 4, EPOCH: 10, train_loss: 0.02010287158191204\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017293102986046246\n",
      "SEED: 1392, FOLD: 4, EPOCH: 11, train_loss: 0.020097504936806534\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01712303228144135\n",
      "SEED: 1392, FOLD: 4, EPOCH: 12, train_loss: 0.020000452864105286\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 12, valid_loss: 0.017002197088939804\n",
      "SEED: 1392, FOLD: 4, EPOCH: 13, train_loss: 0.019934431906195656\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01692537774464914\n",
      "SEED: 1392, FOLD: 4, EPOCH: 14, train_loss: 0.019728242676111236\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016750339578304973\n",
      "SEED: 1392, FOLD: 4, EPOCH: 15, train_loss: 0.019559025346045044\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01664659128125225\n",
      "SEED: 1392, FOLD: 4, EPOCH: 16, train_loss: 0.019339618691499683\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016518595442175866\n",
      "SEED: 1392, FOLD: 4, EPOCH: 17, train_loss: 0.019135596865005253\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016483693623117038\n",
      "SEED: 1392, FOLD: 4, EPOCH: 18, train_loss: 0.01878210970376065\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016285034801278797\n",
      "SEED: 1392, FOLD: 4, EPOCH: 19, train_loss: 0.018398243286039517\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016266303243381637\n",
      "SEED: 1392, FOLD: 4, EPOCH: 20, train_loss: 0.017859465003931436\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016036989114114216\n",
      "SEED: 1392, FOLD: 4, EPOCH: 21, train_loss: 0.017353616290442322\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01596395612827369\n",
      "SEED: 1392, FOLD: 4, EPOCH: 22, train_loss: 0.016813942514683888\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015969880909792015\n",
      "SEED: 1392, FOLD: 4, EPOCH: 23, train_loss: 0.01639235282883696\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01594767903110811\n",
      "SEED: 1392, FOLD: 4, EPOCH: 24, train_loss: 0.016218154144513865\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01594510030533586\n",
      "SEED: 1119, FOLD: 0, EPOCH: 0, train_loss: 0.4713655963027175\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 0, valid_loss: 0.024336124211549758\n",
      "SEED: 1119, FOLD: 0, EPOCH: 1, train_loss: 0.023998577822593674\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 1, valid_loss: 0.0191239133477211\n",
      "SEED: 1119, FOLD: 0, EPOCH: 2, train_loss: 0.02242460189576166\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 2, valid_loss: 0.01780829724988767\n",
      "SEED: 1119, FOLD: 0, EPOCH: 3, train_loss: 0.02079627994933854\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017310584549392972\n",
      "SEED: 1119, FOLD: 0, EPOCH: 4, train_loss: 0.020245597832768723\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 4, valid_loss: 0.01913715944226299\n",
      "SEED: 1119, FOLD: 0, EPOCH: 5, train_loss: 0.020586506450089855\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017462651378342083\n",
      "SEED: 1119, FOLD: 0, EPOCH: 6, train_loss: 0.020250647706722004\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017129314983529705\n",
      "SEED: 1119, FOLD: 0, EPOCH: 7, train_loss: 0.0202227427718648\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017225769215396473\n",
      "SEED: 1119, FOLD: 0, EPOCH: 8, train_loss: 0.020196701049048832\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017204445680337292\n",
      "SEED: 1119, FOLD: 0, EPOCH: 9, train_loss: 0.02009772520809286\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017188532730298384\n",
      "SEED: 1119, FOLD: 0, EPOCH: 10, train_loss: 0.020065564432761807\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017236269584723882\n",
      "SEED: 1119, FOLD: 0, EPOCH: 11, train_loss: 0.02003265386852233\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 11, valid_loss: 0.0171557128695505\n",
      "SEED: 1119, FOLD: 0, EPOCH: 12, train_loss: 0.01998518486979647\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016820252500474454\n",
      "SEED: 1119, FOLD: 0, EPOCH: 13, train_loss: 0.01984441655593506\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 13, valid_loss: 0.017066760015274796\n",
      "SEED: 1119, FOLD: 0, EPOCH: 14, train_loss: 0.019814743754872376\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016886602475174834\n",
      "SEED: 1119, FOLD: 0, EPOCH: 15, train_loss: 0.019526509703069492\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01673820646745818\n",
      "SEED: 1119, FOLD: 0, EPOCH: 16, train_loss: 0.0193549366802841\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016542803522731575\n",
      "SEED: 1119, FOLD: 0, EPOCH: 17, train_loss: 0.0190505793966029\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016482539687837874\n",
      "SEED: 1119, FOLD: 0, EPOCH: 18, train_loss: 0.018695958734800417\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016239877151591437\n",
      "SEED: 1119, FOLD: 0, EPOCH: 19, train_loss: 0.01833286351672765\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016165376294936452\n",
      "SEED: 1119, FOLD: 0, EPOCH: 20, train_loss: 0.01784845985526192\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01606881796781506\n",
      "SEED: 1119, FOLD: 0, EPOCH: 21, train_loss: 0.01726056555070091\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016012373619845935\n",
      "SEED: 1119, FOLD: 0, EPOCH: 22, train_loss: 0.01675991831428331\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01598188347582306\n",
      "SEED: 1119, FOLD: 0, EPOCH: 23, train_loss: 0.01631528032484694\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015987266946051803\n",
      "SEED: 1119, FOLD: 0, EPOCH: 24, train_loss: 0.01610066416416911\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 24, valid_loss: 0.016012947101678165\n",
      "SEED: 1119, FOLD: 1, EPOCH: 0, train_loss: 0.47205141306841286\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 0, valid_loss: 0.023959500236170633\n",
      "SEED: 1119, FOLD: 1, EPOCH: 1, train_loss: 0.023889488905020382\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 1, valid_loss: 0.019256248697638513\n",
      "SEED: 1119, FOLD: 1, EPOCH: 2, train_loss: 0.021870399339367515\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 2, valid_loss: 0.017984679181660926\n",
      "SEED: 1119, FOLD: 1, EPOCH: 3, train_loss: 0.020680677429165528\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 3, valid_loss: 0.018087876055921825\n",
      "SEED: 1119, FOLD: 1, EPOCH: 4, train_loss: 0.020304169721793438\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01739253673170294\n",
      "SEED: 1119, FOLD: 1, EPOCH: 5, train_loss: 0.020220575003844242\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017294884632740704\n",
      "SEED: 1119, FOLD: 1, EPOCH: 6, train_loss: 0.020171055448767933\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017341016552277974\n",
      "SEED: 1119, FOLD: 1, EPOCH: 7, train_loss: 0.020161167920931526\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017220851113753658\n",
      "SEED: 1119, FOLD: 1, EPOCH: 8, train_loss: 0.02018461806996577\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017162537149020603\n",
      "SEED: 1119, FOLD: 1, EPOCH: 9, train_loss: 0.020124814473092556\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01705965982483966\n",
      "SEED: 1119, FOLD: 1, EPOCH: 10, train_loss: 0.02006966493807841\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01719182806887797\n",
      "SEED: 1119, FOLD: 1, EPOCH: 11, train_loss: 0.01998438598399145\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017096162560795033\n",
      "SEED: 1119, FOLD: 1, EPOCH: 12, train_loss: 0.01995569271831841\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 12, valid_loss: 0.017179994684244904\n",
      "SEED: 1119, FOLD: 1, EPOCH: 13, train_loss: 0.01981120130074197\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01693555103348834\n",
      "SEED: 1119, FOLD: 1, EPOCH: 14, train_loss: 0.019803829585620457\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 14, valid_loss: 0.01682909338601998\n",
      "SEED: 1119, FOLD: 1, EPOCH: 15, train_loss: 0.019561201914389065\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016679067643625395\n",
      "SEED: 1119, FOLD: 1, EPOCH: 16, train_loss: 0.019345383645723694\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016554882590259824\n",
      "SEED: 1119, FOLD: 1, EPOCH: 17, train_loss: 0.019074221317102943\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 17, valid_loss: 0.01655280818896634\n",
      "SEED: 1119, FOLD: 1, EPOCH: 18, train_loss: 0.01873957458883524\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016349789606673378\n",
      "SEED: 1119, FOLD: 1, EPOCH: 19, train_loss: 0.018343632514386074\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016288839972444943\n",
      "SEED: 1119, FOLD: 1, EPOCH: 20, train_loss: 0.01778851269973793\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016112907656601498\n",
      "SEED: 1119, FOLD: 1, EPOCH: 21, train_loss: 0.017201601169949423\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01607629914901086\n",
      "SEED: 1119, FOLD: 1, EPOCH: 22, train_loss: 0.016632575669960268\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 22, valid_loss: 0.016024423630109856\n",
      "SEED: 1119, FOLD: 1, EPOCH: 23, train_loss: 0.01623559102712982\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 23, valid_loss: 0.015999063556747777\n",
      "SEED: 1119, FOLD: 1, EPOCH: 24, train_loss: 0.0159662956358406\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 24, valid_loss: 0.016034423879214697\n",
      "SEED: 1119, FOLD: 2, EPOCH: 0, train_loss: 0.4716478960885518\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 0, valid_loss: 0.024561806714960506\n",
      "SEED: 1119, FOLD: 2, EPOCH: 1, train_loss: 0.02387316371111766\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 1, valid_loss: 0.018798206613532136\n",
      "SEED: 1119, FOLD: 2, EPOCH: 2, train_loss: 0.021847188823680946\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 2, valid_loss: 0.01776446324906179\n",
      "SEED: 1119, FOLD: 2, EPOCH: 3, train_loss: 0.020737124687951546\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017571144763912472\n",
      "SEED: 1119, FOLD: 2, EPOCH: 4, train_loss: 0.0202092037036799\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 4, valid_loss: 0.01759449200970786\n",
      "SEED: 1119, FOLD: 2, EPOCH: 5, train_loss: 0.020367861941348816\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01723378457661186\n",
      "SEED: 1119, FOLD: 2, EPOCH: 6, train_loss: 0.020213379011745903\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017569154660616603\n",
      "SEED: 1119, FOLD: 2, EPOCH: 7, train_loss: 0.020270990693698757\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017272744567266532\n",
      "SEED: 1119, FOLD: 2, EPOCH: 8, train_loss: 0.020161280314019626\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 8, valid_loss: 0.016997877401965004\n",
      "SEED: 1119, FOLD: 2, EPOCH: 9, train_loss: 0.020158735090407772\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 9, valid_loss: 0.017202036934239523\n",
      "SEED: 1119, FOLD: 2, EPOCH: 10, train_loss: 0.02012462785764449\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017082233274621623\n",
      "SEED: 1119, FOLD: 2, EPOCH: 11, train_loss: 0.020055438918264015\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 11, valid_loss: 0.01694838290235826\n",
      "SEED: 1119, FOLD: 2, EPOCH: 12, train_loss: 0.019978311020826946\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 12, valid_loss: 0.017085857157196318\n",
      "SEED: 1119, FOLD: 2, EPOCH: 13, train_loss: 0.019860567686998325\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016838518024555275\n",
      "SEED: 1119, FOLD: 2, EPOCH: 14, train_loss: 0.019774769189889015\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016814865810530526\n",
      "SEED: 1119, FOLD: 2, EPOCH: 15, train_loss: 0.01958899544147046\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016720391969595638\n",
      "SEED: 1119, FOLD: 2, EPOCH: 16, train_loss: 0.01938962917504967\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01659827000860657\n",
      "SEED: 1119, FOLD: 2, EPOCH: 17, train_loss: 0.01908964786570573\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01628708748945168\n",
      "SEED: 1119, FOLD: 2, EPOCH: 18, train_loss: 0.018733586724577606\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016379682240741593\n",
      "SEED: 1119, FOLD: 2, EPOCH: 19, train_loss: 0.01833948123174301\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016216898017695974\n",
      "SEED: 1119, FOLD: 2, EPOCH: 20, train_loss: 0.01781386952928227\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01606471072882414\n",
      "SEED: 1119, FOLD: 2, EPOCH: 21, train_loss: 0.017324694769753925\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016029742040804453\n",
      "SEED: 1119, FOLD: 2, EPOCH: 22, train_loss: 0.016778117848857157\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 22, valid_loss: 0.016005826102835793\n",
      "SEED: 1119, FOLD: 2, EPOCH: 23, train_loss: 0.016363211057108383\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015977267175912857\n",
      "SEED: 1119, FOLD: 2, EPOCH: 24, train_loss: 0.01612582723137693\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01599714673523392\n",
      "SEED: 1119, FOLD: 3, EPOCH: 0, train_loss: 0.47250433615746273\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 0, valid_loss: 0.02355631994349616\n",
      "SEED: 1119, FOLD: 3, EPOCH: 1, train_loss: 0.023820163479641727\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 1, valid_loss: 0.02453839166888169\n",
      "SEED: 1119, FOLD: 3, EPOCH: 2, train_loss: 0.025835930666737797\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018869568141443388\n",
      "SEED: 1119, FOLD: 3, EPOCH: 3, train_loss: 0.021719649515074234\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018322994719658578\n",
      "SEED: 1119, FOLD: 3, EPOCH: 4, train_loss: 0.02099154935474845\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017789063655904363\n",
      "SEED: 1119, FOLD: 3, EPOCH: 5, train_loss: 0.020456978686801765\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017604947382850306\n",
      "SEED: 1119, FOLD: 3, EPOCH: 6, train_loss: 0.020260923393610596\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017399900486426693\n",
      "SEED: 1119, FOLD: 3, EPOCH: 7, train_loss: 0.02017521507282188\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 7, valid_loss: 0.0175054967669504\n",
      "SEED: 1119, FOLD: 3, EPOCH: 8, train_loss: 0.020186148394925007\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017428003517644747\n",
      "SEED: 1119, FOLD: 3, EPOCH: 9, train_loss: 0.020074292889161818\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01746360808610916\n",
      "SEED: 1119, FOLD: 3, EPOCH: 10, train_loss: 0.019994157339459744\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017329628020524977\n",
      "SEED: 1119, FOLD: 3, EPOCH: 11, train_loss: 0.019995695816865867\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 11, valid_loss: 0.017283243872225285\n",
      "SEED: 1119, FOLD: 3, EPOCH: 12, train_loss: 0.019921950914937515\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 12, valid_loss: 0.017148993802922112\n",
      "SEED: 1119, FOLD: 3, EPOCH: 13, train_loss: 0.019792580774620823\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01691145050738539\n",
      "SEED: 1119, FOLD: 3, EPOCH: 14, train_loss: 0.019633431729955086\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 14, valid_loss: 0.017143695721668857\n",
      "SEED: 1119, FOLD: 3, EPOCH: 15, train_loss: 0.019493523620716904\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01696061340293714\n",
      "SEED: 1119, FOLD: 3, EPOCH: 16, train_loss: 0.019230247043289135\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016784120590559073\n",
      "SEED: 1119, FOLD: 3, EPOCH: 17, train_loss: 0.018893489344180493\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016703679864960057\n",
      "SEED: 1119, FOLD: 3, EPOCH: 18, train_loss: 0.01855273123668588\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016532376195703233\n",
      "SEED: 1119, FOLD: 3, EPOCH: 19, train_loss: 0.01808700496600806\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01636505989091737\n",
      "SEED: 1119, FOLD: 3, EPOCH: 20, train_loss: 0.017530081354999456\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016403999046555588\n",
      "SEED: 1119, FOLD: 3, EPOCH: 21, train_loss: 0.016776576509996168\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016425463370978832\n",
      "SEED: 1119, FOLD: 3, EPOCH: 22, train_loss: 0.01600613252705206\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 22, valid_loss: 0.016364211615707194\n",
      "SEED: 1119, FOLD: 3, EPOCH: 23, train_loss: 0.015373535784960224\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016384661623409815\n",
      "SEED: 1119, FOLD: 3, EPOCH: 24, train_loss: 0.015009263645101717\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 24, valid_loss: 0.01638758954192911\n",
      "SEED: 1119, FOLD: 4, EPOCH: 0, train_loss: 0.4716731874758135\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 0, valid_loss: 0.0238496796893222\n",
      "SEED: 1119, FOLD: 4, EPOCH: 1, train_loss: 0.023813224114153698\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 1, valid_loss: 0.018970509086336407\n",
      "SEED: 1119, FOLD: 4, EPOCH: 2, train_loss: 0.02178978520459023\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018336198159626553\n",
      "SEED: 1119, FOLD: 4, EPOCH: 3, train_loss: 0.020838231064271236\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01758421640843153\n",
      "SEED: 1119, FOLD: 4, EPOCH: 4, train_loss: 0.020339199287843876\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017160539009741373\n",
      "SEED: 1119, FOLD: 4, EPOCH: 5, train_loss: 0.02017631272420935\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 5, valid_loss: 0.020548901706933975\n",
      "SEED: 1119, FOLD: 4, EPOCH: 6, train_loss: 0.020228206881902355\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017174800272498812\n",
      "SEED: 1119, FOLD: 4, EPOCH: 7, train_loss: 0.020269620934150356\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01712471345173461\n",
      "SEED: 1119, FOLD: 4, EPOCH: 8, train_loss: 0.020211803780841656\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017068991969738687\n",
      "SEED: 1119, FOLD: 4, EPOCH: 9, train_loss: 0.020211525909278705\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017112283568297113\n",
      "SEED: 1119, FOLD: 4, EPOCH: 10, train_loss: 0.02008767724307119\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017142367362976075\n",
      "SEED: 1119, FOLD: 4, EPOCH: 11, train_loss: 0.020100020020660282\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016984944684164865\n",
      "SEED: 1119, FOLD: 4, EPOCH: 12, train_loss: 0.020038281337938446\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 12, valid_loss: 0.01691803660775934\n",
      "SEED: 1119, FOLD: 4, EPOCH: 13, train_loss: 0.019876172793084297\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016721339231090888\n",
      "SEED: 1119, FOLD: 4, EPOCH: 14, train_loss: 0.01973400304795823\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016781865965042796\n",
      "SEED: 1119, FOLD: 4, EPOCH: 15, train_loss: 0.019611186253419823\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016576508725328103\n",
      "SEED: 1119, FOLD: 4, EPOCH: 16, train_loss: 0.0193206117272485\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01665130941463368\n",
      "SEED: 1119, FOLD: 4, EPOCH: 17, train_loss: 0.019060492542558823\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016346160082944802\n",
      "SEED: 1119, FOLD: 4, EPOCH: 18, train_loss: 0.018741005991140137\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016241749562323094\n",
      "SEED: 1119, FOLD: 4, EPOCH: 19, train_loss: 0.01831172105005902\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01619055923074484\n",
      "SEED: 1119, FOLD: 4, EPOCH: 20, train_loss: 0.017790467154396618\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016058293570365225\n",
      "SEED: 1119, FOLD: 4, EPOCH: 21, train_loss: 0.017273365884371426\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 21, valid_loss: 0.015994976966508798\n",
      "SEED: 1119, FOLD: 4, EPOCH: 22, train_loss: 0.01666095414860309\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015970437814082417\n",
      "SEED: 1119, FOLD: 4, EPOCH: 23, train_loss: 0.016217945575498154\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 23, valid_loss: 0.015968531263726098\n",
      "SEED: 1119, FOLD: 4, EPOCH: 24, train_loss: 0.01599805839224786\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015991651320031712\n",
      "SEED: 1303, FOLD: 0, EPOCH: 0, train_loss: 0.4708791820710336\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 0, valid_loss: 0.02515027060040406\n",
      "SEED: 1303, FOLD: 0, EPOCH: 1, train_loss: 0.023906125039186165\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 1, valid_loss: 0.01929606827242034\n",
      "SEED: 1303, FOLD: 0, EPOCH: 2, train_loss: 0.022052054981822552\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 2, valid_loss: 0.0178522400824087\n",
      "SEED: 1303, FOLD: 0, EPOCH: 3, train_loss: 0.020921270781453106\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 3, valid_loss: 0.018255048910421984\n",
      "SEED: 1303, FOLD: 0, EPOCH: 4, train_loss: 0.020488239892259025\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017277948691376617\n",
      "SEED: 1303, FOLD: 0, EPOCH: 5, train_loss: 0.020236417246253594\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017283028098089355\n",
      "SEED: 1303, FOLD: 0, EPOCH: 6, train_loss: 0.020270676905478256\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017501249403825827\n",
      "SEED: 1303, FOLD: 0, EPOCH: 7, train_loss: 0.02024847205620313\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01719059313514403\n",
      "SEED: 1303, FOLD: 0, EPOCH: 8, train_loss: 0.020283566504392937\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01709580421447754\n",
      "SEED: 1303, FOLD: 0, EPOCH: 9, train_loss: 0.020145333722989628\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017202611932797093\n",
      "SEED: 1303, FOLD: 0, EPOCH: 10, train_loss: 0.020120620889508205\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017586828236068996\n",
      "SEED: 1303, FOLD: 0, EPOCH: 11, train_loss: 0.020134114255399807\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 11, valid_loss: 0.017713937456054346\n",
      "SEED: 1303, FOLD: 0, EPOCH: 12, train_loss: 0.02004019297875356\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 12, valid_loss: 0.017023860290646554\n",
      "SEED: 1303, FOLD: 0, EPOCH: 13, train_loss: 0.0198159779732426\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01693353522568941\n",
      "SEED: 1303, FOLD: 0, EPOCH: 14, train_loss: 0.01970715062233849\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 14, valid_loss: 0.017145804555288382\n",
      "SEED: 1303, FOLD: 0, EPOCH: 15, train_loss: 0.019666143666035023\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016739468941731114\n",
      "SEED: 1303, FOLD: 0, EPOCH: 16, train_loss: 0.01944304462792217\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01672058052250317\n",
      "SEED: 1303, FOLD: 0, EPOCH: 17, train_loss: 0.019100600239429354\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01651030456913369\n",
      "SEED: 1303, FOLD: 0, EPOCH: 18, train_loss: 0.01880927192911074\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016328301200909275\n",
      "SEED: 1303, FOLD: 0, EPOCH: 19, train_loss: 0.018412859145335962\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016172078464712414\n",
      "SEED: 1303, FOLD: 0, EPOCH: 20, train_loss: 0.01797146738196413\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016070217373115675\n",
      "SEED: 1303, FOLD: 0, EPOCH: 21, train_loss: 0.01733580025155907\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016028683818876743\n",
      "SEED: 1303, FOLD: 0, EPOCH: 22, train_loss: 0.016879707716567362\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 22, valid_loss: 0.015947839537901538\n",
      "SEED: 1303, FOLD: 0, EPOCH: 23, train_loss: 0.01643662066941244\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015943431189017636\n",
      "SEED: 1303, FOLD: 0, EPOCH: 24, train_loss: 0.016183034435886402\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01593702541930335\n",
      "SEED: 1303, FOLD: 1, EPOCH: 0, train_loss: 0.47100338212929777\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 0, valid_loss: 0.02658444158732891\n",
      "SEED: 1303, FOLD: 1, EPOCH: 1, train_loss: 0.0240245601432263\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 1, valid_loss: 0.019032628142407963\n",
      "SEED: 1303, FOLD: 1, EPOCH: 2, train_loss: 0.022276072074537693\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 2, valid_loss: 0.020226128292935235\n",
      "SEED: 1303, FOLD: 1, EPOCH: 3, train_loss: 0.021266966261833473\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 3, valid_loss: 0.018374345797513212\n",
      "SEED: 1303, FOLD: 1, EPOCH: 4, train_loss: 0.020364389241929504\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01709545323891299\n",
      "SEED: 1303, FOLD: 1, EPOCH: 5, train_loss: 0.020193492035394993\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 5, valid_loss: 0.0176870145169752\n",
      "SEED: 1303, FOLD: 1, EPOCH: 6, train_loss: 0.02031538360144781\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017280231496053084\n",
      "SEED: 1303, FOLD: 1, EPOCH: 7, train_loss: 0.02020197774729003\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017291272112301418\n",
      "SEED: 1303, FOLD: 1, EPOCH: 8, train_loss: 0.020269025819025177\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017315889868353095\n",
      "SEED: 1303, FOLD: 1, EPOCH: 9, train_loss: 0.020155434901623623\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 9, valid_loss: 0.017236238185848508\n",
      "SEED: 1303, FOLD: 1, EPOCH: 10, train_loss: 0.020153724143038624\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01699958739003965\n",
      "SEED: 1303, FOLD: 1, EPOCH: 11, train_loss: 0.020082208800359047\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017083098420075007\n",
      "SEED: 1303, FOLD: 1, EPOCH: 12, train_loss: 0.020041382291178772\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 12, valid_loss: 0.017045904456504755\n",
      "SEED: 1303, FOLD: 1, EPOCH: 13, train_loss: 0.019834665838035122\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016933647889111725\n",
      "SEED: 1303, FOLD: 1, EPOCH: 14, train_loss: 0.01978776722714521\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 14, valid_loss: 0.017189144023827145\n",
      "SEED: 1303, FOLD: 1, EPOCH: 15, train_loss: 0.019638375419637432\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016843692639044353\n",
      "SEED: 1303, FOLD: 1, EPOCH: 16, train_loss: 0.01933821312327316\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016633189097046853\n",
      "SEED: 1303, FOLD: 1, EPOCH: 17, train_loss: 0.019105923254096855\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016546862891742162\n",
      "SEED: 1303, FOLD: 1, EPOCH: 18, train_loss: 0.018837034999244454\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016443341518087046\n",
      "SEED: 1303, FOLD: 1, EPOCH: 19, train_loss: 0.018418548075293285\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016249474084803036\n",
      "SEED: 1303, FOLD: 1, EPOCH: 20, train_loss: 0.017944073426010815\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016163754835724832\n",
      "SEED: 1303, FOLD: 1, EPOCH: 21, train_loss: 0.017381089543788763\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01607709444527115\n",
      "SEED: 1303, FOLD: 1, EPOCH: 22, train_loss: 0.01677722570931782\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 22, valid_loss: 0.0160656797300492\n",
      "SEED: 1303, FOLD: 1, EPOCH: 23, train_loss: 0.01632400599402794\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 23, valid_loss: 0.016079594833510263\n",
      "SEED: 1303, FOLD: 1, EPOCH: 24, train_loss: 0.016172181646191122\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 24, valid_loss: 0.016060272817100797\n",
      "SEED: 1303, FOLD: 2, EPOCH: 0, train_loss: 0.4715842821135901\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 0, valid_loss: 0.02522821458322661\n",
      "SEED: 1303, FOLD: 2, EPOCH: 1, train_loss: 0.023670209220786026\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 1, valid_loss: 0.019123705263648715\n",
      "SEED: 1303, FOLD: 2, EPOCH: 2, train_loss: 0.022345221587929173\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018565650497164046\n",
      "SEED: 1303, FOLD: 2, EPOCH: 3, train_loss: 0.02102827129588611\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 3, valid_loss: 0.01816291556294475\n",
      "SEED: 1303, FOLD: 2, EPOCH: 4, train_loss: 0.02058965791070807\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017501131524997098\n",
      "SEED: 1303, FOLD: 2, EPOCH: 5, train_loss: 0.02034595956944901\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017367604028965745\n",
      "SEED: 1303, FOLD: 2, EPOCH: 6, train_loss: 0.020344275441290676\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01754331857498203\n",
      "SEED: 1303, FOLD: 2, EPOCH: 7, train_loss: 0.020309095122460007\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01738580497247832\n",
      "SEED: 1303, FOLD: 2, EPOCH: 8, train_loss: 0.02022826797126428\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01728823959295239\n",
      "SEED: 1303, FOLD: 2, EPOCH: 9, train_loss: 0.020169275164928124\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 9, valid_loss: 0.017104840757591385\n",
      "SEED: 1303, FOLD: 2, EPOCH: 10, train_loss: 0.02016234304755926\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017070683304752622\n",
      "SEED: 1303, FOLD: 2, EPOCH: 11, train_loss: 0.020092495568636536\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 11, valid_loss: 0.01708340176514217\n",
      "SEED: 1303, FOLD: 2, EPOCH: 12, train_loss: 0.020054829968274502\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 12, valid_loss: 0.017178064371858325\n",
      "SEED: 1303, FOLD: 2, EPOCH: 13, train_loss: 0.019943400596578915\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016805358257676872\n",
      "SEED: 1303, FOLD: 2, EPOCH: 14, train_loss: 0.01974247005916592\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016717422913227763\n",
      "SEED: 1303, FOLD: 2, EPOCH: 15, train_loss: 0.019702875244336716\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01678015302334513\n",
      "SEED: 1303, FOLD: 2, EPOCH: 16, train_loss: 0.019452484068123325\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01655340673668044\n",
      "SEED: 1303, FOLD: 2, EPOCH: 17, train_loss: 0.019101684778064922\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01646890225155013\n",
      "SEED: 1303, FOLD: 2, EPOCH: 18, train_loss: 0.018790958003829353\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 18, valid_loss: 0.01625625230371952\n",
      "SEED: 1303, FOLD: 2, EPOCH: 19, train_loss: 0.01842263461077127\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01624952866030591\n",
      "SEED: 1303, FOLD: 2, EPOCH: 20, train_loss: 0.017967696922520798\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01615268981882504\n",
      "SEED: 1303, FOLD: 2, EPOCH: 21, train_loss: 0.017430155848463375\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01604953852615186\n",
      "SEED: 1303, FOLD: 2, EPOCH: 22, train_loss: 0.016893732955382355\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 22, valid_loss: 0.015993470485721317\n",
      "SEED: 1303, FOLD: 2, EPOCH: 23, train_loss: 0.016482414650744286\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 23, valid_loss: 0.016017028795821325\n",
      "SEED: 1303, FOLD: 2, EPOCH: 24, train_loss: 0.016287566985988964\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 24, valid_loss: 0.015978606630648887\n",
      "SEED: 1303, FOLD: 3, EPOCH: 0, train_loss: 0.4726173679303864\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 0, valid_loss: 0.023593817012650627\n",
      "SEED: 1303, FOLD: 3, EPOCH: 1, train_loss: 0.024039587478382862\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 1, valid_loss: 0.01945159009524754\n",
      "SEED: 1303, FOLD: 3, EPOCH: 2, train_loss: 0.021942939474314884\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 2, valid_loss: 0.01796606427856854\n",
      "SEED: 1303, FOLD: 3, EPOCH: 3, train_loss: 0.02078614124785299\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 3, valid_loss: 0.46203175485134124\n",
      "SEED: 1303, FOLD: 3, EPOCH: 4, train_loss: 0.02477263641692158\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 4, valid_loss: 0.019200818719608444\n",
      "SEED: 1303, FOLD: 3, EPOCH: 5, train_loss: 0.021582215794942516\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 5, valid_loss: 0.018581380216138702\n",
      "SEED: 1303, FOLD: 3, EPOCH: 6, train_loss: 0.02105674586272326\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017997015161173684\n",
      "SEED: 1303, FOLD: 3, EPOCH: 7, train_loss: 0.020892543110834515\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01800112072378397\n",
      "SEED: 1303, FOLD: 3, EPOCH: 8, train_loss: 0.020684721002328224\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017748524567910602\n",
      "SEED: 1303, FOLD: 3, EPOCH: 9, train_loss: 0.020575493155722168\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 9, valid_loss: 0.0177021966448852\n",
      "SEED: 1303, FOLD: 3, EPOCH: 10, train_loss: 0.020476305290408756\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017753447432603153\n",
      "SEED: 1303, FOLD: 3, EPOCH: 11, train_loss: 0.020349153951890228\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 11, valid_loss: 0.017373201197811536\n",
      "SEED: 1303, FOLD: 3, EPOCH: 12, train_loss: 0.020264672803813995\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 12, valid_loss: 0.017482544774455683\n",
      "SEED: 1303, FOLD: 3, EPOCH: 13, train_loss: 0.02012019797457733\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 13, valid_loss: 0.017259476413684232\n",
      "SEED: 1303, FOLD: 3, EPOCH: 14, train_loss: 0.01988120916960896\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 14, valid_loss: 0.017322711353855474\n",
      "SEED: 1303, FOLD: 3, EPOCH: 15, train_loss: 0.019724434201160202\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 15, valid_loss: 0.017047627589532308\n",
      "SEED: 1303, FOLD: 3, EPOCH: 16, train_loss: 0.019530241647600265\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016993828862905503\n",
      "SEED: 1303, FOLD: 3, EPOCH: 17, train_loss: 0.019224610152667847\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016669681375580173\n",
      "SEED: 1303, FOLD: 3, EPOCH: 18, train_loss: 0.018816507799361927\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016629592276045255\n",
      "SEED: 1303, FOLD: 3, EPOCH: 19, train_loss: 0.0184712424820316\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01655218992382288\n",
      "SEED: 1303, FOLD: 3, EPOCH: 20, train_loss: 0.01790215391530723\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016446162600602422\n",
      "SEED: 1303, FOLD: 3, EPOCH: 21, train_loss: 0.017347492264124794\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01636648436209985\n",
      "SEED: 1303, FOLD: 3, EPOCH: 22, train_loss: 0.016672244842123728\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01643866359123162\n",
      "SEED: 1303, FOLD: 3, EPOCH: 23, train_loss: 0.016132686658343977\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016395281521337374\n",
      "SEED: 1303, FOLD: 3, EPOCH: 24, train_loss: 0.015870797981008673\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016404434612819128\n",
      "SEED: 1303, FOLD: 4, EPOCH: 0, train_loss: 0.471571096205625\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 0, valid_loss: 0.024673264580113548\n",
      "SEED: 1303, FOLD: 4, EPOCH: 1, train_loss: 0.023705930503058262\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 1, valid_loss: 0.019389063811727933\n",
      "SEED: 1303, FOLD: 4, EPOCH: 2, train_loss: 0.02222839146312596\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018016360407429082\n",
      "SEED: 1303, FOLD: 4, EPOCH: 3, train_loss: 0.020711967478627743\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 3, valid_loss: 0.017406313706721577\n",
      "SEED: 1303, FOLD: 4, EPOCH: 4, train_loss: 0.02043819909348436\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 4, valid_loss: 0.01754677327615874\n",
      "SEED: 1303, FOLD: 4, EPOCH: 5, train_loss: 0.02026107187882282\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 5, valid_loss: 0.01738382859953812\n",
      "SEED: 1303, FOLD: 4, EPOCH: 6, train_loss: 0.020157667754244976\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017264829017221928\n",
      "SEED: 1303, FOLD: 4, EPOCH: 7, train_loss: 0.020198332861173843\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017091812672359603\n",
      "SEED: 1303, FOLD: 4, EPOCH: 8, train_loss: 0.02024240176314893\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017627268337777682\n",
      "SEED: 1303, FOLD: 4, EPOCH: 9, train_loss: 0.02023091963559821\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017428400819855076\n",
      "SEED: 1303, FOLD: 4, EPOCH: 10, train_loss: 0.020195763855092766\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 10, valid_loss: 0.016961221237267766\n",
      "SEED: 1303, FOLD: 4, EPOCH: 11, train_loss: 0.020107479590544666\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016973201212074074\n",
      "SEED: 1303, FOLD: 4, EPOCH: 12, train_loss: 0.02010437962261663\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 12, valid_loss: 0.017092181981674264\n",
      "SEED: 1303, FOLD: 4, EPOCH: 13, train_loss: 0.01996808527442424\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01700685726744788\n",
      "SEED: 1303, FOLD: 4, EPOCH: 14, train_loss: 0.019726741910520672\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016768387917961394\n",
      "SEED: 1303, FOLD: 4, EPOCH: 15, train_loss: 0.019554465158802013\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016593036082174096\n",
      "SEED: 1303, FOLD: 4, EPOCH: 16, train_loss: 0.019375434428777382\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01668884317789759\n",
      "SEED: 1303, FOLD: 4, EPOCH: 17, train_loss: 0.01908964007768942\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01640979807291712\n",
      "SEED: 1303, FOLD: 4, EPOCH: 18, train_loss: 0.018769908723407898\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016275739669799803\n",
      "SEED: 1303, FOLD: 4, EPOCH: 19, train_loss: 0.018326786812394857\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016092551818915776\n",
      "SEED: 1303, FOLD: 4, EPOCH: 20, train_loss: 0.01788545175846936\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016025794882859504\n",
      "SEED: 1303, FOLD: 4, EPOCH: 21, train_loss: 0.017313035981108744\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01596027985215187\n",
      "SEED: 1303, FOLD: 4, EPOCH: 22, train_loss: 0.016773215387070526\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015928585374993937\n",
      "SEED: 1303, FOLD: 4, EPOCH: 23, train_loss: 0.016317868186835793\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01591321969670909\n",
      "SEED: 1303, FOLD: 4, EPOCH: 24, train_loss: 0.016128030983542187\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015913975717765944\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [940, 1513, 1269,1392,1119,1303]  #<-- Update\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1016117",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T02:13:25.047227Z",
     "iopub.status.busy": "2025-03-15T02:13:25.046753Z",
     "iopub.status.idle": "2025-03-15T02:13:25.065180Z",
     "shell.execute_reply": "2025-03-15T02:13:25.064320Z"
    },
    "papermill": {
     "duration": 0.059982,
     "end_time": "2025-03-15T02:13:25.066437",
     "exception": false,
     "start_time": "2025-03-15T02:13:25.006455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0      id_000644bb2                            0                       0   \n",
       "1      id_000779bfc                            0                       0   \n",
       "2      id_000a6266a                            0                       0   \n",
       "3      id_0015fd391                            0                       0   \n",
       "4      id_001626bd3                            0                       0   \n",
       "...             ...                          ...                     ...   \n",
       "23809  id_fffb1ceed                            0                       0   \n",
       "23810  id_fffb70c0c                            0                       0   \n",
       "23811  id_fffc1c3f4                            0                       0   \n",
       "23812  id_fffcb9e7c                            0                       0   \n",
       "23813  id_ffffdd77b                            0                       0   \n",
       "\n",
       "       acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0                   0                               0   \n",
       "1                   0                               0   \n",
       "2                   0                               0   \n",
       "3                   0                               0   \n",
       "4                   0                               0   \n",
       "...               ...                             ...   \n",
       "23809               0                               0   \n",
       "23810               0                               0   \n",
       "23811               0                               0   \n",
       "23812               0                               0   \n",
       "23813               0                               0   \n",
       "\n",
       "       acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                      0                               0   \n",
       "1                                      0                               0   \n",
       "2                                      0                               0   \n",
       "3                                      0                               0   \n",
       "4                                      0                               0   \n",
       "...                                  ...                             ...   \n",
       "23809                                  0                               0   \n",
       "23810                                  0                               0   \n",
       "23811                                  0                               0   \n",
       "23812                                  0                               0   \n",
       "23813                                  0                               0   \n",
       "\n",
       "       adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                               0                              0   \n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              0   \n",
       "4                               0                              0   \n",
       "...                           ...                            ...   \n",
       "23809                           0                              0   \n",
       "23810                           0                              0   \n",
       "23811                           0                              0   \n",
       "23812                           0                              0   \n",
       "23813                           0                              0   \n",
       "\n",
       "       adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                               0  ...                                      0   \n",
       "1                               0  ...                                      0   \n",
       "2                               0  ...                                      0   \n",
       "3                               0  ...                                      0   \n",
       "4                               0  ...                                      0   \n",
       "...                           ...  ...                                    ...   \n",
       "23809                           0  ...                                      0   \n",
       "23810                           0  ...                                      0   \n",
       "23811                           0  ...                                      0   \n",
       "23812                           0  ...                                      0   \n",
       "23813                           0  ...                                      0   \n",
       "\n",
       "       trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0                 0                0                  0   \n",
       "1                 0                0                  0   \n",
       "2                 0                0                  0   \n",
       "3                 0                0                  0   \n",
       "4                 0                0                  0   \n",
       "...             ...              ...                ...   \n",
       "23809             0                0                  0   \n",
       "23810             0                0                  0   \n",
       "23811             0                0                  0   \n",
       "23812             0                0                  0   \n",
       "23813             0                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "23809                          0                                      0   \n",
       "23810                          0                                      0   \n",
       "23811                          0                                      0   \n",
       "23812                          0                                      0   \n",
       "23813                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                    0          0                           0              0  \n",
       "1                    0          0                           0              0  \n",
       "2                    0          0                           0              0  \n",
       "3                    0          0                           0              0  \n",
       "4                    0          0                           0              0  \n",
       "...                ...        ...                         ...            ...  \n",
       "23809                0          0                           0              0  \n",
       "23810                0          0                           0              0  \n",
       "23811                0          0                           0              0  \n",
       "23812                0          0                           0              0  \n",
       "23813                0          0                           0              0  \n",
       "\n",
       "[23814 rows x 207 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59a35b7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T02:13:25.147653Z",
     "iopub.status.busy": "2025-03-15T02:13:25.147394Z",
     "iopub.status.idle": "2025-03-15T02:13:25.151859Z",
     "shell.execute_reply": "2025-03-15T02:13:25.151040Z"
    },
    "papermill": {
     "duration": 0.046251,
     "end_time": "2025-03-15T02:13:25.153026",
     "exception": false,
     "start_time": "2025-03-15T02:13:25.106775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d71c885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T02:13:25.234300Z",
     "iopub.status.busy": "2025-03-15T02:13:25.234024Z",
     "iopub.status.idle": "2025-03-15T02:13:26.453008Z",
     "shell.execute_reply": "2025-03-15T02:13:26.452262Z"
    },
    "papermill": {
     "duration": 1.261398,
     "end_time": "2025-03-15T02:13:26.454312",
     "exception": false,
     "start_time": "2025-03-15T02:13:25.192914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.01451888630601412\n"
     ]
    }
   ],
   "source": [
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8346fbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T02:13:26.535500Z",
     "iopub.status.busy": "2025-03-15T02:13:26.535251Z",
     "iopub.status.idle": "2025-03-15T02:13:27.664296Z",
     "shell.execute_reply": "2025-03-15T02:13:27.663571Z"
    },
    "papermill": {
     "duration": 1.171052,
     "end_time": "2025-03-15T02:13:27.665793",
     "exception": false,
     "start_time": "2025-03-15T02:13:26.494741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed4bbb00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T02:13:27.747609Z",
     "iopub.status.busy": "2025-03-15T02:13:27.747319Z",
     "iopub.status.idle": "2025-03-15T02:13:27.751910Z",
     "shell.execute_reply": "2025-03-15T02:13:27.751204Z"
    },
    "papermill": {
     "duration": 0.046296,
     "end_time": "2025-03-15T02:13:27.753035",
     "exception": false,
     "start_time": "2025-03-15T02:13:27.706739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3982, 207)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d55cbd",
   "metadata": {
    "papermill": {
     "duration": 0.040104,
     "end_time": "2025-03-15T02:13:27.833191",
     "exception": false,
     "start_time": "2025-03-15T02:13:27.793087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1651354,
     "sourceId": 19988,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "duration": 2372.680908,
   "end_time": "2025-03-15T02:13:29.999352",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-15T01:33:57.318444",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
