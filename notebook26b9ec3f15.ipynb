{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f91c6c34",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-15T04:30:22.970548Z",
     "iopub.status.busy": "2025-03-15T04:30:22.970346Z",
     "iopub.status.idle": "2025-03-15T04:30:28.364028Z",
     "shell.execute_reply": "2025-03-15T04:30:28.363275Z"
    },
    "papermill": {
     "duration": 5.402648,
     "end_time": "2025-03-15T04:30:28.365513",
     "exception": false,
     "start_time": "2025-03-15T04:30:22.962865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/iterative-stratification/iterative_stratification-0.1.9-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from iterative-stratification==0.1.9) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from iterative-stratification==0.1.9) (1.13.1)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from iterative-stratification==0.1.9) (1.2.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->iterative-stratification==0.1.9) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->iterative-stratification==0.1.9) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->iterative-stratification==0.1.9) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->iterative-stratification==0.1.9) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->iterative-stratification==0.1.9) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->iterative-stratification==0.1.9) (2.4.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->iterative-stratification==0.1.9) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->iterative-stratification==0.1.9) (3.5.0)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->iterative-stratification==0.1.9) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->iterative-stratification==0.1.9) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->iterative-stratification==0.1.9) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->iterative-stratification==0.1.9) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->iterative-stratification==0.1.9) (2024.2.0)\r\n",
      "Installing collected packages: iterative-stratification\r\n",
      "Successfully installed iterative-stratification-0.1.9\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#sys.path.append('../input/iterativestratification')\n",
    "#!pip install iterative-stratification\n",
    "#!pip download iterative-stratification -d ./package\n",
    "!pip install /kaggle/input/iterative-stratification/iterative_stratification-0.1.9-py3-none-any.whl\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5790f33d",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2025-03-15T04:30:28.380088Z",
     "iopub.status.busy": "2025-03-15T04:30:28.379775Z",
     "iopub.status.idle": "2025-03-15T04:30:32.806728Z",
     "shell.execute_reply": "2025-03-15T04:30:32.805954Z"
    },
    "papermill": {
     "duration": 4.43564,
     "end_time": "2025-03-15T04:30:32.808290",
     "exception": false,
     "start_time": "2025-03-15T04:30:28.372650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA,FactorAnalysis\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64efa692",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:30:32.822173Z",
     "iopub.status.busy": "2025-03-15T04:30:32.821823Z",
     "iopub.status.idle": "2025-03-15T04:30:32.825091Z",
     "shell.execute_reply": "2025-03-15T04:30:32.824459Z"
    },
    "papermill": {
     "duration": 0.011219,
     "end_time": "2025-03-15T04:30:32.826169",
     "exception": false,
     "start_time": "2025-03-15T04:30:32.814950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a047aa",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-03-15T04:30:32.839217Z",
     "iopub.status.busy": "2025-03-15T04:30:32.839021Z",
     "iopub.status.idle": "2025-03-15T04:30:32.845221Z",
     "shell.execute_reply": "2025-03-15T04:30:32.844604Z"
    },
    "papermill": {
     "duration": 0.013928,
     "end_time": "2025-03-15T04:30:32.846332",
     "exception": false,
     "start_time": "2025-03-15T04:30:32.832404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_targets_scored.csv',\n",
       " 'sample_submission.csv',\n",
       " 'train_drug.csv',\n",
       " 'train_targets_nonscored.csv',\n",
       " 'train_features.csv',\n",
       " 'test_features.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/lish-moa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b0e434b",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-03-15T04:30:32.859553Z",
     "iopub.status.busy": "2025-03-15T04:30:32.859347Z",
     "iopub.status.idle": "2025-03-15T04:30:40.114592Z",
     "shell.execute_reply": "2025-03-15T04:30:40.113611Z"
    },
    "papermill": {
     "duration": 7.26361,
     "end_time": "2025-03-15T04:30:40.116296",
     "exception": false,
     "start_time": "2025-03-15T04:30:32.852686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "sample_submission = pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "070c4598",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:30:40.130903Z",
     "iopub.status.busy": "2025-03-15T04:30:40.130618Z",
     "iopub.status.idle": "2025-03-15T04:30:40.135366Z",
     "shell.execute_reply": "2025-03-15T04:30:40.134494Z"
    },
    "papermill": {
     "duration": 0.013261,
     "end_time": "2025-03-15T04:30:40.136572",
     "exception": false,
     "start_time": "2025-03-15T04:30:40.123311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772 100\n"
     ]
    }
   ],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]\n",
    "print(len(GENES),len(CELLS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83600a38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:30:40.150334Z",
     "iopub.status.busy": "2025-03-15T04:30:40.150109Z",
     "iopub.status.idle": "2025-03-15T04:30:40.153319Z",
     "shell.execute_reply": "2025-03-15T04:30:40.152500Z"
    },
    "papermill": {
     "duration": 0.01164,
     "end_time": "2025-03-15T04:30:40.154623",
     "exception": false,
     "start_time": "2025-03-15T04:30:40.142983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IS_TRAIN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf221de6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:30:40.168025Z",
     "iopub.status.busy": "2025-03-15T04:30:40.167822Z",
     "iopub.status.idle": "2025-03-15T04:52:01.512194Z",
     "shell.execute_reply": "2025-03-15T04:52:01.511208Z"
    },
    "papermill": {
     "duration": 1281.359709,
     "end_time": "2025-03-15T04:52:01.520658",
     "exception": false,
     "start_time": "2025-03-15T04:30:40.160949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 876)\n",
      "(3982, 876)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for col in (GENES + CELLS):\n",
    "\n",
    "  #  transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n",
    "    vec_len = len(train_features[col].values)\n",
    "    vec_len_test = len(test_features[col].values)\n",
    "    raw_vec = train_features[col].values.reshape(vec_len, 1)\n",
    "    if IS_TRAIN:\n",
    "        transformer = QuantileTransformer(n_quantiles=100, random_state=0, output_distribution=\"normal\")\n",
    "        transformer.fit(raw_vec)\n",
    "        pd.to_pickle(transformer, f'{col}_quantile_transformer.pkl')\n",
    "    else:\n",
    "        transformer = pd.read_pickle(f'{col}_quantile_transformer.pkl')        \n",
    "\n",
    "\n",
    "    train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]\n",
    "    test_train_features=np.array(train_features)\n",
    "    test_test_feature=np.array(test_features)\n",
    "print(test_train_features.shape)\n",
    "print(test_test_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b25d2c2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:52:01.534584Z",
     "iopub.status.busy": "2025-03-15T04:52:01.534353Z",
     "iopub.status.idle": "2025-03-15T04:52:01.542913Z",
     "shell.execute_reply": "2025-03-15T04:52:01.542089Z"
    },
    "papermill": {
     "duration": 0.017007,
     "end_time": "2025-03-15T04:52:01.544206",
     "exception": false,
     "start_time": "2025-03-15T04:52:01.527199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81ea15cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:52:01.557814Z",
     "iopub.status.busy": "2025-03-15T04:52:01.557575Z",
     "iopub.status.idle": "2025-03-15T04:52:08.083668Z",
     "shell.execute_reply": "2025-03-15T04:52:08.082979Z"
    },
    "papermill": {
     "duration": 6.534695,
     "end_time": "2025-03-15T04:52:08.085352",
     "exception": false,
     "start_time": "2025-03-15T04:52:01.550657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GENES\n",
    "n_comp = 90  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "#data2 = (FactorAnalysis(n_components=n_comp, random_state=42).fit_transform(data[GENES]))\n",
    "if IS_TRAIN:\n",
    "    fa = FactorAnalysis(n_components=n_comp, random_state=1903).fit(data[GENES])\n",
    "    pd.to_pickle(fa, f'factor_analysis_g.pkl')\n",
    "    #umap = UMAP(n_components=n_dim, random_state=1903).fit(data[GENES])\n",
    "    #pd.to_pickle(umap, f'{MODEL_DIR}/{NB}_umap_g.pkl')\n",
    "else:\n",
    "    fa = pd.read_pickle(f'factor_analysis_g.pkl')\n",
    "    #umap = pd.read_pickle(f'{MODEL_DIR}/{NB}_umap_g.pkl')\n",
    "data2 = fa.transform(data[GENES])\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44f3b6b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:52:08.099873Z",
     "iopub.status.busy": "2025-03-15T04:52:08.099612Z",
     "iopub.status.idle": "2025-03-15T04:52:09.624854Z",
     "shell.execute_reply": "2025-03-15T04:52:09.623891Z"
    },
    "papermill": {
     "duration": 1.534066,
     "end_time": "2025-03-15T04:52:09.626502",
     "exception": false,
     "start_time": "2025-03-15T04:52:08.092436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CELLS\n",
    "n_comp = 50  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "if IS_TRAIN:\n",
    "    fa = FactorAnalysis(n_components=n_comp, random_state=1903).fit(data[CELLS])\n",
    "    pd.to_pickle(fa, f'factor_analysis_c.pkl')\n",
    "    #umap = UMAP(n_components=n_dim, random_state=1903).fit(data[GENES])\n",
    "    #pd.to_pickle(umap, f'{MODEL_DIR}/{NB}_umap_g.pkl')\n",
    "else:\n",
    "    fa = pd.read_pickle(f'factor_analysis_c.pkl')\n",
    "    #umap = pd.read_pickle(f'{MODEL_DIR}/{NB}_umap_g.pkl')\n",
    "data2 = fa.transform(data[CELLS])\n",
    "#data2 = (FactorAnalysis(n_components=n_comp, random_state=42).fit_transform(data[CELLS]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e58bb2ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:52:09.641042Z",
     "iopub.status.busy": "2025-03-15T04:52:09.640803Z",
     "iopub.status.idle": "2025-03-15T04:52:09.645295Z",
     "shell.execute_reply": "2025-03-15T04:52:09.644649Z"
    },
    "papermill": {
     "duration": 0.012811,
     "end_time": "2025-03-15T04:52:09.646465",
     "exception": false,
     "start_time": "2025-03-15T04:52:09.633654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sig_id', 'cp_type', 'cp_time', 'cp_dose', 'g-0', 'g-1', 'g-2', 'g-3',\n",
       "       'g-4', 'g-5',\n",
       "       ...\n",
       "       'pca_C-40', 'pca_C-41', 'pca_C-42', 'pca_C-43', 'pca_C-44', 'pca_C-45',\n",
       "       'pca_C-46', 'pca_C-47', 'pca_C-48', 'pca_C-49'],\n",
       "      dtype='object', length=1016)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape\n",
    "train_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88fdb8e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:52:09.660188Z",
     "iopub.status.busy": "2025-03-15T04:52:09.659989Z",
     "iopub.status.idle": "2025-03-15T04:52:16.586903Z",
     "shell.execute_reply": "2025-03-15T04:52:16.586044Z"
    },
    "papermill": {
     "duration": 6.935306,
     "end_time": "2025-03-15T04:52:16.588366",
     "exception": false,
     "start_time": "2025-03-15T04:52:09.653060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23814, 1015)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "#var_thresh = VarianceThreshold(0.8)  #<-- Update\n",
    "var_thresh = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n",
    "\n",
    "data = pd.concat([train_features, test_features], ignore_index=True)\n",
    "if IS_TRAIN:\n",
    "    transformer = QuantileTransformer(n_quantiles=100, random_state=123, output_distribution=\"normal\")\n",
    "    transformer.fit(data.iloc[:,5:])\n",
    "    pd.to_pickle(transformer, f'{col}_quantile_transformer2.pkl')\n",
    "else:\n",
    "    transformer = pd.read_pickle(f'{col}_quantile_transformer2.pkl')  \n",
    "data_transformed = transformer.transform(data.iloc[:, 5:])\n",
    "\n",
    "train_features_transformed = data_transformed[ : train_features.shape[0]]\n",
    "test_features_transformed = data_transformed[-test_features.shape[0] : ]\n",
    "\n",
    "\n",
    "train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n",
    "\n",
    "\n",
    "test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n",
    "\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "407b5d86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:52:16.602905Z",
     "iopub.status.busy": "2025-03-15T04:52:16.602626Z",
     "iopub.status.idle": "2025-03-15T04:52:16.633936Z",
     "shell.execute_reply": "2025-03-15T04:52:16.633160Z"
    },
    "papermill": {
     "duration": 0.03967,
     "end_time": "2025-03-15T04:52:16.635181",
     "exception": false,
     "start_time": "2025-03-15T04:52:16.595511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>1001</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>1007</th>\n",
       "      <th>1008</th>\n",
       "      <th>1009</th>\n",
       "      <th>1010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.890073</td>\n",
       "      <td>-0.412189</td>\n",
       "      <td>-0.944830</td>\n",
       "      <td>-0.261746</td>\n",
       "      <td>-1.019905</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564399</td>\n",
       "      <td>-0.264961</td>\n",
       "      <td>2.052781</td>\n",
       "      <td>0.725427</td>\n",
       "      <td>2.004088</td>\n",
       "      <td>-0.538631</td>\n",
       "      <td>-0.391831</td>\n",
       "      <td>0.118504</td>\n",
       "      <td>1.139026</td>\n",
       "      <td>-0.492681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.666238</td>\n",
       "      <td>0.291031</td>\n",
       "      <td>0.094330</td>\n",
       "      <td>1.230592</td>\n",
       "      <td>0.663497</td>\n",
       "      <td>0.298448</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.317965</td>\n",
       "      <td>-0.490015</td>\n",
       "      <td>0.581155</td>\n",
       "      <td>0.757636</td>\n",
       "      <td>0.642792</td>\n",
       "      <td>0.302269</td>\n",
       "      <td>0.285574</td>\n",
       "      <td>1.135923</td>\n",
       "      <td>0.514133</td>\n",
       "      <td>0.889294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.928918</td>\n",
       "      <td>1.434467</td>\n",
       "      <td>-0.107724</td>\n",
       "      <td>-0.007338</td>\n",
       "      <td>1.469665</td>\n",
       "      <td>0.224107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232821</td>\n",
       "      <td>-0.269213</td>\n",
       "      <td>-1.666802</td>\n",
       "      <td>1.578149</td>\n",
       "      <td>-0.288255</td>\n",
       "      <td>0.206113</td>\n",
       "      <td>-0.813300</td>\n",
       "      <td>0.671201</td>\n",
       "      <td>0.840813</td>\n",
       "      <td>-0.571809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.281437</td>\n",
       "      <td>-0.437950</td>\n",
       "      <td>0.769865</td>\n",
       "      <td>2.327620</td>\n",
       "      <td>-0.850179</td>\n",
       "      <td>-2.326113</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.907963</td>\n",
       "      <td>0.201992</td>\n",
       "      <td>-0.597280</td>\n",
       "      <td>0.377508</td>\n",
       "      <td>-0.195342</td>\n",
       "      <td>-0.193072</td>\n",
       "      <td>0.343032</td>\n",
       "      <td>0.159275</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.231893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.496357</td>\n",
       "      <td>0.982277</td>\n",
       "      <td>0.987313</td>\n",
       "      <td>1.487840</td>\n",
       "      <td>-0.861976</td>\n",
       "      <td>-0.388252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317295</td>\n",
       "      <td>-1.804858</td>\n",
       "      <td>0.495281</td>\n",
       "      <td>-0.030676</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-0.895828</td>\n",
       "      <td>-2.334076</td>\n",
       "      <td>-0.251194</td>\n",
       "      <td>1.490739</td>\n",
       "      <td>0.997273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.033938</td>\n",
       "      <td>-0.234157</td>\n",
       "      <td>-0.765638</td>\n",
       "      <td>-0.702918</td>\n",
       "      <td>0.894022</td>\n",
       "      <td>0.725918</td>\n",
       "      <td>...</td>\n",
       "      <td>1.291270</td>\n",
       "      <td>0.614803</td>\n",
       "      <td>0.880556</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>-0.183727</td>\n",
       "      <td>0.949953</td>\n",
       "      <td>-0.887562</td>\n",
       "      <td>-0.628253</td>\n",
       "      <td>-0.303959</td>\n",
       "      <td>-0.925261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.574460</td>\n",
       "      <td>-0.584423</td>\n",
       "      <td>1.313386</td>\n",
       "      <td>-1.009899</td>\n",
       "      <td>0.827632</td>\n",
       "      <td>-0.317398</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.232952</td>\n",
       "      <td>1.464645</td>\n",
       "      <td>0.562763</td>\n",
       "      <td>1.259711</td>\n",
       "      <td>-0.983095</td>\n",
       "      <td>1.576557</td>\n",
       "      <td>-0.832365</td>\n",
       "      <td>-0.055082</td>\n",
       "      <td>-0.990865</td>\n",
       "      <td>-1.913727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.616060</td>\n",
       "      <td>0.307320</td>\n",
       "      <td>-1.124344</td>\n",
       "      <td>0.780588</td>\n",
       "      <td>-0.018413</td>\n",
       "      <td>-0.351035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.363167</td>\n",
       "      <td>-0.569549</td>\n",
       "      <td>2.009670</td>\n",
       "      <td>1.083905</td>\n",
       "      <td>-0.939400</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>-1.168008</td>\n",
       "      <td>1.222020</td>\n",
       "      <td>-0.427585</td>\n",
       "      <td>0.688047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.404122</td>\n",
       "      <td>0.452794</td>\n",
       "      <td>0.313924</td>\n",
       "      <td>1.089796</td>\n",
       "      <td>-0.041223</td>\n",
       "      <td>0.040732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.843405</td>\n",
       "      <td>0.226004</td>\n",
       "      <td>-1.963314</td>\n",
       "      <td>-0.509632</td>\n",
       "      <td>-1.475090</td>\n",
       "      <td>-0.732285</td>\n",
       "      <td>1.396649</td>\n",
       "      <td>0.453370</td>\n",
       "      <td>0.310334</td>\n",
       "      <td>1.618901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.544298</td>\n",
       "      <td>-0.265196</td>\n",
       "      <td>1.103513</td>\n",
       "      <td>-0.527464</td>\n",
       "      <td>-2.120578</td>\n",
       "      <td>-1.619244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647490</td>\n",
       "      <td>-0.836719</td>\n",
       "      <td>-0.407389</td>\n",
       "      <td>0.130110</td>\n",
       "      <td>0.200374</td>\n",
       "      <td>-0.360941</td>\n",
       "      <td>-0.399136</td>\n",
       "      <td>0.578968</td>\n",
       "      <td>-0.431915</td>\n",
       "      <td>-0.769602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows Ã— 1015 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id      cp_type cp_time cp_dose         0         1  \\\n",
       "0      id_000644bb2       trt_cp      24      D1  0.890073 -0.412189   \n",
       "1      id_000779bfc       trt_cp      72      D1  0.666238  0.291031   \n",
       "2      id_000a6266a       trt_cp      48      D1  0.928918  1.434467   \n",
       "3      id_0015fd391       trt_cp      48      D1 -0.281437 -0.437950   \n",
       "4      id_001626bd3       trt_cp      72      D2 -0.496357  0.982277   \n",
       "...             ...          ...     ...     ...       ...       ...   \n",
       "23809  id_fffb1ceed       trt_cp      24      D2 -0.033938 -0.234157   \n",
       "23810  id_fffb70c0c       trt_cp      24      D2  0.574460 -0.584423   \n",
       "23811  id_fffc1c3f4  ctl_vehicle      48      D2  0.616060  0.307320   \n",
       "23812  id_fffcb9e7c       trt_cp      24      D1  0.404122  0.452794   \n",
       "23813  id_ffffdd77b       trt_cp      72      D1  1.544298 -0.265196   \n",
       "\n",
       "              2         3         4         5  ...      1001      1002  \\\n",
       "0     -0.944830 -0.261746 -1.019905 -1.357832  ...  0.564399 -0.264961   \n",
       "1      0.094330  1.230592  0.663497  0.298448  ... -0.317965 -0.490015   \n",
       "2     -0.107724 -0.007338  1.469665  0.224107  ...  0.232821 -0.269213   \n",
       "3      0.769865  2.327620 -0.850179 -2.326113  ... -0.907963  0.201992   \n",
       "4      0.987313  1.487840 -0.861976 -0.388252  ...  0.317295 -1.804858   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "23809 -0.765638 -0.702918  0.894022  0.725918  ...  1.291270  0.614803   \n",
       "23810  1.313386 -1.009899  0.827632 -0.317398  ... -3.232952  1.464645   \n",
       "23811 -1.124344  0.780588 -0.018413 -0.351035  ... -0.363167 -0.569549   \n",
       "23812  0.313924  1.089796 -0.041223  0.040732  ... -0.843405  0.226004   \n",
       "23813  1.103513 -0.527464 -2.120578 -1.619244  ...  0.647490 -0.836719   \n",
       "\n",
       "           1003      1004      1005      1006      1007      1008      1009  \\\n",
       "0      2.052781  0.725427  2.004088 -0.538631 -0.391831  0.118504  1.139026   \n",
       "1      0.581155  0.757636  0.642792  0.302269  0.285574  1.135923  0.514133   \n",
       "2     -1.666802  1.578149 -0.288255  0.206113 -0.813300  0.671201  0.840813   \n",
       "3     -0.597280  0.377508 -0.195342 -0.193072  0.343032  0.159275  0.547945   \n",
       "4      0.495281 -0.030676 -1.087009 -0.895828 -2.334076 -0.251194  1.490739   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "23809  0.880556  0.002841 -0.183727  0.949953 -0.887562 -0.628253 -0.303959   \n",
       "23810  0.562763  1.259711 -0.983095  1.576557 -0.832365 -0.055082 -0.990865   \n",
       "23811  2.009670  1.083905 -0.939400 -0.000248 -1.168008  1.222020 -0.427585   \n",
       "23812 -1.963314 -0.509632 -1.475090 -0.732285  1.396649  0.453370  0.310334   \n",
       "23813 -0.407389  0.130110  0.200374 -0.360941 -0.399136  0.578968 -0.431915   \n",
       "\n",
       "           1010  \n",
       "0     -0.492681  \n",
       "1      0.889294  \n",
       "2     -0.571809  \n",
       "3      0.231893  \n",
       "4      0.997273  \n",
       "...         ...  \n",
       "23809 -0.925261  \n",
       "23810 -1.913727  \n",
       "23811  0.688047  \n",
       "23812  1.618901  \n",
       "23813 -0.769602  \n",
       "\n",
       "[23814 rows x 1015 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d010d49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:52:16.649924Z",
     "iopub.status.busy": "2025-03-15T04:52:16.649669Z",
     "iopub.status.idle": "2025-03-15T04:52:16.652349Z",
     "shell.execute_reply": "2025-03-15T04:52:16.651796Z"
    },
    "papermill": {
     "duration": 0.011315,
     "end_time": "2025-03-15T04:52:16.653609",
     "exception": false,
     "start_time": "2025-03-15T04:52:16.642294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pickle import load,dump\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13c8a5c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:52:16.668083Z",
     "iopub.status.busy": "2025-03-15T04:52:16.667858Z",
     "iopub.status.idle": "2025-03-15T04:52:58.087396Z",
     "shell.execute_reply": "2025-03-15T04:52:58.086398Z"
    },
    "papermill": {
     "duration": 41.428482,
     "end_time": "2025-03-15T04:52:58.089073",
     "exception": false,
     "start_time": "2025-03-15T04:52:16.660591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def fe_cluster_genes(train, test, n_clusters_g = 45, SEED = 123):\n",
    "    \n",
    "    #features_g = GENES\n",
    "    #features_c = CELLS\n",
    "    features_g = list(train.columns[4:776])\n",
    "    \n",
    "    def create_cluster(train, test, features, kind = 'g', n_clusters = n_clusters_g):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans_genes = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_genes, open('kmeans_genes.pkl', 'wb'))\n",
    "        train[f'clusters_{kind}'] = kmeans_genes.predict(train_.values)\n",
    "        test[f'clusters_{kind}'] = kmeans_genes.predict(test_.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "    train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "   # train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features ,test_features=fe_cluster_genes(train_features,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe81fcde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:52:58.104409Z",
     "iopub.status.busy": "2025-03-15T04:52:58.104147Z",
     "iopub.status.idle": "2025-03-15T04:53:03.518732Z",
     "shell.execute_reply": "2025-03-15T04:53:03.517778Z"
    },
    "papermill": {
     "duration": 5.423677,
     "end_time": "2025-03-15T04:53:03.520253",
     "exception": false,
     "start_time": "2025-03-15T04:52:58.096576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_cluster_cells(train, test, n_clusters_c = 15, SEED = 123):\n",
    "    \n",
    "    #features_g = GENES\n",
    "    #features_c = CELLS\n",
    "    features_c = list(train.columns[776:876])\n",
    "\n",
    "    def create_cluster(train, test, features, kind = 'c', n_clusters = n_clusters_c):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans_cells = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_cells, open('kmeans_cells.pkl', 'wb'))\n",
    "        train[f'clusters_{kind}'] = kmeans_cells.predict(train_.values)\n",
    "        test[f'clusters_{kind}'] = kmeans_cells.predict(test_.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "   # train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "    train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features ,test_features=fe_cluster_cells(train_features,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bc6c97b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:53:03.536358Z",
     "iopub.status.busy": "2025-03-15T04:53:03.536089Z",
     "iopub.status.idle": "2025-03-15T04:53:06.232928Z",
     "shell.execute_reply": "2025-03-15T04:53:06.231960Z"
    },
    "papermill": {
     "duration": 2.706167,
     "end_time": "2025-03-15T04:53:06.234549",
     "exception": false,
     "start_time": "2025-03-15T04:53:03.528382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_stats(train, test):\n",
    "    \n",
    "    features_g = list(train.columns[4:776])\n",
    "    features_c = list(train.columns[776:876])\n",
    "    \n",
    "    for df in train, test:\n",
    "        df['g_sum'] = df[features_g].sum(axis = 1)\n",
    "        df['g_mean'] = df[features_g].mean(axis = 1)\n",
    "        df['g_std'] = df[features_g].std(axis = 1)\n",
    "        df['g_kurt'] = df[features_g].kurtosis(axis = 1)\n",
    "        df['g_skew'] = df[features_g].skew(axis = 1)\n",
    "        df['c_sum'] = df[features_c].sum(axis = 1)\n",
    "        df['c_mean'] = df[features_c].mean(axis = 1)\n",
    "        df['c_std'] = df[features_c].std(axis = 1)\n",
    "        df['c_kurt'] = df[features_c].kurtosis(axis = 1)\n",
    "        df['c_skew'] = df[features_c].skew(axis = 1)\n",
    "        df['gc_sum'] = df[features_g + features_c].sum(axis = 1)\n",
    "        df['gc_mean'] = df[features_g + features_c].mean(axis = 1)\n",
    "        df['gc_std'] = df[features_g + features_c].std(axis = 1)\n",
    "        df['gc_kurt'] = df[features_g + features_c].kurtosis(axis = 1)\n",
    "        df['gc_skew'] = df[features_g + features_c].skew(axis = 1)\n",
    "        \n",
    "    return train, test\n",
    "\n",
    "train_features,test_features=fe_stats(train_features,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d072050a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:53:06.250438Z",
     "iopub.status.busy": "2025-03-15T04:53:06.250195Z",
     "iopub.status.idle": "2025-03-15T04:53:06.586247Z",
     "shell.execute_reply": "2025-03-15T04:53:06.585531Z"
    },
    "papermill": {
     "duration": 0.345158,
     "end_time": "2025-03-15T04:53:06.587844",
     "exception": false,
     "start_time": "2025-03-15T04:53:06.242686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07076c17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:53:06.603759Z",
     "iopub.status.busy": "2025-03-15T04:53:06.603488Z",
     "iopub.status.idle": "2025-03-15T04:53:06.666621Z",
     "shell.execute_reply": "2025-03-15T04:53:06.665943Z"
    },
    "papermill": {
     "duration": 0.072614,
     "end_time": "2025-03-15T04:53:06.668175",
     "exception": false,
     "start_time": "2025-03-15T04:53:06.595561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "876e7a44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:53:06.683329Z",
     "iopub.status.busy": "2025-03-15T04:53:06.683080Z",
     "iopub.status.idle": "2025-03-15T04:53:06.704026Z",
     "shell.execute_reply": "2025-03-15T04:53:06.703203Z"
    },
    "papermill": {
     "duration": 0.029656,
     "end_time": "2025-03-15T04:53:06.705201",
     "exception": false,
     "start_time": "2025-03-15T04:53:06.675545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.890073</td>\n",
       "      <td>-0.412189</td>\n",
       "      <td>-0.944830</td>\n",
       "      <td>-0.261746</td>\n",
       "      <td>-1.019905</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>-0.029436</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.666238</td>\n",
       "      <td>0.291031</td>\n",
       "      <td>0.094330</td>\n",
       "      <td>1.230592</td>\n",
       "      <td>0.663497</td>\n",
       "      <td>0.298448</td>\n",
       "      <td>0.570563</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.928918</td>\n",
       "      <td>1.434467</td>\n",
       "      <td>-0.107724</td>\n",
       "      <td>-0.007338</td>\n",
       "      <td>1.469665</td>\n",
       "      <td>0.224107</td>\n",
       "      <td>0.365146</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.281437</td>\n",
       "      <td>-0.437950</td>\n",
       "      <td>0.769865</td>\n",
       "      <td>2.327620</td>\n",
       "      <td>-0.850179</td>\n",
       "      <td>-2.326113</td>\n",
       "      <td>0.310265</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.496357</td>\n",
       "      <td>0.982277</td>\n",
       "      <td>0.987313</td>\n",
       "      <td>1.487840</td>\n",
       "      <td>-0.861976</td>\n",
       "      <td>-0.388252</td>\n",
       "      <td>-0.215173</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.247670</td>\n",
       "      <td>0.232367</td>\n",
       "      <td>-0.333729</td>\n",
       "      <td>-0.336437</td>\n",
       "      <td>0.544847</td>\n",
       "      <td>-0.161153</td>\n",
       "      <td>-0.261668</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.033938</td>\n",
       "      <td>-0.234157</td>\n",
       "      <td>-0.765638</td>\n",
       "      <td>-0.702918</td>\n",
       "      <td>0.894022</td>\n",
       "      <td>0.725918</td>\n",
       "      <td>0.519715</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.574460</td>\n",
       "      <td>-0.584423</td>\n",
       "      <td>1.313386</td>\n",
       "      <td>-1.009899</td>\n",
       "      <td>0.827632</td>\n",
       "      <td>-0.317398</td>\n",
       "      <td>-0.710768</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.404122</td>\n",
       "      <td>0.452794</td>\n",
       "      <td>0.313924</td>\n",
       "      <td>1.089796</td>\n",
       "      <td>-0.041223</td>\n",
       "      <td>0.040732</td>\n",
       "      <td>0.096359</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.544298</td>\n",
       "      <td>-0.265196</td>\n",
       "      <td>1.103513</td>\n",
       "      <td>-0.527464</td>\n",
       "      <td>-2.120578</td>\n",
       "      <td>-1.619244</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows Ã— 1295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose         0         1         2         3  \\\n",
       "0      id_000644bb2      24      D1  0.890073 -0.412189 -0.944830 -0.261746   \n",
       "1      id_000779bfc      72      D1  0.666238  0.291031  0.094330  1.230592   \n",
       "2      id_000a6266a      48      D1  0.928918  1.434467 -0.107724 -0.007338   \n",
       "3      id_0015fd391      48      D1 -0.281437 -0.437950  0.769865  2.327620   \n",
       "4      id_001626bd3      72      D2 -0.496357  0.982277  0.987313  1.487840   \n",
       "...             ...     ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444      72      D1 -1.247670  0.232367 -0.333729 -0.336437   \n",
       "21944  id_fffb1ceed      24      D2 -0.033938 -0.234157 -0.765638 -0.702918   \n",
       "21945  id_fffb70c0c      24      D2  0.574460 -0.584423  1.313386 -1.009899   \n",
       "21946  id_fffcb9e7c      24      D1  0.404122  0.452794  0.313924  1.089796   \n",
       "21947  id_ffffdd77b      72      D1  1.544298 -0.265196  1.103513 -0.527464   \n",
       "\n",
       "              4         5         6  ...  \\\n",
       "0     -1.019905 -1.357832 -0.029436  ...   \n",
       "1      0.663497  0.298448  0.570563  ...   \n",
       "2      1.469665  0.224107  0.365146  ...   \n",
       "3     -0.850179 -2.326113  0.310265  ...   \n",
       "4     -0.861976 -0.388252 -0.215173  ...   \n",
       "...         ...       ...       ...  ...   \n",
       "21943  0.544847 -0.161153 -0.261668  ...   \n",
       "21944  0.894022  0.725918  0.519715  ...   \n",
       "21945  0.827632 -0.317398 -0.710768  ...   \n",
       "21946 -0.041223  0.040732  0.096359  ...   \n",
       "21947 -2.120578 -1.619244  1.422976  ...   \n",
       "\n",
       "       tropomyosin_receptor_kinase_inhibitor  trpv_agonist  trpv_antagonist  \\\n",
       "0                                          0             0                0   \n",
       "1                                          0             0                0   \n",
       "2                                          0             0                0   \n",
       "3                                          0             0                0   \n",
       "4                                          0             0                0   \n",
       "...                                      ...           ...              ...   \n",
       "21943                                      0             0                0   \n",
       "21944                                      0             0                0   \n",
       "21945                                      0             0                0   \n",
       "21946                                      0             0                0   \n",
       "21947                                      0             0                0   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "...                  ...                        ...   \n",
       "21943                  0                          0   \n",
       "21944                  0                          0   \n",
       "21945                  0                          0   \n",
       "21946                  0                          0   \n",
       "21947                  0                          0   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                          0                0          0   \n",
       "1                                          0                0          0   \n",
       "2                                          0                0          0   \n",
       "3                                          0                0          0   \n",
       "4                                          0                0          0   \n",
       "...                                      ...              ...        ...   \n",
       "21943                                      0                0          0   \n",
       "21944                                      0                0          0   \n",
       "21945                                      0                0          0   \n",
       "21946                                      0                0          0   \n",
       "21947                                      0                0          0   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                               0              0  \n",
       "1                               0              0  \n",
       "2                               0              0  \n",
       "3                               0              0  \n",
       "4                               0              0  \n",
       "...                           ...            ...  \n",
       "21943                           0              0  \n",
       "21944                           0              0  \n",
       "21945                           0              0  \n",
       "21946                           0              0  \n",
       "21947                           0              0  \n",
       "\n",
       "[21948 rows x 1295 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08afcaf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:53:06.720737Z",
     "iopub.status.busy": "2025-03-15T04:53:06.720484Z",
     "iopub.status.idle": "2025-03-15T04:53:06.732016Z",
     "shell.execute_reply": "2025-03-15T04:53:06.731129Z"
    },
    "papermill": {
     "duration": 0.020619,
     "end_time": "2025-03-15T04:53:06.733286",
     "exception": false,
     "start_time": "2025-03-15T04:53:06.712667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53d878d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:53:06.748617Z",
     "iopub.status.busy": "2025-03-15T04:53:06.748378Z",
     "iopub.status.idle": "2025-03-15T04:53:08.903993Z",
     "shell.execute_reply": "2025-03-15T04:53:08.903078Z"
    },
    "papermill": {
     "duration": 2.164584,
     "end_time": "2025-03-15T04:53:08.905233",
     "exception": false,
     "start_time": "2025-03-15T04:53:06.740649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.890073</td>\n",
       "      <td>-0.412189</td>\n",
       "      <td>-0.944830</td>\n",
       "      <td>-0.261746</td>\n",
       "      <td>-1.019905</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>-0.029436</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.666238</td>\n",
       "      <td>0.291031</td>\n",
       "      <td>0.094330</td>\n",
       "      <td>1.230592</td>\n",
       "      <td>0.663497</td>\n",
       "      <td>0.298448</td>\n",
       "      <td>0.570563</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.928918</td>\n",
       "      <td>1.434467</td>\n",
       "      <td>-0.107724</td>\n",
       "      <td>-0.007338</td>\n",
       "      <td>1.469665</td>\n",
       "      <td>0.224107</td>\n",
       "      <td>0.365146</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.281437</td>\n",
       "      <td>-0.437950</td>\n",
       "      <td>0.769865</td>\n",
       "      <td>2.327620</td>\n",
       "      <td>-0.850179</td>\n",
       "      <td>-2.326113</td>\n",
       "      <td>0.310265</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.496357</td>\n",
       "      <td>0.982277</td>\n",
       "      <td>0.987313</td>\n",
       "      <td>1.487840</td>\n",
       "      <td>-0.861976</td>\n",
       "      <td>-0.388252</td>\n",
       "      <td>-0.215173</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.247670</td>\n",
       "      <td>0.232367</td>\n",
       "      <td>-0.333729</td>\n",
       "      <td>-0.336437</td>\n",
       "      <td>0.544847</td>\n",
       "      <td>-0.161153</td>\n",
       "      <td>-0.261668</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.033938</td>\n",
       "      <td>-0.234157</td>\n",
       "      <td>-0.765638</td>\n",
       "      <td>-0.702918</td>\n",
       "      <td>0.894022</td>\n",
       "      <td>0.725918</td>\n",
       "      <td>0.519715</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.574460</td>\n",
       "      <td>-0.584423</td>\n",
       "      <td>1.313386</td>\n",
       "      <td>-1.009899</td>\n",
       "      <td>0.827632</td>\n",
       "      <td>-0.317398</td>\n",
       "      <td>-0.710768</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.404122</td>\n",
       "      <td>0.452794</td>\n",
       "      <td>0.313924</td>\n",
       "      <td>1.089796</td>\n",
       "      <td>-0.041223</td>\n",
       "      <td>0.040732</td>\n",
       "      <td>0.096359</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.544298</td>\n",
       "      <td>-0.265196</td>\n",
       "      <td>1.103513</td>\n",
       "      <td>-0.527464</td>\n",
       "      <td>-2.120578</td>\n",
       "      <td>-1.619244</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows Ã— 1296 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose         0         1         2         3  \\\n",
       "0      id_000644bb2      24      D1  0.890073 -0.412189 -0.944830 -0.261746   \n",
       "1      id_000779bfc      72      D1  0.666238  0.291031  0.094330  1.230592   \n",
       "2      id_000a6266a      48      D1  0.928918  1.434467 -0.107724 -0.007338   \n",
       "3      id_0015fd391      48      D1 -0.281437 -0.437950  0.769865  2.327620   \n",
       "4      id_001626bd3      72      D2 -0.496357  0.982277  0.987313  1.487840   \n",
       "...             ...     ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444      72      D1 -1.247670  0.232367 -0.333729 -0.336437   \n",
       "21944  id_fffb1ceed      24      D2 -0.033938 -0.234157 -0.765638 -0.702918   \n",
       "21945  id_fffb70c0c      24      D2  0.574460 -0.584423  1.313386 -1.009899   \n",
       "21946  id_fffcb9e7c      24      D1  0.404122  0.452794  0.313924  1.089796   \n",
       "21947  id_ffffdd77b      72      D1  1.544298 -0.265196  1.103513 -0.527464   \n",
       "\n",
       "              4         5         6  ...  trpv_agonist  trpv_antagonist  \\\n",
       "0     -1.019905 -1.357832 -0.029436  ...             0                0   \n",
       "1      0.663497  0.298448  0.570563  ...             0                0   \n",
       "2      1.469665  0.224107  0.365146  ...             0                0   \n",
       "3     -0.850179 -2.326113  0.310265  ...             0                0   \n",
       "4     -0.861976 -0.388252 -0.215173  ...             0                0   \n",
       "...         ...       ...       ...  ...           ...              ...   \n",
       "21943  0.544847 -0.161153 -0.261668  ...             0                0   \n",
       "21944  0.894022  0.725918  0.519715  ...             0                0   \n",
       "21945  0.827632 -0.317398 -0.710768  ...             0                0   \n",
       "21946 -0.041223  0.040732  0.096359  ...             0                0   \n",
       "21947 -2.120578 -1.619244  1.422976  ...             0                0   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "...                  ...                        ...   \n",
       "21943                  0                          0   \n",
       "21944                  0                          0   \n",
       "21945                  0                          0   \n",
       "21946                  0                          0   \n",
       "21947                  0                          0   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                          0                0          0   \n",
       "1                                          0                0          0   \n",
       "2                                          0                0          0   \n",
       "3                                          0                0          0   \n",
       "4                                          0                0          0   \n",
       "...                                      ...              ...        ...   \n",
       "21943                                      0                0          0   \n",
       "21944                                      0                0          0   \n",
       "21945                                      0                0          0   \n",
       "21946                                      0                0          0   \n",
       "21947                                      0                0          0   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  kfold  \n",
       "0                               0              0      0  \n",
       "1                               0              0      2  \n",
       "2                               0              0      1  \n",
       "3                               0              0      2  \n",
       "4                               0              0      2  \n",
       "...                           ...            ...    ...  \n",
       "21943                           0              0      0  \n",
       "21944                           0              0      4  \n",
       "21945                           0              0      0  \n",
       "21946                           0              0      1  \n",
       "21947                           0              0      2  \n",
       "\n",
       "[21948 rows x 1296 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=5)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c27c5e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:53:08.922643Z",
     "iopub.status.busy": "2025-03-15T04:53:08.922407Z",
     "iopub.status.idle": "2025-03-15T04:53:08.926798Z",
     "shell.execute_reply": "2025-03-15T04:53:08.926020Z"
    },
    "papermill": {
     "duration": 0.013817,
     "end_time": "2025-03-15T04:53:08.927939",
     "exception": false,
     "start_time": "2025-03-15T04:53:08.914122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1295)\n",
      "(21948, 1296)\n",
      "(3624, 1089)\n",
      "(21948, 207)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7b4c7f",
   "metadata": {
    "papermill": {
     "duration": 0.007389,
     "end_time": "2025-03-15T04:53:08.943055",
     "exception": false,
     "start_time": "2025-03-15T04:53:08.935666",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab1aa24a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:53:08.959068Z",
     "iopub.status.busy": "2025-03-15T04:53:08.958841Z",
     "iopub.status.idle": "2025-03-15T04:53:08.964160Z",
     "shell.execute_reply": "2025-03-15T04:53:08.963506Z"
    },
    "papermill": {
     "duration": 0.014606,
     "end_time": "2025-03-15T04:53:08.965295",
     "exception": false,
     "start_time": "2025-03-15T04:53:08.950689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features.astype(np.float32)\n",
    "        self.targets = targets.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8b10b4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:53:08.981630Z",
     "iopub.status.busy": "2025-03-15T04:53:08.981408Z",
     "iopub.status.idle": "2025-03-15T04:53:08.987830Z",
     "shell.execute_reply": "2025-03-15T04:53:08.987169Z"
    },
    "papermill": {
     "duration": 0.015806,
     "end_time": "2025-03-15T04:53:08.989028",
     "exception": false,
     "start_time": "2025-03-15T04:53:08.973222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "#         print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b2e2d32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:53:09.004989Z",
     "iopub.status.busy": "2025-03-15T04:53:09.004759Z",
     "iopub.status.idle": "2025-03-15T04:53:09.010358Z",
     "shell.execute_reply": "2025-03-15T04:53:09.009559Z"
    },
    "papermill": {
     "duration": 0.01499,
     "end_time": "2025-03-15T04:53:09.011632",
     "exception": false,
     "start_time": "2025-03-15T04:53:08.996642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "948eab6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:53:09.027882Z",
     "iopub.status.busy": "2025-03-15T04:53:09.027566Z",
     "iopub.status.idle": "2025-03-15T04:53:09.032850Z",
     "shell.execute_reply": "2025-03-15T04:53:09.032181Z"
    },
    "papermill": {
     "duration": 0.014742,
     "end_time": "2025-03-15T04:53:09.034179",
     "exception": false,
     "start_time": "2025-03-15T04:53:09.019437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):      # <-- Update\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.dense2 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.leaky_relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.leaky_relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa4f40a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:53:09.050291Z",
     "iopub.status.busy": "2025-03-15T04:53:09.050097Z",
     "iopub.status.idle": "2025-03-15T04:53:09.053248Z",
     "shell.execute_reply": "2025-03-15T04:53:09.052604Z"
    },
    "papermill": {
     "duration": 0.012438,
     "end_time": "2025-03-15T04:53:09.054431",
     "exception": false,
     "start_time": "2025-03-15T04:53:09.041993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09894bb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:53:09.070828Z",
     "iopub.status.busy": "2025-03-15T04:53:09.070589Z",
     "iopub.status.idle": "2025-03-15T04:53:09.250872Z",
     "shell.execute_reply": "2025-03-15T04:53:09.250060Z"
    },
    "papermill": {
     "duration": 0.189905,
     "end_time": "2025-03-15T04:53:09.252208",
     "exception": false,
     "start_time": "2025-03-15T04:53:09.062303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1091"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "541c061c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:53:09.269211Z",
     "iopub.status.busy": "2025-03-15T04:53:09.268993Z",
     "iopub.status.idle": "2025-03-15T04:53:09.338350Z",
     "shell.execute_reply": "2025-03-15T04:53:09.337528Z"
    },
    "papermill": {
     "duration": 0.079174,
     "end_time": "2025-03-15T04:53:09.339658",
     "exception": false,
     "start_time": "2025-03-15T04:53:09.260484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 5e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 5            #<-- Update\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=2048\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "356d4328",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:53:09.356650Z",
     "iopub.status.busy": "2025-03-15T04:53:09.356426Z",
     "iopub.status.idle": "2025-03-15T04:53:09.366389Z",
     "shell.execute_reply": "2025-03-15T04:53:09.365375Z"
    },
    "papermill": {
     "duration": 0.019724,
     "end_time": "2025-03-15T04:53:09.367788",
     "exception": false,
     "start_time": "2025-03-15T04:53:09.348064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-3, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"SEED: {seed} ,FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"SEED{seed}_FOLD{fold}_.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"SEED{seed}_FOLD{fold}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea9ff0b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:53:09.384250Z",
     "iopub.status.busy": "2025-03-15T04:53:09.384050Z",
     "iopub.status.idle": "2025-03-15T04:53:09.387582Z",
     "shell.execute_reply": "2025-03-15T04:53:09.387017Z"
    },
    "papermill": {
     "duration": 0.012864,
     "end_time": "2025-03-15T04:53:09.388626",
     "exception": false,
     "start_time": "2025-03-15T04:53:09.375762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60434b3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T04:53:09.404910Z",
     "iopub.status.busy": "2025-03-15T04:53:09.404666Z",
     "iopub.status.idle": "2025-03-15T05:09:29.522452Z",
     "shell.execute_reply": "2025-03-15T05:09:29.521773Z"
    },
    "papermill": {
     "duration": 980.127636,
     "end_time": "2025-03-15T05:09:29.524124",
     "exception": false,
     "start_time": "2025-03-15T04:53:09.396488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 940, FOLD: 0, EPOCH: 0, train_loss: 0.4710014884940524\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 0, valid_loss: 0.023523257193820816\n",
      "SEED: 940, FOLD: 0, EPOCH: 1, train_loss: 0.023648104508933815\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 1, valid_loss: 0.018759854723300252\n",
      "SEED: 940, FOLD: 0, EPOCH: 2, train_loss: 0.02179516255315663\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 2, valid_loss: 0.017789908551744053\n",
      "SEED: 940, FOLD: 0, EPOCH: 3, train_loss: 0.02124146609634593\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 3, valid_loss: 0.01728952806442976\n",
      "SEED: 940, FOLD: 0, EPOCH: 4, train_loss: 0.02030121396039275\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017331369301038128\n",
      "SEED: 940, FOLD: 0, EPOCH: 5, train_loss: 0.02047741726256799\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 5, valid_loss: 0.01734606054212366\n",
      "SEED: 940, FOLD: 0, EPOCH: 6, train_loss: 0.02021799275678569\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017249195863093647\n",
      "SEED: 940, FOLD: 0, EPOCH: 7, train_loss: 0.020195152381084103\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017209224668996676\n",
      "SEED: 940, FOLD: 0, EPOCH: 8, train_loss: 0.020205059007782\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017046885405267987\n",
      "SEED: 940, FOLD: 0, EPOCH: 9, train_loss: 0.020156528854715652\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017288648683045593\n",
      "SEED: 940, FOLD: 0, EPOCH: 10, train_loss: 0.02015985765804847\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017093356273003988\n",
      "SEED: 940, FOLD: 0, EPOCH: 11, train_loss: 0.020036208065415638\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 11, valid_loss: 0.017144494876265525\n",
      "SEED: 940, FOLD: 0, EPOCH: 12, train_loss: 0.02002012965849776\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 12, valid_loss: 0.017129433846899442\n",
      "SEED: 940, FOLD: 0, EPOCH: 13, train_loss: 0.019997494241249733\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01688494011759758\n",
      "SEED: 940, FOLD: 0, EPOCH: 14, train_loss: 0.019686631844851418\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016970001480409076\n",
      "SEED: 940, FOLD: 0, EPOCH: 15, train_loss: 0.019552895461843498\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016695975086518697\n",
      "SEED: 940, FOLD: 0, EPOCH: 16, train_loss: 0.01937392595615508\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01656330826559237\n",
      "SEED: 940, FOLD: 0, EPOCH: 17, train_loss: 0.01913273126642773\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 17, valid_loss: 0.0164726014648165\n",
      "SEED: 940, FOLD: 0, EPOCH: 18, train_loss: 0.018799208813225447\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 18, valid_loss: 0.01628383712044784\n",
      "SEED: 940, FOLD: 0, EPOCH: 19, train_loss: 0.018353998094149258\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016158683598041533\n",
      "SEED: 940, FOLD: 0, EPOCH: 20, train_loss: 0.017840709712734257\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016155844527695862\n",
      "SEED: 940, FOLD: 0, EPOCH: 21, train_loss: 0.017311321335264307\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016029928837503704\n",
      "SEED: 940, FOLD: 0, EPOCH: 22, train_loss: 0.016730185645375994\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01604124770632812\n",
      "SEED: 940, FOLD: 0, EPOCH: 23, train_loss: 0.01627579257837024\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 23, valid_loss: 0.016050762284014905\n",
      "SEED: 940, FOLD: 0, EPOCH: 24, train_loss: 0.016037665428998676\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 24, valid_loss: 0.016109686344861984\n",
      "SEED: 940, FOLD: 1, EPOCH: 0, train_loss: 0.4722805485345315\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 0, valid_loss: 0.023859903269580433\n",
      "SEED: 940, FOLD: 1, EPOCH: 1, train_loss: 0.023601809435564537\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 1, valid_loss: 0.019166276923247745\n",
      "SEED: 940, FOLD: 1, EPOCH: 2, train_loss: 0.022171437483874783\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 2, valid_loss: 0.01907728894480637\n",
      "SEED: 940, FOLD: 1, EPOCH: 3, train_loss: 0.020802925651272137\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 3, valid_loss: 0.018096173953797135\n",
      "SEED: 940, FOLD: 1, EPOCH: 4, train_loss: 0.020207421638179516\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017584697396627495\n",
      "SEED: 940, FOLD: 1, EPOCH: 5, train_loss: 0.02018038454749014\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017488416151276658\n",
      "SEED: 940, FOLD: 1, EPOCH: 6, train_loss: 0.020226849229547424\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017244946637323923\n",
      "SEED: 940, FOLD: 1, EPOCH: 7, train_loss: 0.020186762176993965\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01707700166319098\n",
      "SEED: 940, FOLD: 1, EPOCH: 8, train_loss: 0.02023015746279903\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017502883289541516\n",
      "SEED: 940, FOLD: 1, EPOCH: 9, train_loss: 0.020188350459911686\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 9, valid_loss: 0.017091515713504382\n",
      "SEED: 940, FOLD: 1, EPOCH: 10, train_loss: 0.020140111068452614\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01731598491647414\n",
      "SEED: 940, FOLD: 1, EPOCH: 11, train_loss: 0.020078422731139522\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017123708873987196\n",
      "SEED: 940, FOLD: 1, EPOCH: 12, train_loss: 0.020087008661442043\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 12, valid_loss: 0.017119820176490715\n",
      "SEED: 940, FOLD: 1, EPOCH: 13, train_loss: 0.019902124380071957\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016915500057595116\n",
      "SEED: 940, FOLD: 1, EPOCH: 14, train_loss: 0.019746979725533638\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016750291202749526\n",
      "SEED: 940, FOLD: 1, EPOCH: 15, train_loss: 0.019577609105170635\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016646800749003886\n",
      "SEED: 940, FOLD: 1, EPOCH: 16, train_loss: 0.019383582165059837\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 16, valid_loss: 0.01661947633006743\n",
      "SEED: 940, FOLD: 1, EPOCH: 17, train_loss: 0.019076537691812584\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016547327462051595\n",
      "SEED: 940, FOLD: 1, EPOCH: 18, train_loss: 0.018755701330044994\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016293824650347233\n",
      "SEED: 940, FOLD: 1, EPOCH: 19, train_loss: 0.018384130698615227\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01626503701720919\n",
      "SEED: 940, FOLD: 1, EPOCH: 20, train_loss: 0.017866881226823814\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016128316574863025\n",
      "SEED: 940, FOLD: 1, EPOCH: 21, train_loss: 0.01727400420476561\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01606932513947998\n",
      "SEED: 940, FOLD: 1, EPOCH: 22, train_loss: 0.016712515608178102\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 22, valid_loss: 0.016000951799963203\n",
      "SEED: 940, FOLD: 1, EPOCH: 23, train_loss: 0.01626222717670211\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01603019405156374\n",
      "SEED: 940, FOLD: 1, EPOCH: 24, train_loss: 0.016077807787265898\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 24, valid_loss: 0.016008805909327097\n",
      "SEED: 940, FOLD: 2, EPOCH: 0, train_loss: 0.47011388086484396\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 0, valid_loss: 0.024073853663035803\n",
      "SEED: 940, FOLD: 2, EPOCH: 1, train_loss: 0.023823268603587498\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 1, valid_loss: 0.019071323850325176\n",
      "SEED: 940, FOLD: 2, EPOCH: 2, train_loss: 0.02181675206815851\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018496058136224746\n",
      "SEED: 940, FOLD: 2, EPOCH: 3, train_loss: 0.020838995558628136\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017617323196360044\n",
      "SEED: 940, FOLD: 2, EPOCH: 4, train_loss: 0.020350349149194317\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 4, valid_loss: 0.01722237363989864\n",
      "SEED: 940, FOLD: 2, EPOCH: 5, train_loss: 0.02030685808563578\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01729101857968739\n",
      "SEED: 940, FOLD: 2, EPOCH: 6, train_loss: 0.020238450755351696\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017177968685116087\n",
      "SEED: 940, FOLD: 2, EPOCH: 7, train_loss: 0.020158932908721592\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017422201564269407\n",
      "SEED: 940, FOLD: 2, EPOCH: 8, train_loss: 0.02020547534946514\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017215248809329103\n",
      "SEED: 940, FOLD: 2, EPOCH: 9, train_loss: 0.02019970043413881\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 9, valid_loss: 0.016991134599915574\n",
      "SEED: 940, FOLD: 2, EPOCH: 10, train_loss: 0.020099834215057934\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017279223299452237\n",
      "SEED: 940, FOLD: 2, EPOCH: 11, train_loss: 0.020101658959427605\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 11, valid_loss: 0.017453538626432417\n",
      "SEED: 940, FOLD: 2, EPOCH: 12, train_loss: 0.02012361573946217\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01711676155350038\n",
      "SEED: 940, FOLD: 2, EPOCH: 13, train_loss: 0.019886937424324562\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016847327990191324\n",
      "SEED: 940, FOLD: 2, EPOCH: 14, train_loss: 0.019754245431850784\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016925621644726822\n",
      "SEED: 940, FOLD: 2, EPOCH: 15, train_loss: 0.01955983550220296\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016659288853406905\n",
      "SEED: 940, FOLD: 2, EPOCH: 16, train_loss: 0.019322750590525677\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016562603121357305\n",
      "SEED: 940, FOLD: 2, EPOCH: 17, train_loss: 0.01906107106934423\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016565859876573087\n",
      "SEED: 940, FOLD: 2, EPOCH: 18, train_loss: 0.018792744105060894\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016465836656945093\n",
      "SEED: 940, FOLD: 2, EPOCH: 19, train_loss: 0.01836234497824225\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01630113303129162\n",
      "SEED: 940, FOLD: 2, EPOCH: 20, train_loss: 0.01791371691270151\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 20, valid_loss: 0.016126766268696104\n",
      "SEED: 940, FOLD: 2, EPOCH: 21, train_loss: 0.017422712954652052\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01608825743730579\n",
      "SEED: 940, FOLD: 2, EPOCH: 22, train_loss: 0.01690454204040377\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01598263199308089\n",
      "SEED: 940, FOLD: 2, EPOCH: 23, train_loss: 0.016470805883569563\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01603211819061211\n",
      "SEED: 940, FOLD: 2, EPOCH: 24, train_loss: 0.016262996752840885\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01604032013565302\n",
      "SEED: 940, FOLD: 3, EPOCH: 0, train_loss: 0.4705053523884735\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 0, valid_loss: 0.02497671406183924\n",
      "SEED: 940, FOLD: 3, EPOCH: 1, train_loss: 0.023680464216116547\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 1, valid_loss: 0.021801588843975747\n",
      "SEED: 940, FOLD: 3, EPOCH: 2, train_loss: 0.02202840961947821\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018272418528795242\n",
      "SEED: 940, FOLD: 3, EPOCH: 3, train_loss: 0.02090983185917139\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 3, valid_loss: 0.017675888910889625\n",
      "SEED: 940, FOLD: 3, EPOCH: 4, train_loss: 0.02023978767565627\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 4, valid_loss: 0.01756035712148462\n",
      "SEED: 940, FOLD: 3, EPOCH: 5, train_loss: 0.020182113689572914\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017260003834962845\n",
      "SEED: 940, FOLD: 3, EPOCH: 6, train_loss: 0.020078192154566448\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017447111276643616\n",
      "SEED: 940, FOLD: 3, EPOCH: 7, train_loss: 0.02019817978683589\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017188436617808684\n",
      "SEED: 940, FOLD: 3, EPOCH: 8, train_loss: 0.020114623023655968\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017838242437158314\n",
      "SEED: 940, FOLD: 3, EPOCH: 9, train_loss: 0.02008980713730705\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 9, valid_loss: 0.017477127031556197\n",
      "SEED: 940, FOLD: 3, EPOCH: 10, train_loss: 0.020104741326708725\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017366774034287248\n",
      "SEED: 940, FOLD: 3, EPOCH: 11, train_loss: 0.0200751151052722\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01720959421779428\n",
      "SEED: 940, FOLD: 3, EPOCH: 12, train_loss: 0.019961568122000797\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 12, valid_loss: 0.0170134859425681\n",
      "SEED: 940, FOLD: 3, EPOCH: 13, train_loss: 0.019782969566143078\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 13, valid_loss: 0.017340129534048693\n",
      "SEED: 940, FOLD: 3, EPOCH: 14, train_loss: 0.01965193005035753\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01688144677983863\n",
      "SEED: 940, FOLD: 3, EPOCH: 15, train_loss: 0.01942586068711851\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016802123188972472\n",
      "SEED: 940, FOLD: 3, EPOCH: 16, train_loss: 0.019214883352211422\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 16, valid_loss: 0.01669385191053152\n",
      "SEED: 940, FOLD: 3, EPOCH: 17, train_loss: 0.01894978622811428\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016474428666489464\n",
      "SEED: 940, FOLD: 3, EPOCH: 18, train_loss: 0.018648100267771795\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016436442892466274\n",
      "SEED: 940, FOLD: 3, EPOCH: 19, train_loss: 0.018204368084021236\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016350595466792583\n",
      "SEED: 940, FOLD: 3, EPOCH: 20, train_loss: 0.01765222713837157\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016237180520381245\n",
      "SEED: 940, FOLD: 3, EPOCH: 21, train_loss: 0.017043149355205074\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016243361149515426\n",
      "SEED: 940, FOLD: 3, EPOCH: 22, train_loss: 0.01643187944790807\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01620818323322705\n",
      "SEED: 940, FOLD: 3, EPOCH: 23, train_loss: 0.01602652067642497\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01621205128197159\n",
      "SEED: 940, FOLD: 3, EPOCH: 24, train_loss: 0.015792468292773632\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016242898282195842\n",
      "SEED: 940, FOLD: 4, EPOCH: 0, train_loss: 0.4698299863578185\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 0, valid_loss: 0.02314047318484102\n",
      "SEED: 940, FOLD: 4, EPOCH: 1, train_loss: 0.02364226732996927\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 1, valid_loss: 0.01894268308367048\n",
      "SEED: 940, FOLD: 4, EPOCH: 2, train_loss: 0.0219224554527065\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 2, valid_loss: 0.017981359335993017\n",
      "SEED: 940, FOLD: 4, EPOCH: 3, train_loss: 0.020859186591553516\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01766908344413553\n",
      "SEED: 940, FOLD: 4, EPOCH: 4, train_loss: 0.02026199210651111\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017231247095125062\n",
      "SEED: 940, FOLD: 4, EPOCH: 5, train_loss: 0.020262247288896553\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017403749376535417\n",
      "SEED: 940, FOLD: 4, EPOCH: 6, train_loss: 0.02011988453728997\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01723526969019856\n",
      "SEED: 940, FOLD: 4, EPOCH: 7, train_loss: 0.020143405210388744\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01722336576453277\n",
      "SEED: 940, FOLD: 4, EPOCH: 8, train_loss: 0.020093521832124046\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017009673081338404\n",
      "SEED: 940, FOLD: 4, EPOCH: 9, train_loss: 0.02012932866109886\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017023634245353084\n",
      "SEED: 940, FOLD: 4, EPOCH: 10, train_loss: 0.020099102006550285\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017018212218369758\n",
      "SEED: 940, FOLD: 4, EPOCH: 11, train_loss: 0.02006692539198675\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01712296743478094\n",
      "SEED: 940, FOLD: 4, EPOCH: 12, train_loss: 0.019875601122992626\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016870397169675144\n",
      "SEED: 940, FOLD: 4, EPOCH: 13, train_loss: 0.01982583656259205\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016889048660440106\n",
      "SEED: 940, FOLD: 4, EPOCH: 14, train_loss: 0.019726375549815704\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016921098131154264\n",
      "SEED: 940, FOLD: 4, EPOCH: 15, train_loss: 0.019544904538686726\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016671273431607656\n",
      "SEED: 940, FOLD: 4, EPOCH: 16, train_loss: 0.019372836943121925\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016475015319883823\n",
      "SEED: 940, FOLD: 4, EPOCH: 17, train_loss: 0.019046781368661617\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016407281000699315\n",
      "SEED: 940, FOLD: 4, EPOCH: 18, train_loss: 0.018726064432142437\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01629202485616718\n",
      "SEED: 940, FOLD: 4, EPOCH: 19, train_loss: 0.01831982651239504\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016154818502920016\n",
      "SEED: 940, FOLD: 4, EPOCH: 20, train_loss: 0.01784966657937005\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016044764327151434\n",
      "SEED: 940, FOLD: 4, EPOCH: 21, train_loss: 0.017305767865500588\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01594336639557566\n",
      "SEED: 940, FOLD: 4, EPOCH: 22, train_loss: 0.016737095437997927\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 22, valid_loss: 0.01596398994858776\n",
      "SEED: 940, FOLD: 4, EPOCH: 23, train_loss: 0.016284045520360054\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01591901079352413\n",
      "SEED: 940, FOLD: 4, EPOCH: 24, train_loss: 0.01602839738589482\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015916618225829942\n",
      "SEED: 1513, FOLD: 0, EPOCH: 0, train_loss: 0.4703520646696721\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 0, valid_loss: 0.02468744856970651\n",
      "SEED: 1513, FOLD: 0, EPOCH: 1, train_loss: 0.023763856027221333\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 1, valid_loss: 0.01872725510703666\n",
      "SEED: 1513, FOLD: 0, EPOCH: 2, train_loss: 0.0228827941244927\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 2, valid_loss: 0.018076472144041743\n",
      "SEED: 1513, FOLD: 0, EPOCH: 3, train_loss: 0.02106351995219787\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017333313157515868\n",
      "SEED: 1513, FOLD: 0, EPOCH: 4, train_loss: 0.020384670883093193\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017269115921642098\n",
      "SEED: 1513, FOLD: 0, EPOCH: 5, train_loss: 0.020282141283910343\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017424349885966098\n",
      "SEED: 1513, FOLD: 0, EPOCH: 6, train_loss: 0.02032620732443056\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01729874805148159\n",
      "SEED: 1513, FOLD: 0, EPOCH: 7, train_loss: 0.020258009082813194\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01731123990778412\n",
      "SEED: 1513, FOLD: 0, EPOCH: 8, train_loss: 0.020188179393501385\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01761786158063582\n",
      "SEED: 1513, FOLD: 0, EPOCH: 9, train_loss: 0.020240676508325596\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01733983143099717\n",
      "SEED: 1513, FOLD: 0, EPOCH: 10, train_loss: 0.02010371783019408\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017195072663681848\n",
      "SEED: 1513, FOLD: 0, EPOCH: 11, train_loss: 0.020085257977463196\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01720097347029618\n",
      "SEED: 1513, FOLD: 0, EPOCH: 12, train_loss: 0.020003433244815773\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01697427989648921\n",
      "SEED: 1513, FOLD: 0, EPOCH: 13, train_loss: 0.01979947380343641\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 13, valid_loss: 0.017099094577133656\n",
      "SEED: 1513, FOLD: 0, EPOCH: 14, train_loss: 0.019765281671847122\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016852353167321\n",
      "SEED: 1513, FOLD: 0, EPOCH: 15, train_loss: 0.019576745958107968\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01684199587575027\n",
      "SEED: 1513, FOLD: 0, EPOCH: 16, train_loss: 0.019385214287625706\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01656383621905531\n",
      "SEED: 1513, FOLD: 0, EPOCH: 17, train_loss: 0.019046806406391704\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016420705510037287\n",
      "SEED: 1513, FOLD: 0, EPOCH: 18, train_loss: 0.01878823494484675\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016358348141823496\n",
      "SEED: 1513, FOLD: 0, EPOCH: 19, train_loss: 0.018378736235309338\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016179548230554376\n",
      "SEED: 1513, FOLD: 0, EPOCH: 20, train_loss: 0.01785685620068208\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016112873596804484\n",
      "SEED: 1513, FOLD: 0, EPOCH: 21, train_loss: 0.017284751626784386\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015954802078860148\n",
      "SEED: 1513, FOLD: 0, EPOCH: 22, train_loss: 0.016777333749485188\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01593536428575005\n",
      "SEED: 1513, FOLD: 0, EPOCH: 23, train_loss: 0.016289474321124348\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01596553030290774\n",
      "SEED: 1513, FOLD: 0, EPOCH: 24, train_loss: 0.01606145559175723\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015951366829020635\n",
      "SEED: 1513, FOLD: 1, EPOCH: 0, train_loss: 0.47082636786111887\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 0, valid_loss: 0.02380216813513211\n",
      "SEED: 1513, FOLD: 1, EPOCH: 1, train_loss: 0.023727129510455372\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 1, valid_loss: 0.01888812759092876\n",
      "SEED: 1513, FOLD: 1, EPOCH: 2, train_loss: 0.021719961724095585\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 2, valid_loss: 0.02021299685750689\n",
      "SEED: 1513, FOLD: 1, EPOCH: 3, train_loss: 0.020711453995950844\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 3, valid_loss: 0.018538251519203186\n",
      "SEED: 1513, FOLD: 1, EPOCH: 4, train_loss: 0.02024381752193406\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017500084399112634\n",
      "SEED: 1513, FOLD: 1, EPOCH: 5, train_loss: 0.020125367206291878\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017227294562118394\n",
      "SEED: 1513, FOLD: 1, EPOCH: 6, train_loss: 0.020139929217596848\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 6, valid_loss: 0.01716949338359492\n",
      "SEED: 1513, FOLD: 1, EPOCH: 7, train_loss: 0.020091887995384743\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017350693845323156\n",
      "SEED: 1513, FOLD: 1, EPOCH: 8, train_loss: 0.020102715322180935\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017098316576864038\n",
      "SEED: 1513, FOLD: 1, EPOCH: 9, train_loss: 0.020090294502459576\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01715701368770429\n",
      "SEED: 1513, FOLD: 1, EPOCH: 10, train_loss: 0.02013549621662368\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01702342727886779\n",
      "SEED: 1513, FOLD: 1, EPOCH: 11, train_loss: 0.019986241853431515\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017065735374178204\n",
      "SEED: 1513, FOLD: 1, EPOCH: 12, train_loss: 0.019953514030878094\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 12, valid_loss: 0.017055253604693073\n",
      "SEED: 1513, FOLD: 1, EPOCH: 13, train_loss: 0.019842416358490784\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01691500996904714\n",
      "SEED: 1513, FOLD: 1, EPOCH: 14, train_loss: 0.019755971523514694\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016715731019420282\n",
      "SEED: 1513, FOLD: 1, EPOCH: 15, train_loss: 0.019537392193856445\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016568847160254207\n",
      "SEED: 1513, FOLD: 1, EPOCH: 16, train_loss: 0.019360759794928024\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016587458444493157\n",
      "SEED: 1513, FOLD: 1, EPOCH: 17, train_loss: 0.019103448298098385\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 17, valid_loss: 0.01647712194493839\n",
      "SEED: 1513, FOLD: 1, EPOCH: 18, train_loss: 0.018705150470191587\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01631604270743472\n",
      "SEED: 1513, FOLD: 1, EPOCH: 19, train_loss: 0.018325656956142706\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01620901221675532\n",
      "SEED: 1513, FOLD: 1, EPOCH: 20, train_loss: 0.017788866798028997\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016143732597785336\n",
      "SEED: 1513, FOLD: 1, EPOCH: 21, train_loss: 0.017191030247055965\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 21, valid_loss: 0.016047183477452823\n",
      "SEED: 1513, FOLD: 1, EPOCH: 22, train_loss: 0.016606460089214903\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 22, valid_loss: 0.016077075978474957\n",
      "SEED: 1513, FOLD: 1, EPOCH: 23, train_loss: 0.016171774698718302\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01606351610805307\n",
      "SEED: 1513, FOLD: 1, EPOCH: 24, train_loss: 0.015948897335624348\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 24, valid_loss: 0.016054626234940122\n",
      "SEED: 1513, FOLD: 2, EPOCH: 0, train_loss: 0.46958023585055186\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 0, valid_loss: 0.0244343103574855\n",
      "SEED: 1513, FOLD: 2, EPOCH: 1, train_loss: 0.023957832297985104\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 1, valid_loss: 0.01951797663101128\n",
      "SEED: 1513, FOLD: 2, EPOCH: 2, train_loss: 0.02183892837037211\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 2, valid_loss: 0.017851122867848193\n",
      "SEED: 1513, FOLD: 2, EPOCH: 3, train_loss: 0.020711365803752258\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017353205436042376\n",
      "SEED: 1513, FOLD: 2, EPOCH: 4, train_loss: 0.020170060850247955\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017234175971576147\n",
      "SEED: 1513, FOLD: 2, EPOCH: 5, train_loss: 0.02012510441135669\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017273364535399845\n",
      "SEED: 1513, FOLD: 2, EPOCH: 6, train_loss: 0.02016784570625295\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01718881627810853\n",
      "SEED: 1513, FOLD: 2, EPOCH: 7, train_loss: 0.020267071688304775\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017322644644549915\n",
      "SEED: 1513, FOLD: 2, EPOCH: 8, train_loss: 0.02020138557460429\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01735017259738275\n",
      "SEED: 1513, FOLD: 2, EPOCH: 9, train_loss: 0.02017199145495028\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 9, valid_loss: 0.017008180171251296\n",
      "SEED: 1513, FOLD: 2, EPOCH: 10, train_loss: 0.02010443594738625\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017104422886456763\n",
      "SEED: 1513, FOLD: 2, EPOCH: 11, train_loss: 0.020017868015861164\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 11, valid_loss: 0.017337099223264627\n",
      "SEED: 1513, FOLD: 2, EPOCH: 12, train_loss: 0.019993874392863632\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01682927901191371\n",
      "SEED: 1513, FOLD: 2, EPOCH: 13, train_loss: 0.01986033157647952\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 13, valid_loss: 0.01690915479723896\n",
      "SEED: 1513, FOLD: 2, EPOCH: 14, train_loss: 0.019744347969906918\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016721067151853015\n",
      "SEED: 1513, FOLD: 2, EPOCH: 15, train_loss: 0.019574055542656475\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016685535359595504\n",
      "SEED: 1513, FOLD: 2, EPOCH: 16, train_loss: 0.019360045969918156\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016525694036058018\n",
      "SEED: 1513, FOLD: 2, EPOCH: 17, train_loss: 0.019062562643185905\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016467339944626604\n",
      "SEED: 1513, FOLD: 2, EPOCH: 18, train_loss: 0.018749260465088097\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016297020709940366\n",
      "SEED: 1513, FOLD: 2, EPOCH: 19, train_loss: 0.018331986042144505\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016239062856350628\n",
      "SEED: 1513, FOLD: 2, EPOCH: 20, train_loss: 0.01785505869412336\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01608028837612697\n",
      "SEED: 1513, FOLD: 2, EPOCH: 21, train_loss: 0.017292863068481285\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 21, valid_loss: 0.015998178347945213\n",
      "SEED: 1513, FOLD: 2, EPOCH: 22, train_loss: 0.016714002309448046\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01596547860120024\n",
      "SEED: 1513, FOLD: 2, EPOCH: 23, train_loss: 0.016239147154155417\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015952681244484016\n",
      "SEED: 1513, FOLD: 2, EPOCH: 24, train_loss: 0.01604088868918842\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 24, valid_loss: 0.015974046502794537\n",
      "SEED: 1513, FOLD: 3, EPOCH: 0, train_loss: 0.4702085381427753\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 0, valid_loss: 0.024361002179128784\n",
      "SEED: 1513, FOLD: 3, EPOCH: 1, train_loss: 0.023700966783191845\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 1, valid_loss: 0.01974916851946286\n",
      "SEED: 1513, FOLD: 3, EPOCH: 2, train_loss: 0.021921215659898262\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 2, valid_loss: 0.01853981518319675\n",
      "SEED: 1513, FOLD: 3, EPOCH: 3, train_loss: 0.020737489860882793\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 3, valid_loss: 0.017487863823771477\n",
      "SEED: 1513, FOLD: 3, EPOCH: 4, train_loss: 0.02017549195907254\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 4, valid_loss: 0.01754270073558603\n",
      "SEED: 1513, FOLD: 3, EPOCH: 5, train_loss: 0.02008653630543014\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017342186266822473\n",
      "SEED: 1513, FOLD: 3, EPOCH: 6, train_loss: 0.020046820945065956\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017640368826687337\n",
      "SEED: 1513, FOLD: 3, EPOCH: 7, train_loss: 0.020162760927949264\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01747000954513039\n",
      "SEED: 1513, FOLD: 3, EPOCH: 8, train_loss: 0.02009718657295773\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017392355895468167\n",
      "SEED: 1513, FOLD: 3, EPOCH: 9, train_loss: 0.020137298663241276\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01717250131602798\n",
      "SEED: 1513, FOLD: 3, EPOCH: 10, train_loss: 0.02006039393228897\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017448050289281775\n",
      "SEED: 1513, FOLD: 3, EPOCH: 11, train_loss: 0.0200098504487803\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 11, valid_loss: 0.0176701051316091\n",
      "SEED: 1513, FOLD: 3, EPOCH: 12, train_loss: 0.019949316735500874\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 12, valid_loss: 0.01709080154874495\n",
      "SEED: 1513, FOLD: 3, EPOCH: 13, train_loss: 0.019850748469648155\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 13, valid_loss: 0.017168747766741686\n",
      "SEED: 1513, FOLD: 3, EPOCH: 14, train_loss: 0.0196218263303888\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01711331656468766\n",
      "SEED: 1513, FOLD: 3, EPOCH: 15, train_loss: 0.019482541856342468\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01690653719540153\n",
      "SEED: 1513, FOLD: 3, EPOCH: 16, train_loss: 0.019251171998895596\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016799530839281422\n",
      "SEED: 1513, FOLD: 3, EPOCH: 17, train_loss: 0.018969520852239668\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016926178123269763\n",
      "SEED: 1513, FOLD: 3, EPOCH: 18, train_loss: 0.018665743600307167\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 18, valid_loss: 0.01656260908182178\n",
      "SEED: 1513, FOLD: 3, EPOCH: 19, train_loss: 0.01821761580346071\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016353318893483706\n",
      "SEED: 1513, FOLD: 3, EPOCH: 20, train_loss: 0.017724287095547155\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016344075969287327\n",
      "SEED: 1513, FOLD: 3, EPOCH: 21, train_loss: 0.017129739570984806\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016226124869925636\n",
      "SEED: 1513, FOLD: 3, EPOCH: 22, train_loss: 0.01652261557435428\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01624036394059658\n",
      "SEED: 1513, FOLD: 3, EPOCH: 23, train_loss: 0.01611705104806933\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016254329468522753\n",
      "SEED: 1513, FOLD: 3, EPOCH: 24, train_loss: 0.015884977387453335\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016236722362892968\n",
      "SEED: 1513, FOLD: 4, EPOCH: 0, train_loss: 0.4705649203742328\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 0, valid_loss: 0.02504995891026088\n",
      "SEED: 1513, FOLD: 4, EPOCH: 1, train_loss: 0.0238266765423443\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 1, valid_loss: 0.0189557459205389\n",
      "SEED: 1513, FOLD: 4, EPOCH: 2, train_loss: 0.022485272621438988\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018776918681604523\n",
      "SEED: 1513, FOLD: 4, EPOCH: 3, train_loss: 0.021081524806610054\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01830321986760412\n",
      "SEED: 1513, FOLD: 4, EPOCH: 4, train_loss: 0.020568547486934975\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017632988201720375\n",
      "SEED: 1513, FOLD: 4, EPOCH: 5, train_loss: 0.02028906319722317\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 5, valid_loss: 0.018837807061416762\n",
      "SEED: 1513, FOLD: 4, EPOCH: 6, train_loss: 0.020415828914206097\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017461665852793625\n",
      "SEED: 1513, FOLD: 4, EPOCH: 7, train_loss: 0.020209871569945328\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017348332170929227\n",
      "SEED: 1513, FOLD: 4, EPOCH: 8, train_loss: 0.02031364991073159\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017273143120110034\n",
      "SEED: 1513, FOLD: 4, EPOCH: 9, train_loss: 0.020251272286733856\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 9, valid_loss: 0.01710092108696699\n",
      "SEED: 1513, FOLD: 4, EPOCH: 10, train_loss: 0.020242943495943928\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017084522758211408\n",
      "SEED: 1513, FOLD: 4, EPOCH: 11, train_loss: 0.02012933567976174\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 11, valid_loss: 0.017052598616906573\n",
      "SEED: 1513, FOLD: 4, EPOCH: 12, train_loss: 0.02006802255746679\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016953422129154204\n",
      "SEED: 1513, FOLD: 4, EPOCH: 13, train_loss: 0.01999666046459174\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01685408598610333\n",
      "SEED: 1513, FOLD: 4, EPOCH: 14, train_loss: 0.019783189088322113\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016817503635372433\n",
      "SEED: 1513, FOLD: 4, EPOCH: 15, train_loss: 0.019602840050946976\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016560345302735056\n",
      "SEED: 1513, FOLD: 4, EPOCH: 16, train_loss: 0.019444227380597073\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01654053365013429\n",
      "SEED: 1513, FOLD: 4, EPOCH: 17, train_loss: 0.01916345627303573\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016432522636439118\n",
      "SEED: 1513, FOLD: 4, EPOCH: 18, train_loss: 0.018854319090968456\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01629689397024257\n",
      "SEED: 1513, FOLD: 4, EPOCH: 19, train_loss: 0.018381132595780968\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01618473638913461\n",
      "SEED: 1513, FOLD: 4, EPOCH: 20, train_loss: 0.01798383711391817\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016098404595894473\n",
      "SEED: 1513, FOLD: 4, EPOCH: 21, train_loss: 0.017353738651381456\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 21, valid_loss: 0.016021342096584183\n",
      "SEED: 1513, FOLD: 4, EPOCH: 22, train_loss: 0.01682041264206603\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 22, valid_loss: 0.016004260443150998\n",
      "SEED: 1513, FOLD: 4, EPOCH: 23, train_loss: 0.01639097646229725\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01597626664276634\n",
      "SEED: 1513, FOLD: 4, EPOCH: 24, train_loss: 0.016116796668780888\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01598264511142458\n",
      "SEED: 1269, FOLD: 0, EPOCH: 0, train_loss: 0.47258509650988423\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 0, valid_loss: 0.0254850943173681\n",
      "SEED: 1269, FOLD: 0, EPOCH: 1, train_loss: 0.023802423917189026\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 1, valid_loss: 0.019256007352045603\n",
      "SEED: 1269, FOLD: 0, EPOCH: 2, train_loss: 0.02245258986679972\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 2, valid_loss: 0.02085249647498131\n",
      "SEED: 1269, FOLD: 0, EPOCH: 3, train_loss: 0.021760463147707607\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017582333726542335\n",
      "SEED: 1269, FOLD: 0, EPOCH: 4, train_loss: 0.020568448145860348\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 4, valid_loss: 0.01775532564414399\n",
      "SEED: 1269, FOLD: 0, EPOCH: 5, train_loss: 0.02024786757386249\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017825311954532352\n",
      "SEED: 1269, FOLD: 0, EPOCH: 6, train_loss: 0.020281252734687016\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 6, valid_loss: 0.0173838201378073\n",
      "SEED: 1269, FOLD: 0, EPOCH: 7, train_loss: 0.020252272014276707\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017396143158631666\n",
      "SEED: 1269, FOLD: 0, EPOCH: 8, train_loss: 0.020262368131374966\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01727404429444245\n",
      "SEED: 1269, FOLD: 0, EPOCH: 9, train_loss: 0.020204674493035545\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017578965558537416\n",
      "SEED: 1269, FOLD: 0, EPOCH: 10, train_loss: 0.02016360358591529\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 10, valid_loss: 0.01712294215602534\n",
      "SEED: 1269, FOLD: 0, EPOCH: 11, train_loss: 0.020101818984941296\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01745588614472321\n",
      "SEED: 1269, FOLD: 0, EPOCH: 12, train_loss: 0.020026447021982807\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 12, valid_loss: 0.017045878831829342\n",
      "SEED: 1269, FOLD: 0, EPOCH: 13, train_loss: 0.019889252759732197\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016852356387036187\n",
      "SEED: 1269, FOLD: 0, EPOCH: 14, train_loss: 0.01973396719203911\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016821962728032044\n",
      "SEED: 1269, FOLD: 0, EPOCH: 15, train_loss: 0.019576901920895645\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016673296317458154\n",
      "SEED: 1269, FOLD: 0, EPOCH: 16, train_loss: 0.019346901957971462\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016685322299599646\n",
      "SEED: 1269, FOLD: 0, EPOCH: 17, train_loss: 0.01907033355825621\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01645796000957489\n",
      "SEED: 1269, FOLD: 0, EPOCH: 18, train_loss: 0.018761231496498203\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016464684158563614\n",
      "SEED: 1269, FOLD: 0, EPOCH: 19, train_loss: 0.018410695109354412\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016273470329386846\n",
      "SEED: 1269, FOLD: 0, EPOCH: 20, train_loss: 0.017919097136220207\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016107454550053392\n",
      "SEED: 1269, FOLD: 0, EPOCH: 21, train_loss: 0.017324297014029995\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015995057273123947\n",
      "SEED: 1269, FOLD: 0, EPOCH: 22, train_loss: 0.016716822630901268\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01592772946293865\n",
      "SEED: 1269, FOLD: 0, EPOCH: 23, train_loss: 0.016308101177539513\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015903937523918492\n",
      "SEED: 1269, FOLD: 0, EPOCH: 24, train_loss: 0.016099186263222626\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015901206832911286\n",
      "SEED: 1269, FOLD: 1, EPOCH: 0, train_loss: 0.47105829498690105\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 0, valid_loss: 0.0266524360116039\n",
      "SEED: 1269, FOLD: 1, EPOCH: 1, train_loss: 0.02392630207527807\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 1, valid_loss: 0.018915835289018496\n",
      "SEED: 1269, FOLD: 1, EPOCH: 2, train_loss: 0.0218659534888423\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 2, valid_loss: 0.018303314915725163\n",
      "SEED: 1269, FOLD: 1, EPOCH: 3, train_loss: 0.020717025154094765\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 3, valid_loss: 0.017371039810989586\n",
      "SEED: 1269, FOLD: 1, EPOCH: 4, train_loss: 0.0204121892111025\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017480012827685902\n",
      "SEED: 1269, FOLD: 1, EPOCH: 5, train_loss: 0.0202234396306069\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017297110493694035\n",
      "SEED: 1269, FOLD: 1, EPOCH: 6, train_loss: 0.020242446601606796\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017393219524196216\n",
      "SEED: 1269, FOLD: 1, EPOCH: 7, train_loss: 0.020203075844092644\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017451683485082217\n",
      "SEED: 1269, FOLD: 1, EPOCH: 8, train_loss: 0.020191011423973934\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 8, valid_loss: 0.01715436838567257\n",
      "SEED: 1269, FOLD: 1, EPOCH: 9, train_loss: 0.020170280642375565\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 9, valid_loss: 0.017163172151361192\n",
      "SEED: 1269, FOLD: 1, EPOCH: 10, train_loss: 0.020108395849988945\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 10, valid_loss: 0.017247655881302698\n",
      "SEED: 1269, FOLD: 1, EPOCH: 11, train_loss: 0.020120684286930424\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017145087915871826\n",
      "SEED: 1269, FOLD: 1, EPOCH: 12, train_loss: 0.02008284527160551\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01704272712979998\n",
      "SEED: 1269, FOLD: 1, EPOCH: 13, train_loss: 0.019919039924507557\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016861397214233874\n",
      "SEED: 1269, FOLD: 1, EPOCH: 14, train_loss: 0.01975516148208492\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016916797789079802\n",
      "SEED: 1269, FOLD: 1, EPOCH: 15, train_loss: 0.01957091790340517\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01682284924068621\n",
      "SEED: 1269, FOLD: 1, EPOCH: 16, train_loss: 0.019363219795775585\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 16, valid_loss: 0.01665597789521728\n",
      "SEED: 1269, FOLD: 1, EPOCH: 17, train_loss: 0.01913200522624496\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 17, valid_loss: 0.01658847906759807\n",
      "SEED: 1269, FOLD: 1, EPOCH: 18, train_loss: 0.018833032559495474\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01637789173317807\n",
      "SEED: 1269, FOLD: 1, EPOCH: 19, train_loss: 0.01840963031745691\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016202884939100062\n",
      "SEED: 1269, FOLD: 1, EPOCH: 20, train_loss: 0.01792544176451106\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016089499395872866\n",
      "SEED: 1269, FOLD: 1, EPOCH: 21, train_loss: 0.01738209024314647\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 21, valid_loss: 0.016033451152699333\n",
      "SEED: 1269, FOLD: 1, EPOCH: 22, train_loss: 0.016866213864768328\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015969982131251267\n",
      "SEED: 1269, FOLD: 1, EPOCH: 23, train_loss: 0.016411700009273878\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 23, valid_loss: 0.016019154100545815\n",
      "SEED: 1269, FOLD: 1, EPOCH: 24, train_loss: 0.016217781041843304\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 24, valid_loss: 0.01598901783249208\n",
      "SEED: 1269, FOLD: 2, EPOCH: 0, train_loss: 0.47087701142806077\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 0, valid_loss: 0.025248308533004353\n",
      "SEED: 1269, FOLD: 2, EPOCH: 1, train_loss: 0.02371261127131141\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 1, valid_loss: 0.018945961498788425\n",
      "SEED: 1269, FOLD: 2, EPOCH: 2, train_loss: 0.022244743260460487\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 2, valid_loss: 0.04750065164906638\n",
      "SEED: 1269, FOLD: 2, EPOCH: 3, train_loss: 0.020884673759017303\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017483447013156756\n",
      "SEED: 1269, FOLD: 2, EPOCH: 4, train_loss: 0.020366607571317665\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 4, valid_loss: 0.0177231599177633\n",
      "SEED: 1269, FOLD: 2, EPOCH: 5, train_loss: 0.020209765169715534\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01733121975724186\n",
      "SEED: 1269, FOLD: 2, EPOCH: 6, train_loss: 0.020269977536214435\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017209983244538308\n",
      "SEED: 1269, FOLD: 2, EPOCH: 7, train_loss: 0.020233843246123928\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017126796740506378\n",
      "SEED: 1269, FOLD: 2, EPOCH: 8, train_loss: 0.02024662014150965\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017162848955818585\n",
      "SEED: 1269, FOLD: 2, EPOCH: 9, train_loss: 0.02020725652413524\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01714084539562464\n",
      "SEED: 1269, FOLD: 2, EPOCH: 10, train_loss: 0.020139855427154595\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017065365905208248\n",
      "SEED: 1269, FOLD: 2, EPOCH: 11, train_loss: 0.020062031224370003\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 11, valid_loss: 0.01707664430141449\n",
      "SEED: 1269, FOLD: 2, EPOCH: 12, train_loss: 0.019980123968444008\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016984039252357825\n",
      "SEED: 1269, FOLD: 2, EPOCH: 13, train_loss: 0.019892840794679047\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016974469779857566\n",
      "SEED: 1269, FOLD: 2, EPOCH: 14, train_loss: 0.019735927450592102\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016788944069828306\n",
      "SEED: 1269, FOLD: 2, EPOCH: 15, train_loss: 0.01954714346515096\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01676917334220239\n",
      "SEED: 1269, FOLD: 2, EPOCH: 16, train_loss: 0.019384065791424633\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016486896388232707\n",
      "SEED: 1269, FOLD: 2, EPOCH: 17, train_loss: 0.019080464606699737\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016456241000975882\n",
      "SEED: 1269, FOLD: 2, EPOCH: 18, train_loss: 0.018771925752145657\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016362897173634598\n",
      "SEED: 1269, FOLD: 2, EPOCH: 19, train_loss: 0.01841916664220069\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016166649412895952\n",
      "SEED: 1269, FOLD: 2, EPOCH: 20, train_loss: 0.017923872850403404\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 20, valid_loss: 0.016003540344536306\n",
      "SEED: 1269, FOLD: 2, EPOCH: 21, train_loss: 0.017339783761164417\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016036383834268364\n",
      "SEED: 1269, FOLD: 2, EPOCH: 22, train_loss: 0.01674054297146158\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 22, valid_loss: 0.016044916452041695\n",
      "SEED: 1269, FOLD: 2, EPOCH: 23, train_loss: 0.016307281397714996\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 23, valid_loss: 0.016014749902699674\n",
      "SEED: 1269, FOLD: 2, EPOCH: 24, train_loss: 0.01613865657777026\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 24, valid_loss: 0.016002334601112774\n",
      "SEED: 1269, FOLD: 3, EPOCH: 0, train_loss: 0.4719382741124086\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 0, valid_loss: 0.0256246344851596\n",
      "SEED: 1269, FOLD: 3, EPOCH: 1, train_loss: 0.02380364795849807\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 1, valid_loss: 0.022078601164477213\n",
      "SEED: 1269, FOLD: 3, EPOCH: 2, train_loss: 0.021981300367717293\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018500378515039172\n",
      "SEED: 1269, FOLD: 3, EPOCH: 3, train_loss: 0.020807369612157345\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 3, valid_loss: 0.017947907612792083\n",
      "SEED: 1269, FOLD: 3, EPOCH: 4, train_loss: 0.020368426579280174\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017434403539768287\n",
      "SEED: 1269, FOLD: 3, EPOCH: 5, train_loss: 0.02043706669971563\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 5, valid_loss: 0.01744518144322293\n",
      "SEED: 1269, FOLD: 3, EPOCH: 6, train_loss: 0.02015732795647953\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017729350472135204\n",
      "SEED: 1269, FOLD: 3, EPOCH: 7, train_loss: 0.020149793921281463\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01736321050141539\n",
      "SEED: 1269, FOLD: 3, EPOCH: 8, train_loss: 0.020177051816405594\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017286600385393414\n",
      "SEED: 1269, FOLD: 3, EPOCH: 9, train_loss: 0.02015527254105478\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 9, valid_loss: 0.017552608491054604\n",
      "SEED: 1269, FOLD: 3, EPOCH: 10, train_loss: 0.020075099556234436\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 10, valid_loss: 0.01734310926071235\n",
      "SEED: 1269, FOLD: 3, EPOCH: 11, train_loss: 0.020107028830418552\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 11, valid_loss: 0.017199876558567796\n",
      "SEED: 1269, FOLD: 3, EPOCH: 12, train_loss: 0.019911731876756832\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 12, valid_loss: 0.01713481196867568\n",
      "SEED: 1269, FOLD: 3, EPOCH: 13, train_loss: 0.019872911085469135\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01722454210477216\n",
      "SEED: 1269, FOLD: 3, EPOCH: 14, train_loss: 0.019728800119913143\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016843389134321894\n",
      "SEED: 1269, FOLD: 3, EPOCH: 15, train_loss: 0.019505016478723373\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016801390424370767\n",
      "SEED: 1269, FOLD: 3, EPOCH: 16, train_loss: 0.019310816919997982\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 16, valid_loss: 0.01667405856507165\n",
      "SEED: 1269, FOLD: 3, EPOCH: 17, train_loss: 0.01907769998913442\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01658285805689437\n",
      "SEED: 1269, FOLD: 3, EPOCH: 18, train_loss: 0.01868808770255334\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016526736691594122\n",
      "SEED: 1269, FOLD: 3, EPOCH: 19, train_loss: 0.018369786151131426\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016447135673037596\n",
      "SEED: 1269, FOLD: 3, EPOCH: 20, train_loss: 0.017843817455181175\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016301356442272662\n",
      "SEED: 1269, FOLD: 3, EPOCH: 21, train_loss: 0.017248925098312506\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016241837106645108\n",
      "SEED: 1269, FOLD: 3, EPOCH: 22, train_loss: 0.01670182589441538\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 22, valid_loss: 0.016195829665022237\n",
      "SEED: 1269, FOLD: 3, EPOCH: 23, train_loss: 0.016222563835427813\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016220374165901115\n",
      "SEED: 1269, FOLD: 3, EPOCH: 24, train_loss: 0.016029469689111345\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 24, valid_loss: 0.01623233963868448\n",
      "SEED: 1269, FOLD: 4, EPOCH: 0, train_loss: 0.4709199544015354\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 0, valid_loss: 0.024815865659288\n",
      "SEED: 1269, FOLD: 4, EPOCH: 1, train_loss: 0.023656316209530483\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 1, valid_loss: 0.018737326402749332\n",
      "SEED: 1269, FOLD: 4, EPOCH: 2, train_loss: 0.022043919001800426\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 2, valid_loss: 0.017831380612083843\n",
      "SEED: 1269, FOLD: 4, EPOCH: 3, train_loss: 0.020670009533996166\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 3, valid_loss: 0.0172396560598697\n",
      "SEED: 1269, FOLD: 4, EPOCH: 4, train_loss: 0.020797966183095738\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017337478244943277\n",
      "SEED: 1269, FOLD: 4, EPOCH: 5, train_loss: 0.020260332975590576\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017336020884769304\n",
      "SEED: 1269, FOLD: 4, EPOCH: 6, train_loss: 0.02027905925406494\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017165684460529258\n",
      "SEED: 1269, FOLD: 4, EPOCH: 7, train_loss: 0.020233859861458557\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017246934425617966\n",
      "SEED: 1269, FOLD: 4, EPOCH: 8, train_loss: 0.020198821198141228\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017123155854642393\n",
      "SEED: 1269, FOLD: 4, EPOCH: 9, train_loss: 0.020166983962922855\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017307597478585585\n",
      "SEED: 1269, FOLD: 4, EPOCH: 10, train_loss: 0.020184945598568604\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01758922774876867\n",
      "SEED: 1269, FOLD: 4, EPOCH: 11, train_loss: 0.020124276209136715\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 11, valid_loss: 0.017128145561686584\n",
      "SEED: 1269, FOLD: 4, EPOCH: 12, train_loss: 0.020011424937325974\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016943858510681562\n",
      "SEED: 1269, FOLD: 4, EPOCH: 13, train_loss: 0.0198893117165004\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016878105806452888\n",
      "SEED: 1269, FOLD: 4, EPOCH: 14, train_loss: 0.019766929856353047\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016792972279446466\n",
      "SEED: 1269, FOLD: 4, EPOCH: 15, train_loss: 0.019628452272086903\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016533624061516355\n",
      "SEED: 1269, FOLD: 4, EPOCH: 16, train_loss: 0.01939024195830891\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016667961409049376\n",
      "SEED: 1269, FOLD: 4, EPOCH: 17, train_loss: 0.019149969561376434\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01632245403847524\n",
      "SEED: 1269, FOLD: 4, EPOCH: 18, train_loss: 0.01879422444904196\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016165946663490364\n",
      "SEED: 1269, FOLD: 4, EPOCH: 19, train_loss: 0.018395666451449844\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016218596936336586\n",
      "SEED: 1269, FOLD: 4, EPOCH: 20, train_loss: 0.01792904393126567\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016013154839830738\n",
      "SEED: 1269, FOLD: 4, EPOCH: 21, train_loss: 0.017323083946130413\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01602154097386769\n",
      "SEED: 1269, FOLD: 4, EPOCH: 22, train_loss: 0.016754579008219465\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 22, valid_loss: 0.01596181783825159\n",
      "SEED: 1269, FOLD: 4, EPOCH: 23, train_loss: 0.016354711888277012\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01590621378272772\n",
      "SEED: 1269, FOLD: 4, EPOCH: 24, train_loss: 0.016088415807841913\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015948001721075602\n",
      "SEED: 1392, FOLD: 0, EPOCH: 0, train_loss: 0.46942387406538794\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 0, valid_loss: 0.0247997023165226\n",
      "SEED: 1392, FOLD: 0, EPOCH: 1, train_loss: 0.023712535469752292\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 1, valid_loss: 0.018706350401043893\n",
      "SEED: 1392, FOLD: 0, EPOCH: 2, train_loss: 0.021971328872377457\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 2, valid_loss: 0.019522871316543646\n",
      "SEED: 1392, FOLD: 0, EPOCH: 3, train_loss: 0.020938100657709267\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 3, valid_loss: 0.01849158935781036\n",
      "SEED: 1392, FOLD: 0, EPOCH: 4, train_loss: 0.020511151102465996\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017338794443224156\n",
      "SEED: 1392, FOLD: 0, EPOCH: 5, train_loss: 0.020232783832951733\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017333705377365862\n",
      "SEED: 1392, FOLD: 0, EPOCH: 6, train_loss: 0.020199156163827232\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017179516330361366\n",
      "SEED: 1392, FOLD: 0, EPOCH: 7, train_loss: 0.020158112656487072\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01718168742954731\n",
      "SEED: 1392, FOLD: 0, EPOCH: 8, train_loss: 0.020224772704144318\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017151805731867042\n",
      "SEED: 1392, FOLD: 0, EPOCH: 9, train_loss: 0.020178178473767162\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01731215888368232\n",
      "SEED: 1392, FOLD: 0, EPOCH: 10, train_loss: 0.020102438489919987\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017396489770284723\n",
      "SEED: 1392, FOLD: 0, EPOCH: 11, train_loss: 0.020062016161239666\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 11, valid_loss: 0.017381312538470542\n",
      "SEED: 1392, FOLD: 0, EPOCH: 12, train_loss: 0.020068232536963795\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 12, valid_loss: 0.017088669911026956\n",
      "SEED: 1392, FOLD: 0, EPOCH: 13, train_loss: 0.019930046497155792\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 13, valid_loss: 0.017017987689801624\n",
      "SEED: 1392, FOLD: 0, EPOCH: 14, train_loss: 0.019763131484227335\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 14, valid_loss: 0.01696788149752787\n",
      "SEED: 1392, FOLD: 0, EPOCH: 15, train_loss: 0.019589271018470543\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016748605242797306\n",
      "SEED: 1392, FOLD: 0, EPOCH: 16, train_loss: 0.0193339372323691\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 16, valid_loss: 0.0165072341848697\n",
      "SEED: 1392, FOLD: 0, EPOCH: 17, train_loss: 0.0190707352552293\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016344962348895414\n",
      "SEED: 1392, FOLD: 0, EPOCH: 18, train_loss: 0.01868629948222551\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016265436155455452\n",
      "SEED: 1392, FOLD: 0, EPOCH: 19, train_loss: 0.01824700593462457\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 19, valid_loss: 0.01610216237604618\n",
      "SEED: 1392, FOLD: 0, EPOCH: 20, train_loss: 0.017843312320663877\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01606462254588093\n",
      "SEED: 1392, FOLD: 0, EPOCH: 21, train_loss: 0.01719346489298387\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015978721289762427\n",
      "SEED: 1392, FOLD: 0, EPOCH: 22, train_loss: 0.016612887099061325\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01596632386956896\n",
      "SEED: 1392, FOLD: 0, EPOCH: 23, train_loss: 0.016181633639000895\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015997401970837797\n",
      "SEED: 1392, FOLD: 0, EPOCH: 24, train_loss: 0.0159479890126681\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015986199118196966\n",
      "SEED: 1392, FOLD: 1, EPOCH: 0, train_loss: 0.4701697213602239\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 0, valid_loss: 0.025926682938422475\n",
      "SEED: 1392, FOLD: 1, EPOCH: 1, train_loss: 0.025232990393820015\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 1, valid_loss: 0.019470704240458353\n",
      "SEED: 1392, FOLD: 1, EPOCH: 2, train_loss: 0.022190053083434486\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 2, valid_loss: 0.019648880405085428\n",
      "SEED: 1392, FOLD: 1, EPOCH: 3, train_loss: 0.02104213901296042\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 3, valid_loss: 0.017634083862815585\n",
      "SEED: 1392, FOLD: 1, EPOCH: 4, train_loss: 0.020304914550396843\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01731063521334103\n",
      "SEED: 1392, FOLD: 1, EPOCH: 5, train_loss: 0.02014064011366471\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017313043267599176\n",
      "SEED: 1392, FOLD: 1, EPOCH: 6, train_loss: 0.02016430630254141\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017352160518722876\n",
      "SEED: 1392, FOLD: 1, EPOCH: 7, train_loss: 0.02013972435362529\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01748556425528867\n",
      "SEED: 1392, FOLD: 1, EPOCH: 8, train_loss: 0.02018169103109318\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017248957630779063\n",
      "SEED: 1392, FOLD: 1, EPOCH: 9, train_loss: 0.020126144320744534\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 9, valid_loss: 0.017157618568411897\n",
      "SEED: 1392, FOLD: 1, EPOCH: 10, train_loss: 0.020155184159892193\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 10, valid_loss: 0.017342579205121313\n",
      "SEED: 1392, FOLD: 1, EPOCH: 11, train_loss: 0.020047110923822376\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017118384928575585\n",
      "SEED: 1392, FOLD: 1, EPOCH: 12, train_loss: 0.01995350254456634\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016964277252554893\n",
      "SEED: 1392, FOLD: 1, EPOCH: 13, train_loss: 0.01987562879272129\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01708402109465429\n",
      "SEED: 1392, FOLD: 1, EPOCH: 14, train_loss: 0.0197214484349757\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 14, valid_loss: 0.01691995643611465\n",
      "SEED: 1392, FOLD: 1, EPOCH: 15, train_loss: 0.019563478647150856\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016719427944294044\n",
      "SEED: 1392, FOLD: 1, EPOCH: 16, train_loss: 0.01938853582934193\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016621136904827187\n",
      "SEED: 1392, FOLD: 1, EPOCH: 17, train_loss: 0.019076726709802944\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016443537761058127\n",
      "SEED: 1392, FOLD: 1, EPOCH: 18, train_loss: 0.018689419561322185\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 18, valid_loss: 0.0164377204275557\n",
      "SEED: 1392, FOLD: 1, EPOCH: 19, train_loss: 0.018306916417635006\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016257564590445587\n",
      "SEED: 1392, FOLD: 1, EPOCH: 20, train_loss: 0.017732890754722168\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016222788340279033\n",
      "SEED: 1392, FOLD: 1, EPOCH: 21, train_loss: 0.017167330280864153\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 21, valid_loss: 0.016145097703805993\n",
      "SEED: 1392, FOLD: 1, EPOCH: 22, train_loss: 0.01660637456950718\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 22, valid_loss: 0.016085513973874706\n",
      "SEED: 1392, FOLD: 1, EPOCH: 23, train_loss: 0.016158843325262053\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01609057044344289\n",
      "SEED: 1392, FOLD: 1, EPOCH: 24, train_loss: 0.015920226819867243\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 24, valid_loss: 0.016135492974093984\n",
      "SEED: 1392, FOLD: 2, EPOCH: 0, train_loss: 0.47153712501344475\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 0, valid_loss: 0.02447243912943772\n",
      "SEED: 1392, FOLD: 2, EPOCH: 1, train_loss: 0.023683403443167175\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 1, valid_loss: 0.019311516093356268\n",
      "SEED: 1392, FOLD: 2, EPOCH: 2, train_loss: 0.021977332542124\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 2, valid_loss: 0.023091089352965354\n",
      "SEED: 1392, FOLD: 2, EPOCH: 3, train_loss: 0.0207606451180966\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017386839086455958\n",
      "SEED: 1392, FOLD: 2, EPOCH: 4, train_loss: 0.02027978551020657\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017991811116891247\n",
      "SEED: 1392, FOLD: 2, EPOCH: 5, train_loss: 0.020243752525066553\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01721400238041367\n",
      "SEED: 1392, FOLD: 2, EPOCH: 6, train_loss: 0.02017392936176148\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017364450996475562\n",
      "SEED: 1392, FOLD: 2, EPOCH: 7, train_loss: 0.020254060153619968\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01728608775883913\n",
      "SEED: 1392, FOLD: 2, EPOCH: 8, train_loss: 0.020178497957902542\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017230012480701717\n",
      "SEED: 1392, FOLD: 2, EPOCH: 9, train_loss: 0.020158645764425182\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 9, valid_loss: 0.017134514903383597\n",
      "SEED: 1392, FOLD: 2, EPOCH: 10, train_loss: 0.020156289180875687\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017236450500786305\n",
      "SEED: 1392, FOLD: 2, EPOCH: 11, train_loss: 0.020020530127204846\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 11, valid_loss: 0.0170333399570414\n",
      "SEED: 1392, FOLD: 2, EPOCH: 12, train_loss: 0.020030478366475174\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01694974529423884\n",
      "SEED: 1392, FOLD: 2, EPOCH: 13, train_loss: 0.0198745458940233\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016930629605693477\n",
      "SEED: 1392, FOLD: 2, EPOCH: 14, train_loss: 0.01975805408226839\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01682802169982876\n",
      "SEED: 1392, FOLD: 2, EPOCH: 15, train_loss: 0.019528759117035763\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01671659419579165\n",
      "SEED: 1392, FOLD: 2, EPOCH: 16, train_loss: 0.01939767493825892\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016521133854985236\n",
      "SEED: 1392, FOLD: 2, EPOCH: 17, train_loss: 0.019089676345280117\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01635557043233088\n",
      "SEED: 1392, FOLD: 2, EPOCH: 18, train_loss: 0.018741557185632595\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 18, valid_loss: 0.01635759440915925\n",
      "SEED: 1392, FOLD: 2, EPOCH: 19, train_loss: 0.018374922658330288\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016234563131417547\n",
      "SEED: 1392, FOLD: 2, EPOCH: 20, train_loss: 0.017829020035223686\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 20, valid_loss: 0.016099563666752408\n",
      "SEED: 1392, FOLD: 2, EPOCH: 21, train_loss: 0.017301270562777485\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016081297477441175\n",
      "SEED: 1392, FOLD: 2, EPOCH: 22, train_loss: 0.01674887743792024\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 22, valid_loss: 0.016026927530765532\n",
      "SEED: 1392, FOLD: 2, EPOCH: 23, train_loss: 0.016278316455798737\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015998449016894612\n",
      "SEED: 1392, FOLD: 2, EPOCH: 24, train_loss: 0.016060414460852095\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 24, valid_loss: 0.016015365560139928\n",
      "SEED: 1392, FOLD: 3, EPOCH: 0, train_loss: 0.4716439625869195\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 0, valid_loss: 0.02430701819913728\n",
      "SEED: 1392, FOLD: 3, EPOCH: 1, train_loss: 0.023921569363902443\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 1, valid_loss: 0.020037527116281647\n",
      "SEED: 1392, FOLD: 3, EPOCH: 2, train_loss: 0.02196520927321652\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 2, valid_loss: 0.019163598226649422\n",
      "SEED: 1392, FOLD: 3, EPOCH: 3, train_loss: 0.02068714609882538\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018130413203367165\n",
      "SEED: 1392, FOLD: 3, EPOCH: 4, train_loss: 0.020360600149285965\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 4, valid_loss: 0.018173612042197158\n",
      "SEED: 1392, FOLD: 3, EPOCH: 5, train_loss: 0.020071635738123154\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017644732871225904\n",
      "SEED: 1392, FOLD: 3, EPOCH: 6, train_loss: 0.020076431388008423\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01738294738211802\n",
      "SEED: 1392, FOLD: 3, EPOCH: 7, train_loss: 0.020120600022483563\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01734862213156053\n",
      "SEED: 1392, FOLD: 3, EPOCH: 8, train_loss: 0.020110263043771618\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017527581857783452\n",
      "SEED: 1392, FOLD: 3, EPOCH: 9, train_loss: 0.020111912078615547\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01733402745532138\n",
      "SEED: 1392, FOLD: 3, EPOCH: 10, train_loss: 0.020082435381693253\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 10, valid_loss: 0.01731167430324214\n",
      "SEED: 1392, FOLD: 3, EPOCH: 11, train_loss: 0.01999579849180536\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01736648662814072\n",
      "SEED: 1392, FOLD: 3, EPOCH: 12, train_loss: 0.019941652949521507\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 12, valid_loss: 0.017414820274072033\n",
      "SEED: 1392, FOLD: 3, EPOCH: 13, train_loss: 0.01990920540107333\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01706276017108134\n",
      "SEED: 1392, FOLD: 3, EPOCH: 14, train_loss: 0.01971716229952332\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016970016860536168\n",
      "SEED: 1392, FOLD: 3, EPOCH: 15, train_loss: 0.019504669459833614\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016792987952274935\n",
      "SEED: 1392, FOLD: 3, EPOCH: 16, train_loss: 0.019319595215653164\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 16, valid_loss: 0.01669974752834865\n",
      "SEED: 1392, FOLD: 3, EPOCH: 17, train_loss: 0.018980426038952843\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016519867868295738\n",
      "SEED: 1392, FOLD: 3, EPOCH: 18, train_loss: 0.01861481198474117\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016404872174773898\n",
      "SEED: 1392, FOLD: 3, EPOCH: 19, train_loss: 0.01816627165923516\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016336328057306154\n",
      "SEED: 1392, FOLD: 3, EPOCH: 20, train_loss: 0.01771473956118891\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016284660143511636\n",
      "SEED: 1392, FOLD: 3, EPOCH: 21, train_loss: 0.01710015168224556\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01624022690313203\n",
      "SEED: 1392, FOLD: 3, EPOCH: 22, train_loss: 0.016517166864882776\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01621401783611093\n",
      "SEED: 1392, FOLD: 3, EPOCH: 23, train_loss: 0.01602197803583914\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01618215409772737\n",
      "SEED: 1392, FOLD: 3, EPOCH: 24, train_loss: 0.015785701579643763\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 24, valid_loss: 0.0161674153059721\n",
      "SEED: 1392, FOLD: 4, EPOCH: 0, train_loss: 0.469678016676419\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 0, valid_loss: 0.02500185828123774\n",
      "SEED: 1392, FOLD: 4, EPOCH: 1, train_loss: 0.02424666524419318\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 1, valid_loss: 0.01940356870847089\n",
      "SEED: 1392, FOLD: 4, EPOCH: 2, train_loss: 0.021964977481874867\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018131006908203875\n",
      "SEED: 1392, FOLD: 4, EPOCH: 3, train_loss: 0.0206796210664122\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 3, valid_loss: 0.017852565087378026\n",
      "SEED: 1392, FOLD: 4, EPOCH: 4, train_loss: 0.020540897532001785\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 4, valid_loss: 0.0182838324457407\n",
      "SEED: 1392, FOLD: 4, EPOCH: 5, train_loss: 0.020344671293877174\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 5, valid_loss: 0.01735125229294811\n",
      "SEED: 1392, FOLD: 4, EPOCH: 6, train_loss: 0.02022176823052375\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017332517488726547\n",
      "SEED: 1392, FOLD: 4, EPOCH: 7, train_loss: 0.02027391253606133\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017248387315443585\n",
      "SEED: 1392, FOLD: 4, EPOCH: 8, train_loss: 0.020195322381197544\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017722255789807864\n",
      "SEED: 1392, FOLD: 4, EPOCH: 9, train_loss: 0.020123833115550056\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017459546348878315\n",
      "SEED: 1392, FOLD: 4, EPOCH: 10, train_loss: 0.02010287158191204\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017293102986046246\n",
      "SEED: 1392, FOLD: 4, EPOCH: 11, train_loss: 0.020097504936806534\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01712303228144135\n",
      "SEED: 1392, FOLD: 4, EPOCH: 12, train_loss: 0.020000452864105286\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 12, valid_loss: 0.017002197088939804\n",
      "SEED: 1392, FOLD: 4, EPOCH: 13, train_loss: 0.019934431906195656\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01692537774464914\n",
      "SEED: 1392, FOLD: 4, EPOCH: 14, train_loss: 0.019728242676111236\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016750339578304973\n",
      "SEED: 1392, FOLD: 4, EPOCH: 15, train_loss: 0.019559025346045044\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01664659128125225\n",
      "SEED: 1392, FOLD: 4, EPOCH: 16, train_loss: 0.019339618691499683\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016518595442175866\n",
      "SEED: 1392, FOLD: 4, EPOCH: 17, train_loss: 0.019135596865005253\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016483693623117038\n",
      "SEED: 1392, FOLD: 4, EPOCH: 18, train_loss: 0.01878210970376065\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016285034801278797\n",
      "SEED: 1392, FOLD: 4, EPOCH: 19, train_loss: 0.018398243286039517\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016266303243381637\n",
      "SEED: 1392, FOLD: 4, EPOCH: 20, train_loss: 0.017859465003931436\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016036989114114216\n",
      "SEED: 1392, FOLD: 4, EPOCH: 21, train_loss: 0.017353616290442322\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01596395612827369\n",
      "SEED: 1392, FOLD: 4, EPOCH: 22, train_loss: 0.016813942514683888\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015969880909792015\n",
      "SEED: 1392, FOLD: 4, EPOCH: 23, train_loss: 0.01639235282883696\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01594767903110811\n",
      "SEED: 1392, FOLD: 4, EPOCH: 24, train_loss: 0.016218154144513865\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01594510030533586\n",
      "SEED: 1119, FOLD: 0, EPOCH: 0, train_loss: 0.4713655963027175\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 0, valid_loss: 0.024336124211549758\n",
      "SEED: 1119, FOLD: 0, EPOCH: 1, train_loss: 0.023998577822593674\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 1, valid_loss: 0.0191239133477211\n",
      "SEED: 1119, FOLD: 0, EPOCH: 2, train_loss: 0.02242460189576166\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 2, valid_loss: 0.01780829724988767\n",
      "SEED: 1119, FOLD: 0, EPOCH: 3, train_loss: 0.02079627994933854\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017310584549392972\n",
      "SEED: 1119, FOLD: 0, EPOCH: 4, train_loss: 0.020245597832768723\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 4, valid_loss: 0.01913715944226299\n",
      "SEED: 1119, FOLD: 0, EPOCH: 5, train_loss: 0.020586506450089855\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017462651378342083\n",
      "SEED: 1119, FOLD: 0, EPOCH: 6, train_loss: 0.020250647706722004\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017129314983529705\n",
      "SEED: 1119, FOLD: 0, EPOCH: 7, train_loss: 0.0202227427718648\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017225769215396473\n",
      "SEED: 1119, FOLD: 0, EPOCH: 8, train_loss: 0.020196701049048832\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017204445680337292\n",
      "SEED: 1119, FOLD: 0, EPOCH: 9, train_loss: 0.02009772520809286\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017188532730298384\n",
      "SEED: 1119, FOLD: 0, EPOCH: 10, train_loss: 0.020065564432761807\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017236269584723882\n",
      "SEED: 1119, FOLD: 0, EPOCH: 11, train_loss: 0.02003265386852233\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 11, valid_loss: 0.0171557128695505\n",
      "SEED: 1119, FOLD: 0, EPOCH: 12, train_loss: 0.01998518486979647\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016820252500474454\n",
      "SEED: 1119, FOLD: 0, EPOCH: 13, train_loss: 0.01984441655593506\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 13, valid_loss: 0.017066760015274796\n",
      "SEED: 1119, FOLD: 0, EPOCH: 14, train_loss: 0.019814743754872376\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016886602475174834\n",
      "SEED: 1119, FOLD: 0, EPOCH: 15, train_loss: 0.019526509703069492\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01673820646745818\n",
      "SEED: 1119, FOLD: 0, EPOCH: 16, train_loss: 0.0193549366802841\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016542803522731575\n",
      "SEED: 1119, FOLD: 0, EPOCH: 17, train_loss: 0.0190505793966029\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016482539687837874\n",
      "SEED: 1119, FOLD: 0, EPOCH: 18, train_loss: 0.018695958734800417\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016239877151591437\n",
      "SEED: 1119, FOLD: 0, EPOCH: 19, train_loss: 0.01833286351672765\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016165376294936452\n",
      "SEED: 1119, FOLD: 0, EPOCH: 20, train_loss: 0.01784845985526192\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01606881796781506\n",
      "SEED: 1119, FOLD: 0, EPOCH: 21, train_loss: 0.01726056555070091\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016012373619845935\n",
      "SEED: 1119, FOLD: 0, EPOCH: 22, train_loss: 0.01675991831428331\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01598188347582306\n",
      "SEED: 1119, FOLD: 0, EPOCH: 23, train_loss: 0.01631528032484694\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015987266946051803\n",
      "SEED: 1119, FOLD: 0, EPOCH: 24, train_loss: 0.01610066416416911\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 24, valid_loss: 0.016012947101678165\n",
      "SEED: 1119, FOLD: 1, EPOCH: 0, train_loss: 0.47205141306841286\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 0, valid_loss: 0.023959500236170633\n",
      "SEED: 1119, FOLD: 1, EPOCH: 1, train_loss: 0.023889488905020382\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 1, valid_loss: 0.019256248697638513\n",
      "SEED: 1119, FOLD: 1, EPOCH: 2, train_loss: 0.021870399339367515\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 2, valid_loss: 0.017984679181660926\n",
      "SEED: 1119, FOLD: 1, EPOCH: 3, train_loss: 0.020680677429165528\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 3, valid_loss: 0.018087876055921825\n",
      "SEED: 1119, FOLD: 1, EPOCH: 4, train_loss: 0.020304169721793438\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01739253673170294\n",
      "SEED: 1119, FOLD: 1, EPOCH: 5, train_loss: 0.020220575003844242\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017294884632740704\n",
      "SEED: 1119, FOLD: 1, EPOCH: 6, train_loss: 0.020171055448767933\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017341016552277974\n",
      "SEED: 1119, FOLD: 1, EPOCH: 7, train_loss: 0.020161167920931526\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017220851113753658\n",
      "SEED: 1119, FOLD: 1, EPOCH: 8, train_loss: 0.02018461806996577\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017162537149020603\n",
      "SEED: 1119, FOLD: 1, EPOCH: 9, train_loss: 0.020124814473092556\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01705965982483966\n",
      "SEED: 1119, FOLD: 1, EPOCH: 10, train_loss: 0.02006966493807841\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01719182806887797\n",
      "SEED: 1119, FOLD: 1, EPOCH: 11, train_loss: 0.01998438598399145\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017096162560795033\n",
      "SEED: 1119, FOLD: 1, EPOCH: 12, train_loss: 0.01995569271831841\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 12, valid_loss: 0.017179994684244904\n",
      "SEED: 1119, FOLD: 1, EPOCH: 13, train_loss: 0.01981120130074197\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01693555103348834\n",
      "SEED: 1119, FOLD: 1, EPOCH: 14, train_loss: 0.019803829585620457\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 14, valid_loss: 0.01682909338601998\n",
      "SEED: 1119, FOLD: 1, EPOCH: 15, train_loss: 0.019561201914389065\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016679067643625395\n",
      "SEED: 1119, FOLD: 1, EPOCH: 16, train_loss: 0.019345383645723694\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016554882590259824\n",
      "SEED: 1119, FOLD: 1, EPOCH: 17, train_loss: 0.019074221317102943\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 17, valid_loss: 0.01655280818896634\n",
      "SEED: 1119, FOLD: 1, EPOCH: 18, train_loss: 0.01873957458883524\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016349789606673378\n",
      "SEED: 1119, FOLD: 1, EPOCH: 19, train_loss: 0.018343632514386074\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016288839972444943\n",
      "SEED: 1119, FOLD: 1, EPOCH: 20, train_loss: 0.01778851269973793\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016112907656601498\n",
      "SEED: 1119, FOLD: 1, EPOCH: 21, train_loss: 0.017201601169949423\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01607629914901086\n",
      "SEED: 1119, FOLD: 1, EPOCH: 22, train_loss: 0.016632575669960268\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 22, valid_loss: 0.016024423630109856\n",
      "SEED: 1119, FOLD: 1, EPOCH: 23, train_loss: 0.01623559102712982\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 23, valid_loss: 0.015999063556747777\n",
      "SEED: 1119, FOLD: 1, EPOCH: 24, train_loss: 0.0159662956358406\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 24, valid_loss: 0.016034423879214697\n",
      "SEED: 1119, FOLD: 2, EPOCH: 0, train_loss: 0.4716478960885518\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 0, valid_loss: 0.024561806714960506\n",
      "SEED: 1119, FOLD: 2, EPOCH: 1, train_loss: 0.02387316371111766\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 1, valid_loss: 0.018798206613532136\n",
      "SEED: 1119, FOLD: 2, EPOCH: 2, train_loss: 0.021847188823680946\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 2, valid_loss: 0.01776446324906179\n",
      "SEED: 1119, FOLD: 2, EPOCH: 3, train_loss: 0.020737124687951546\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017571144763912472\n",
      "SEED: 1119, FOLD: 2, EPOCH: 4, train_loss: 0.0202092037036799\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 4, valid_loss: 0.01759449200970786\n",
      "SEED: 1119, FOLD: 2, EPOCH: 5, train_loss: 0.020367861941348816\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01723378457661186\n",
      "SEED: 1119, FOLD: 2, EPOCH: 6, train_loss: 0.020213379011745903\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017569154660616603\n",
      "SEED: 1119, FOLD: 2, EPOCH: 7, train_loss: 0.020270990693698757\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017272744567266532\n",
      "SEED: 1119, FOLD: 2, EPOCH: 8, train_loss: 0.020161280314019626\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 8, valid_loss: 0.016997877401965004\n",
      "SEED: 1119, FOLD: 2, EPOCH: 9, train_loss: 0.020158735090407772\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 9, valid_loss: 0.017202036934239523\n",
      "SEED: 1119, FOLD: 2, EPOCH: 10, train_loss: 0.02012462785764449\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017082233274621623\n",
      "SEED: 1119, FOLD: 2, EPOCH: 11, train_loss: 0.020055438918264015\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 11, valid_loss: 0.01694838290235826\n",
      "SEED: 1119, FOLD: 2, EPOCH: 12, train_loss: 0.019978311020826946\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 12, valid_loss: 0.017085857157196318\n",
      "SEED: 1119, FOLD: 2, EPOCH: 13, train_loss: 0.019860567686998325\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016838518024555275\n",
      "SEED: 1119, FOLD: 2, EPOCH: 14, train_loss: 0.019774769189889015\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016814865810530526\n",
      "SEED: 1119, FOLD: 2, EPOCH: 15, train_loss: 0.01958899544147046\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016720391969595638\n",
      "SEED: 1119, FOLD: 2, EPOCH: 16, train_loss: 0.01938962917504967\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01659827000860657\n",
      "SEED: 1119, FOLD: 2, EPOCH: 17, train_loss: 0.01908964786570573\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01628708748945168\n",
      "SEED: 1119, FOLD: 2, EPOCH: 18, train_loss: 0.018733586724577606\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016379682240741593\n",
      "SEED: 1119, FOLD: 2, EPOCH: 19, train_loss: 0.01833948123174301\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016216898017695974\n",
      "SEED: 1119, FOLD: 2, EPOCH: 20, train_loss: 0.01781386952928227\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01606471072882414\n",
      "SEED: 1119, FOLD: 2, EPOCH: 21, train_loss: 0.017324694769753925\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016029742040804453\n",
      "SEED: 1119, FOLD: 2, EPOCH: 22, train_loss: 0.016778117848857157\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 22, valid_loss: 0.016005826102835793\n",
      "SEED: 1119, FOLD: 2, EPOCH: 23, train_loss: 0.016363211057108383\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015977267175912857\n",
      "SEED: 1119, FOLD: 2, EPOCH: 24, train_loss: 0.01612582723137693\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01599714673523392\n",
      "SEED: 1119, FOLD: 3, EPOCH: 0, train_loss: 0.47250433615746273\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 0, valid_loss: 0.02355631994349616\n",
      "SEED: 1119, FOLD: 3, EPOCH: 1, train_loss: 0.023820163479641727\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 1, valid_loss: 0.02453839166888169\n",
      "SEED: 1119, FOLD: 3, EPOCH: 2, train_loss: 0.025835930666737797\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018869568141443388\n",
      "SEED: 1119, FOLD: 3, EPOCH: 3, train_loss: 0.021719649515074234\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018322994719658578\n",
      "SEED: 1119, FOLD: 3, EPOCH: 4, train_loss: 0.02099154935474845\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017789063655904363\n",
      "SEED: 1119, FOLD: 3, EPOCH: 5, train_loss: 0.020456978686801765\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017604947382850306\n",
      "SEED: 1119, FOLD: 3, EPOCH: 6, train_loss: 0.020260923393610596\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017399900486426693\n",
      "SEED: 1119, FOLD: 3, EPOCH: 7, train_loss: 0.02017521507282188\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 7, valid_loss: 0.0175054967669504\n",
      "SEED: 1119, FOLD: 3, EPOCH: 8, train_loss: 0.020186148394925007\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017428003517644747\n",
      "SEED: 1119, FOLD: 3, EPOCH: 9, train_loss: 0.020074292889161818\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01746360808610916\n",
      "SEED: 1119, FOLD: 3, EPOCH: 10, train_loss: 0.019994157339459744\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017329628020524977\n",
      "SEED: 1119, FOLD: 3, EPOCH: 11, train_loss: 0.019995695816865867\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 11, valid_loss: 0.017283243872225285\n",
      "SEED: 1119, FOLD: 3, EPOCH: 12, train_loss: 0.019921950914937515\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 12, valid_loss: 0.017148993802922112\n",
      "SEED: 1119, FOLD: 3, EPOCH: 13, train_loss: 0.019792580774620823\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01691145050738539\n",
      "SEED: 1119, FOLD: 3, EPOCH: 14, train_loss: 0.019633431729955086\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 14, valid_loss: 0.017143695721668857\n",
      "SEED: 1119, FOLD: 3, EPOCH: 15, train_loss: 0.019493523620716904\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01696061340293714\n",
      "SEED: 1119, FOLD: 3, EPOCH: 16, train_loss: 0.019230247043289135\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016784120590559073\n",
      "SEED: 1119, FOLD: 3, EPOCH: 17, train_loss: 0.018893489344180493\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016703679864960057\n",
      "SEED: 1119, FOLD: 3, EPOCH: 18, train_loss: 0.01855273123668588\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016532376195703233\n",
      "SEED: 1119, FOLD: 3, EPOCH: 19, train_loss: 0.01808700496600806\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01636505989091737\n",
      "SEED: 1119, FOLD: 3, EPOCH: 20, train_loss: 0.017530081354999456\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016403999046555588\n",
      "SEED: 1119, FOLD: 3, EPOCH: 21, train_loss: 0.016776576509996168\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016425463370978832\n",
      "SEED: 1119, FOLD: 3, EPOCH: 22, train_loss: 0.01600613252705206\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 22, valid_loss: 0.016364211615707194\n",
      "SEED: 1119, FOLD: 3, EPOCH: 23, train_loss: 0.015373535784960224\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016384661623409815\n",
      "SEED: 1119, FOLD: 3, EPOCH: 24, train_loss: 0.015009263645101717\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 24, valid_loss: 0.01638758954192911\n",
      "SEED: 1119, FOLD: 4, EPOCH: 0, train_loss: 0.4716731874758135\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 0, valid_loss: 0.0238496796893222\n",
      "SEED: 1119, FOLD: 4, EPOCH: 1, train_loss: 0.023813224114153698\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 1, valid_loss: 0.018970509086336407\n",
      "SEED: 1119, FOLD: 4, EPOCH: 2, train_loss: 0.02178978520459023\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018336198159626553\n",
      "SEED: 1119, FOLD: 4, EPOCH: 3, train_loss: 0.020838231064271236\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01758421640843153\n",
      "SEED: 1119, FOLD: 4, EPOCH: 4, train_loss: 0.020339199287843876\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017160539009741373\n",
      "SEED: 1119, FOLD: 4, EPOCH: 5, train_loss: 0.02017631272420935\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 5, valid_loss: 0.020548901706933975\n",
      "SEED: 1119, FOLD: 4, EPOCH: 6, train_loss: 0.020228206881902355\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017174800272498812\n",
      "SEED: 1119, FOLD: 4, EPOCH: 7, train_loss: 0.020269620934150356\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01712471345173461\n",
      "SEED: 1119, FOLD: 4, EPOCH: 8, train_loss: 0.020211803780841656\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017068991969738687\n",
      "SEED: 1119, FOLD: 4, EPOCH: 9, train_loss: 0.020211525909278705\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017112283568297113\n",
      "SEED: 1119, FOLD: 4, EPOCH: 10, train_loss: 0.02008767724307119\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017142367362976075\n",
      "SEED: 1119, FOLD: 4, EPOCH: 11, train_loss: 0.020100020020660282\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016984944684164865\n",
      "SEED: 1119, FOLD: 4, EPOCH: 12, train_loss: 0.020038281337938446\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 12, valid_loss: 0.01691803660775934\n",
      "SEED: 1119, FOLD: 4, EPOCH: 13, train_loss: 0.019876172793084297\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016721339231090888\n",
      "SEED: 1119, FOLD: 4, EPOCH: 14, train_loss: 0.01973400304795823\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016781865965042796\n",
      "SEED: 1119, FOLD: 4, EPOCH: 15, train_loss: 0.019611186253419823\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016576508725328103\n",
      "SEED: 1119, FOLD: 4, EPOCH: 16, train_loss: 0.0193206117272485\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01665130941463368\n",
      "SEED: 1119, FOLD: 4, EPOCH: 17, train_loss: 0.019060492542558823\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016346160082944802\n",
      "SEED: 1119, FOLD: 4, EPOCH: 18, train_loss: 0.018741005991140137\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016241749562323094\n",
      "SEED: 1119, FOLD: 4, EPOCH: 19, train_loss: 0.01831172105005902\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01619055923074484\n",
      "SEED: 1119, FOLD: 4, EPOCH: 20, train_loss: 0.017790467154396618\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016058293570365225\n",
      "SEED: 1119, FOLD: 4, EPOCH: 21, train_loss: 0.017273365884371426\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 21, valid_loss: 0.015994976966508798\n",
      "SEED: 1119, FOLD: 4, EPOCH: 22, train_loss: 0.01666095414860309\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015970437814082417\n",
      "SEED: 1119, FOLD: 4, EPOCH: 23, train_loss: 0.016217945575498154\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 23, valid_loss: 0.015968531263726098\n",
      "SEED: 1119, FOLD: 4, EPOCH: 24, train_loss: 0.01599805839224786\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015991651320031712\n",
      "SEED: 1303, FOLD: 0, EPOCH: 0, train_loss: 0.4708791820710336\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 0, valid_loss: 0.02515027060040406\n",
      "SEED: 1303, FOLD: 0, EPOCH: 1, train_loss: 0.023906125039186165\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 1, valid_loss: 0.01929606827242034\n",
      "SEED: 1303, FOLD: 0, EPOCH: 2, train_loss: 0.022052054981822552\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 2, valid_loss: 0.0178522400824087\n",
      "SEED: 1303, FOLD: 0, EPOCH: 3, train_loss: 0.020921270781453106\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 3, valid_loss: 0.018255048910421984\n",
      "SEED: 1303, FOLD: 0, EPOCH: 4, train_loss: 0.020488239892259025\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017277948691376617\n",
      "SEED: 1303, FOLD: 0, EPOCH: 5, train_loss: 0.020236417246253594\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017283028098089355\n",
      "SEED: 1303, FOLD: 0, EPOCH: 6, train_loss: 0.020270676905478256\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017501249403825827\n",
      "SEED: 1303, FOLD: 0, EPOCH: 7, train_loss: 0.02024847205620313\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01719059313514403\n",
      "SEED: 1303, FOLD: 0, EPOCH: 8, train_loss: 0.020283566504392937\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01709580421447754\n",
      "SEED: 1303, FOLD: 0, EPOCH: 9, train_loss: 0.020145333722989628\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017202611932797093\n",
      "SEED: 1303, FOLD: 0, EPOCH: 10, train_loss: 0.020120620889508205\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017586828236068996\n",
      "SEED: 1303, FOLD: 0, EPOCH: 11, train_loss: 0.020134114255399807\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 11, valid_loss: 0.017713937456054346\n",
      "SEED: 1303, FOLD: 0, EPOCH: 12, train_loss: 0.02004019297875356\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 12, valid_loss: 0.017023860290646554\n",
      "SEED: 1303, FOLD: 0, EPOCH: 13, train_loss: 0.0198159779732426\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01693353522568941\n",
      "SEED: 1303, FOLD: 0, EPOCH: 14, train_loss: 0.01970715062233849\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 14, valid_loss: 0.017145804555288382\n",
      "SEED: 1303, FOLD: 0, EPOCH: 15, train_loss: 0.019666143666035023\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016739468941731114\n",
      "SEED: 1303, FOLD: 0, EPOCH: 16, train_loss: 0.01944304462792217\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01672058052250317\n",
      "SEED: 1303, FOLD: 0, EPOCH: 17, train_loss: 0.019100600239429354\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01651030456913369\n",
      "SEED: 1303, FOLD: 0, EPOCH: 18, train_loss: 0.01880927192911074\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016328301200909275\n",
      "SEED: 1303, FOLD: 0, EPOCH: 19, train_loss: 0.018412859145335962\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016172078464712414\n",
      "SEED: 1303, FOLD: 0, EPOCH: 20, train_loss: 0.01797146738196413\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016070217373115675\n",
      "SEED: 1303, FOLD: 0, EPOCH: 21, train_loss: 0.01733580025155907\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016028683818876743\n",
      "SEED: 1303, FOLD: 0, EPOCH: 22, train_loss: 0.016879707716567362\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 22, valid_loss: 0.015947839537901538\n",
      "SEED: 1303, FOLD: 0, EPOCH: 23, train_loss: 0.01643662066941244\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015943431189017636\n",
      "SEED: 1303, FOLD: 0, EPOCH: 24, train_loss: 0.016183034435886402\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01593702541930335\n",
      "SEED: 1303, FOLD: 1, EPOCH: 0, train_loss: 0.47100338212929777\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 0, valid_loss: 0.02658444158732891\n",
      "SEED: 1303, FOLD: 1, EPOCH: 1, train_loss: 0.0240245601432263\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 1, valid_loss: 0.019032628142407963\n",
      "SEED: 1303, FOLD: 1, EPOCH: 2, train_loss: 0.022276072074537693\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 2, valid_loss: 0.020226128292935235\n",
      "SEED: 1303, FOLD: 1, EPOCH: 3, train_loss: 0.021266966261833473\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 3, valid_loss: 0.018374345797513212\n",
      "SEED: 1303, FOLD: 1, EPOCH: 4, train_loss: 0.020364389241929504\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01709545323891299\n",
      "SEED: 1303, FOLD: 1, EPOCH: 5, train_loss: 0.020193492035394993\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 5, valid_loss: 0.0176870145169752\n",
      "SEED: 1303, FOLD: 1, EPOCH: 6, train_loss: 0.02031538360144781\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017280231496053084\n",
      "SEED: 1303, FOLD: 1, EPOCH: 7, train_loss: 0.02020197774729003\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017291272112301418\n",
      "SEED: 1303, FOLD: 1, EPOCH: 8, train_loss: 0.020269025819025177\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017315889868353095\n",
      "SEED: 1303, FOLD: 1, EPOCH: 9, train_loss: 0.020155434901623623\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 9, valid_loss: 0.017236238185848508\n",
      "SEED: 1303, FOLD: 1, EPOCH: 10, train_loss: 0.020153724143038624\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01699958739003965\n",
      "SEED: 1303, FOLD: 1, EPOCH: 11, train_loss: 0.020082208800359047\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017083098420075007\n",
      "SEED: 1303, FOLD: 1, EPOCH: 12, train_loss: 0.020041382291178772\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 12, valid_loss: 0.017045904456504755\n",
      "SEED: 1303, FOLD: 1, EPOCH: 13, train_loss: 0.019834665838035122\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016933647889111725\n",
      "SEED: 1303, FOLD: 1, EPOCH: 14, train_loss: 0.01978776722714521\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 14, valid_loss: 0.017189144023827145\n",
      "SEED: 1303, FOLD: 1, EPOCH: 15, train_loss: 0.019638375419637432\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016843692639044353\n",
      "SEED: 1303, FOLD: 1, EPOCH: 16, train_loss: 0.01933821312327316\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016633189097046853\n",
      "SEED: 1303, FOLD: 1, EPOCH: 17, train_loss: 0.019105923254096855\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016546862891742162\n",
      "SEED: 1303, FOLD: 1, EPOCH: 18, train_loss: 0.018837034999244454\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016443341518087046\n",
      "SEED: 1303, FOLD: 1, EPOCH: 19, train_loss: 0.018418548075293285\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016249474084803036\n",
      "SEED: 1303, FOLD: 1, EPOCH: 20, train_loss: 0.017944073426010815\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016163754835724832\n",
      "SEED: 1303, FOLD: 1, EPOCH: 21, train_loss: 0.017381089543788763\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01607709444527115\n",
      "SEED: 1303, FOLD: 1, EPOCH: 22, train_loss: 0.01677722570931782\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 22, valid_loss: 0.0160656797300492\n",
      "SEED: 1303, FOLD: 1, EPOCH: 23, train_loss: 0.01632400599402794\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 23, valid_loss: 0.016079594833510263\n",
      "SEED: 1303, FOLD: 1, EPOCH: 24, train_loss: 0.016172181646191122\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 24, valid_loss: 0.016060272817100797\n",
      "SEED: 1303, FOLD: 2, EPOCH: 0, train_loss: 0.4715842821135901\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 0, valid_loss: 0.02522821458322661\n",
      "SEED: 1303, FOLD: 2, EPOCH: 1, train_loss: 0.023670209220786026\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 1, valid_loss: 0.019123705263648715\n",
      "SEED: 1303, FOLD: 2, EPOCH: 2, train_loss: 0.022345221587929173\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018565650497164046\n",
      "SEED: 1303, FOLD: 2, EPOCH: 3, train_loss: 0.02102827129588611\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 3, valid_loss: 0.01816291556294475\n",
      "SEED: 1303, FOLD: 2, EPOCH: 4, train_loss: 0.02058965791070807\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017501131524997098\n",
      "SEED: 1303, FOLD: 2, EPOCH: 5, train_loss: 0.02034595956944901\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017367604028965745\n",
      "SEED: 1303, FOLD: 2, EPOCH: 6, train_loss: 0.020344275441290676\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01754331857498203\n",
      "SEED: 1303, FOLD: 2, EPOCH: 7, train_loss: 0.020309095122460007\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01738580497247832\n",
      "SEED: 1303, FOLD: 2, EPOCH: 8, train_loss: 0.02022826797126428\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01728823959295239\n",
      "SEED: 1303, FOLD: 2, EPOCH: 9, train_loss: 0.020169275164928124\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 9, valid_loss: 0.017104840757591385\n",
      "SEED: 1303, FOLD: 2, EPOCH: 10, train_loss: 0.02016234304755926\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017070683304752622\n",
      "SEED: 1303, FOLD: 2, EPOCH: 11, train_loss: 0.020092495568636536\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 11, valid_loss: 0.01708340176514217\n",
      "SEED: 1303, FOLD: 2, EPOCH: 12, train_loss: 0.020054829968274502\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 12, valid_loss: 0.017178064371858325\n",
      "SEED: 1303, FOLD: 2, EPOCH: 13, train_loss: 0.019943400596578915\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016805358257676872\n",
      "SEED: 1303, FOLD: 2, EPOCH: 14, train_loss: 0.01974247005916592\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016717422913227763\n",
      "SEED: 1303, FOLD: 2, EPOCH: 15, train_loss: 0.019702875244336716\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01678015302334513\n",
      "SEED: 1303, FOLD: 2, EPOCH: 16, train_loss: 0.019452484068123325\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01655340673668044\n",
      "SEED: 1303, FOLD: 2, EPOCH: 17, train_loss: 0.019101684778064922\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01646890225155013\n",
      "SEED: 1303, FOLD: 2, EPOCH: 18, train_loss: 0.018790958003829353\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 18, valid_loss: 0.01625625230371952\n",
      "SEED: 1303, FOLD: 2, EPOCH: 19, train_loss: 0.01842263461077127\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01624952866030591\n",
      "SEED: 1303, FOLD: 2, EPOCH: 20, train_loss: 0.017967696922520798\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01615268981882504\n",
      "SEED: 1303, FOLD: 2, EPOCH: 21, train_loss: 0.017430155848463375\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01604953852615186\n",
      "SEED: 1303, FOLD: 2, EPOCH: 22, train_loss: 0.016893732955382355\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 22, valid_loss: 0.015993470485721317\n",
      "SEED: 1303, FOLD: 2, EPOCH: 23, train_loss: 0.016482414650744286\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 23, valid_loss: 0.016017028795821325\n",
      "SEED: 1303, FOLD: 2, EPOCH: 24, train_loss: 0.016287566985988964\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 24, valid_loss: 0.015978606630648887\n",
      "SEED: 1303, FOLD: 3, EPOCH: 0, train_loss: 0.4726173679303864\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 0, valid_loss: 0.023593817012650627\n",
      "SEED: 1303, FOLD: 3, EPOCH: 1, train_loss: 0.024039587478382862\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 1, valid_loss: 0.01945159009524754\n",
      "SEED: 1303, FOLD: 3, EPOCH: 2, train_loss: 0.021942939474314884\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 2, valid_loss: 0.01796606427856854\n",
      "SEED: 1303, FOLD: 3, EPOCH: 3, train_loss: 0.02078614124785299\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 3, valid_loss: 0.46203175485134124\n",
      "SEED: 1303, FOLD: 3, EPOCH: 4, train_loss: 0.02477263641692158\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 4, valid_loss: 0.019200818719608444\n",
      "SEED: 1303, FOLD: 3, EPOCH: 5, train_loss: 0.021582215794942516\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 5, valid_loss: 0.018581380216138702\n",
      "SEED: 1303, FOLD: 3, EPOCH: 6, train_loss: 0.02105674586272326\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017997015161173684\n",
      "SEED: 1303, FOLD: 3, EPOCH: 7, train_loss: 0.020892543110834515\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01800112072378397\n",
      "SEED: 1303, FOLD: 3, EPOCH: 8, train_loss: 0.020684721002328224\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017748524567910602\n",
      "SEED: 1303, FOLD: 3, EPOCH: 9, train_loss: 0.020575493155722168\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 9, valid_loss: 0.0177021966448852\n",
      "SEED: 1303, FOLD: 3, EPOCH: 10, train_loss: 0.020476305290408756\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017753447432603153\n",
      "SEED: 1303, FOLD: 3, EPOCH: 11, train_loss: 0.020349153951890228\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 11, valid_loss: 0.017373201197811536\n",
      "SEED: 1303, FOLD: 3, EPOCH: 12, train_loss: 0.020264672803813995\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 12, valid_loss: 0.017482544774455683\n",
      "SEED: 1303, FOLD: 3, EPOCH: 13, train_loss: 0.02012019797457733\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 13, valid_loss: 0.017259476413684232\n",
      "SEED: 1303, FOLD: 3, EPOCH: 14, train_loss: 0.01988120916960896\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 14, valid_loss: 0.017322711353855474\n",
      "SEED: 1303, FOLD: 3, EPOCH: 15, train_loss: 0.019724434201160202\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 15, valid_loss: 0.017047627589532308\n",
      "SEED: 1303, FOLD: 3, EPOCH: 16, train_loss: 0.019530241647600265\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016993828862905503\n",
      "SEED: 1303, FOLD: 3, EPOCH: 17, train_loss: 0.019224610152667847\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016669681375580173\n",
      "SEED: 1303, FOLD: 3, EPOCH: 18, train_loss: 0.018816507799361927\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016629592276045255\n",
      "SEED: 1303, FOLD: 3, EPOCH: 19, train_loss: 0.0184712424820316\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01655218992382288\n",
      "SEED: 1303, FOLD: 3, EPOCH: 20, train_loss: 0.01790215391530723\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016446162600602422\n",
      "SEED: 1303, FOLD: 3, EPOCH: 21, train_loss: 0.017347492264124794\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01636648436209985\n",
      "SEED: 1303, FOLD: 3, EPOCH: 22, train_loss: 0.016672244842123728\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01643866359123162\n",
      "SEED: 1303, FOLD: 3, EPOCH: 23, train_loss: 0.016132686658343977\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016395281521337374\n",
      "SEED: 1303, FOLD: 3, EPOCH: 24, train_loss: 0.015870797981008673\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016404434612819128\n",
      "SEED: 1303, FOLD: 4, EPOCH: 0, train_loss: 0.471571096205625\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 0, valid_loss: 0.024673264580113548\n",
      "SEED: 1303, FOLD: 4, EPOCH: 1, train_loss: 0.023705930503058262\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 1, valid_loss: 0.019389063811727933\n",
      "SEED: 1303, FOLD: 4, EPOCH: 2, train_loss: 0.02222839146312596\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018016360407429082\n",
      "SEED: 1303, FOLD: 4, EPOCH: 3, train_loss: 0.020711967478627743\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 3, valid_loss: 0.017406313706721577\n",
      "SEED: 1303, FOLD: 4, EPOCH: 4, train_loss: 0.02043819909348436\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 4, valid_loss: 0.01754677327615874\n",
      "SEED: 1303, FOLD: 4, EPOCH: 5, train_loss: 0.02026107187882282\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 5, valid_loss: 0.01738382859953812\n",
      "SEED: 1303, FOLD: 4, EPOCH: 6, train_loss: 0.020157667754244976\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017264829017221928\n",
      "SEED: 1303, FOLD: 4, EPOCH: 7, train_loss: 0.020198332861173843\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017091812672359603\n",
      "SEED: 1303, FOLD: 4, EPOCH: 8, train_loss: 0.02024240176314893\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017627268337777682\n",
      "SEED: 1303, FOLD: 4, EPOCH: 9, train_loss: 0.02023091963559821\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017428400819855076\n",
      "SEED: 1303, FOLD: 4, EPOCH: 10, train_loss: 0.020195763855092766\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 10, valid_loss: 0.016961221237267766\n",
      "SEED: 1303, FOLD: 4, EPOCH: 11, train_loss: 0.020107479590544666\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016973201212074074\n",
      "SEED: 1303, FOLD: 4, EPOCH: 12, train_loss: 0.02010437962261663\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 12, valid_loss: 0.017092181981674264\n",
      "SEED: 1303, FOLD: 4, EPOCH: 13, train_loss: 0.01996808527442424\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01700685726744788\n",
      "SEED: 1303, FOLD: 4, EPOCH: 14, train_loss: 0.019726741910520672\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016768387917961394\n",
      "SEED: 1303, FOLD: 4, EPOCH: 15, train_loss: 0.019554465158802013\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016593036082174096\n",
      "SEED: 1303, FOLD: 4, EPOCH: 16, train_loss: 0.019375434428777382\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01668884317789759\n",
      "SEED: 1303, FOLD: 4, EPOCH: 17, train_loss: 0.01908964007768942\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01640979807291712\n",
      "SEED: 1303, FOLD: 4, EPOCH: 18, train_loss: 0.018769908723407898\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016275739669799803\n",
      "SEED: 1303, FOLD: 4, EPOCH: 19, train_loss: 0.018326786812394857\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016092551818915776\n",
      "SEED: 1303, FOLD: 4, EPOCH: 20, train_loss: 0.01788545175846936\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016025794882859504\n",
      "SEED: 1303, FOLD: 4, EPOCH: 21, train_loss: 0.017313035981108744\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01596027985215187\n",
      "SEED: 1303, FOLD: 4, EPOCH: 22, train_loss: 0.016773215387070526\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015928585374993937\n",
      "SEED: 1303, FOLD: 4, EPOCH: 23, train_loss: 0.016317868186835793\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01591321969670909\n",
      "SEED: 1303, FOLD: 4, EPOCH: 24, train_loss: 0.016128030983542187\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015913975717765944\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [940, 1513, 1269,1392,1119,1303]  #<-- Update\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3f3226e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T05:09:29.604498Z",
     "iopub.status.busy": "2025-03-15T05:09:29.604114Z",
     "iopub.status.idle": "2025-03-15T05:09:29.621502Z",
     "shell.execute_reply": "2025-03-15T05:09:29.620799Z"
    },
    "papermill": {
     "duration": 0.058328,
     "end_time": "2025-03-15T05:09:29.622801",
     "exception": false,
     "start_time": "2025-03-15T05:09:29.564473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows Ã— 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0      id_000644bb2                            0                       0   \n",
       "1      id_000779bfc                            0                       0   \n",
       "2      id_000a6266a                            0                       0   \n",
       "3      id_0015fd391                            0                       0   \n",
       "4      id_001626bd3                            0                       0   \n",
       "...             ...                          ...                     ...   \n",
       "23809  id_fffb1ceed                            0                       0   \n",
       "23810  id_fffb70c0c                            0                       0   \n",
       "23811  id_fffc1c3f4                            0                       0   \n",
       "23812  id_fffcb9e7c                            0                       0   \n",
       "23813  id_ffffdd77b                            0                       0   \n",
       "\n",
       "       acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0                   0                               0   \n",
       "1                   0                               0   \n",
       "2                   0                               0   \n",
       "3                   0                               0   \n",
       "4                   0                               0   \n",
       "...               ...                             ...   \n",
       "23809               0                               0   \n",
       "23810               0                               0   \n",
       "23811               0                               0   \n",
       "23812               0                               0   \n",
       "23813               0                               0   \n",
       "\n",
       "       acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                      0                               0   \n",
       "1                                      0                               0   \n",
       "2                                      0                               0   \n",
       "3                                      0                               0   \n",
       "4                                      0                               0   \n",
       "...                                  ...                             ...   \n",
       "23809                                  0                               0   \n",
       "23810                                  0                               0   \n",
       "23811                                  0                               0   \n",
       "23812                                  0                               0   \n",
       "23813                                  0                               0   \n",
       "\n",
       "       adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                               0                              0   \n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              0   \n",
       "4                               0                              0   \n",
       "...                           ...                            ...   \n",
       "23809                           0                              0   \n",
       "23810                           0                              0   \n",
       "23811                           0                              0   \n",
       "23812                           0                              0   \n",
       "23813                           0                              0   \n",
       "\n",
       "       adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                               0  ...                                      0   \n",
       "1                               0  ...                                      0   \n",
       "2                               0  ...                                      0   \n",
       "3                               0  ...                                      0   \n",
       "4                               0  ...                                      0   \n",
       "...                           ...  ...                                    ...   \n",
       "23809                           0  ...                                      0   \n",
       "23810                           0  ...                                      0   \n",
       "23811                           0  ...                                      0   \n",
       "23812                           0  ...                                      0   \n",
       "23813                           0  ...                                      0   \n",
       "\n",
       "       trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0                 0                0                  0   \n",
       "1                 0                0                  0   \n",
       "2                 0                0                  0   \n",
       "3                 0                0                  0   \n",
       "4                 0                0                  0   \n",
       "...             ...              ...                ...   \n",
       "23809             0                0                  0   \n",
       "23810             0                0                  0   \n",
       "23811             0                0                  0   \n",
       "23812             0                0                  0   \n",
       "23813             0                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "23809                          0                                      0   \n",
       "23810                          0                                      0   \n",
       "23811                          0                                      0   \n",
       "23812                          0                                      0   \n",
       "23813                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                    0          0                           0              0  \n",
       "1                    0          0                           0              0  \n",
       "2                    0          0                           0              0  \n",
       "3                    0          0                           0              0  \n",
       "4                    0          0                           0              0  \n",
       "...                ...        ...                         ...            ...  \n",
       "23809                0          0                           0              0  \n",
       "23810                0          0                           0              0  \n",
       "23811                0          0                           0              0  \n",
       "23812                0          0                           0              0  \n",
       "23813                0          0                           0              0  \n",
       "\n",
       "[23814 rows x 207 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08a92941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T05:09:29.702321Z",
     "iopub.status.busy": "2025-03-15T05:09:29.702116Z",
     "iopub.status.idle": "2025-03-15T05:09:29.706310Z",
     "shell.execute_reply": "2025-03-15T05:09:29.705544Z"
    },
    "papermill": {
     "duration": 0.044967,
     "end_time": "2025-03-15T05:09:29.707383",
     "exception": false,
     "start_time": "2025-03-15T05:09:29.662416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef0f46e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T05:09:29.787471Z",
     "iopub.status.busy": "2025-03-15T05:09:29.787238Z",
     "iopub.status.idle": "2025-03-15T05:09:31.011244Z",
     "shell.execute_reply": "2025-03-15T05:09:31.010422Z"
    },
    "papermill": {
     "duration": 1.265469,
     "end_time": "2025-03-15T05:09:31.012579",
     "exception": false,
     "start_time": "2025-03-15T05:09:29.747110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.01451888630601412\n"
     ]
    }
   ],
   "source": [
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f255ce00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T05:09:31.094619Z",
     "iopub.status.busy": "2025-03-15T05:09:31.094381Z",
     "iopub.status.idle": "2025-03-15T05:09:32.220689Z",
     "shell.execute_reply": "2025-03-15T05:09:32.219730Z"
    },
    "papermill": {
     "duration": 1.168622,
     "end_time": "2025-03-15T05:09:32.221985",
     "exception": false,
     "start_time": "2025-03-15T05:09:31.053363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['g-163_quantile_transformer.pkl', 'g-101_quantile_transformer.pkl', 'g-116_quantile_transformer.pkl', 'g-562_quantile_transformer.pkl', 'g-439_quantile_transformer.pkl', 'g-400_quantile_transformer.pkl', 'g-747_quantile_transformer.pkl', 'g-465_quantile_transformer.pkl', 'g-490_quantile_transformer.pkl', 'c-95_quantile_transformer.pkl', 'c-23_quantile_transformer.pkl', 'c-13_quantile_transformer.pkl', 'g-641_quantile_transformer.pkl', 'g-511_quantile_transformer.pkl', 'g-733_quantile_transformer.pkl', 'g-748_quantile_transformer.pkl', 'g-712_quantile_transformer.pkl', 'SEED1303_FOLD3_.pth', 'g-627_quantile_transformer.pkl', 'g-478_quantile_transformer.pkl', 'g-713_quantile_transformer.pkl', 'g-190_quantile_transformer.pkl', 'g-156_quantile_transformer.pkl', 'kmeans_cells.pkl', 'g-384_quantile_transformer.pkl', 'g-130_quantile_transformer.pkl', 'g-188_quantile_transformer.pkl', 'g-751_quantile_transformer.pkl', 'g-106_quantile_transformer.pkl', 'g-177_quantile_transformer.pkl', 'g-652_quantile_transformer.pkl', 'g-327_quantile_transformer.pkl', 'g-581_quantile_transformer.pkl', 'g-3_quantile_transformer.pkl', 'g-22_quantile_transformer.pkl', 'g-636_quantile_transformer.pkl', 'g-593_quantile_transformer.pkl', 'g-380_quantile_transformer.pkl', 'c-33_quantile_transformer.pkl', 'g-265_quantile_transformer.pkl', 'g-522_quantile_transformer.pkl', 'c-99_quantile_transformer2.pkl', 'g-540_quantile_transformer.pkl', 'g-161_quantile_transformer.pkl', 'g-243_quantile_transformer.pkl', 'g-311_quantile_transformer.pkl', 'g-660_quantile_transformer.pkl', 'g-565_quantile_transformer.pkl', 'g-552_quantile_transformer.pkl', 'g-721_quantile_transformer.pkl', 'g-251_quantile_transformer.pkl', 'g-245_quantile_transformer.pkl', 'g-21_quantile_transformer.pkl', 'g-720_quantile_transformer.pkl', 'g-693_quantile_transformer.pkl', 'g-489_quantile_transformer.pkl', 'g-745_quantile_transformer.pkl', 'g-728_quantile_transformer.pkl', 'g-469_quantile_transformer.pkl', 'g-150_quantile_transformer.pkl', 'g-49_quantile_transformer.pkl', 'g-529_quantile_transformer.pkl', 'g-637_quantile_transformer.pkl', 'g-569_quantile_transformer.pkl', 'g-534_quantile_transformer.pkl', 'g-648_quantile_transformer.pkl', 'g-56_quantile_transformer.pkl', 'g-482_quantile_transformer.pkl', 'g-582_quantile_transformer.pkl', 'g-99_quantile_transformer.pkl', 'g-92_quantile_transformer.pkl', 'c-74_quantile_transformer.pkl', 'g-69_quantile_transformer.pkl', 'g-554_quantile_transformer.pkl', 'g-26_quantile_transformer.pkl', 'g-271_quantile_transformer.pkl', 'g-715_quantile_transformer.pkl', 'g-47_quantile_transformer.pkl', 'SEED1392_FOLD2_.pth', 'g-211_quantile_transformer.pkl', 'g-111_quantile_transformer.pkl', 'c-73_quantile_transformer.pkl', 'g-266_quantile_transformer.pkl', 'g-287_quantile_transformer.pkl', 'c-98_quantile_transformer.pkl', 'g-248_quantile_transformer.pkl', 'g-575_quantile_transformer.pkl', 'g-521_quantile_transformer.pkl', 'c-80_quantile_transformer.pkl', 'g-598_quantile_transformer.pkl', 'g-343_quantile_transformer.pkl', 'g-335_quantile_transformer.pkl', 'g-244_quantile_transformer.pkl', 'g-318_quantile_transformer.pkl', 'g-36_quantile_transformer.pkl', 'g-455_quantile_transformer.pkl', 'g-321_quantile_transformer.pkl', 'g-383_quantile_transformer.pkl', 'g-339_quantile_transformer.pkl', 'g-307_quantile_transformer.pkl', 'g-138_quantile_transformer.pkl', 'g-27_quantile_transformer.pkl', 'g-259_quantile_transformer.pkl', 'g-396_quantile_transformer.pkl', 'g-547_quantile_transformer.pkl', 'g-409_quantile_transformer.pkl', 'g-236_quantile_transformer.pkl', 'c-99_quantile_transformer.pkl', 'g-257_quantile_transformer.pkl', 'g-557_quantile_transformer.pkl', 'g-176_quantile_transformer.pkl', 'g-658_quantile_transformer.pkl', 'g-398_quantile_transformer.pkl', 'g-189_quantile_transformer.pkl', 'g-219_quantile_transformer.pkl', 'g-309_quantile_transformer.pkl', 'g-180_quantile_transformer.pkl', 'g-375_quantile_transformer.pkl', 'g-690_quantile_transformer.pkl', 'g-164_quantile_transformer.pkl', 'c-28_quantile_transformer.pkl', 'g-394_quantile_transformer.pkl', 'g-546_quantile_transformer.pkl', 'g-134_quantile_transformer.pkl', 'g-483_quantile_transformer.pkl', 'g-104_quantile_transformer.pkl', 'g-595_quantile_transformer.pkl', 'g-532_quantile_transformer.pkl', 'g-594_quantile_transformer.pkl', 'g-639_quantile_transformer.pkl', 'c-94_quantile_transformer.pkl', 'g-344_quantile_transformer.pkl', 'g-427_quantile_transformer.pkl', 'g-406_quantile_transformer.pkl', 'g-261_quantile_transformer.pkl', 'SEED1303_FOLD4_.pth', 'g-303_quantile_transformer.pkl', 'g-602_quantile_transformer.pkl', 'c-68_quantile_transformer.pkl', 'g-606_quantile_transformer.pkl', 'g-734_quantile_transformer.pkl', 'g-294_quantile_transformer.pkl', 'g-414_quantile_transformer.pkl', 'c-85_quantile_transformer.pkl', 'g-487_quantile_transformer.pkl', 'c-86_quantile_transformer.pkl', 'g-560_quantile_transformer.pkl', 'g-15_quantile_transformer.pkl', 'g-78_quantile_transformer.pkl', 'g-474_quantile_transformer.pkl', 'SEED1392_FOLD4_.pth', 'g-463_quantile_transformer.pkl', 'g-11_quantile_transformer.pkl', 'c-66_quantile_transformer.pkl', 'g-523_quantile_transformer.pkl', 'g-645_quantile_transformer.pkl', 'g-423_quantile_transformer.pkl', 'g-442_quantile_transformer.pkl', 'g-71_quantile_transformer.pkl', 'g-204_quantile_transformer.pkl', 'SEED1269_FOLD3_.pth', 'g-208_quantile_transformer.pkl', 'c-30_quantile_transformer.pkl', 'g-710_quantile_transformer.pkl', 'g-623_quantile_transformer.pkl', 'g-468_quantile_transformer.pkl', 'g-191_quantile_transformer.pkl', 'g-433_quantile_transformer.pkl', 'g-117_quantile_transformer.pkl', 'g-515_quantile_transformer.pkl', 'g-576_quantile_transformer.pkl', 'g-220_quantile_transformer.pkl', 'c-36_quantile_transformer.pkl', 'g-537_quantile_transformer.pkl', 'g-587_quantile_transformer.pkl', 'g-202_quantile_transformer.pkl', 'c-47_quantile_transformer.pkl', 'g-399_quantile_transformer.pkl', 'g-88_quantile_transformer.pkl', 'g-73_quantile_transformer.pkl', 'g-100_quantile_transformer.pkl', 'g-517_quantile_transformer.pkl', 'g-83_quantile_transformer.pkl', 'g-324_quantile_transformer.pkl', 'g-333_quantile_transformer.pkl', 'g-696_quantile_transformer.pkl', 'g-705_quantile_transformer.pkl', 'g-697_quantile_transformer.pkl', 'c-12_quantile_transformer.pkl', 'g-454_quantile_transformer.pkl', 'g-123_quantile_transformer.pkl', 'g-315_quantile_transformer.pkl', 'g-744_quantile_transformer.pkl', 'c-75_quantile_transformer.pkl', 'g-192_quantile_transformer.pkl', 'g-149_quantile_transformer.pkl', 'c-15_quantile_transformer.pkl', 'g-98_quantile_transformer.pkl', 'g-297_quantile_transformer.pkl', 'g-695_quantile_transformer.pkl', 'SEED1269_FOLD2_.pth', 'g-520_quantile_transformer.pkl', 'g-424_quantile_transformer.pkl', 'g-682_quantile_transformer.pkl', 'g-524_quantile_transformer.pkl', 'g-657_quantile_transformer.pkl', 'g-280_quantile_transformer.pkl', 'g-770_quantile_transformer.pkl', 'g-50_quantile_transformer.pkl', 'g-719_quantile_transformer.pkl', 'g-76_quantile_transformer.pkl', 'SEED940_FOLD3_.pth', 'g-158_quantile_transformer.pkl', 'g-110_quantile_transformer.pkl', 'g-128_quantile_transformer.pkl', 'c-1_quantile_transformer.pkl', 'g-589_quantile_transformer.pkl', 'g-392_quantile_transformer.pkl', 'g-541_quantile_transformer.pkl', 'g-17_quantile_transformer.pkl', 'g-65_quantile_transformer.pkl', 'g-608_quantile_transformer.pkl', 'g-366_quantile_transformer.pkl', 'g-340_quantile_transformer.pkl', 'g-44_quantile_transformer.pkl', 'g-678_quantile_transformer.pkl', 'g-430_quantile_transformer.pkl', 'g-755_quantile_transformer.pkl', 'g-214_quantile_transformer.pkl', 'g-132_quantile_transformer.pkl', 'g-223_quantile_transformer.pkl', 'g-170_quantile_transformer.pkl', 'g-239_quantile_transformer.pkl', 'g-596_quantile_transformer.pkl', 'g-332_quantile_transformer.pkl', 'g-355_quantile_transformer.pkl', 'g-462_quantile_transformer.pkl', 'g-359_quantile_transformer.pkl', 'g-395_quantile_transformer.pkl', 'SEED1303_FOLD1_.pth', 'g-655_quantile_transformer.pkl', 'g-260_quantile_transformer.pkl', 'g-704_quantile_transformer.pkl', 'g-142_quantile_transformer.pkl', 'g-525_quantile_transformer.pkl', 'g-535_quantile_transformer.pkl', 'g-196_quantile_transformer.pkl', 'g-358_quantile_transformer.pkl', 'g-126_quantile_transformer.pkl', 'g-393_quantile_transformer.pkl', 'c-90_quantile_transformer.pkl', 'g-707_quantile_transformer.pkl', 'factor_analysis_g.pkl', 'kmeans_genes.pkl', 'g-310_quantile_transformer.pkl', 'g-234_quantile_transformer.pkl', 'g-95_quantile_transformer.pkl', 'c-58_quantile_transformer.pkl', 'g-367_quantile_transformer.pkl', 'c-26_quantile_transformer.pkl', 'g-118_quantile_transformer.pkl', 'g-471_quantile_transformer.pkl', 'c-0_quantile_transformer.pkl', 'g-759_quantile_transformer.pkl', 'g-276_quantile_transformer.pkl', 'SEED1303_FOLD0_.pth', 'g-320_quantile_transformer.pkl', 'SEED1119_FOLD2_.pth', 'c-27_quantile_transformer.pkl', 'g-538_quantile_transformer.pkl', 'g-684_quantile_transformer.pkl', 'SEED1269_FOLD1_.pth', 'g-584_quantile_transformer.pkl', 'g-1_quantile_transformer.pkl', 'g-152_quantile_transformer.pkl', 'g-41_quantile_transformer.pkl', 'g-420_quantile_transformer.pkl', 'g-29_quantile_transformer.pkl', 'g-160_quantile_transformer.pkl', 'g-97_quantile_transformer.pkl', 'g-391_quantile_transformer.pkl', 'g-35_quantile_transformer.pkl', 'g-299_quantile_transformer.pkl', 'g-448_quantile_transformer.pkl', 'g-12_quantile_transformer.pkl', 'g-605_quantile_transformer.pkl', 'c-21_quantile_transformer.pkl', 'g-198_quantile_transformer.pkl', 'g-59_quantile_transformer.pkl', 'g-273_quantile_transformer.pkl', 'c-44_quantile_transformer.pkl', 'g-80_quantile_transformer.pkl', 'g-488_quantile_transformer.pkl', 'g-54_quantile_transformer.pkl', 'g-588_quantile_transformer.pkl', 'g-67_quantile_transformer.pkl', 'SEED1513_FOLD3_.pth', 'g-550_quantile_transformer.pkl', 'g-363_quantile_transformer.pkl', 'g-644_quantile_transformer.pkl', 'g-173_quantile_transformer.pkl', 'g-8_quantile_transformer.pkl', 'g-677_quantile_transformer.pkl', 'c-8_quantile_transformer.pkl', 'g-681_quantile_transformer.pkl', 'g-591_quantile_transformer.pkl', 'g-55_quantile_transformer.pkl', 'g-686_quantile_transformer.pkl', 'c-25_quantile_transformer.pkl', 'c-5_quantile_transformer.pkl', 'g-680_quantile_transformer.pkl', 'g-542_quantile_transformer.pkl', 'c-24_quantile_transformer.pkl', 'g-501_quantile_transformer.pkl', 'g-356_quantile_transformer.pkl', 'c-96_quantile_transformer.pkl', 'c-14_quantile_transformer.pkl', 'g-769_quantile_transformer.pkl', 'g-497_quantile_transformer.pkl', 'c-51_quantile_transformer.pkl', 'g-254_quantile_transformer.pkl', 'g-203_quantile_transformer.pkl', 'c-84_quantile_transformer.pkl', 'g-597_quantile_transformer.pkl', 'g-458_quantile_transformer.pkl', 'g-275_quantile_transformer.pkl', 'g-313_quantile_transformer.pkl', 'g-555_quantile_transformer.pkl', 'g-62_quantile_transformer.pkl', 'SEED1392_FOLD0_.pth', 'g-32_quantile_transformer.pkl', 'c-89_quantile_transformer.pkl', 'g-687_quantile_transformer.pkl', 'g-306_quantile_transformer.pkl', 'g-323_quantile_transformer.pkl', 'g-749_quantile_transformer.pkl', 'c-41_quantile_transformer.pkl', 'g-445_quantile_transformer.pkl', 'c-71_quantile_transformer.pkl', 'g-650_quantile_transformer.pkl', 'g-304_quantile_transformer.pkl', 'g-450_quantile_transformer.pkl', 'g-52_quantile_transformer.pkl', 'g-353_quantile_transformer.pkl', 'g-703_quantile_transformer.pkl', 'g-229_quantile_transformer.pkl', 'g-252_quantile_transformer.pkl', 'g-631_quantile_transformer.pkl', 'g-431_quantile_transformer.pkl', 'g-267_quantile_transformer.pkl', 'g-691_quantile_transformer.pkl', 'g-544_quantile_transformer.pkl', 'g-663_quantile_transformer.pkl', 'g-376_quantile_transformer.pkl', 'g-638_quantile_transformer.pkl', 'g-503_quantile_transformer.pkl', 'g-402_quantile_transformer.pkl', 'g-13_quantile_transformer.pkl', 'g-536_quantile_transformer.pkl', 'g-674_quantile_transformer.pkl', 'g-312_quantile_transformer.pkl', 'g-735_quantile_transformer.pkl', 'g-410_quantile_transformer.pkl', 'g-385_quantile_transformer.pkl', 'g-615_quantile_transformer.pkl', 'g-466_quantile_transformer.pkl', 'c-83_quantile_transformer.pkl', 'g-197_quantile_transformer.pkl', 'g-178_quantile_transformer.pkl', 'g-672_quantile_transformer.pkl', 'g-561_quantile_transformer.pkl', 'g-346_quantile_transformer.pkl', 'g-625_quantile_transformer.pkl', 'g-174_quantile_transformer.pkl', 'g-334_quantile_transformer.pkl', 'g-228_quantile_transformer.pkl', 'g-630_quantile_transformer.pkl', 'SEED1513_FOLD0_.pth', 'g-567_quantile_transformer.pkl', 'g-269_quantile_transformer.pkl', 'g-206_quantile_transformer.pkl', 'g-633_quantile_transformer.pkl', 'g-238_quantile_transformer.pkl', 'g-386_quantile_transformer.pkl', 'c-77_quantile_transformer.pkl', 'g-601_quantile_transformer.pkl', 'g-256_quantile_transformer.pkl', 'g-231_quantile_transformer.pkl', 'g-764_quantile_transformer.pkl', 'g-66_quantile_transformer.pkl', 'g-493_quantile_transformer.pkl', 'g-9_quantile_transformer.pkl', 'c-88_quantile_transformer.pkl', 'g-230_quantile_transformer.pkl', 'g-447_quantile_transformer.pkl', 'g-199_quantile_transformer.pkl', 'g-563_quantile_transformer.pkl', 'g-86_quantile_transformer.pkl', 'g-435_quantile_transformer.pkl', 'g-654_quantile_transformer.pkl', 'g-115_quantile_transformer.pkl', 'g-379_quantile_transformer.pkl', 'g-289_quantile_transformer.pkl', 'g-168_quantile_transformer.pkl', 'g-451_quantile_transformer.pkl', 'g-93_quantile_transformer.pkl', 'SEED1269_FOLD4_.pth', 'g-357_quantile_transformer.pkl', 'g-717_quantile_transformer.pkl', 'SEED940_FOLD1_.pth', 'g-347_quantile_transformer.pkl', 'g-64_quantile_transformer.pkl', 'g-341_quantile_transformer.pkl', 'g-314_quantile_transformer.pkl', 'g-258_quantile_transformer.pkl', 'g-539_quantile_transformer.pkl', 'g-446_quantile_transformer.pkl', 'g-632_quantile_transformer.pkl', 'c-38_quantile_transformer.pkl', 'g-438_quantile_transformer.pkl', 'g-649_quantile_transformer.pkl', 'g-566_quantile_transformer.pkl', 'g-105_quantile_transformer.pkl', 'g-492_quantile_transformer.pkl', 'c-29_quantile_transformer.pkl', 'g-610_quantile_transformer.pkl', 'g-609_quantile_transformer.pkl', 'g-763_quantile_transformer.pkl', 'g-295_quantile_transformer.pkl', 'g-74_quantile_transformer.pkl', 'g-621_quantile_transformer.pkl', 'c-91_quantile_transformer.pkl', 'g-586_quantile_transformer.pkl', 'g-316_quantile_transformer.pkl', 'g-270_quantile_transformer.pkl', 'g-368_quantile_transformer.pkl', 'g-38_quantile_transformer.pkl', 'g-61_quantile_transformer.pkl', 'g-653_quantile_transformer.pkl', 'g-124_quantile_transformer.pkl', 'g-207_quantile_transformer.pkl', 'g-107_quantile_transformer.pkl', 'g-698_quantile_transformer.pkl', 'g-157_quantile_transformer.pkl', 'g-579_quantile_transformer.pkl', 'g-162_quantile_transformer.pkl', 'g-255_quantile_transformer.pkl', 'g-179_quantile_transformer.pkl', 'c-2_quantile_transformer.pkl', 'g-415_quantile_transformer.pkl', 'g-90_quantile_transformer.pkl', 'g-760_quantile_transformer.pkl', 'g-629_quantile_transformer.pkl', 'g-559_quantile_transformer.pkl', 'g-676_quantile_transformer.pkl', 'g-145_quantile_transformer.pkl', 'g-159_quantile_transformer.pkl', 'g-476_quantile_transformer.pkl', 'g-620_quantile_transformer.pkl', 'g-568_quantile_transformer.pkl', 'g-669_quantile_transformer.pkl', 'c-18_quantile_transformer.pkl', 'g-154_quantile_transformer.pkl', 'g-216_quantile_transformer.pkl', 'g-283_quantile_transformer.pkl', 'g-708_quantile_transformer.pkl', 'g-89_quantile_transformer.pkl', 'g-183_quantile_transformer.pkl', 'g-221_quantile_transformer.pkl', 'g-45_quantile_transformer.pkl', 'g-31_quantile_transformer.pkl', 'g-7_quantile_transformer.pkl', 'c-87_quantile_transformer.pkl', 'g-292_quantile_transformer.pkl', 'g-434_quantile_transformer.pkl', 'g-370_quantile_transformer.pkl', 'g-647_quantile_transformer.pkl', 'g-247_quantile_transformer.pkl', 'g-141_quantile_transformer.pkl', 'g-408_quantile_transformer.pkl', 'g-729_quantile_transformer.pkl', 'g-711_quantile_transformer.pkl', 'g-679_quantile_transformer.pkl', 'g-131_quantile_transformer.pkl', 'g-322_quantile_transformer.pkl', 'g-670_quantile_transformer.pkl', 'g-373_quantile_transformer.pkl', 'g-48_quantile_transformer.pkl', 'c-67_quantile_transformer.pkl', 'g-121_quantile_transformer.pkl', 'g-727_quantile_transformer.pkl', 'g-479_quantile_transformer.pkl', 'g-585_quantile_transformer.pkl', 'g-413_quantile_transformer.pkl', 'c-10_quantile_transformer.pkl', 'g-342_quantile_transformer.pkl', 'g-0_quantile_transformer.pkl', 'g-227_quantile_transformer.pkl', 'g-750_quantile_transformer.pkl', 'g-401_quantile_transformer.pkl', 'g-181_quantile_transformer.pkl', 'g-195_quantile_transformer.pkl', 'g-246_quantile_transformer.pkl', 'g-505_quantile_transformer.pkl', 'g-81_quantile_transformer.pkl', 'g-264_quantile_transformer.pkl', 'g-572_quantile_transformer.pkl', 'g-714_quantile_transformer.pkl', 'g-604_quantile_transformer.pkl', 'g-762_quantile_transformer.pkl', 'g-432_quantile_transformer.pkl', 'g-461_quantile_transformer.pkl', 'g-209_quantile_transformer.pkl', 'g-628_quantile_transformer.pkl', 'g-736_quantile_transformer.pkl', 'g-96_quantile_transformer.pkl', 'g-624_quantile_transformer.pkl', 'g-301_quantile_transformer.pkl', 'g-193_quantile_transformer.pkl', 'g-467_quantile_transformer.pkl', 'g-288_quantile_transformer.pkl', 'g-551_quantile_transformer.pkl', 'g-345_quantile_transformer.pkl', 'g-574_quantile_transformer.pkl', 'g-556_quantile_transformer.pkl', 'g-519_quantile_transformer.pkl', 'g-291_quantile_transformer.pkl', 'g-666_quantile_transformer.pkl', 'g-428_quantile_transformer.pkl', 'g-771_quantile_transformer.pkl', 'g-382_quantile_transformer.pkl', 'g-397_quantile_transformer.pkl', 'g-486_quantile_transformer.pkl', 'g-422_quantile_transformer.pkl', 'g-689_quantile_transformer.pkl', 'g-646_quantile_transformer.pkl', 'g-692_quantile_transformer.pkl', 'g-63_quantile_transformer.pkl', 'g-33_quantile_transformer.pkl', 'g-360_quantile_transformer.pkl', 'g-558_quantile_transformer.pkl', 'g-25_quantile_transformer.pkl', 'g-592_quantile_transformer.pkl', 'g-165_quantile_transformer.pkl', 'g-619_quantile_transformer.pkl', 'g-514_quantile_transformer.pkl', 'g-18_quantile_transformer.pkl', 'g-39_quantile_transformer.pkl', 'g-452_quantile_transformer.pkl', 'g-667_quantile_transformer.pkl', 'g-285_quantile_transformer.pkl', 'g-70_quantile_transformer.pkl', 'g-730_quantile_transformer.pkl', 'g-330_quantile_transformer.pkl', 'g-57_quantile_transformer.pkl', 'g-688_quantile_transformer.pkl', 'g-531_quantile_transformer.pkl', 'g-137_quantile_transformer.pkl', 'c-52_quantile_transformer.pkl', 'g-767_quantile_transformer.pkl', 'g-407_quantile_transformer.pkl', 'c-11_quantile_transformer.pkl', 'g-533_quantile_transformer.pkl', 'g-443_quantile_transformer.pkl', 'g-274_quantile_transformer.pkl', 'g-440_quantile_transformer.pkl', 'g-43_quantile_transformer.pkl', 'g-752_quantile_transformer.pkl', 'g-325_quantile_transformer.pkl', 'c-59_quantile_transformer.pkl', 'g-148_quantile_transformer.pkl', 'g-761_quantile_transformer.pkl', 'g-279_quantile_transformer.pkl', 'g-241_quantile_transformer.pkl', 'g-350_quantile_transformer.pkl', 'g-72_quantile_transformer.pkl', 'g-526_quantile_transformer.pkl', 'g-425_quantile_transformer.pkl', 'g-84_quantile_transformer.pkl', 'g-23_quantile_transformer.pkl', 'g-599_quantile_transformer.pkl', 'c-46_quantile_transformer.pkl', 'g-416_quantile_transformer.pkl', 'g-577_quantile_transformer.pkl', 'g-249_quantile_transformer.pkl', 'g-108_quantile_transformer.pkl', 'g-298_quantile_transformer.pkl', 'c-16_quantile_transformer.pkl', 'c-60_quantile_transformer.pkl', 'g-685_quantile_transformer.pkl', 'g-60_quantile_transformer.pkl', 'c-70_quantile_transformer.pkl', 'g-701_quantile_transformer.pkl', 'g-724_quantile_transformer.pkl', 'g-387_quantile_transformer.pkl', 'g-200_quantile_transformer.pkl', 'g-224_quantile_transformer.pkl', 'g-140_quantile_transformer.pkl', 'g-300_quantile_transformer.pkl', 'g-172_quantile_transformer.pkl', 'g-494_quantile_transformer.pkl', 'g-740_quantile_transformer.pkl', 'g-731_quantile_transformer.pkl', 'g-122_quantile_transformer.pkl', 'g-464_quantile_transformer.pkl', 'g-68_quantile_transformer.pkl', 'g-753_quantile_transformer.pkl', 'g-404_quantile_transformer.pkl', 'g-498_quantile_transformer.pkl', 'g-441_quantile_transformer.pkl', 'g-151_quantile_transformer.pkl', 'g-732_quantile_transformer.pkl', 'SEED1392_FOLD1_.pth', 'c-55_quantile_transformer.pkl', 'SEED1513_FOLD4_.pth', 'g-20_quantile_transformer.pkl', 'g-726_quantile_transformer.pkl', 'g-119_quantile_transformer.pkl', 'g-272_quantile_transformer.pkl', 'g-766_quantile_transformer.pkl', 'g-754_quantile_transformer.pkl', 'g-475_quantile_transformer.pkl', 'g-127_quantile_transformer.pkl', 'g-351_quantile_transformer.pkl', 'c-49_quantile_transformer.pkl', 'g-262_quantile_transformer.pkl', 'g-614_quantile_transformer.pkl', 'g-212_quantile_transformer.pkl', 'g-114_quantile_transformer.pkl', 'g-723_quantile_transformer.pkl', 'SEED940_FOLD2_.pth', 'g-364_quantile_transformer.pkl', 'g-284_quantile_transformer.pkl', 'g-635_quantile_transformer.pkl', 'g-133_quantile_transformer.pkl', 'g-113_quantile_transformer.pkl', 'g-743_quantile_transformer.pkl', 'g-570_quantile_transformer.pkl', 'g-543_quantile_transformer.pkl', 'c-63_quantile_transformer.pkl', 'g-24_quantile_transformer.pkl', 'g-233_quantile_transformer.pkl', 'g-530_quantile_transformer.pkl', 'g-716_quantile_transformer.pkl', 'g-109_quantile_transformer.pkl', 'c-61_quantile_transformer.pkl', 'g-603_quantile_transformer.pkl', 'g-352_quantile_transformer.pkl', 'g-656_quantile_transformer.pkl', 'g-502_quantile_transformer.pkl', 'g-444_quantile_transformer.pkl', 'g-702_quantile_transformer.pkl', 'g-549_quantile_transformer.pkl', 'g-194_quantile_transformer.pkl', 'g-185_quantile_transformer.pkl', 'c-7_quantile_transformer.pkl', 'g-694_quantile_transformer.pkl', 'g-144_quantile_transformer.pkl', 'g-573_quantile_transformer.pkl', 'g-28_quantile_transformer.pkl', 'c-6_quantile_transformer.pkl', 'g-146_quantile_transformer.pkl', 'g-10_quantile_transformer.pkl', 'g-171_quantile_transformer.pkl', 'c-72_quantile_transformer.pkl', 'c-69_quantile_transformer.pkl', 'g-590_quantile_transformer.pkl', 'g-583_quantile_transformer.pkl', 'g-626_quantile_transformer.pkl', 'c-82_quantile_transformer.pkl', 'g-518_quantile_transformer.pkl', 'g-472_quantile_transformer.pkl', 'g-571_quantile_transformer.pkl', 'g-390_quantile_transformer.pkl', 'g-607_quantile_transformer.pkl', 'g-282_quantile_transformer.pkl', 'g-338_quantile_transformer.pkl', 'g-508_quantile_transformer.pkl', 'g-419_quantile_transformer.pkl', 'g-201_quantile_transformer.pkl', 'g-205_quantile_transformer.pkl', 'g-613_quantile_transformer.pkl', 'g-611_quantile_transformer.pkl', 'g-746_quantile_transformer.pkl', 'g-166_quantile_transformer.pkl', 'g-182_quantile_transformer.pkl', 'g-722_quantile_transformer.pkl', 'g-528_quantile_transformer.pkl', 'g-79_quantile_transformer.pkl', 'g-675_quantile_transformer.pkl', 'g-500_quantile_transformer.pkl', 'g-643_quantile_transformer.pkl', 'g-42_quantile_transformer.pkl', 'c-57_quantile_transformer.pkl', 'g-459_quantile_transformer.pkl', 'submission.csv', 'c-4_quantile_transformer.pkl', 'g-226_quantile_transformer.pkl', 'g-296_quantile_transformer.pkl', 'g-429_quantile_transformer.pkl', 'g-34_quantile_transformer.pkl', 'g-512_quantile_transformer.pkl', 'c-32_quantile_transformer.pkl', 'g-580_quantile_transformer.pkl', 'g-499_quantile_transformer.pkl', 'g-242_quantile_transformer.pkl', 'g-706_quantile_transformer.pkl', 'g-371_quantile_transformer.pkl', 'g-77_quantile_transformer.pkl', 'g-281_quantile_transformer.pkl', 'c-37_quantile_transformer.pkl', 'g-2_quantile_transformer.pkl', 'g-268_quantile_transformer.pkl', 'g-217_quantile_transformer.pkl', 'g-485_quantile_transformer.pkl', 'g-718_quantile_transformer.pkl', 'g-354_quantile_transformer.pkl', 'g-336_quantile_transformer.pkl', 'g-369_quantile_transformer.pkl', 'g-495_quantile_transformer.pkl', 'SEED1513_FOLD2_.pth', 'g-618_quantile_transformer.pkl', 'g-215_quantile_transformer.pkl', 'g-509_quantile_transformer.pkl', 'g-527_quantile_transformer.pkl', 'c-54_quantile_transformer.pkl', 'g-578_quantile_transformer.pkl', 'c-62_quantile_transformer.pkl', 'g-169_quantile_transformer.pkl', 'g-664_quantile_transformer.pkl', 'g-362_quantile_transformer.pkl', 'g-418_quantile_transformer.pkl', 'g-58_quantile_transformer.pkl', 'c-17_quantile_transformer.pkl', 'g-139_quantile_transformer.pkl', 'g-348_quantile_transformer.pkl', 'SEED940_FOLD4_.pth', 'g-319_quantile_transformer.pkl', 'g-337_quantile_transformer.pkl', 'c-9_quantile_transformer.pkl', 'g-85_quantile_transformer.pkl', 'g-480_quantile_transformer.pkl', 'g-82_quantile_transformer.pkl', 'c-53_quantile_transformer.pkl', 'g-129_quantile_transformer.pkl', 'g-737_quantile_transformer.pkl', 'g-496_quantile_transformer.pkl', 'g-381_quantile_transformer.pkl', 'g-739_quantile_transformer.pkl', 'g-155_quantile_transformer.pkl', 'c-93_quantile_transformer.pkl', 'c-48_quantile_transformer.pkl', 'g-37_quantile_transformer.pkl', 'g-513_quantile_transformer.pkl', 'g-30_quantile_transformer.pkl', 'g-372_quantile_transformer.pkl', 'g-377_quantile_transformer.pkl', 'g-741_quantile_transformer.pkl', 'g-671_quantile_transformer.pkl', 'g-143_quantile_transformer.pkl', 'g-640_quantile_transformer.pkl', 'g-405_quantile_transformer.pkl', 'c-19_quantile_transformer.pkl', 'g-417_quantile_transformer.pkl', 'g-421_quantile_transformer.pkl', 'c-78_quantile_transformer.pkl', 'SEED1303_FOLD2_.pth', 'g-507_quantile_transformer.pkl', 'g-51_quantile_transformer.pkl', 'g-16_quantile_transformer.pkl', 'g-210_quantile_transformer.pkl', 'g-473_quantile_transformer.pkl', 'g-389_quantile_transformer.pkl', 'g-240_quantile_transformer.pkl', 'c-34_quantile_transformer.pkl', 'g-491_quantile_transformer.pkl', 'g-87_quantile_transformer.pkl', 'g-187_quantile_transformer.pkl', 'g-278_quantile_transformer.pkl', 'g-756_quantile_transformer.pkl', 'g-506_quantile_transformer.pkl', 'g-167_quantile_transformer.pkl', 'g-326_quantile_transformer.pkl', 'g-553_quantile_transformer.pkl', 'g-302_quantile_transformer.pkl', 'g-4_quantile_transformer.pkl', 'c-65_quantile_transformer.pkl', 'g-308_quantile_transformer.pkl', 'g-103_quantile_transformer.pkl', 'c-20_quantile_transformer.pkl', 'c-56_quantile_transformer.pkl', 'g-328_quantile_transformer.pkl', 'g-222_quantile_transformer.pkl', 'g-661_quantile_transformer.pkl', 'c-3_quantile_transformer.pkl', 'g-616_quantile_transformer.pkl', 'g-19_quantile_transformer.pkl', 'g-412_quantile_transformer.pkl', 'g-186_quantile_transformer.pkl', 'g-481_quantile_transformer.pkl', 'g-120_quantile_transformer.pkl', 'c-42_quantile_transformer.pkl', 'g-456_quantile_transformer.pkl', 'g-662_quantile_transformer.pkl', 'g-53_quantile_transformer.pkl', 'g-545_quantile_transformer.pkl', 'c-81_quantile_transformer.pkl', 'g-634_quantile_transformer.pkl', 'g-504_quantile_transformer.pkl', 'g-40_quantile_transformer.pkl', 'c-45_quantile_transformer.pkl', 'g-612_quantile_transformer.pkl', 'g-699_quantile_transformer.pkl', 'c-97_quantile_transformer.pkl', 'g-175_quantile_transformer.pkl', 'g-516_quantile_transformer.pkl', 'g-642_quantile_transformer.pkl', 'g-235_quantile_transformer.pkl', 'c-76_quantile_transformer.pkl', 'g-263_quantile_transformer.pkl', 'g-600_quantile_transformer.pkl', 'g-5_quantile_transformer.pkl', 'g-94_quantile_transformer.pkl', 'g-286_quantile_transformer.pkl', 'g-564_quantile_transformer.pkl', 'g-250_quantile_transformer.pkl', 'g-14_quantile_transformer.pkl', 'g-683_quantile_transformer.pkl', 'g-725_quantile_transformer.pkl', 'g-388_quantile_transformer.pkl', 'g-331_quantile_transformer.pkl', 'g-75_quantile_transformer.pkl', 'g-361_quantile_transformer.pkl', 'g-765_quantile_transformer.pkl', 'SEED1119_FOLD0_.pth', 'c-39_quantile_transformer.pkl', 'g-510_quantile_transformer.pkl', 'g-768_quantile_transformer.pkl', 'g-374_quantile_transformer.pkl', 'g-365_quantile_transformer.pkl', 'g-232_quantile_transformer.pkl', 'g-477_quantile_transformer.pkl', 'g-757_quantile_transformer.pkl', 'g-700_quantile_transformer.pkl', 'g-378_quantile_transformer.pkl', 'g-125_quantile_transformer.pkl', 'g-253_quantile_transformer.pkl', 'c-40_quantile_transformer.pkl', 'g-147_quantile_transformer.pkl', '__notebook__.ipynb', 'g-277_quantile_transformer.pkl', 'g-317_quantile_transformer.pkl', 'g-237_quantile_transformer.pkl', 'g-622_quantile_transformer.pkl', 'SEED1269_FOLD0_.pth', 'g-225_quantile_transformer.pkl', 'g-460_quantile_transformer.pkl', 'g-329_quantile_transformer.pkl', 'g-112_quantile_transformer.pkl', 'c-79_quantile_transformer.pkl', 'c-64_quantile_transformer.pkl', 'g-668_quantile_transformer.pkl', 'g-758_quantile_transformer.pkl', 'SEED1392_FOLD3_.pth', 'g-411_quantile_transformer.pkl', 'g-436_quantile_transformer.pkl', 'g-293_quantile_transformer.pkl', 'g-91_quantile_transformer.pkl', 'g-738_quantile_transformer.pkl', 'c-22_quantile_transformer.pkl', 'g-457_quantile_transformer.pkl', 'g-709_quantile_transformer.pkl', 'SEED1119_FOLD1_.pth', 'SEED940_FOLD0_.pth', 'g-453_quantile_transformer.pkl', 'g-484_quantile_transformer.pkl', 'g-6_quantile_transformer.pkl', 'g-305_quantile_transformer.pkl', 'g-213_quantile_transformer.pkl', 'g-673_quantile_transformer.pkl', 'g-617_quantile_transformer.pkl', 'c-35_quantile_transformer.pkl', 'g-659_quantile_transformer.pkl', 'g-184_quantile_transformer.pkl', 'SEED1119_FOLD4_.pth', 'g-437_quantile_transformer.pkl', 'g-742_quantile_transformer.pkl', 'g-153_quantile_transformer.pkl', 'g-290_quantile_transformer.pkl', 'g-349_quantile_transformer.pkl', 'factor_analysis_c.pkl', 'g-426_quantile_transformer.pkl', 'g-46_quantile_transformer.pkl', 'g-470_quantile_transformer.pkl', 'SEED1513_FOLD1_.pth', 'g-403_quantile_transformer.pkl', 'c-43_quantile_transformer.pkl', 'g-548_quantile_transformer.pkl', 'g-135_quantile_transformer.pkl', 'g-665_quantile_transformer.pkl', 'c-50_quantile_transformer.pkl', 'c-92_quantile_transformer.pkl', 'c-31_quantile_transformer.pkl', 'SEED1119_FOLD3_.pth', 'g-449_quantile_transformer.pkl', 'g-136_quantile_transformer.pkl', 'g-218_quantile_transformer.pkl', 'g-102_quantile_transformer.pkl', 'g-651_quantile_transformer.pkl']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.013952</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.008347</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.003089</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>0.002239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.009164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.008731</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.005078</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.002330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>0.018703</td>\n",
       "      <td>0.006827</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>0.014278</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.002215</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.003278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.014530</td>\n",
       "      <td>0.015760</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>0.004422</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.002610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_0004d9e33                     0.001242                0.002355   \n",
       "1  id_001897cda                     0.000671                0.001114   \n",
       "2  id_002429b5b                     0.000000                0.000000   \n",
       "3  id_00276f245                     0.001930                0.001536   \n",
       "4  id_0027f1083                     0.001897                0.002099   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0        0.002655                        0.010628   \n",
       "1        0.003112                        0.003991   \n",
       "2        0.000000                        0.000000   \n",
       "3        0.002350                        0.009501   \n",
       "4        0.002558                        0.014530   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                           0.013952                        0.005872   \n",
       "1                           0.002251                        0.001864   \n",
       "2                           0.000000                        0.000000   \n",
       "3                           0.018703                        0.006827   \n",
       "4                           0.015760                        0.004204   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                    0.002216                       0.008347   \n",
       "1                    0.006382                       0.011500   \n",
       "2                    0.000000                       0.000000   \n",
       "3                    0.003400                       0.004219   \n",
       "4                    0.004422                       0.002948   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                    0.000578  ...                               0.001184   \n",
       "1                    0.009164  ...                               0.001598   \n",
       "2                    0.000000  ...                               0.000000   \n",
       "3                    0.000596  ...                               0.000968   \n",
       "4                    0.000881  ...                               0.001275   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0      0.003089         0.004364           0.001622   \n",
       "1      0.002049         0.008139           0.000654   \n",
       "2      0.000000         0.000000           0.000000   \n",
       "3      0.001438         0.002812           0.014278   \n",
       "4      0.001178         0.002847           0.001970   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                   0.001340                               0.001100   \n",
       "1                   0.008731                               0.000909   \n",
       "2                   0.000000                               0.000000   \n",
       "3                   0.006459                               0.001083   \n",
       "4                   0.002247                               0.001276   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0         0.001426   0.002170                    0.005835       0.002239  \n",
       "1         0.005078   0.001588                    0.001180       0.002330  \n",
       "2         0.000000   0.000000                    0.000000       0.000000  \n",
       "3         0.002215   0.002311                    0.000942       0.003278  \n",
       "4         0.002042   0.002598                    0.000558       0.002610  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "import os\n",
    "print(os.listdir('/kaggle/working/'))\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "706771e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T05:09:32.304814Z",
     "iopub.status.busy": "2025-03-15T05:09:32.304526Z",
     "iopub.status.idle": "2025-03-15T05:09:32.309081Z",
     "shell.execute_reply": "2025-03-15T05:09:32.308267Z"
    },
    "papermill": {
     "duration": 0.046381,
     "end_time": "2025-03-15T05:09:32.310293",
     "exception": false,
     "start_time": "2025-03-15T05:09:32.263912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3982, 207)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94361e",
   "metadata": {
    "papermill": {
     "duration": 0.040156,
     "end_time": "2025-03-15T05:09:32.390671",
     "exception": false,
     "start_time": "2025-03-15T05:09:32.350515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1651354,
     "isSourceIdPinned": false,
     "sourceId": 19988,
     "sourceType": "competition"
    },
    {
     "datasetId": 6874007,
     "sourceId": 11036227,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "duration": 2354.862715,
   "end_time": "2025-03-15T05:09:35.243021",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-15T04:30:20.380306",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
