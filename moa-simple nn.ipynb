{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eace7acf",
   "metadata": {
    "papermill": {
     "duration": 0.009115,
     "end_time": "2025-03-31T12:08:49.923620",
     "exception": false,
     "start_time": "2025-03-31T12:08:49.914505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# This Notebook is an Updated version of my previous kernel https://www.kaggle.com/kushal1506/moa-pytorch-feature-engineering-0-01846"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd92f6c",
   "metadata": {
    "papermill": {
     "duration": 0.007853,
     "end_time": "2025-03-31T12:08:49.940092",
     "exception": false,
     "start_time": "2025-03-31T12:08:49.932239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# If U find my work helpful and consider forking it, please do Upvote :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01ec8851",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-31T12:08:49.957949Z",
     "iopub.status.busy": "2025-03-31T12:08:49.957536Z",
     "iopub.status.idle": "2025-03-31T12:08:51.143866Z",
     "shell.execute_reply": "2025-03-31T12:08:51.142993Z"
    },
    "papermill": {
     "duration": 1.197483,
     "end_time": "2025-03-31T12:08:51.145687",
     "exception": false,
     "start_time": "2025-03-31T12:08:49.948204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/iterativestratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cda0a8e",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2025-03-31T12:08:51.163727Z",
     "iopub.status.busy": "2025-03-31T12:08:51.163302Z",
     "iopub.status.idle": "2025-03-31T12:08:56.018479Z",
     "shell.execute_reply": "2025-03-31T12:08:56.017542Z"
    },
    "papermill": {
     "duration": 4.866187,
     "end_time": "2025-03-31T12:08:56.020384",
     "exception": false,
     "start_time": "2025-03-31T12:08:51.154197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss ,roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from pickle import load,dump\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffb96175",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:08:56.038596Z",
     "iopub.status.busy": "2025-03-31T12:08:56.038114Z",
     "iopub.status.idle": "2025-03-31T12:08:56.042240Z",
     "shell.execute_reply": "2025-03-31T12:08:56.041254Z"
    },
    "papermill": {
     "duration": 0.014894,
     "end_time": "2025-03-31T12:08:56.043689",
     "exception": false,
     "start_time": "2025-03-31T12:08:56.028795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48fd33b1",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-03-31T12:08:56.061302Z",
     "iopub.status.busy": "2025-03-31T12:08:56.060936Z",
     "iopub.status.idle": "2025-03-31T12:08:56.067787Z",
     "shell.execute_reply": "2025-03-31T12:08:56.066851Z"
    },
    "papermill": {
     "duration": 0.017287,
     "end_time": "2025-03-31T12:08:56.069431",
     "exception": false,
     "start_time": "2025-03-31T12:08:56.052144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_targets_scored.csv',\n",
       " 'sample_submission.csv',\n",
       " 'train_drug.csv',\n",
       " 'train_targets_nonscored.csv',\n",
       " 'train_features.csv',\n",
       " 'test_features.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/lish-moa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e87a2a93",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-03-31T12:08:56.087511Z",
     "iopub.status.busy": "2025-03-31T12:08:56.087215Z",
     "iopub.status.idle": "2025-03-31T12:09:02.877560Z",
     "shell.execute_reply": "2025-03-31T12:09:02.876335Z"
    },
    "papermill": {
     "duration": 6.801285,
     "end_time": "2025-03-31T12:09:02.879497",
     "exception": false,
     "start_time": "2025-03-31T12:08:56.078212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "df = pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c72572c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:09:02.897846Z",
     "iopub.status.busy": "2025-03-31T12:09:02.897523Z",
     "iopub.status.idle": "2025-03-31T12:09:02.967253Z",
     "shell.execute_reply": "2025-03-31T12:09:02.966398Z"
    },
    "papermill": {
     "duration": 0.080658,
     "end_time": "2025-03-31T12:09:02.968969",
     "exception": false,
     "start_time": "2025-03-31T12:09:02.888311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features2=train_features.copy()\n",
    "test_features2=test_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "691ef427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:09:02.987005Z",
     "iopub.status.busy": "2025-03-31T12:09:02.986638Z",
     "iopub.status.idle": "2025-03-31T12:09:02.991572Z",
     "shell.execute_reply": "2025-03-31T12:09:02.990582Z"
    },
    "papermill": {
     "duration": 0.015641,
     "end_time": "2025-03-31T12:09:02.993203",
     "exception": false,
     "start_time": "2025-03-31T12:09:02.977562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31c1d1f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:09:03.011059Z",
     "iopub.status.busy": "2025-03-31T12:09:03.010698Z",
     "iopub.status.idle": "2025-03-31T12:09:11.977046Z",
     "shell.execute_reply": "2025-03-31T12:09:11.976152Z"
    },
    "papermill": {
     "duration": 8.977237,
     "end_time": "2025-03-31T12:09:11.978785",
     "exception": false,
     "start_time": "2025-03-31T12:09:03.001548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in (GENES + CELLS):\n",
    "\n",
    "    transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n",
    "    vec_len = len(train_features[col].values)\n",
    "    vec_len_test = len(test_features[col].values)\n",
    "    raw_vec = train_features[col].values.reshape(vec_len, 1)\n",
    "    transformer.fit(raw_vec)\n",
    "\n",
    "    train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bedc948f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:09:11.997383Z",
     "iopub.status.busy": "2025-03-31T12:09:11.997049Z",
     "iopub.status.idle": "2025-03-31T12:09:12.063869Z",
     "shell.execute_reply": "2025-03-31T12:09:12.062774Z"
    },
    "papermill": {
     "duration": 0.078217,
     "end_time": "2025-03-31T12:09:12.065833",
     "exception": false,
     "start_time": "2025-03-31T12:09:11.987616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "\n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54bdd309",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:09:12.084596Z",
     "iopub.status.busy": "2025-03-31T12:09:12.084239Z",
     "iopub.status.idle": "2025-03-31T12:09:20.793201Z",
     "shell.execute_reply": "2025-03-31T12:09:20.792341Z"
    },
    "papermill": {
     "duration": 8.720406,
     "end_time": "2025-03-31T12:09:20.794977",
     "exception": false,
     "start_time": "2025-03-31T12:09:12.074571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_comp = 600  #<--Update\n",
    "pca_g = PCA(n_components=n_comp, random_state=42)\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "gpca= (pca_g.fit(data[GENES]))\n",
    "train2= (gpca.transform(train_features[GENES]))\n",
    "test2 = (gpca.transform(test_features[GENES]))\n",
    "\n",
    "train_gpca = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test_gpca = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train_gpca), axis=1)\n",
    "test_features = pd.concat((test_features, test_gpca), axis=1)\n",
    "\n",
    "dump(gpca, open('gpca.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0850b3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:09:20.813668Z",
     "iopub.status.busy": "2025-03-31T12:09:20.813314Z",
     "iopub.status.idle": "2025-03-31T12:09:21.450439Z",
     "shell.execute_reply": "2025-03-31T12:09:21.449281Z"
    },
    "papermill": {
     "duration": 0.648798,
     "end_time": "2025-03-31T12:09:21.452660",
     "exception": false,
     "start_time": "2025-03-31T12:09:20.803862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CELLS\n",
    "n_comp = 50  #<--Update\n",
    "\n",
    "pca_c = PCA(n_components=n_comp, random_state=42)\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "cpca= (pca_c.fit(data[CELLS]))\n",
    "train2= (cpca.transform(train_features[CELLS]))\n",
    "test2 = (cpca.transform(test_features[CELLS]))\n",
    "\n",
    "train_cpca = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test_cpca = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train_cpca), axis=1)\n",
    "test_features = pd.concat((test_features, test_cpca), axis=1)\n",
    "\n",
    "dump(cpca, open('cpca.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "643ca443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:09:21.472318Z",
     "iopub.status.busy": "2025-03-31T12:09:21.471951Z",
     "iopub.status.idle": "2025-03-31T12:09:22.156750Z",
     "shell.execute_reply": "2025-03-31T12:09:22.155874Z"
    },
    "papermill": {
     "duration": 0.696195,
     "end_time": "2025-03-31T12:09:22.158552",
     "exception": false,
     "start_time": "2025-03-31T12:09:21.462357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#通过方差阈值（0.85）过滤低方差特征，保留信息量大的特征，提升模型效率并减少噪声。\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "#提取所有数值型特征列（排除ID和分类字段）\n",
    "c_n = [f for f in list(train_features.columns) if f not in ['sig_id', 'cp_type', 'cp_time', 'cp_dose']]\n",
    "#对训练集的数值特征计算方差（var()）生成布尔掩码mask，标记方差≥0.85的特征为True。\n",
    "mask = (train_features[c_n].var() >= 0.85).values\n",
    "#从训练集中选择高方差特征列（mask=True的列）,将非数值列（ID、类别）与筛选后的特征重新拼接。\n",
    "tmp = train_features[c_n].loc[:, mask]\n",
    "train_features = pd.concat([train_features[['sig_id', 'cp_type', 'cp_time', 'cp_dose']], tmp], axis=1)\n",
    "#测试集使用训练集计算的mask，避免数据泄漏。\n",
    "tmp = test_features[c_n].loc[:, mask]\n",
    "test_features = pd.concat([test_features[['sig_id', 'cp_type', 'cp_time', 'cp_dose']], tmp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59c46f8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:09:22.177304Z",
     "iopub.status.busy": "2025-03-31T12:09:22.176973Z",
     "iopub.status.idle": "2025-03-31T12:09:48.270213Z",
     "shell.execute_reply": "2025-03-31T12:09:48.269090Z"
    },
    "papermill": {
     "duration": 26.104418,
     "end_time": "2025-03-31T12:09:48.271963",
     "exception": false,
     "start_time": "2025-03-31T12:09:22.167545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def fe_cluster_genes(train, test, n_clusters_g = 22, SEED = 42):\n",
    "    \n",
    "    features_g = GENES\n",
    "    #features_c = CELLS\n",
    "    \n",
    "    def create_cluster(train, test, features, kind = 'g', n_clusters = n_clusters_g):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans_genes = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_genes, open('kmeans_genes.pkl', 'wb'))\n",
    "        train[f'clusters_{kind}'] = kmeans_genes.predict(train_.values)\n",
    "        test[f'clusters_{kind}'] = kmeans_genes.predict(test_.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "    train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "   # train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features2 ,test_features2=fe_cluster_genes(train_features2,test_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "897dacc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:09:48.290364Z",
     "iopub.status.busy": "2025-03-31T12:09:48.290069Z",
     "iopub.status.idle": "2025-03-31T12:09:49.478174Z",
     "shell.execute_reply": "2025-03-31T12:09:49.477314Z"
    },
    "papermill": {
     "duration": 1.199089,
     "end_time": "2025-03-31T12:09:49.480106",
     "exception": false,
     "start_time": "2025-03-31T12:09:48.281017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_cluster_cells(train, test, n_clusters_c = 4, SEED = 42):\n",
    "    \n",
    "    #features_g = GENES\n",
    "    features_c = CELLS\n",
    "    \n",
    "    def create_cluster(train, test, features, kind = 'c', n_clusters = n_clusters_c):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans_cells = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_cells, open('kmeans_cells.pkl', 'wb'))\n",
    "        train[f'clusters_{kind}'] = kmeans_cells.predict(train_.values)\n",
    "        test[f'clusters_{kind}'] = kmeans_cells.predict(test_.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "   # train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "    train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features2 ,test_features2=fe_cluster_cells(train_features2,test_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8bd7848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:09:49.503186Z",
     "iopub.status.busy": "2025-03-31T12:09:49.502794Z",
     "iopub.status.idle": "2025-03-31T12:09:49.612423Z",
     "shell.execute_reply": "2025-03-31T12:09:49.611291Z"
    },
    "papermill": {
     "duration": 0.122545,
     "end_time": "2025-03-31T12:09:49.614342",
     "exception": false,
     "start_time": "2025-03-31T12:09:49.491797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pca=pd.concat((train_gpca,train_cpca),axis=1)\n",
    "test_pca=pd.concat((test_gpca,test_cpca),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2085f969",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:09:49.633342Z",
     "iopub.status.busy": "2025-03-31T12:09:49.633011Z",
     "iopub.status.idle": "2025-03-31T12:09:59.106194Z",
     "shell.execute_reply": "2025-03-31T12:09:59.105140Z"
    },
    "papermill": {
     "duration": 9.484853,
     "end_time": "2025-03-31T12:09:59.108165",
     "exception": false,
     "start_time": "2025-03-31T12:09:49.623312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_cluster_pca(train, test,n_clusters=5,SEED = 42):\n",
    "        data=pd.concat([train,test],axis=0)\n",
    "        kmeans_pca = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_pca, open('kmeans_pca.pkl', 'wb'))\n",
    "        train[f'clusters_pca'] = kmeans_pca.predict(train.values)\n",
    "        test[f'clusters_pca'] = kmeans_pca.predict(test.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_pca'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_pca'])\n",
    "        return train, test\n",
    "train_cluster_pca ,test_cluster_pca = fe_cluster_pca(train_pca,test_pca) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eef71c",
   "metadata": {
    "papermill": {
     "duration": 0.008305,
     "end_time": "2025-03-31T12:09:59.126518",
     "exception": false,
     "start_time": "2025-03-31T12:09:59.118213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "就是在pca特征后面又加了独热编码的pca簇特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c57067f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:09:59.144953Z",
     "iopub.status.busy": "2025-03-31T12:09:59.144488Z",
     "iopub.status.idle": "2025-03-31T12:09:59.151112Z",
     "shell.execute_reply": "2025-03-31T12:09:59.150185Z"
    },
    "papermill": {
     "duration": 0.017645,
     "end_time": "2025-03-31T12:09:59.152667",
     "exception": false,
     "start_time": "2025-03-31T12:09:59.135022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_cluster_pca = train_cluster_pca.iloc[:,650:]\n",
    "test_cluster_pca = test_cluster_pca.iloc[:,650:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6e0c46b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:09:59.171921Z",
     "iopub.status.busy": "2025-03-31T12:09:59.171471Z",
     "iopub.status.idle": "2025-03-31T12:09:59.178251Z",
     "shell.execute_reply": "2025-03-31T12:09:59.177323Z"
    },
    "papermill": {
     "duration": 0.018369,
     "end_time": "2025-03-31T12:09:59.179882",
     "exception": false,
     "start_time": "2025-03-31T12:09:59.161513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features_cluster=train_features2.iloc[:,876:]\n",
    "test_features_cluster=test_features2.iloc[:,876:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63388d24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:09:59.198666Z",
     "iopub.status.busy": "2025-03-31T12:09:59.198258Z",
     "iopub.status.idle": "2025-03-31T12:09:59.204504Z",
     "shell.execute_reply": "2025-03-31T12:09:59.203569Z"
    },
    "papermill": {
     "duration": 0.017282,
     "end_time": "2025-03-31T12:09:59.205873",
     "exception": false,
     "start_time": "2025-03-31T12:09:59.188591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "gsquarecols=['g-574','g-211','g-216','g-0','g-255','g-577','g-153','g-389','g-60','g-370','g-248','g-167','g-203','g-177','g-301','g-332','g-517','g-6','g-744','g-224','g-162','g-3','g-736','g-486','g-283','g-22','g-359','g-361','g-440','g-335','g-106','g-307','g-745','g-146','g-416','g-298','g-666','g-91','g-17','g-549','g-145','g-157','g-768','g-568','g-396']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0a9fc1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:09:59.224328Z",
     "iopub.status.busy": "2025-03-31T12:09:59.223940Z",
     "iopub.status.idle": "2025-03-31T12:10:02.795827Z",
     "shell.execute_reply": "2025-03-31T12:10:02.794877Z"
    },
    "papermill": {
     "duration": 3.583169,
     "end_time": "2025-03-31T12:10:02.797676",
     "exception": false,
     "start_time": "2025-03-31T12:09:59.214507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_stats(train, test):\n",
    "    \n",
    "    features_g = GENES\n",
    "    features_c = CELLS\n",
    "    \n",
    "    for df in train, test:\n",
    "        df['g_sum'] = df[features_g].sum(axis = 1)\n",
    "        df['g_mean'] = df[features_g].mean(axis = 1)\n",
    "        df['g_std'] = df[features_g].std(axis = 1)\n",
    "        df['g_kurt'] = df[features_g].kurtosis(axis = 1)\n",
    "        df['g_skew'] = df[features_g].skew(axis = 1)\n",
    "        df['c_sum'] = df[features_c].sum(axis = 1)\n",
    "        df['c_mean'] = df[features_c].mean(axis = 1)\n",
    "        df['c_std'] = df[features_c].std(axis = 1)\n",
    "        df['c_kurt'] = df[features_c].kurtosis(axis = 1)\n",
    "        df['c_skew'] = df[features_c].skew(axis = 1)\n",
    "        df['gc_sum'] = df[features_g + features_c].sum(axis = 1)\n",
    "        df['gc_mean'] = df[features_g + features_c].mean(axis = 1)\n",
    "        df['gc_std'] = df[features_g + features_c].std(axis = 1)\n",
    "        df['gc_kurt'] = df[features_g + features_c].kurtosis(axis = 1)\n",
    "        df['gc_skew'] = df[features_g + features_c].skew(axis = 1)\n",
    "        \n",
    "        df['c52_c42'] = df['c-52'] * df['c-42']\n",
    "        df['c13_c73'] = df['c-13'] * df['c-73']\n",
    "        df['c26_c13'] = df['c-26'] * df['c-13']\n",
    "        df['c33_c6'] = df['c-33'] * df['c-6']\n",
    "        df['c11_c55'] = df['c-11'] * df['c-55']\n",
    "        df['c38_c63'] = df['c-38'] * df['c-63']\n",
    "        df['c38_c94'] = df['c-38'] * df['c-94']\n",
    "        df['c13_c94'] = df['c-13'] * df['c-94']\n",
    "        df['c4_c52'] = df['c-4'] * df['c-52']\n",
    "        df['c4_c42'] = df['c-4'] * df['c-42']\n",
    "        df['c13_c38'] = df['c-13'] * df['c-38']\n",
    "        df['c55_c2'] = df['c-55'] * df['c-2']\n",
    "        df['c55_c4'] = df['c-55'] * df['c-4']\n",
    "        df['c4_c13'] = df['c-4'] * df['c-13']\n",
    "        df['c82_c42'] = df['c-82'] * df['c-42']\n",
    "        df['c66_c42'] = df['c-66'] * df['c-42']\n",
    "        df['c6_c38'] = df['c-6'] * df['c-38']\n",
    "        df['c2_c13'] = df['c-2'] * df['c-13']\n",
    "        df['c62_c42'] = df['c-62'] * df['c-42']\n",
    "        df['c90_c55'] = df['c-90'] * df['c-55']\n",
    "        df['c26_c38'] = df['c-26'] * df['c-38']\n",
    "        df['c90_c13'] = df['c-90'] * df['c-13']\n",
    "        df['c85_c31'] = df['c-85'] * df['c-31']\n",
    "        df['c63_c42'] = df['c-63'] * df['c-42']\n",
    "        df['c94_c11'] = df['c-94'] * df['c-11']\n",
    "        df['c94_c60'] = df['c-94'] * df['c-60']\n",
    "        df['c55_c42'] = df['c-55'] * df['c-42']\n",
    "        df['g37_c50'] = df['g-37'] * df['g-50']\n",
    "        \n",
    "        \n",
    "        for feature in features_c:\n",
    "             df[f'{feature}_squared'] = df[feature] ** 2     \n",
    "                \n",
    "        for feature in gsquarecols:\n",
    "            df[f'{feature}_squared'] = df[feature] ** 2        \n",
    "        \n",
    "    return train, test\n",
    "\n",
    "train_features2,test_features2=fe_stats(train_features2,test_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "796025b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:02.817304Z",
     "iopub.status.busy": "2025-03-31T12:10:02.816996Z",
     "iopub.status.idle": "2025-03-31T12:10:02.847762Z",
     "shell.execute_reply": "2025-03-31T12:10:02.846857Z"
    },
    "papermill": {
     "duration": 0.042099,
     "end_time": "2025-03-31T12:10:02.849536",
     "exception": false,
     "start_time": "2025-03-31T12:10:02.807437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features_stats=train_features2.iloc[:,902:]\n",
    "test_features_stats=test_features2.iloc[:,902:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "925e50c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:02.868800Z",
     "iopub.status.busy": "2025-03-31T12:10:02.868471Z",
     "iopub.status.idle": "2025-03-31T12:10:02.986357Z",
     "shell.execute_reply": "2025-03-31T12:10:02.985493Z"
    },
    "papermill": {
     "duration": 0.129465,
     "end_time": "2025-03-31T12:10:02.988134",
     "exception": false,
     "start_time": "2025-03-31T12:10:02.858669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.concat((train_features, train_features_cluster,train_cluster_pca,train_features_stats), axis=1)\n",
    "test_features = pd.concat((test_features, test_features_cluster,test_cluster_pca,test_features_stats), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d6d4b51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:03.007765Z",
     "iopub.status.busy": "2025-03-31T12:10:03.007437Z",
     "iopub.status.idle": "2025-03-31T12:10:03.124911Z",
     "shell.execute_reply": "2025-03-31T12:10:03.123553Z"
    },
    "papermill": {
     "duration": 0.129043,
     "end_time": "2025-03-31T12:10:03.126518",
     "exception": false,
     "start_time": "2025-03-31T12:10:02.997475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 targets without ANY mechanism of action in the nonscored dataset\n"
     ]
    }
   ],
   "source": [
    "#Extract unique elements per column\n",
    "cols2 = train_targets_nonscored.columns.to_list() # specify the columns whose unique values you want here\n",
    "uniques2 = {col: train_targets_nonscored[col].nunique() for col in cols2}\n",
    "uniques2=pd.DataFrame(uniques2, index=[0]).T\n",
    "uniques2=uniques2.rename(columns={0:'count'})\n",
    "uniques2= uniques2.drop('sig_id', axis=0)#行是moa标签，列是出现的次数的种类数\n",
    "print(f\"{len(uniques2[uniques2['count']==1])} targets without ANY mechanism of action in the nonscored dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34253661",
   "metadata": {
    "papermill": {
     "duration": 0.008788,
     "end_time": "2025-03-31T12:10:03.145758",
     "exception": false,
     "start_time": "2025-03-31T12:10:03.136970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "筛掉了那些只有0或者只有1的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2875f1f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:03.165451Z",
     "iopub.status.busy": "2025-03-31T12:10:03.165117Z",
     "iopub.status.idle": "2025-03-31T12:10:03.194136Z",
     "shell.execute_reply": "2025-03-31T12:10:03.193294Z"
    },
    "papermill": {
     "duration": 0.040992,
     "end_time": "2025-03-31T12:10:03.195758",
     "exception": false,
     "start_time": "2025-03-31T12:10:03.154766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nonmoacols=uniques2[uniques2['count']==1].index\n",
    "train_targets_nonscored_columns = [col for col in list(train_targets_nonscored.columns) if col not in nonmoacols]\n",
    "train_targets_nonscored=train_targets_nonscored[train_targets_nonscored_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14a9a56f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:03.215420Z",
     "iopub.status.busy": "2025-03-31T12:10:03.215091Z",
     "iopub.status.idle": "2025-03-31T12:10:03.841154Z",
     "shell.execute_reply": "2025-03-31T12:10:03.840253Z"
    },
    "papermill": {
     "duration": 0.637877,
     "end_time": "2025-03-31T12:10:03.842976",
     "exception": false,
     "start_time": "2025-03-31T12:10:03.205099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_nonscored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_nonscored.columns]  #有意义的非评分目标标签"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3a9b30",
   "metadata": {
    "papermill": {
     "duration": 0.00942,
     "end_time": "2025-03-31T12:10:03.861884",
     "exception": false,
     "start_time": "2025-03-31T12:10:03.852464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "先是删除了控制组样本，然后删除了cp_type这一列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7e7cfee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:03.881763Z",
     "iopub.status.busy": "2025-03-31T12:10:03.881427Z",
     "iopub.status.idle": "2025-03-31T12:10:03.987773Z",
     "shell.execute_reply": "2025-03-31T12:10:03.986770Z"
    },
    "papermill": {
     "duration": 0.118269,
     "end_time": "2025-03-31T12:10:03.989718",
     "exception": false,
     "start_time": "2025-03-31T12:10:03.871449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5983b6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:04.010968Z",
     "iopub.status.busy": "2025-03-31T12:10:04.010565Z",
     "iopub.status.idle": "2025-03-31T12:10:04.035191Z",
     "shell.execute_reply": "2025-03-31T12:10:04.033994Z"
    },
    "papermill": {
     "duration": 0.036824,
     "end_time": "2025-03-31T12:10:04.037291",
     "exception": false,
     "start_time": "2025-03-31T12:10:04.000467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist() #有意义的非评分标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37037db3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:04.058552Z",
     "iopub.status.busy": "2025-03-31T12:10:04.058231Z",
     "iopub.status.idle": "2025-03-31T12:10:04.287904Z",
     "shell.execute_reply": "2025-03-31T12:10:04.287072Z"
    },
    "papermill": {
     "duration": 0.241546,
     "end_time": "2025-03-31T12:10:04.289591",
     "exception": false,
     "start_time": "2025-03-31T12:10:04.048045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=['cp_time','cp_dose'])\n",
    "test_ = pd.get_dummies(test, columns=['cp_time','cp_dose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42b4be63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:04.309923Z",
     "iopub.status.busy": "2025-03-31T12:10:04.309542Z",
     "iopub.status.idle": "2025-03-31T12:10:04.320638Z",
     "shell.execute_reply": "2025-03-31T12:10:04.319792Z"
    },
    "papermill": {
     "duration": 0.022546,
     "end_time": "2025-03-31T12:10:04.322093",
     "exception": false,
     "start_time": "2025-03-31T12:10:04.299547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_cols = [c for c in train.columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['sig_id']]\n",
    "#所有特征组成的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41bf437a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:04.342058Z",
     "iopub.status.busy": "2025-03-31T12:10:04.341687Z",
     "iopub.status.idle": "2025-03-31T12:10:04.346952Z",
     "shell.execute_reply": "2025-03-31T12:10:04.345982Z"
    },
    "papermill": {
     "duration": 0.017095,
     "end_time": "2025-03-31T12:10:04.348625",
     "exception": false,
     "start_time": "2025-03-31T12:10:04.331530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1248"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f231d28b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:04.368933Z",
     "iopub.status.busy": "2025-03-31T12:10:04.368571Z",
     "iopub.status.idle": "2025-03-31T12:10:04.375079Z",
     "shell.execute_reply": "2025-03-31T12:10:04.374250Z"
    },
    "papermill": {
     "duration": 0.018265,
     "end_time": "2025-03-31T12:10:04.376511",
     "exception": false,
     "start_time": "2025-03-31T12:10:04.358246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features.astype(np.float32)\n",
    "        self.targets = targets.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48e655c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:04.396691Z",
     "iopub.status.busy": "2025-03-31T12:10:04.396361Z",
     "iopub.status.idle": "2025-03-31T12:10:04.404490Z",
     "shell.execute_reply": "2025-03-31T12:10:04.403698Z"
    },
    "papermill": {
     "duration": 0.019993,
     "end_time": "2025-03-31T12:10:04.406024",
     "exception": false,
     "start_time": "2025-03-31T12:10:04.386031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "243522d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:04.426381Z",
     "iopub.status.busy": "2025-03-31T12:10:04.426054Z",
     "iopub.status.idle": "2025-03-31T12:10:04.432951Z",
     "shell.execute_reply": "2025-03-31T12:10:04.432116Z"
    },
    "papermill": {
     "duration": 0.018752,
     "end_time": "2025-03-31T12:10:04.434420",
     "exception": false,
     "start_time": "2025-03-31T12:10:04.415668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8201b6d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:04.455145Z",
     "iopub.status.busy": "2025-03-31T12:10:04.454776Z",
     "iopub.status.idle": "2025-03-31T12:10:04.461492Z",
     "shell.execute_reply": "2025-03-31T12:10:04.460654Z"
    },
    "papermill": {
     "duration": 0.018564,
     "end_time": "2025-03-31T12:10:04.462947",
     "exception": false,
     "start_time": "2025-03-31T12:10:04.444383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model1, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.leaky_relu(self.dense1(x), 1e-3)\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57a94bb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:04.483413Z",
     "iopub.status.busy": "2025-03-31T12:10:04.483086Z",
     "iopub.status.idle": "2025-03-31T12:10:04.495543Z",
     "shell.execute_reply": "2025-03-31T12:10:04.494673Z"
    },
    "papermill": {
     "duration": 0.02437,
     "end_time": "2025-03-31T12:10:04.496980",
     "exception": false,
     "start_time": "2025-03-31T12:10:04.472610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "        def __init__(self, num_features, num_targets, hidden_size):\n",
    "            super(Model, self).__init__()\n",
    "            cha_1 = 256\n",
    "            cha_2 = 512\n",
    "            cha_3 = 512\n",
    "\n",
    "            cha_1_reshape = int(hidden_size/cha_1)\n",
    "            cha_po_1 = int(hidden_size/cha_1/2)\n",
    "            cha_po_2 = int(hidden_size/cha_1/2/2) * cha_3\n",
    "\n",
    "            self.cha_1 = cha_1\n",
    "            self.cha_2 = cha_2\n",
    "            self.cha_3 = cha_3\n",
    "            self.cha_1_reshape = cha_1_reshape\n",
    "            self.cha_po_1 = cha_po_1\n",
    "            self.cha_po_2 = cha_po_2\n",
    "\n",
    "            self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "            self.dropout1 = nn.Dropout(0.1)\n",
    "            self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "\n",
    "            self.batch_norm_c1 = nn.BatchNorm1d(cha_1)\n",
    "            self.dropout_c1 = nn.Dropout(0.1)\n",
    "            self.conv1 = nn.utils.weight_norm(nn.Conv1d(cha_1,cha_2, kernel_size = 5, stride = 1, padding=2,  bias=False),dim=None)\n",
    "\n",
    "            self.ave_po_c1 = nn.AdaptiveAvgPool1d(output_size = cha_po_1)\n",
    "\n",
    "            self.batch_norm_c2 = nn.BatchNorm1d(cha_2)\n",
    "            self.dropout_c2 = nn.Dropout(0.1)\n",
    "            self.conv2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "\n",
    "            self.batch_norm_c2_1 = nn.BatchNorm1d(cha_2)\n",
    "            self.dropout_c2_1 = nn.Dropout(0.3)\n",
    "            self.conv2_1 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "\n",
    "            self.batch_norm_c2_2 = nn.BatchNorm1d(cha_2)\n",
    "            self.dropout_c2_2 = nn.Dropout(0.2)\n",
    "            self.conv2_2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_3, kernel_size = 5, stride = 1, padding=2, bias=True),dim=None)\n",
    "\n",
    "            self.max_po_c2 = nn.MaxPool1d(kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "            self.flt = nn.Flatten()\n",
    "\n",
    "            self.batch_norm3 = nn.BatchNorm1d(cha_po_2)\n",
    "            self.dropout3 = nn.Dropout(0.2)\n",
    "            self.dense3 = nn.utils.weight_norm(nn.Linear(cha_po_2, num_targets))\n",
    "\n",
    "        def forward(self, x):\n",
    "\n",
    "            x = self.batch_norm1(x)\n",
    "            x = self.dropout1(x)\n",
    "            x = F.celu(self.dense1(x), alpha=0.06)\n",
    "\n",
    "            x = x.reshape(x.shape[0],self.cha_1,\n",
    "                          self.cha_1_reshape)\n",
    "\n",
    "            x = self.batch_norm_c1(x)\n",
    "            x = self.dropout_c1(x)\n",
    "            x = F.relu(self.conv1(x))\n",
    "\n",
    "            x = self.ave_po_c1(x)\n",
    "\n",
    "            x = self.batch_norm_c2(x)\n",
    "            x = self.dropout_c2(x)\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x_s = x\n",
    "\n",
    "            x = self.batch_norm_c2_1(x)\n",
    "            x = self.dropout_c2_1(x)\n",
    "            x = F.relu(self.conv2_1(x))\n",
    "\n",
    "            x = self.batch_norm_c2_2(x)\n",
    "            x = self.dropout_c2_2(x)\n",
    "            x = F.relu(self.conv2_2(x))\n",
    "            x =  x * x_s\n",
    "\n",
    "            x = self.max_po_c2(x)\n",
    "\n",
    "            x = self.flt(x)\n",
    "\n",
    "            x = self.batch_norm3(x)\n",
    "            x = self.dropout3(x)\n",
    "            x = self.dense3(x)\n",
    "\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fb3bded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:04.518154Z",
     "iopub.status.busy": "2025-03-31T12:10:04.517782Z",
     "iopub.status.idle": "2025-03-31T12:10:04.522419Z",
     "shell.execute_reply": "2025-03-31T12:10:04.521605Z"
    },
    "papermill": {
     "duration": 0.016656,
     "end_time": "2025-03-31T12:10:04.523883",
     "exception": false,
     "start_time": "2025-03-31T12:10:04.507227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 26\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 6e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 7\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = True\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "672c4146",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:04.544485Z",
     "iopub.status.busy": "2025-03-31T12:10:04.544133Z",
     "iopub.status.idle": "2025-03-31T12:10:04.555836Z",
     "shell.execute_reply": "2025-03-31T12:10:04.555020Z"
    },
    "papermill": {
     "duration": 0.023764,
     "end_time": "2025-03-31T12:10:04.557425",
     "exception": false,
     "start_time": "2025-03-31T12:10:04.533661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    mskf = MultilabelStratifiedKFold(n_splits=7)\n",
    "    for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "         train.loc[v_idx, 'kfold'] = int(f)\n",
    "    train['kfold'] = train['kfold'].astype(int)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model1(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"SEED: {seed} ,FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"SEED{seed}_FOLD{fold}_nonscored.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model1(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "\n",
    "    )\n",
    "    model.load_state_dict(torch.load(f\"SEED{seed}_FOLD{fold}_nonscored.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9fc3efbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:04.578175Z",
     "iopub.status.busy": "2025-03-31T12:10:04.577778Z",
     "iopub.status.idle": "2025-03-31T12:10:04.582686Z",
     "shell.execute_reply": "2025-03-31T12:10:04.581872Z"
    },
    "papermill": {
     "duration": 0.016881,
     "end_time": "2025-03-31T12:10:04.584212",
     "exception": false,
     "start_time": "2025-03-31T12:10:04.567331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "abdd969c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:10:04.604697Z",
     "iopub.status.busy": "2025-03-31T12:10:04.604350Z",
     "iopub.status.idle": "2025-03-31T12:34:06.821294Z",
     "shell.execute_reply": "2025-03-31T12:34:06.820558Z"
    },
    "papermill": {
     "duration": 1442.228976,
     "end_time": "2025-03-31T12:34:06.822948",
     "exception": false,
     "start_time": "2025-03-31T12:10:04.593972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 0, FOLD: 0, EPOCH: 0, train_loss: 0.5876662201575331\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08735949947283818\n",
      "SEED: 0, FOLD: 0, EPOCH: 1, train_loss: 0.01642236878743043\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 1, valid_loss: 0.006098045466037897\n",
      "SEED: 0, FOLD: 0, EPOCH: 2, train_loss: 0.009288513095344644\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 2, valid_loss: 0.00570342313641539\n",
      "SEED: 0, FOLD: 0, EPOCH: 3, train_loss: 0.009243685764738836\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 3, valid_loss: 0.005432544168657982\n",
      "SEED: 0, FOLD: 0, EPOCH: 4, train_loss: 0.009058085414958564\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 4, valid_loss: 0.0056814294881545584\n",
      "SEED: 0, FOLD: 0, EPOCH: 5, train_loss: 0.008968649123719818\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 5, valid_loss: 0.006163321578731904\n",
      "SEED: 0, FOLD: 0, EPOCH: 6, train_loss: 0.008935478729875507\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 6, valid_loss: 0.005566556042490097\n",
      "SEED: 0, FOLD: 0, EPOCH: 7, train_loss: 0.0089206681586802\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 7, valid_loss: 0.005454980696623142\n",
      "SEED: 0, FOLD: 0, EPOCH: 8, train_loss: 0.00891725074600529\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005343718346781456\n",
      "SEED: 0, FOLD: 0, EPOCH: 9, train_loss: 0.008920828975435044\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005449817515909672\n",
      "SEED: 0, FOLD: 0, EPOCH: 10, train_loss: 0.008921764665157409\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 10, valid_loss: 0.005380897281261591\n",
      "SEED: 0, FOLD: 0, EPOCH: 11, train_loss: 0.008907786570489407\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 11, valid_loss: 0.0054936249238940384\n",
      "SEED: 0, FOLD: 0, EPOCH: 12, train_loss: 0.008915787449458966\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 12, valid_loss: 0.005443041678518057\n",
      "SEED: 0, FOLD: 0, EPOCH: 13, train_loss: 0.008898159929526013\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 13, valid_loss: 0.0055284513017305964\n",
      "SEED: 0, FOLD: 0, EPOCH: 14, train_loss: 0.008907997414369035\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 14, valid_loss: 0.005464372905687644\n",
      "SEED: 0, FOLD: 1, EPOCH: 0, train_loss: 0.5898985481141387\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 0, valid_loss: 0.07304490816134673\n",
      "SEED: 0, FOLD: 1, EPOCH: 1, train_loss: 0.0165955687344477\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 1, valid_loss: 0.006285903581346457\n",
      "SEED: 0, FOLD: 1, EPOCH: 2, train_loss: 0.009306169933060536\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 2, valid_loss: 0.005721114217661894\n",
      "SEED: 0, FOLD: 1, EPOCH: 3, train_loss: 0.009267349941404286\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 3, valid_loss: 0.00664001706844339\n",
      "SEED: 0, FOLD: 1, EPOCH: 4, train_loss: 0.00906510852478646\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 4, valid_loss: 0.005669546958345633\n",
      "SEED: 0, FOLD: 1, EPOCH: 5, train_loss: 0.008982734691754386\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005806745889668281\n",
      "SEED: 0, FOLD: 1, EPOCH: 6, train_loss: 0.008945100072368577\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 6, valid_loss: 0.00539482868491457\n",
      "SEED: 0, FOLD: 1, EPOCH: 7, train_loss: 0.008915679220965988\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 7, valid_loss: 0.005617495017269483\n",
      "SEED: 0, FOLD: 1, EPOCH: 8, train_loss: 0.008907006650760368\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 8, valid_loss: 0.005553674991600788\n",
      "SEED: 0, FOLD: 1, EPOCH: 9, train_loss: 0.008922309778328683\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 9, valid_loss: 0.00549962822921001\n",
      "SEED: 0, FOLD: 1, EPOCH: 10, train_loss: 0.008921518676436029\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 10, valid_loss: 0.005609941955369253\n",
      "SEED: 0, FOLD: 1, EPOCH: 11, train_loss: 0.008923781337216496\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005465968691099148\n",
      "SEED: 0, FOLD: 1, EPOCH: 12, train_loss: 0.008917932952376636\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 12, valid_loss: 0.00555486035031768\n",
      "SEED: 0, FOLD: 1, EPOCH: 13, train_loss: 0.008911650489411643\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 13, valid_loss: 0.0054608829534397675\n",
      "SEED: 0, FOLD: 1, EPOCH: 14, train_loss: 0.008912083938264766\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 14, valid_loss: 0.005461962320483648\n",
      "SEED: 0, FOLD: 2, EPOCH: 0, train_loss: 0.5872873206799095\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 0, valid_loss: 0.07838250467410454\n",
      "SEED: 0, FOLD: 2, EPOCH: 1, train_loss: 0.01640476891770959\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 1, valid_loss: 0.005937647325201676\n",
      "SEED: 0, FOLD: 2, EPOCH: 2, train_loss: 0.009281511682815649\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 2, valid_loss: 0.005729350368850506\n",
      "SEED: 0, FOLD: 2, EPOCH: 3, train_loss: 0.00951878322489761\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 3, valid_loss: 0.005623035204525177\n",
      "SEED: 0, FOLD: 2, EPOCH: 4, train_loss: 0.009076970484661492\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 4, valid_loss: 0.005512142303184821\n",
      "SEED: 0, FOLD: 2, EPOCH: 5, train_loss: 0.008988389141253522\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 5, valid_loss: 0.00551372214865226\n",
      "SEED: 0, FOLD: 2, EPOCH: 6, train_loss: 0.00892183862978945\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 6, valid_loss: 0.0056115098727437165\n",
      "SEED: 0, FOLD: 2, EPOCH: 7, train_loss: 0.008915396092610585\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 7, valid_loss: 0.005602292788143341\n",
      "SEED: 0, FOLD: 2, EPOCH: 8, train_loss: 0.0088956841028522\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005507586201509604\n",
      "SEED: 0, FOLD: 2, EPOCH: 9, train_loss: 0.008890325323099623\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 9, valid_loss: 0.005385659061945402\n",
      "SEED: 0, FOLD: 2, EPOCH: 10, train_loss: 0.00888240577753734\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 10, valid_loss: 0.005505289058559216\n",
      "SEED: 0, FOLD: 2, EPOCH: 11, train_loss: 0.008886182762531412\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 11, valid_loss: 0.005564621470582027\n",
      "SEED: 0, FOLD: 2, EPOCH: 12, train_loss: 0.00888754625024425\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 12, valid_loss: 0.00549854373989197\n",
      "SEED: 0, FOLD: 2, EPOCH: 13, train_loss: 0.00887631912514366\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 13, valid_loss: 0.005515067247100747\n",
      "SEED: 0, FOLD: 2, EPOCH: 14, train_loss: 0.00886149046237807\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 14, valid_loss: 0.005470173648343637\n",
      "SEED: 0, FOLD: 2, EPOCH: 15, train_loss: 0.008846769845616576\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 15, valid_loss: 0.005418510247881596\n",
      "SEED: 0, FOLD: 2, EPOCH: 16, train_loss: 0.00880645723963106\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 16, valid_loss: 0.005428526335610793\n",
      "SEED: 0, FOLD: 3, EPOCH: 0, train_loss: 0.5886571423427479\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08341109408782078\n",
      "SEED: 0, FOLD: 3, EPOCH: 1, train_loss: 0.016732343850103585\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 1, valid_loss: 0.0061826631785012204\n",
      "SEED: 0, FOLD: 3, EPOCH: 2, train_loss: 0.009286166445629017\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 2, valid_loss: 0.005865958375999561\n",
      "SEED: 0, FOLD: 3, EPOCH: 3, train_loss: 0.009213193842033679\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 3, valid_loss: 0.005697771799392425\n",
      "SEED: 0, FOLD: 3, EPOCH: 4, train_loss: 0.009075647320699048\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 4, valid_loss: 0.005651852689110315\n",
      "SEED: 0, FOLD: 3, EPOCH: 5, train_loss: 0.008953778922708856\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 5, valid_loss: 0.005632614036305592\n",
      "SEED: 0, FOLD: 3, EPOCH: 6, train_loss: 0.008894730321559552\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 6, valid_loss: 0.0058202577683214955\n",
      "SEED: 0, FOLD: 3, EPOCH: 7, train_loss: 0.008892577342890404\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 7, valid_loss: 0.005803129779031644\n",
      "SEED: 0, FOLD: 3, EPOCH: 8, train_loss: 0.008892554217144041\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 8, valid_loss: 0.00566709188457865\n",
      "SEED: 0, FOLD: 3, EPOCH: 9, train_loss: 0.008889168872170755\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 9, valid_loss: 0.005661432846234395\n",
      "SEED: 0, FOLD: 3, EPOCH: 10, train_loss: 0.008879610557562194\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 10, valid_loss: 0.00566706398072151\n",
      "SEED: 0, FOLD: 3, EPOCH: 11, train_loss: 0.008886532688110665\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 11, valid_loss: 0.005689855736608689\n",
      "SEED: 0, FOLD: 3, EPOCH: 12, train_loss: 0.008895864905286077\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 12, valid_loss: 0.005723057493854027\n",
      "SEED: 0, FOLD: 3, EPOCH: 13, train_loss: 0.008885899401345366\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 13, valid_loss: 0.005659622999911125\n",
      "SEED: 0, FOLD: 3, EPOCH: 14, train_loss: 0.008857097973845698\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 14, valid_loss: 0.005701113348970046\n",
      "SEED: 0, FOLD: 3, EPOCH: 15, train_loss: 0.00885509223853414\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 15, valid_loss: 0.005684371177966778\n",
      "SEED: 0, FOLD: 4, EPOCH: 0, train_loss: 0.5894653625987671\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08442431344435765\n",
      "SEED: 0, FOLD: 4, EPOCH: 1, train_loss: 0.016757108761954145\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 1, valid_loss: 0.0061729466542601585\n",
      "SEED: 0, FOLD: 4, EPOCH: 2, train_loss: 0.009343262384268077\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 2, valid_loss: 0.006413396555357254\n",
      "SEED: 0, FOLD: 4, EPOCH: 3, train_loss: 0.009206576033721905\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 3, valid_loss: 0.0059522983546440415\n",
      "SEED: 0, FOLD: 4, EPOCH: 4, train_loss: 0.009188509244169737\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 4, valid_loss: 0.005589836456168156\n",
      "SEED: 0, FOLD: 4, EPOCH: 5, train_loss: 0.008995731512235629\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 5, valid_loss: 0.0057354455169003745\n",
      "SEED: 0, FOLD: 4, EPOCH: 6, train_loss: 0.008942337908052109\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 6, valid_loss: 0.00555793450285609\n",
      "SEED: 0, FOLD: 4, EPOCH: 7, train_loss: 0.008917107253108878\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 7, valid_loss: 0.005576268769800663\n",
      "SEED: 0, FOLD: 4, EPOCH: 8, train_loss: 0.008913805557263864\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 8, valid_loss: 0.005647500726179435\n",
      "SEED: 0, FOLD: 4, EPOCH: 9, train_loss: 0.008896282792242395\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 9, valid_loss: 0.005566018526084148\n",
      "SEED: 0, FOLD: 4, EPOCH: 10, train_loss: 0.008898993349961332\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 10, valid_loss: 0.00560589929899344\n",
      "SEED: 0, FOLD: 4, EPOCH: 11, train_loss: 0.008887103267920178\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005686640954361512\n",
      "SEED: 0, FOLD: 4, EPOCH: 12, train_loss: 0.00889037295269805\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 12, valid_loss: 0.005629724572197749\n",
      "SEED: 0, FOLD: 4, EPOCH: 13, train_loss: 0.008880058750258508\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 13, valid_loss: 0.005631906911730766\n",
      "SEED: 0, FOLD: 4, EPOCH: 14, train_loss: 0.008872469188645482\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005617973215591449\n",
      "SEED: 0, FOLD: 5, EPOCH: 0, train_loss: 0.5908610691895356\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 0, valid_loss: 0.08319659531116486\n",
      "SEED: 0, FOLD: 5, EPOCH: 1, train_loss: 0.01699509778739633\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 1, valid_loss: 0.006121026602788613\n",
      "SEED: 0, FOLD: 5, EPOCH: 2, train_loss: 0.009274371597613837\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 2, valid_loss: 0.00571313461002249\n",
      "SEED: 0, FOLD: 5, EPOCH: 3, train_loss: 0.009221957039994162\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 3, valid_loss: 0.005595686988761792\n",
      "SEED: 0, FOLD: 5, EPOCH: 4, train_loss: 0.009023354791507527\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 4, valid_loss: 0.005463069340643974\n",
      "SEED: 0, FOLD: 5, EPOCH: 5, train_loss: 0.00901474670909748\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 5, valid_loss: 0.005731737133688652\n",
      "SEED: 0, FOLD: 5, EPOCH: 6, train_loss: 0.008933025752068372\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 6, valid_loss: 0.005486289254174783\n",
      "SEED: 0, FOLD: 5, EPOCH: 7, train_loss: 0.008934671134763473\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 7, valid_loss: 0.005419546809907143\n",
      "SEED: 0, FOLD: 5, EPOCH: 8, train_loss: 0.00892342400510569\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 8, valid_loss: 0.005471997751066318\n",
      "SEED: 0, FOLD: 5, EPOCH: 9, train_loss: 0.008910915008871942\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 9, valid_loss: 0.005377137352927373\n",
      "SEED: 0, FOLD: 5, EPOCH: 10, train_loss: 0.008900095280763265\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005426479360231986\n",
      "SEED: 0, FOLD: 5, EPOCH: 11, train_loss: 0.008892842241235682\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005672360125642557\n",
      "SEED: 0, FOLD: 5, EPOCH: 12, train_loss: 0.008905006157284652\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 12, valid_loss: 0.005575537860680085\n",
      "SEED: 0, FOLD: 5, EPOCH: 13, train_loss: 0.008886259200202452\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 13, valid_loss: 0.005469336138608364\n",
      "SEED: 0, FOLD: 5, EPOCH: 14, train_loss: 0.008879602156780861\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 14, valid_loss: 0.005488681535308178\n",
      "SEED: 0, FOLD: 5, EPOCH: 15, train_loss: 0.008849629477874653\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 15, valid_loss: 0.005525730227908263\n",
      "SEED: 0, FOLD: 5, EPOCH: 16, train_loss: 0.00884063556991719\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 16, valid_loss: 0.005470185146595423\n",
      "SEED: 0, FOLD: 6, EPOCH: 0, train_loss: 0.5900932601778894\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 0, valid_loss: 0.08445440633938862\n",
      "SEED: 0, FOLD: 6, EPOCH: 1, train_loss: 0.01678675985769243\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 1, valid_loss: 0.006002930172074299\n",
      "SEED: 0, FOLD: 6, EPOCH: 2, train_loss: 0.00951976329088211\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 2, valid_loss: 0.00567622035025404\n",
      "SEED: 0, FOLD: 6, EPOCH: 3, train_loss: 0.00923579274299177\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 3, valid_loss: 0.0055347038074754756\n",
      "SEED: 0, FOLD: 6, EPOCH: 4, train_loss: 0.009026853776713079\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 4, valid_loss: 0.005570971263715854\n",
      "SEED: 0, FOLD: 6, EPOCH: 5, train_loss: 0.008934725849964732\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 5, valid_loss: 0.00561168549868923\n",
      "SEED: 0, FOLD: 6, EPOCH: 6, train_loss: 0.008919826696148596\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 6, valid_loss: 0.00555527163669467\n",
      "SEED: 0, FOLD: 6, EPOCH: 7, train_loss: 0.008910739756617192\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005487327213184192\n",
      "SEED: 0, FOLD: 6, EPOCH: 8, train_loss: 0.008892881262393014\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 8, valid_loss: 0.005550400282327945\n",
      "SEED: 0, FOLD: 6, EPOCH: 9, train_loss: 0.008891698426088772\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 9, valid_loss: 0.00547876817962298\n",
      "SEED: 0, FOLD: 6, EPOCH: 10, train_loss: 0.008890946244669927\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 10, valid_loss: 0.005557896246990332\n",
      "SEED: 0, FOLD: 6, EPOCH: 11, train_loss: 0.0088898638213003\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 11, valid_loss: 0.00548152095423295\n",
      "SEED: 0, FOLD: 6, EPOCH: 12, train_loss: 0.00889324676245451\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 12, valid_loss: 0.005531393278103609\n",
      "SEED: 0, FOLD: 6, EPOCH: 13, train_loss: 0.008883492756836317\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 13, valid_loss: 0.005611182512858739\n",
      "SEED: 0, FOLD: 6, EPOCH: 14, train_loss: 0.00888014620018972\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 14, valid_loss: 0.005449137614610104\n",
      "SEED: 0, FOLD: 6, EPOCH: 15, train_loss: 0.008868079833887718\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 15, valid_loss: 0.005584151161691317\n",
      "SEED: 0, FOLD: 6, EPOCH: 16, train_loss: 0.00886295349463015\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 16, valid_loss: 0.005513417534530163\n",
      "SEED: 1, FOLD: 0, EPOCH: 0, train_loss: 0.5881155934688207\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 0, valid_loss: 0.07895448001531455\n",
      "SEED: 1, FOLD: 0, EPOCH: 1, train_loss: 0.016467345324722497\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 1, valid_loss: 0.006176632327529101\n",
      "SEED: 1, FOLD: 0, EPOCH: 2, train_loss: 0.009319909986712643\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 2, valid_loss: 0.006108797334421139\n",
      "SEED: 1, FOLD: 0, EPOCH: 3, train_loss: 0.010355266012452744\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 3, valid_loss: 0.0055563613199270685\n",
      "SEED: 1, FOLD: 0, EPOCH: 4, train_loss: 0.00909313520517301\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 4, valid_loss: 0.005549571978358122\n",
      "SEED: 1, FOLD: 0, EPOCH: 5, train_loss: 0.009012423380202538\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 5, valid_loss: 0.0055406620869269734\n",
      "SEED: 1, FOLD: 0, EPOCH: 6, train_loss: 0.00897150582986305\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 6, valid_loss: 0.005627090469575846\n",
      "SEED: 1, FOLD: 0, EPOCH: 7, train_loss: 0.008952363155077438\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 7, valid_loss: 0.00560337881772564\n",
      "SEED: 1, FOLD: 0, EPOCH: 8, train_loss: 0.008951522674210169\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005573377443047671\n",
      "SEED: 1, FOLD: 0, EPOCH: 9, train_loss: 0.008936749305576086\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005555083151333607\n",
      "SEED: 1, FOLD: 0, EPOCH: 10, train_loss: 0.008940115998927\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 10, valid_loss: 0.005566306233119506\n",
      "SEED: 1, FOLD: 0, EPOCH: 11, train_loss: 0.008908712217030493\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 11, valid_loss: 0.0055299424566328526\n",
      "SEED: 1, FOLD: 0, EPOCH: 12, train_loss: 0.00891513071601858\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 12, valid_loss: 0.0054752346701346915\n",
      "SEED: 1, FOLD: 0, EPOCH: 13, train_loss: 0.008893715330978503\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 13, valid_loss: 0.005487573118163989\n",
      "SEED: 1, FOLD: 0, EPOCH: 14, train_loss: 0.008875281285695933\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 14, valid_loss: 0.0056426008231937885\n",
      "SEED: 1, FOLD: 0, EPOCH: 15, train_loss: 0.00887745216715376\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 15, valid_loss: 0.0055331742892471645\n",
      "SEED: 1, FOLD: 0, EPOCH: 16, train_loss: 0.008840240085044422\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 16, valid_loss: 0.005488872671356568\n",
      "SEED: 1, FOLD: 0, EPOCH: 17, train_loss: 0.008831705791070251\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 17, valid_loss: 0.005550670974816267\n",
      "SEED: 1, FOLD: 1, EPOCH: 0, train_loss: 0.5879643745720387\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 0, valid_loss: 0.08726315372265302\n",
      "SEED: 1, FOLD: 1, EPOCH: 1, train_loss: 0.01657429795611549\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 1, valid_loss: 0.0061585900302116685\n",
      "SEED: 1, FOLD: 1, EPOCH: 2, train_loss: 0.009347163644191381\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 2, valid_loss: 0.0057883885904000355\n",
      "SEED: 1, FOLD: 1, EPOCH: 3, train_loss: 0.009150076531679244\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 3, valid_loss: 0.006349267473874183\n",
      "SEED: 1, FOLD: 1, EPOCH: 4, train_loss: 0.009160139528732444\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 4, valid_loss: 0.0056581890497070094\n",
      "SEED: 1, FOLD: 1, EPOCH: 5, train_loss: 0.008970065073840119\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005607785083926641\n",
      "SEED: 1, FOLD: 1, EPOCH: 6, train_loss: 0.008957800203682604\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 6, valid_loss: 0.005963461079563086\n",
      "SEED: 1, FOLD: 1, EPOCH: 7, train_loss: 0.008922679941295772\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 7, valid_loss: 0.0056333667240463774\n",
      "SEED: 1, FOLD: 1, EPOCH: 8, train_loss: 0.008906111278495676\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 8, valid_loss: 0.005569510376797273\n",
      "SEED: 1, FOLD: 1, EPOCH: 9, train_loss: 0.008911331920456645\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 9, valid_loss: 0.005567500940882242\n",
      "SEED: 1, FOLD: 1, EPOCH: 10, train_loss: 0.00891301264936054\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 10, valid_loss: 0.005571326025976584\n",
      "SEED: 1, FOLD: 1, EPOCH: 11, train_loss: 0.008915565480050203\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005554138646962551\n",
      "SEED: 1, FOLD: 1, EPOCH: 12, train_loss: 0.008912599595213259\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 12, valid_loss: 0.005614089922836194\n",
      "SEED: 1, FOLD: 1, EPOCH: 13, train_loss: 0.008899102541240485\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 13, valid_loss: 0.005575902939129334\n",
      "SEED: 1, FOLD: 1, EPOCH: 14, train_loss: 0.008869887757542971\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 14, valid_loss: 0.005560458745234287\n",
      "SEED: 1, FOLD: 1, EPOCH: 15, train_loss: 0.008858350999149922\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 15, valid_loss: 0.005613536323205783\n",
      "SEED: 1, FOLD: 1, EPOCH: 16, train_loss: 0.00883810326608049\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 16, valid_loss: 0.005574341612653091\n",
      "SEED: 1, FOLD: 1, EPOCH: 17, train_loss: 0.00881756330538239\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 17, valid_loss: 0.0055262966869542235\n",
      "SEED: 1, FOLD: 1, EPOCH: 18, train_loss: 0.008781760314328445\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 18, valid_loss: 0.005509662728470106\n",
      "SEED: 1, FOLD: 1, EPOCH: 19, train_loss: 0.008741602641404481\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 19, valid_loss: 0.005510189176465456\n",
      "SEED: 1, FOLD: 2, EPOCH: 0, train_loss: 0.5883725091210894\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 0, valid_loss: 0.08447422832250595\n",
      "SEED: 1, FOLD: 2, EPOCH: 1, train_loss: 0.01660373463370913\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 1, valid_loss: 0.005993613543418737\n",
      "SEED: 1, FOLD: 2, EPOCH: 2, train_loss: 0.009311280880324744\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 2, valid_loss: 0.0065572680547260325\n",
      "SEED: 1, FOLD: 2, EPOCH: 3, train_loss: 0.00925738417316933\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 3, valid_loss: 0.005780413997574494\n",
      "SEED: 1, FOLD: 2, EPOCH: 4, train_loss: 0.009035551555555415\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 4, valid_loss: 0.005486656016168686\n",
      "SEED: 1, FOLD: 2, EPOCH: 5, train_loss: 0.009082218820883616\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 5, valid_loss: 0.005385379306972027\n",
      "SEED: 1, FOLD: 2, EPOCH: 6, train_loss: 0.008958398112775507\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 6, valid_loss: 0.0054870378942443775\n",
      "SEED: 1, FOLD: 2, EPOCH: 7, train_loss: 0.008937015298854661\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 7, valid_loss: 0.005647105343926411\n",
      "SEED: 1, FOLD: 2, EPOCH: 8, train_loss: 0.008935307970622907\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005458928573016937\n",
      "SEED: 1, FOLD: 2, EPOCH: 9, train_loss: 0.008931291465823716\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 9, valid_loss: 0.005524443569951332\n",
      "SEED: 1, FOLD: 2, EPOCH: 10, train_loss: 0.008928119544745297\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 10, valid_loss: 0.005546307083792412\n",
      "SEED: 1, FOLD: 2, EPOCH: 11, train_loss: 0.008918688003275846\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 11, valid_loss: 0.005487383665660253\n",
      "SEED: 1, FOLD: 2, EPOCH: 12, train_loss: 0.008918820295130482\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 12, valid_loss: 0.005455162555265885\n",
      "SEED: 1, FOLD: 2, EPOCH: 13, train_loss: 0.008899679596258982\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 13, valid_loss: 0.005489014841329593\n",
      "SEED: 1, FOLD: 2, EPOCH: 14, train_loss: 0.008915356781988128\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 14, valid_loss: 0.00543298411111419\n",
      "SEED: 1, FOLD: 3, EPOCH: 0, train_loss: 0.5872844787868293\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08597635019284028\n",
      "SEED: 1, FOLD: 3, EPOCH: 1, train_loss: 0.016513131219088227\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 1, valid_loss: 0.006052242377056525\n",
      "SEED: 1, FOLD: 3, EPOCH: 2, train_loss: 0.009423302750833131\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 2, valid_loss: 0.005749867906650672\n",
      "SEED: 1, FOLD: 3, EPOCH: 3, train_loss: 0.009161056459856194\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 3, valid_loss: 0.007670914467710715\n",
      "SEED: 1, FOLD: 3, EPOCH: 4, train_loss: 0.009039786719792598\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 4, valid_loss: 0.005569616046089392\n",
      "SEED: 1, FOLD: 3, EPOCH: 5, train_loss: 0.008975667287469716\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 5, valid_loss: 0.005734234081151394\n",
      "SEED: 1, FOLD: 3, EPOCH: 6, train_loss: 0.008923910986128691\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 6, valid_loss: 0.005477507849438832\n",
      "SEED: 1, FOLD: 3, EPOCH: 7, train_loss: 0.00890864827040885\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 7, valid_loss: 0.00555610921807014\n",
      "SEED: 1, FOLD: 3, EPOCH: 8, train_loss: 0.008910159970558173\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 8, valid_loss: 0.005517732387838455\n",
      "SEED: 1, FOLD: 3, EPOCH: 9, train_loss: 0.008909477902626669\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 9, valid_loss: 0.0055632906822630996\n",
      "SEED: 1, FOLD: 3, EPOCH: 10, train_loss: 0.008919064377157672\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 10, valid_loss: 0.005554613406555011\n",
      "SEED: 1, FOLD: 3, EPOCH: 11, train_loss: 0.00890859729308333\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 11, valid_loss: 0.005609000173325722\n",
      "SEED: 1, FOLD: 3, EPOCH: 12, train_loss: 0.00890226465196827\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 12, valid_loss: 0.005616048565850808\n",
      "SEED: 1, FOLD: 3, EPOCH: 13, train_loss: 0.00891764639448878\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 13, valid_loss: 0.0055657574692024635\n",
      "SEED: 1, FOLD: 3, EPOCH: 14, train_loss: 0.008882950324363805\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 14, valid_loss: 0.005583270058895533\n",
      "SEED: 1, FOLD: 4, EPOCH: 0, train_loss: 0.5873773328557208\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08033040051276867\n",
      "SEED: 1, FOLD: 4, EPOCH: 1, train_loss: 0.016765171599045798\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 1, valid_loss: 0.006060766521841288\n",
      "SEED: 1, FOLD: 4, EPOCH: 2, train_loss: 0.009279275539557676\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 2, valid_loss: 0.005712433252483606\n",
      "SEED: 1, FOLD: 4, EPOCH: 3, train_loss: 0.009226611563684168\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 3, valid_loss: 0.00739072564129646\n",
      "SEED: 1, FOLD: 4, EPOCH: 4, train_loss: 0.009134558885282761\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 4, valid_loss: 0.005515858101157041\n",
      "SEED: 1, FOLD: 4, EPOCH: 5, train_loss: 0.00895940830201112\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 5, valid_loss: 0.005460826321863211\n",
      "SEED: 1, FOLD: 4, EPOCH: 6, train_loss: 0.008918966676385419\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 6, valid_loss: 0.005440035405067297\n",
      "SEED: 1, FOLD: 4, EPOCH: 7, train_loss: 0.008901807441804055\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 7, valid_loss: 0.00562561837096627\n",
      "SEED: 1, FOLD: 4, EPOCH: 8, train_loss: 0.008894768178563666\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 8, valid_loss: 0.005384816788136959\n",
      "SEED: 1, FOLD: 4, EPOCH: 9, train_loss: 0.008915134705603123\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 9, valid_loss: 0.00543954660399602\n",
      "SEED: 1, FOLD: 4, EPOCH: 10, train_loss: 0.008898142756692864\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 10, valid_loss: 0.0054946132362462\n",
      "SEED: 1, FOLD: 4, EPOCH: 11, train_loss: 0.008894150894185578\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005532433493779256\n",
      "SEED: 1, FOLD: 4, EPOCH: 12, train_loss: 0.008886526571586728\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 12, valid_loss: 0.005470324522600724\n",
      "SEED: 1, FOLD: 4, EPOCH: 13, train_loss: 0.008900519063998316\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 13, valid_loss: 0.005521247020134559\n",
      "SEED: 1, FOLD: 4, EPOCH: 14, train_loss: 0.008884850505588425\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005539457421176708\n",
      "SEED: 1, FOLD: 4, EPOCH: 15, train_loss: 0.008852812008479156\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 15, valid_loss: 0.005477515300019429\n",
      "SEED: 1, FOLD: 4, EPOCH: 16, train_loss: 0.008828378427219955\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 16, valid_loss: 0.0054614577227487015\n",
      "SEED: 1, FOLD: 5, EPOCH: 0, train_loss: 0.588012109435088\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 0, valid_loss: 0.06784696590441924\n",
      "SEED: 1, FOLD: 5, EPOCH: 1, train_loss: 0.01658173612746838\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 1, valid_loss: 0.0062116292090370106\n",
      "SEED: 1, FOLD: 5, EPOCH: 2, train_loss: 0.009327097204387994\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 2, valid_loss: 0.005939299885470133\n",
      "SEED: 1, FOLD: 5, EPOCH: 3, train_loss: 0.00990927143878228\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 3, valid_loss: 0.005528412472743254\n",
      "SEED: 1, FOLD: 5, EPOCH: 4, train_loss: 0.00911886724517555\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 4, valid_loss: 0.005613170170153563\n",
      "SEED: 1, FOLD: 5, EPOCH: 5, train_loss: 0.009002291874305622\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 5, valid_loss: 0.005662117010125747\n",
      "SEED: 1, FOLD: 5, EPOCH: 6, train_loss: 0.008977903588045691\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 6, valid_loss: 0.005536567706328172\n",
      "SEED: 1, FOLD: 5, EPOCH: 7, train_loss: 0.008947383562052573\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 7, valid_loss: 0.00561618572100997\n",
      "SEED: 1, FOLD: 5, EPOCH: 8, train_loss: 0.008929106639698148\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 8, valid_loss: 0.0055559926952880164\n",
      "SEED: 1, FOLD: 5, EPOCH: 9, train_loss: 0.008927112520747894\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 9, valid_loss: 0.005600448733625503\n",
      "SEED: 1, FOLD: 5, EPOCH: 10, train_loss: 0.008922332815976965\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005527768176622116\n",
      "SEED: 1, FOLD: 5, EPOCH: 11, train_loss: 0.00890834297909326\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005575360658650215\n",
      "SEED: 1, FOLD: 5, EPOCH: 12, train_loss: 0.008910923887900001\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 12, valid_loss: 0.005532394199130626\n",
      "SEED: 1, FOLD: 5, EPOCH: 13, train_loss: 0.00888855309804549\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 13, valid_loss: 0.005467426461669115\n",
      "SEED: 1, FOLD: 5, EPOCH: 14, train_loss: 0.008880198247277656\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 14, valid_loss: 0.005545745030618631\n",
      "SEED: 1, FOLD: 5, EPOCH: 15, train_loss: 0.008854685735108482\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 15, valid_loss: 0.005524331202300696\n",
      "SEED: 1, FOLD: 6, EPOCH: 0, train_loss: 0.5864471917015475\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 0, valid_loss: 0.08721258147404744\n",
      "SEED: 1, FOLD: 6, EPOCH: 1, train_loss: 0.016458621953387518\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 1, valid_loss: 0.0061880419962108135\n",
      "SEED: 1, FOLD: 6, EPOCH: 2, train_loss: 0.010521568584482412\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 2, valid_loss: 0.005866353220951099\n",
      "SEED: 1, FOLD: 6, EPOCH: 3, train_loss: 0.009204671441300495\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 3, valid_loss: 0.005655646288337616\n",
      "SEED: 1, FOLD: 6, EPOCH: 4, train_loss: 0.009048482604526184\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 4, valid_loss: 0.005654988201478353\n",
      "SEED: 1, FOLD: 6, EPOCH: 5, train_loss: 0.00900477810913848\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 5, valid_loss: 0.005525394915961302\n",
      "SEED: 1, FOLD: 6, EPOCH: 6, train_loss: 0.008944232180412556\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 6, valid_loss: 0.005602850542905239\n",
      "SEED: 1, FOLD: 6, EPOCH: 7, train_loss: 0.00892748509382678\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005580145041816509\n",
      "SEED: 1, FOLD: 6, EPOCH: 8, train_loss: 0.008912723737995367\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 8, valid_loss: 0.005517668054940609\n",
      "SEED: 1, FOLD: 6, EPOCH: 9, train_loss: 0.008927092358872697\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 9, valid_loss: 0.005604358891455026\n",
      "SEED: 1, FOLD: 6, EPOCH: 10, train_loss: 0.008924954935807633\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 10, valid_loss: 0.005517085620130484\n",
      "SEED: 1, FOLD: 6, EPOCH: 11, train_loss: 0.008921916514786112\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 11, valid_loss: 0.005555381210377583\n",
      "SEED: 1, FOLD: 6, EPOCH: 12, train_loss: 0.008896081884567803\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 12, valid_loss: 0.00559855062657824\n",
      "SEED: 1, FOLD: 6, EPOCH: 13, train_loss: 0.008903185264333277\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 13, valid_loss: 0.005551216479104299\n",
      "SEED: 1, FOLD: 6, EPOCH: 14, train_loss: 0.008890331741674123\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 14, valid_loss: 0.0055441675492777275\n",
      "SEED: 1, FOLD: 6, EPOCH: 15, train_loss: 0.008867269174220998\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 15, valid_loss: 0.005534876281252274\n",
      "SEED: 1, FOLD: 6, EPOCH: 16, train_loss: 0.008846117781374502\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 16, valid_loss: 0.005518193105952098\n",
      "SEED: 1, FOLD: 6, EPOCH: 17, train_loss: 0.008796503484198774\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 17, valid_loss: 0.005461041600658343\n",
      "SEED: 1, FOLD: 6, EPOCH: 18, train_loss: 0.008776944420124227\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 18, valid_loss: 0.005505819196024766\n",
      "SEED: 2, FOLD: 0, EPOCH: 0, train_loss: 0.5873940748137396\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08106216788291931\n",
      "SEED: 2, FOLD: 0, EPOCH: 1, train_loss: 0.01680874443185088\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 1, valid_loss: 0.00616163806989789\n",
      "SEED: 2, FOLD: 0, EPOCH: 2, train_loss: 0.00923524536444126\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 2, valid_loss: 0.005997529325003807\n",
      "SEED: 2, FOLD: 0, EPOCH: 3, train_loss: 0.009209836845764437\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 3, valid_loss: 0.005594783999885504\n",
      "SEED: 2, FOLD: 0, EPOCH: 4, train_loss: 0.009025148355175514\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 4, valid_loss: 0.005928125841399798\n",
      "SEED: 2, FOLD: 0, EPOCH: 5, train_loss: 0.00912245999820329\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 5, valid_loss: 0.005494634979046308\n",
      "SEED: 2, FOLD: 0, EPOCH: 6, train_loss: 0.008919971044854941\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 6, valid_loss: 0.005535841238899873\n",
      "SEED: 2, FOLD: 0, EPOCH: 7, train_loss: 0.008928818911364352\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 7, valid_loss: 0.005604915965635043\n",
      "SEED: 2, FOLD: 0, EPOCH: 8, train_loss: 0.00891888073670703\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005539070456646956\n",
      "SEED: 2, FOLD: 0, EPOCH: 9, train_loss: 0.00889637166432835\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005637789682413523\n",
      "SEED: 2, FOLD: 0, EPOCH: 10, train_loss: 0.00889789402434552\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 10, valid_loss: 0.005559507470864516\n",
      "SEED: 2, FOLD: 0, EPOCH: 11, train_loss: 0.008897809349503872\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 11, valid_loss: 0.00562832887785939\n",
      "SEED: 2, FOLD: 0, EPOCH: 12, train_loss: 0.008903452019030983\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 12, valid_loss: 0.0056229142042306755\n",
      "SEED: 2, FOLD: 0, EPOCH: 13, train_loss: 0.008897488905318282\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 13, valid_loss: 0.005614744463505654\n",
      "SEED: 2, FOLD: 0, EPOCH: 14, train_loss: 0.008884326919812608\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 14, valid_loss: 0.005692636629996391\n",
      "SEED: 2, FOLD: 1, EPOCH: 0, train_loss: 0.5886654192330064\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 0, valid_loss: 0.08902096117918308\n",
      "SEED: 2, FOLD: 1, EPOCH: 1, train_loss: 0.017157139785185054\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 1, valid_loss: 0.006000684359325812\n",
      "SEED: 2, FOLD: 1, EPOCH: 2, train_loss: 0.009269461488804302\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 2, valid_loss: 0.005811915661279972\n",
      "SEED: 2, FOLD: 1, EPOCH: 3, train_loss: 0.009794269675842009\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 3, valid_loss: 0.005562068106463322\n",
      "SEED: 2, FOLD: 1, EPOCH: 4, train_loss: 0.009162404782113593\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 4, valid_loss: 0.005628257667502532\n",
      "SEED: 2, FOLD: 1, EPOCH: 5, train_loss: 0.00901133009559802\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005525841700056424\n",
      "SEED: 2, FOLD: 1, EPOCH: 6, train_loss: 0.00894808119188088\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 6, valid_loss: 0.005978752930576985\n",
      "SEED: 2, FOLD: 1, EPOCH: 7, train_loss: 0.008943183284655615\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 7, valid_loss: 0.005407736779978642\n",
      "SEED: 2, FOLD: 1, EPOCH: 8, train_loss: 0.00892804843700818\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 8, valid_loss: 0.00547136223086944\n",
      "SEED: 2, FOLD: 1, EPOCH: 9, train_loss: 0.008922055464338613\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 9, valid_loss: 0.005610978015913413\n",
      "SEED: 2, FOLD: 1, EPOCH: 10, train_loss: 0.008911147852101037\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 10, valid_loss: 0.005587091454519675\n",
      "SEED: 2, FOLD: 1, EPOCH: 11, train_loss: 0.00889888996057011\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005672046269934911\n",
      "SEED: 2, FOLD: 1, EPOCH: 12, train_loss: 0.008884162440694668\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 12, valid_loss: 0.005446669788887868\n",
      "SEED: 2, FOLD: 1, EPOCH: 13, train_loss: 0.008868907981023594\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 13, valid_loss: 0.005475883407948108\n",
      "SEED: 2, FOLD: 1, EPOCH: 14, train_loss: 0.008859398202165155\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 14, valid_loss: 0.005465608161802475\n",
      "SEED: 2, FOLD: 1, EPOCH: 15, train_loss: 0.008852200658136123\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 15, valid_loss: 0.0055239421243851\n",
      "SEED: 2, FOLD: 2, EPOCH: 0, train_loss: 0.5889658696345381\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 0, valid_loss: 0.07999937178996894\n",
      "SEED: 2, FOLD: 2, EPOCH: 1, train_loss: 0.01656684573941134\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 1, valid_loss: 0.006167388413674557\n",
      "SEED: 2, FOLD: 2, EPOCH: 2, train_loss: 0.00944235548377037\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 2, valid_loss: 0.005834147405739014\n",
      "SEED: 2, FOLD: 2, EPOCH: 3, train_loss: 0.009169220905499282\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 3, valid_loss: 0.005860041003101147\n",
      "SEED: 2, FOLD: 2, EPOCH: 4, train_loss: 0.009023148428044608\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 4, valid_loss: 0.0055205751783572714\n",
      "SEED: 2, FOLD: 2, EPOCH: 5, train_loss: 0.00894026574678719\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 5, valid_loss: 0.005647833494899364\n",
      "SEED: 2, FOLD: 2, EPOCH: 6, train_loss: 0.008912003762717988\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 6, valid_loss: 0.005607480362344246\n",
      "SEED: 2, FOLD: 2, EPOCH: 7, train_loss: 0.008896379039396305\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 7, valid_loss: 0.005580159441496317\n",
      "SEED: 2, FOLD: 2, EPOCH: 8, train_loss: 0.00889993886891249\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005679593636439397\n",
      "SEED: 2, FOLD: 2, EPOCH: 9, train_loss: 0.008893942636613911\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 9, valid_loss: 0.0055666671564372685\n",
      "SEED: 2, FOLD: 2, EPOCH: 10, train_loss: 0.008896261340359578\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 10, valid_loss: 0.0055414974832764035\n",
      "SEED: 2, FOLD: 2, EPOCH: 11, train_loss: 0.008899082756928495\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 11, valid_loss: 0.005608494859188795\n",
      "SEED: 2, FOLD: 2, EPOCH: 12, train_loss: 0.008901445025175408\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 12, valid_loss: 0.005590554398412888\n",
      "SEED: 2, FOLD: 2, EPOCH: 13, train_loss: 0.00891156169283833\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 13, valid_loss: 0.005713404872669623\n",
      "SEED: 2, FOLD: 3, EPOCH: 0, train_loss: 0.588565627465377\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08669564930292276\n",
      "SEED: 2, FOLD: 3, EPOCH: 1, train_loss: 0.01664444203866092\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 1, valid_loss: 0.006225092264895256\n",
      "SEED: 2, FOLD: 3, EPOCH: 2, train_loss: 0.009280550117428238\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 2, valid_loss: 0.005866130384115072\n",
      "SEED: 2, FOLD: 3, EPOCH: 3, train_loss: 0.009182843807581309\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 3, valid_loss: 0.005855337967379735\n",
      "SEED: 2, FOLD: 3, EPOCH: 4, train_loss: 0.00903477952689738\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 4, valid_loss: 0.005612568965611549\n",
      "SEED: 2, FOLD: 3, EPOCH: 5, train_loss: 0.008930964634527225\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 5, valid_loss: 0.005639818532822223\n",
      "SEED: 2, FOLD: 3, EPOCH: 6, train_loss: 0.008910525181154543\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 6, valid_loss: 0.005472176851561436\n",
      "SEED: 2, FOLD: 3, EPOCH: 7, train_loss: 0.00890657989106871\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 7, valid_loss: 0.005488111959913602\n",
      "SEED: 2, FOLD: 3, EPOCH: 8, train_loss: 0.00888864217779121\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 8, valid_loss: 0.005584446068566579\n",
      "SEED: 2, FOLD: 3, EPOCH: 9, train_loss: 0.008884200045989978\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 9, valid_loss: 0.005612645369882767\n",
      "SEED: 2, FOLD: 3, EPOCH: 10, train_loss: 0.00889519469283924\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 10, valid_loss: 0.005661384560740911\n",
      "SEED: 2, FOLD: 3, EPOCH: 11, train_loss: 0.008886775127737908\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 11, valid_loss: 0.005586762052889054\n",
      "SEED: 2, FOLD: 3, EPOCH: 12, train_loss: 0.008889916220780563\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 12, valid_loss: 0.005508342901101479\n",
      "SEED: 2, FOLD: 3, EPOCH: 13, train_loss: 0.008888944782115318\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 13, valid_loss: 0.005568003711792139\n",
      "SEED: 2, FOLD: 3, EPOCH: 14, train_loss: 0.008861774792643013\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 14, valid_loss: 0.005618117104929227\n",
      "SEED: 2, FOLD: 3, EPOCH: 15, train_loss: 0.008846979550513867\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 15, valid_loss: 0.005558471338680157\n",
      "SEED: 2, FOLD: 4, EPOCH: 0, train_loss: 0.5867371635662543\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08387443537895496\n",
      "SEED: 2, FOLD: 4, EPOCH: 1, train_loss: 0.01643751101014582\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 1, valid_loss: 0.005950860177668242\n",
      "SEED: 2, FOLD: 4, EPOCH: 2, train_loss: 0.00928509805502521\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 2, valid_loss: 0.005940639772094213\n",
      "SEED: 2, FOLD: 4, EPOCH: 3, train_loss: 0.009257800575043704\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 3, valid_loss: 0.0054849564241102105\n",
      "SEED: 2, FOLD: 4, EPOCH: 4, train_loss: 0.00906068248976324\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 4, valid_loss: 0.005750339227513625\n",
      "SEED: 2, FOLD: 4, EPOCH: 5, train_loss: 0.008966341425941602\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 5, valid_loss: 0.005497719985074722\n",
      "SEED: 2, FOLD: 4, EPOCH: 6, train_loss: 0.008914597181452287\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 6, valid_loss: 0.005590851024652903\n",
      "SEED: 2, FOLD: 4, EPOCH: 7, train_loss: 0.008896271213637414\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 7, valid_loss: 0.005398218842366567\n",
      "SEED: 2, FOLD: 4, EPOCH: 8, train_loss: 0.008901128174132994\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 8, valid_loss: 0.005586104216770484\n",
      "SEED: 2, FOLD: 4, EPOCH: 9, train_loss: 0.00890153315472039\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 9, valid_loss: 0.005373736915106957\n",
      "SEED: 2, FOLD: 4, EPOCH: 10, train_loss: 0.008886375835769483\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 10, valid_loss: 0.0054403269806733495\n",
      "SEED: 2, FOLD: 4, EPOCH: 11, train_loss: 0.008901300720518103\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005395512060763745\n",
      "SEED: 2, FOLD: 4, EPOCH: 12, train_loss: 0.008899032452924026\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 12, valid_loss: 0.0054731350392103195\n",
      "SEED: 2, FOLD: 4, EPOCH: 13, train_loss: 0.008896528931989058\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 13, valid_loss: 0.00552732153580739\n",
      "SEED: 2, FOLD: 4, EPOCH: 14, train_loss: 0.008873895188239781\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005431058315130381\n",
      "SEED: 2, FOLD: 4, EPOCH: 15, train_loss: 0.008865431485999678\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 15, valid_loss: 0.005492764560935589\n",
      "SEED: 2, FOLD: 5, EPOCH: 0, train_loss: 0.5872574179760508\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 0, valid_loss: 0.07367615057871892\n",
      "SEED: 2, FOLD: 5, EPOCH: 1, train_loss: 0.0167554782678348\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 1, valid_loss: 0.006005338966273344\n",
      "SEED: 2, FOLD: 5, EPOCH: 2, train_loss: 0.00949181425007614\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 2, valid_loss: 0.005670481576369359\n",
      "SEED: 2, FOLD: 5, EPOCH: 3, train_loss: 0.009216079740105448\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 3, valid_loss: 0.005712306126952171\n",
      "SEED: 2, FOLD: 5, EPOCH: 4, train_loss: 0.009066380283518418\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 4, valid_loss: 0.005489444431777184\n",
      "SEED: 2, FOLD: 5, EPOCH: 5, train_loss: 0.008955477183130948\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 5, valid_loss: 0.00558648226209558\n",
      "SEED: 2, FOLD: 5, EPOCH: 6, train_loss: 0.008930131522435191\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 6, valid_loss: 0.005490232330675309\n",
      "SEED: 2, FOLD: 5, EPOCH: 7, train_loss: 0.008890996171111191\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 7, valid_loss: 0.0055162015800865796\n",
      "SEED: 2, FOLD: 5, EPOCH: 8, train_loss: 0.008896466992745126\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 8, valid_loss: 0.005538505251304462\n",
      "SEED: 2, FOLD: 5, EPOCH: 9, train_loss: 0.008918306947610265\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 9, valid_loss: 0.0055923459048454575\n",
      "SEED: 2, FOLD: 5, EPOCH: 10, train_loss: 0.008891021971263596\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005527226970745967\n",
      "SEED: 2, FOLD: 5, EPOCH: 11, train_loss: 0.008896722571571937\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005553742154286458\n",
      "SEED: 2, FOLD: 5, EPOCH: 12, train_loss: 0.008902306983096374\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 12, valid_loss: 0.0055097790721517345\n",
      "SEED: 2, FOLD: 5, EPOCH: 13, train_loss: 0.008884295965922443\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 13, valid_loss: 0.005652530835225032\n",
      "SEED: 2, FOLD: 6, EPOCH: 0, train_loss: 0.5872166090317674\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 0, valid_loss: 0.07321341393085626\n",
      "SEED: 2, FOLD: 6, EPOCH: 1, train_loss: 0.016530762187431793\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 1, valid_loss: 0.006105216542402139\n",
      "SEED: 2, FOLD: 6, EPOCH: 2, train_loss: 0.009318799195760811\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 2, valid_loss: 0.006075729401065753\n",
      "SEED: 2, FOLD: 6, EPOCH: 3, train_loss: 0.009238922704212569\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 3, valid_loss: 0.006270637198422964\n",
      "SEED: 2, FOLD: 6, EPOCH: 4, train_loss: 0.009074449400744727\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 4, valid_loss: 0.005811879053138769\n",
      "SEED: 2, FOLD: 6, EPOCH: 5, train_loss: 0.008959563247658111\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 5, valid_loss: 0.006027977913618088\n",
      "SEED: 2, FOLD: 6, EPOCH: 6, train_loss: 0.008933461441129848\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 6, valid_loss: 0.005488205199631361\n",
      "SEED: 2, FOLD: 6, EPOCH: 7, train_loss: 0.008922778340559956\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005609554668458609\n",
      "SEED: 2, FOLD: 6, EPOCH: 8, train_loss: 0.00891978817840887\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 8, valid_loss: 0.005500164276991899\n",
      "SEED: 2, FOLD: 6, EPOCH: 9, train_loss: 0.008928859417603628\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 9, valid_loss: 0.005255331321117969\n",
      "SEED: 2, FOLD: 6, EPOCH: 10, train_loss: 0.008913071316390022\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 10, valid_loss: 0.00537034016675674\n",
      "SEED: 2, FOLD: 6, EPOCH: 11, train_loss: 0.008922552173906887\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 11, valid_loss: 0.005378772486717655\n",
      "SEED: 2, FOLD: 6, EPOCH: 12, train_loss: 0.008930994046700967\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 12, valid_loss: 0.005421200982080056\n",
      "SEED: 2, FOLD: 6, EPOCH: 13, train_loss: 0.008912300326030803\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 13, valid_loss: 0.005429839858641991\n",
      "SEED: 2, FOLD: 6, EPOCH: 14, train_loss: 0.008910023009505224\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 14, valid_loss: 0.005417084500480156\n",
      "SEED: 2, FOLD: 6, EPOCH: 15, train_loss: 0.008884432568290346\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 15, valid_loss: 0.005469599487976386\n",
      "SEED: 3, FOLD: 0, EPOCH: 0, train_loss: 0.5885433746954879\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 0, valid_loss: 0.07826988914838204\n",
      "SEED: 3, FOLD: 0, EPOCH: 1, train_loss: 0.01670195094334918\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 1, valid_loss: 0.006234562812516322\n",
      "SEED: 3, FOLD: 0, EPOCH: 2, train_loss: 0.009279434279714888\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 2, valid_loss: 0.0058000442357017444\n",
      "SEED: 3, FOLD: 0, EPOCH: 3, train_loss: 0.00919954280520009\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 3, valid_loss: 0.006283481390430377\n",
      "SEED: 3, FOLD: 0, EPOCH: 4, train_loss: 0.009105376521679195\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 4, valid_loss: 0.005635776628668492\n",
      "SEED: 3, FOLD: 0, EPOCH: 5, train_loss: 0.009029818547738565\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 5, valid_loss: 0.007371784653514624\n",
      "SEED: 3, FOLD: 0, EPOCH: 6, train_loss: 0.008960792801116366\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 6, valid_loss: 0.005572985105503064\n",
      "SEED: 3, FOLD: 0, EPOCH: 7, train_loss: 0.008936515971514824\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 7, valid_loss: 0.00552600109949708\n",
      "SEED: 3, FOLD: 0, EPOCH: 8, train_loss: 0.008898700920965624\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005548943443080554\n",
      "SEED: 3, FOLD: 0, EPOCH: 9, train_loss: 0.008917069276543083\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005572141004869571\n",
      "SEED: 3, FOLD: 0, EPOCH: 10, train_loss: 0.008899115869221656\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 10, valid_loss: 0.0056421087624935005\n",
      "SEED: 3, FOLD: 0, EPOCH: 11, train_loss: 0.008910509984235506\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 11, valid_loss: 0.005559365515812085\n",
      "SEED: 3, FOLD: 0, EPOCH: 12, train_loss: 0.008900974455566422\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 12, valid_loss: 0.005537639694431653\n",
      "SEED: 3, FOLD: 0, EPOCH: 13, train_loss: 0.008880827103968005\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 13, valid_loss: 0.005492571490601852\n",
      "SEED: 3, FOLD: 0, EPOCH: 14, train_loss: 0.008867796743288636\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 14, valid_loss: 0.005747197733189051\n",
      "SEED: 3, FOLD: 0, EPOCH: 15, train_loss: 0.008858326331687134\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 15, valid_loss: 0.005576427846860427\n",
      "SEED: 3, FOLD: 0, EPOCH: 16, train_loss: 0.008832943562820956\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 16, valid_loss: 0.005590360181835981\n",
      "SEED: 3, FOLD: 1, EPOCH: 0, train_loss: 0.5888906470625788\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 0, valid_loss: 0.07987237377808644\n",
      "SEED: 3, FOLD: 1, EPOCH: 1, train_loss: 0.016606862480575975\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 1, valid_loss: 0.006117401143106131\n",
      "SEED: 3, FOLD: 1, EPOCH: 2, train_loss: 0.009995614260284079\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 2, valid_loss: 0.005690853398006696\n",
      "SEED: 3, FOLD: 1, EPOCH: 3, train_loss: 0.009219648970945462\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 3, valid_loss: 0.005672165729965155\n",
      "SEED: 3, FOLD: 1, EPOCH: 4, train_loss: 0.009145919548196567\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 4, valid_loss: 0.005575039782203161\n",
      "SEED: 3, FOLD: 1, EPOCH: 5, train_loss: 0.008988052908633207\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005596765746863989\n",
      "SEED: 3, FOLD: 1, EPOCH: 6, train_loss: 0.008947346007099023\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 6, valid_loss: 0.005530080364014094\n",
      "SEED: 3, FOLD: 1, EPOCH: 7, train_loss: 0.00894069529415385\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 7, valid_loss: 0.00580941538254802\n",
      "SEED: 3, FOLD: 1, EPOCH: 8, train_loss: 0.008918295494859686\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 8, valid_loss: 0.005627419190624585\n",
      "SEED: 3, FOLD: 1, EPOCH: 9, train_loss: 0.008920728178644503\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 9, valid_loss: 0.005632843678960433\n",
      "SEED: 3, FOLD: 1, EPOCH: 10, train_loss: 0.008907992348729356\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 10, valid_loss: 0.005719446362211154\n",
      "SEED: 3, FOLD: 1, EPOCH: 11, train_loss: 0.008904656892441012\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005543247796595097\n",
      "SEED: 3, FOLD: 1, EPOCH: 12, train_loss: 0.008892701900992039\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 12, valid_loss: 0.005550881489538229\n",
      "SEED: 3, FOLD: 1, EPOCH: 13, train_loss: 0.008894180054650517\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 13, valid_loss: 0.005552891534394943\n",
      "SEED: 3, FOLD: 1, EPOCH: 14, train_loss: 0.00888342862143307\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 14, valid_loss: 0.0055970414899862726\n",
      "SEED: 3, FOLD: 1, EPOCH: 15, train_loss: 0.00886254320927971\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 15, valid_loss: 0.005533903299902494\n",
      "SEED: 3, FOLD: 2, EPOCH: 0, train_loss: 0.5890669468286875\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 0, valid_loss: 0.07664683747750062\n",
      "SEED: 3, FOLD: 2, EPOCH: 1, train_loss: 0.01698569507917037\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 1, valid_loss: 0.006164527713106229\n",
      "SEED: 3, FOLD: 2, EPOCH: 2, train_loss: 0.009279718899444954\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 2, valid_loss: 0.007239246311096044\n",
      "SEED: 3, FOLD: 2, EPOCH: 3, train_loss: 0.009408358975338775\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 3, valid_loss: 0.005672541411163716\n",
      "SEED: 3, FOLD: 2, EPOCH: 4, train_loss: 0.009059627716605729\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 4, valid_loss: 0.005556100191405186\n",
      "SEED: 3, FOLD: 2, EPOCH: 5, train_loss: 0.008953802671434509\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 5, valid_loss: 0.005634608248678537\n",
      "SEED: 3, FOLD: 2, EPOCH: 6, train_loss: 0.00891692831332015\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 6, valid_loss: 0.005500916570711594\n",
      "SEED: 3, FOLD: 2, EPOCH: 7, train_loss: 0.00892553958613929\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 7, valid_loss: 0.005717567598017363\n",
      "SEED: 3, FOLD: 2, EPOCH: 8, train_loss: 0.008920636028051376\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005562746073477543\n",
      "SEED: 3, FOLD: 2, EPOCH: 9, train_loss: 0.008899697366900541\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 9, valid_loss: 0.00555396989847605\n",
      "SEED: 3, FOLD: 2, EPOCH: 10, train_loss: 0.008897411957936915\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 10, valid_loss: 0.005527236677992802\n",
      "SEED: 3, FOLD: 2, EPOCH: 11, train_loss: 0.008915559092939302\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 11, valid_loss: 0.005535529066736882\n",
      "SEED: 3, FOLD: 2, EPOCH: 12, train_loss: 0.00890610391601316\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 12, valid_loss: 0.005519149574236228\n",
      "SEED: 3, FOLD: 2, EPOCH: 13, train_loss: 0.008917689531085056\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 13, valid_loss: 0.005637091620323749\n",
      "SEED: 3, FOLD: 2, EPOCH: 14, train_loss: 0.008880581014563103\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 14, valid_loss: 0.005490359062185654\n",
      "SEED: 3, FOLD: 2, EPOCH: 15, train_loss: 0.008866965342816469\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 15, valid_loss: 0.00558849133980962\n",
      "SEED: 3, FOLD: 3, EPOCH: 0, train_loss: 0.5875804273260606\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 0, valid_loss: 0.0774078695819928\n",
      "SEED: 3, FOLD: 3, EPOCH: 1, train_loss: 0.016592440346406924\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 1, valid_loss: 0.005919294575086007\n",
      "SEED: 3, FOLD: 3, EPOCH: 2, train_loss: 0.009378174496059483\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 2, valid_loss: 0.005796154746069358\n",
      "SEED: 3, FOLD: 3, EPOCH: 3, train_loss: 0.00920969938129388\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 3, valid_loss: 0.005663792387797282\n",
      "SEED: 3, FOLD: 3, EPOCH: 4, train_loss: 0.009027784350454001\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 4, valid_loss: 0.005546903775001948\n",
      "SEED: 3, FOLD: 3, EPOCH: 5, train_loss: 0.008936172848366\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 5, valid_loss: 0.0054154830554930065\n",
      "SEED: 3, FOLD: 3, EPOCH: 6, train_loss: 0.008946037763175933\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 6, valid_loss: 0.005596635254243245\n",
      "SEED: 3, FOLD: 3, EPOCH: 7, train_loss: 0.008907198226331053\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 7, valid_loss: 0.0054913858095040685\n",
      "SEED: 3, FOLD: 3, EPOCH: 8, train_loss: 0.008925606200874254\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 8, valid_loss: 0.005572783617446056\n",
      "SEED: 3, FOLD: 3, EPOCH: 9, train_loss: 0.008930935285280685\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 9, valid_loss: 0.005457333432367215\n",
      "SEED: 3, FOLD: 3, EPOCH: 10, train_loss: 0.008902670324754875\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 10, valid_loss: 0.005550127225713088\n",
      "SEED: 3, FOLD: 3, EPOCH: 11, train_loss: 0.008921318869987453\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 11, valid_loss: 0.005532883859884281\n",
      "SEED: 3, FOLD: 3, EPOCH: 12, train_loss: 0.00891299221689838\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 12, valid_loss: 0.005515367007599427\n",
      "SEED: 3, FOLD: 3, EPOCH: 13, train_loss: 0.00892463791486178\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 13, valid_loss: 0.005409786620965371\n",
      "SEED: 3, FOLD: 3, EPOCH: 14, train_loss: 0.00890483458627116\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 14, valid_loss: 0.0055632597695176415\n",
      "SEED: 3, FOLD: 3, EPOCH: 15, train_loss: 0.00888240201449072\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 15, valid_loss: 0.005452010171631208\n",
      "SEED: 3, FOLD: 3, EPOCH: 16, train_loss: 0.008861594739042827\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 16, valid_loss: 0.005465416022791312\n",
      "SEED: 3, FOLD: 4, EPOCH: 0, train_loss: 0.588463639991509\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08769323906073204\n",
      "SEED: 3, FOLD: 4, EPOCH: 1, train_loss: 0.01671478119552941\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 1, valid_loss: 0.006028920841904787\n",
      "SEED: 3, FOLD: 4, EPOCH: 2, train_loss: 0.009289387563193167\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 2, valid_loss: 0.005856464437853832\n",
      "SEED: 3, FOLD: 4, EPOCH: 3, train_loss: 0.009252369743645997\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 3, valid_loss: 0.006279826809007388\n",
      "SEED: 3, FOLD: 4, EPOCH: 4, train_loss: 0.009164833199434183\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 4, valid_loss: 0.0055104889906942844\n",
      "SEED: 3, FOLD: 4, EPOCH: 5, train_loss: 0.008972665936862296\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 5, valid_loss: 0.005681760501689636\n",
      "SEED: 3, FOLD: 4, EPOCH: 6, train_loss: 0.008965370459230366\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 6, valid_loss: 0.00561599347453851\n",
      "SEED: 3, FOLD: 4, EPOCH: 7, train_loss: 0.008919011436503482\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 7, valid_loss: 0.0055306971144790835\n",
      "SEED: 3, FOLD: 4, EPOCH: 8, train_loss: 0.008905647083412151\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 8, valid_loss: 0.005508047994226217\n",
      "SEED: 3, FOLD: 4, EPOCH: 9, train_loss: 0.008919543605549512\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 9, valid_loss: 0.005548469686450867\n",
      "SEED: 3, FOLD: 4, EPOCH: 10, train_loss: 0.008913842621385245\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 10, valid_loss: 0.005573477739324937\n",
      "SEED: 3, FOLD: 4, EPOCH: 11, train_loss: 0.008898809558485408\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005637496817283905\n",
      "SEED: 3, FOLD: 4, EPOCH: 12, train_loss: 0.008891067606069752\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 12, valid_loss: 0.005552864167839289\n",
      "SEED: 3, FOLD: 4, EPOCH: 13, train_loss: 0.008877130017641026\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 13, valid_loss: 0.0055505450313481\n",
      "SEED: 3, FOLD: 4, EPOCH: 14, train_loss: 0.008871113850005172\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005650980863720179\n",
      "SEED: 3, FOLD: 5, EPOCH: 0, train_loss: 0.5889076851308346\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 0, valid_loss: 0.07639590478860415\n",
      "SEED: 3, FOLD: 5, EPOCH: 1, train_loss: 0.016684242285083275\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 1, valid_loss: 0.00601208618340584\n",
      "SEED: 3, FOLD: 5, EPOCH: 2, train_loss: 0.009306797493450545\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 2, valid_loss: 0.005505352173573696\n",
      "SEED: 3, FOLD: 5, EPOCH: 3, train_loss: 0.009263028183045823\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 3, valid_loss: 0.007612886372953653\n",
      "SEED: 3, FOLD: 5, EPOCH: 4, train_loss: 0.009056680445634836\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 4, valid_loss: 0.00577192660421133\n",
      "SEED: 3, FOLD: 5, EPOCH: 5, train_loss: 0.008967379649245256\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 5, valid_loss: 0.005664196116133378\n",
      "SEED: 3, FOLD: 5, EPOCH: 6, train_loss: 0.008924863030630592\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 6, valid_loss: 0.005380353138137322\n",
      "SEED: 3, FOLD: 5, EPOCH: 7, train_loss: 0.008901863371500292\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 7, valid_loss: 0.005353266337456612\n",
      "SEED: 3, FOLD: 5, EPOCH: 8, train_loss: 0.008905768016907008\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 8, valid_loss: 0.005467000309951031\n",
      "SEED: 3, FOLD: 5, EPOCH: 9, train_loss: 0.00890699981686634\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 9, valid_loss: 0.005396533148506513\n",
      "SEED: 3, FOLD: 5, EPOCH: 10, train_loss: 0.008894928624048023\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 10, valid_loss: 0.0054139423972138995\n",
      "SEED: 3, FOLD: 5, EPOCH: 11, train_loss: 0.00889920478535665\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005542577280161472\n",
      "SEED: 3, FOLD: 5, EPOCH: 12, train_loss: 0.008907850019986162\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 12, valid_loss: 0.005474540476615612\n",
      "SEED: 3, FOLD: 5, EPOCH: 13, train_loss: 0.008895548287074308\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 13, valid_loss: 0.0054321462073578285\n",
      "SEED: 3, FOLD: 5, EPOCH: 14, train_loss: 0.008874714468933037\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 14, valid_loss: 0.0054572219602190535\n",
      "SEED: 3, FOLD: 6, EPOCH: 0, train_loss: 0.5883239604331352\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 0, valid_loss: 0.07978164920440087\n",
      "SEED: 3, FOLD: 6, EPOCH: 1, train_loss: 0.01688411212652116\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 1, valid_loss: 0.006193630289859497\n",
      "SEED: 3, FOLD: 6, EPOCH: 2, train_loss: 0.00934956844493344\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 2, valid_loss: 0.005836712232289406\n",
      "SEED: 3, FOLD: 6, EPOCH: 3, train_loss: 0.009193180550544246\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 3, valid_loss: 0.006003214153819359\n",
      "SEED: 3, FOLD: 6, EPOCH: 4, train_loss: 0.009071419909093026\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 4, valid_loss: 0.005587480783175964\n",
      "SEED: 3, FOLD: 6, EPOCH: 5, train_loss: 0.009007796349406644\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 5, valid_loss: 0.005654432739202793\n",
      "SEED: 3, FOLD: 6, EPOCH: 6, train_loss: 0.008958486475151134\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 6, valid_loss: 0.0054892001028817436\n",
      "SEED: 3, FOLD: 6, EPOCH: 7, train_loss: 0.008917895070201642\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005515687955686679\n",
      "SEED: 3, FOLD: 6, EPOCH: 8, train_loss: 0.008933728900612206\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 8, valid_loss: 0.005462738112188303\n",
      "SEED: 3, FOLD: 6, EPOCH: 9, train_loss: 0.008919606016747452\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 9, valid_loss: 0.005471821372898726\n",
      "SEED: 3, FOLD: 6, EPOCH: 10, train_loss: 0.008924234740285052\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 10, valid_loss: 0.005680571202761852\n",
      "SEED: 3, FOLD: 6, EPOCH: 11, train_loss: 0.0089119637536036\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 11, valid_loss: 0.005531286283467825\n",
      "SEED: 3, FOLD: 6, EPOCH: 12, train_loss: 0.008914142526132433\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 12, valid_loss: 0.005573987602614439\n",
      "SEED: 3, FOLD: 6, EPOCH: 13, train_loss: 0.008897200189027432\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 13, valid_loss: 0.005623683655777803\n",
      "SEED: 3, FOLD: 6, EPOCH: 14, train_loss: 0.008892135298181628\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 14, valid_loss: 0.005594818208080072\n",
      "SEED: 3, FOLD: 6, EPOCH: 15, train_loss: 0.008877138034566431\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 15, valid_loss: 0.005535216608013098\n",
      "SEED: 4, FOLD: 0, EPOCH: 0, train_loss: 0.5877427804107601\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 0, valid_loss: 0.07683941091482456\n",
      "SEED: 4, FOLD: 0, EPOCH: 1, train_loss: 0.01663507244272812\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 1, valid_loss: 0.006098823299488196\n",
      "SEED: 4, FOLD: 0, EPOCH: 2, train_loss: 0.009323356157118405\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 2, valid_loss: 0.0057836555374356415\n",
      "SEED: 4, FOLD: 0, EPOCH: 3, train_loss: 0.009222024258830258\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 3, valid_loss: 0.00567881168367771\n",
      "SEED: 4, FOLD: 0, EPOCH: 4, train_loss: 0.009063878858059243\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 4, valid_loss: 0.0058035645992136915\n",
      "SEED: 4, FOLD: 0, EPOCH: 5, train_loss: 0.009029502766458569\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 5, valid_loss: 0.005602536472277\n",
      "SEED: 4, FOLD: 0, EPOCH: 6, train_loss: 0.008949311110316901\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 6, valid_loss: 0.005544954230292485\n",
      "SEED: 4, FOLD: 0, EPOCH: 7, train_loss: 0.00893995021092328\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 7, valid_loss: 0.005630422240266433\n",
      "SEED: 4, FOLD: 0, EPOCH: 8, train_loss: 0.008931657941256827\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005590604761472115\n",
      "SEED: 4, FOLD: 0, EPOCH: 9, train_loss: 0.008933312775617515\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005538782140669914\n",
      "SEED: 4, FOLD: 0, EPOCH: 10, train_loss: 0.008878389323079909\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 10, valid_loss: 0.005539652891457081\n",
      "SEED: 4, FOLD: 0, EPOCH: 11, train_loss: 0.008885984447457501\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 11, valid_loss: 0.005557772452728107\n",
      "SEED: 4, FOLD: 0, EPOCH: 12, train_loss: 0.008884025095785791\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 12, valid_loss: 0.005695829490342965\n",
      "SEED: 4, FOLD: 0, EPOCH: 13, train_loss: 0.008892849754743479\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 13, valid_loss: 0.0055883466624296625\n",
      "SEED: 4, FOLD: 0, EPOCH: 14, train_loss: 0.008872257885397286\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 14, valid_loss: 0.00560997433673877\n",
      "SEED: 4, FOLD: 0, EPOCH: 15, train_loss: 0.008867781332417115\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 15, valid_loss: 0.005596973431798128\n",
      "SEED: 4, FOLD: 0, EPOCH: 16, train_loss: 0.008846540060649449\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 16, valid_loss: 0.005484525042657669\n",
      "SEED: 4, FOLD: 0, EPOCH: 17, train_loss: 0.008804745128932031\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 17, valid_loss: 0.005529823068242807\n",
      "SEED: 4, FOLD: 1, EPOCH: 0, train_loss: 0.5874308605451841\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 0, valid_loss: 0.07396995792022118\n",
      "SEED: 4, FOLD: 1, EPOCH: 1, train_loss: 0.016483482829219586\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 1, valid_loss: 0.006030681113211008\n",
      "SEED: 4, FOLD: 1, EPOCH: 2, train_loss: 0.009314493351691478\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 2, valid_loss: 0.006326656609487075\n",
      "SEED: 4, FOLD: 1, EPOCH: 3, train_loss: 0.009309242278136112\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 3, valid_loss: 0.005484375959405532\n",
      "SEED: 4, FOLD: 1, EPOCH: 4, train_loss: 0.009051629423944128\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 4, valid_loss: 0.005645072696587214\n",
      "SEED: 4, FOLD: 1, EPOCH: 5, train_loss: 0.009003805695101619\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005598224556216827\n",
      "SEED: 4, FOLD: 1, EPOCH: 6, train_loss: 0.008932040947665637\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 6, valid_loss: 0.005504932863494525\n",
      "SEED: 4, FOLD: 1, EPOCH: 7, train_loss: 0.00890944221661099\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 7, valid_loss: 0.00548797448237355\n",
      "SEED: 4, FOLD: 1, EPOCH: 8, train_loss: 0.008912944964863159\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 8, valid_loss: 0.005515977632827484\n",
      "SEED: 4, FOLD: 1, EPOCH: 9, train_loss: 0.00891605332317586\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 9, valid_loss: 0.005453067509314189\n",
      "SEED: 4, FOLD: 1, EPOCH: 10, train_loss: 0.008885651575149717\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 10, valid_loss: 0.00549549781359159\n",
      "SEED: 4, FOLD: 1, EPOCH: 11, train_loss: 0.008888212410179345\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005534558556973934\n",
      "SEED: 4, FOLD: 1, EPOCH: 12, train_loss: 0.008901094766081991\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 12, valid_loss: 0.005522807845129416\n",
      "SEED: 4, FOLD: 1, EPOCH: 13, train_loss: 0.008879946374862984\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 13, valid_loss: 0.005495533060569029\n",
      "SEED: 4, FOLD: 2, EPOCH: 0, train_loss: 0.5879494365606759\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 0, valid_loss: 0.07654604545006385\n",
      "SEED: 4, FOLD: 2, EPOCH: 1, train_loss: 0.01671503363428889\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 1, valid_loss: 0.006094575322304781\n",
      "SEED: 4, FOLD: 2, EPOCH: 2, train_loss: 0.009716890865584483\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 2, valid_loss: 0.023472063816510715\n",
      "SEED: 4, FOLD: 2, EPOCH: 3, train_loss: 0.009253411188822341\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 3, valid_loss: 0.0058741915899400525\n",
      "SEED: 4, FOLD: 2, EPOCH: 4, train_loss: 0.009049619529144588\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 4, valid_loss: 0.005716095571047985\n",
      "SEED: 4, FOLD: 2, EPOCH: 5, train_loss: 0.008979474024444416\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 5, valid_loss: 0.00587363512470172\n",
      "SEED: 4, FOLD: 2, EPOCH: 6, train_loss: 0.009333047430609932\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 6, valid_loss: 0.005584292042140777\n",
      "SEED: 4, FOLD: 2, EPOCH: 7, train_loss: 0.0089642792260526\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 7, valid_loss: 0.005537065104223215\n",
      "SEED: 4, FOLD: 2, EPOCH: 8, train_loss: 0.008937334773961353\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005514547121352875\n",
      "SEED: 4, FOLD: 2, EPOCH: 9, train_loss: 0.008931059371428313\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 9, valid_loss: 0.0056755122943566395\n",
      "SEED: 4, FOLD: 2, EPOCH: 10, train_loss: 0.008929944798551701\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 10, valid_loss: 0.005582719647253935\n",
      "SEED: 4, FOLD: 2, EPOCH: 11, train_loss: 0.008914409438148141\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 11, valid_loss: 0.005681064839546497\n",
      "SEED: 4, FOLD: 2, EPOCH: 12, train_loss: 0.008907432642740172\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 12, valid_loss: 0.005529400785095417\n",
      "SEED: 4, FOLD: 2, EPOCH: 13, train_loss: 0.008873022016691597\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 13, valid_loss: 0.0055902759687831765\n",
      "SEED: 4, FOLD: 2, EPOCH: 14, train_loss: 0.008878754231625714\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 14, valid_loss: 0.005498450141973221\n",
      "SEED: 4, FOLD: 2, EPOCH: 15, train_loss: nan\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 15, valid_loss: nan\n",
      "SEED: 4, FOLD: 2, EPOCH: 16, train_loss: nan\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 16, valid_loss: nan\n",
      "SEED: 4, FOLD: 2, EPOCH: 17, train_loss: nan\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 17, valid_loss: nan\n",
      "SEED: 4, FOLD: 3, EPOCH: 0, train_loss: 0.5882420477432173\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08104009410509697\n",
      "SEED: 4, FOLD: 3, EPOCH: 1, train_loss: 0.017282138654106372\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 1, valid_loss: 0.0061469649752745265\n",
      "SEED: 4, FOLD: 3, EPOCH: 2, train_loss: 0.009369968864563349\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 2, valid_loss: 0.005873522721230984\n",
      "SEED: 4, FOLD: 3, EPOCH: 3, train_loss: 0.009153361010642068\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 3, valid_loss: 0.005750618516825712\n",
      "SEED: 4, FOLD: 3, EPOCH: 4, train_loss: 0.009096317112798223\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 4, valid_loss: 0.005938389875854437\n",
      "SEED: 4, FOLD: 3, EPOCH: 5, train_loss: 0.009010928267663395\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 5, valid_loss: 0.0064591662600063365\n",
      "SEED: 4, FOLD: 3, EPOCH: 6, train_loss: 0.008953446629331322\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 6, valid_loss: 0.005599414858107383\n",
      "SEED: 4, FOLD: 3, EPOCH: 7, train_loss: 0.00892518857821218\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 7, valid_loss: 0.0057962188998667095\n",
      "SEED: 4, FOLD: 3, EPOCH: 8, train_loss: 0.008901459108282989\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 8, valid_loss: 0.005623019013840418\n",
      "SEED: 4, FOLD: 3, EPOCH: 9, train_loss: 0.008915416575414507\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 9, valid_loss: 0.005738961725280835\n",
      "SEED: 4, FOLD: 3, EPOCH: 10, train_loss: 0.008900024462491274\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 10, valid_loss: 0.005561250333602612\n",
      "SEED: 4, FOLD: 3, EPOCH: 11, train_loss: 0.008898878243525286\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 11, valid_loss: 0.0056853390012222985\n",
      "SEED: 4, FOLD: 3, EPOCH: 12, train_loss: 0.008888217431769983\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 12, valid_loss: 0.005636408244474576\n",
      "SEED: 4, FOLD: 3, EPOCH: 13, train_loss: 0.008883446266220228\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 13, valid_loss: 0.005724647870430579\n",
      "SEED: 4, FOLD: 3, EPOCH: 14, train_loss: 0.00886626007362596\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 14, valid_loss: 0.00564256446579328\n",
      "SEED: 4, FOLD: 3, EPOCH: 15, train_loss: 0.00885470087539304\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 15, valid_loss: 0.005668019660963462\n",
      "SEED: 4, FOLD: 4, EPOCH: 0, train_loss: 0.5877754687256104\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 0, valid_loss: 0.07531988792694531\n",
      "SEED: 4, FOLD: 4, EPOCH: 1, train_loss: 0.016643101487912842\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 1, valid_loss: 0.005996827931644825\n",
      "SEED: 4, FOLD: 4, EPOCH: 2, train_loss: 0.009277597497645262\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 2, valid_loss: 0.005527558951423719\n",
      "SEED: 4, FOLD: 4, EPOCH: 3, train_loss: 0.009169118566992315\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 3, valid_loss: 0.005631366314796301\n",
      "SEED: 4, FOLD: 4, EPOCH: 4, train_loss: 0.009038129116635065\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 4, valid_loss: 0.006216423084529547\n",
      "SEED: 4, FOLD: 4, EPOCH: 5, train_loss: 0.009013876293760699\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 5, valid_loss: 0.005438560655770393\n",
      "SEED: 4, FOLD: 4, EPOCH: 6, train_loss: 0.008910226780367462\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 6, valid_loss: 0.00555174181667658\n",
      "SEED: 4, FOLD: 4, EPOCH: 7, train_loss: 0.00891020829235581\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 7, valid_loss: 0.005545839631500153\n",
      "SEED: 4, FOLD: 4, EPOCH: 8, train_loss: 0.00890464087746836\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 8, valid_loss: 0.0053108339914335655\n",
      "SEED: 4, FOLD: 4, EPOCH: 9, train_loss: 0.008896700251293747\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 9, valid_loss: 0.005360097409440921\n",
      "SEED: 4, FOLD: 4, EPOCH: 10, train_loss: 0.008914513085540888\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 10, valid_loss: 0.005380715530079145\n",
      "SEED: 4, FOLD: 4, EPOCH: 11, train_loss: 0.008917256774431144\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005466793556339466\n",
      "SEED: 4, FOLD: 4, EPOCH: 12, train_loss: 0.008905313877590202\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 12, valid_loss: 0.005476851267023728\n",
      "SEED: 4, FOLD: 4, EPOCH: 13, train_loss: 0.00890345812296948\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 13, valid_loss: 0.005446511822251173\n",
      "SEED: 4, FOLD: 4, EPOCH: 14, train_loss: 0.008894652052706963\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005420839199079917\n",
      "SEED: 4, FOLD: 5, EPOCH: 0, train_loss: 0.5876216919639626\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 0, valid_loss: 0.07472669963653271\n",
      "SEED: 4, FOLD: 5, EPOCH: 1, train_loss: 0.016441668887194748\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 1, valid_loss: 0.006014209527235765\n",
      "SEED: 4, FOLD: 5, EPOCH: 2, train_loss: 0.009293824207742472\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 2, valid_loss: 0.006125454969990712\n",
      "SEED: 4, FOLD: 5, EPOCH: 3, train_loss: 0.009281480697461882\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 3, valid_loss: 0.005734363570809364\n",
      "SEED: 4, FOLD: 5, EPOCH: 4, train_loss: 0.009023220127297414\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 4, valid_loss: 0.0057050138353728335\n",
      "SEED: 4, FOLD: 5, EPOCH: 5, train_loss: 0.008940337905408564\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 5, valid_loss: 0.005555532084634671\n",
      "SEED: 4, FOLD: 5, EPOCH: 6, train_loss: 0.008914822769175107\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 6, valid_loss: 0.005686160571013506\n",
      "SEED: 4, FOLD: 5, EPOCH: 7, train_loss: 0.008892096969223506\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 7, valid_loss: 0.005396466200741438\n",
      "SEED: 4, FOLD: 5, EPOCH: 8, train_loss: 0.008892001747782971\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 8, valid_loss: 0.005495624509281837\n",
      "SEED: 4, FOLD: 5, EPOCH: 9, train_loss: 0.008919017993517825\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 9, valid_loss: 0.005459970185676446\n",
      "SEED: 4, FOLD: 5, EPOCH: 10, train_loss: 0.008911509526188712\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005556660847595105\n",
      "SEED: 4, FOLD: 5, EPOCH: 11, train_loss: 0.008910154294524644\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005609969895046491\n",
      "SEED: 4, FOLD: 5, EPOCH: 12, train_loss: 0.00890242407173925\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 12, valid_loss: 0.005547259719325946\n",
      "SEED: 4, FOLD: 5, EPOCH: 13, train_loss: 0.008894252704104056\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 13, valid_loss: 0.00555688407845222\n",
      "SEED: 4, FOLD: 5, EPOCH: 14, train_loss: 0.00889321941429296\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 14, valid_loss: 0.005493328154373627\n",
      "SEED: 4, FOLD: 5, EPOCH: 15, train_loss: 0.008873002093939765\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 15, valid_loss: 0.005450623862158794\n",
      "SEED: 4, FOLD: 6, EPOCH: 0, train_loss: 0.5878535785989182\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 0, valid_loss: 0.07484311495835964\n",
      "SEED: 4, FOLD: 6, EPOCH: 1, train_loss: 0.01654651538292701\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 1, valid_loss: 0.006093113718984218\n",
      "SEED: 4, FOLD: 6, EPOCH: 2, train_loss: 0.009783756780765346\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 2, valid_loss: 0.017666414881554935\n",
      "SEED: 4, FOLD: 6, EPOCH: 3, train_loss: 0.009282653559804769\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 3, valid_loss: 0.005669370687638338\n",
      "SEED: 4, FOLD: 6, EPOCH: 4, train_loss: 0.009030594087734416\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 4, valid_loss: 0.005626136257957954\n",
      "SEED: 4, FOLD: 6, EPOCH: 5, train_loss: 0.008964405508359542\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 5, valid_loss: 0.005929620542491858\n",
      "SEED: 4, FOLD: 6, EPOCH: 6, train_loss: 0.008930981404626288\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 6, valid_loss: 0.005364296026527882\n",
      "SEED: 4, FOLD: 6, EPOCH: 7, train_loss: 0.008911894539975235\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005468024227481622\n",
      "SEED: 4, FOLD: 6, EPOCH: 8, train_loss: 0.008900640142225736\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 8, valid_loss: 0.005509575112507894\n",
      "SEED: 4, FOLD: 6, EPOCH: 9, train_loss: 0.00888472086926167\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 9, valid_loss: 0.005470133279092037\n",
      "SEED: 4, FOLD: 6, EPOCH: 10, train_loss: 0.008913771041694123\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 10, valid_loss: 0.00542137768262854\n",
      "SEED: 4, FOLD: 6, EPOCH: 11, train_loss: 0.00890836663342811\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 11, valid_loss: 0.005526124929579405\n",
      "SEED: 4, FOLD: 6, EPOCH: 12, train_loss: 0.008897631743771804\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 12, valid_loss: 0.0055253459498859365\n",
      "SEED: 4, FOLD: 6, EPOCH: 13, train_loss: 0.008874155247483301\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 13, valid_loss: 0.00541647498567517\n",
      "SEED: 4, FOLD: 6, EPOCH: 14, train_loss: 0.008872531851552226\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 14, valid_loss: 0.005482633848889516\n",
      "SEED: 5, FOLD: 0, EPOCH: 0, train_loss: 0.5894418760530047\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08157596737146378\n",
      "SEED: 5, FOLD: 0, EPOCH: 1, train_loss: 0.01662522561948847\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 1, valid_loss: 0.006099872971669986\n",
      "SEED: 5, FOLD: 0, EPOCH: 2, train_loss: 0.009325025930396608\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 2, valid_loss: 0.005832186219497369\n",
      "SEED: 5, FOLD: 0, EPOCH: 3, train_loss: 0.009169133820545834\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 3, valid_loss: 0.005684141499491839\n",
      "SEED: 5, FOLD: 0, EPOCH: 4, train_loss: 0.009067072205849597\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 4, valid_loss: 0.005549469282134221\n",
      "SEED: 5, FOLD: 0, EPOCH: 5, train_loss: 0.008956086903659476\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 5, valid_loss: 0.005981058670351138\n",
      "SEED: 5, FOLD: 0, EPOCH: 6, train_loss: 0.008927016456082865\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 6, valid_loss: 0.005383976269513369\n",
      "SEED: 5, FOLD: 0, EPOCH: 7, train_loss: 0.008901593602589658\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 7, valid_loss: 0.005500300644108882\n",
      "SEED: 5, FOLD: 0, EPOCH: 8, train_loss: 0.008912626175662956\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005421587480948522\n",
      "SEED: 5, FOLD: 0, EPOCH: 9, train_loss: 0.008902024773478106\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005529798495654876\n",
      "SEED: 5, FOLD: 0, EPOCH: 10, train_loss: 0.008895788757080162\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 10, valid_loss: 0.005483865594634643\n",
      "SEED: 5, FOLD: 0, EPOCH: 11, train_loss: 0.008881221110051548\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 11, valid_loss: 0.005480775036490881\n",
      "SEED: 5, FOLD: 0, EPOCH: 12, train_loss: 0.008889672094704332\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 12, valid_loss: 0.005467778429962122\n",
      "SEED: 5, FOLD: 0, EPOCH: 13, train_loss: 0.008884479392420602\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 13, valid_loss: 0.005532222620856304\n",
      "SEED: 5, FOLD: 0, EPOCH: 14, train_loss: 0.008874825642419022\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 14, valid_loss: 0.0054535083830929715\n",
      "SEED: 5, FOLD: 0, EPOCH: 15, train_loss: 0.008852024159922794\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 15, valid_loss: 0.005562900493924434\n",
      "SEED: 5, FOLD: 1, EPOCH: 0, train_loss: 0.5880729419154089\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 0, valid_loss: 0.0890753108721513\n",
      "SEED: 5, FOLD: 1, EPOCH: 1, train_loss: 0.016779437887708883\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 1, valid_loss: 0.00599273587935246\n",
      "SEED: 5, FOLD: 1, EPOCH: 2, train_loss: 0.009303496231803217\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 2, valid_loss: 0.0057558544481603\n",
      "SEED: 5, FOLD: 1, EPOCH: 3, train_loss: 0.009432758462640483\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 3, valid_loss: 0.00550432435165231\n",
      "SEED: 5, FOLD: 1, EPOCH: 4, train_loss: 0.009095230139791965\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 4, valid_loss: 0.005620822059707\n",
      "SEED: 5, FOLD: 1, EPOCH: 5, train_loss: 0.00898942574103539\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005557323053765755\n",
      "SEED: 5, FOLD: 1, EPOCH: 6, train_loss: 0.0089624707863943\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 6, valid_loss: 0.0056173242270373385\n",
      "SEED: 5, FOLD: 1, EPOCH: 7, train_loss: 0.008939045248553157\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 7, valid_loss: 0.005743985780729697\n",
      "SEED: 5, FOLD: 1, EPOCH: 8, train_loss: 0.008909170666860568\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 8, valid_loss: 0.005537353097819365\n",
      "SEED: 5, FOLD: 1, EPOCH: 9, train_loss: 0.008928738685475814\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 9, valid_loss: 0.005535366658407908\n",
      "SEED: 5, FOLD: 1, EPOCH: 10, train_loss: 0.008900195825845003\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 10, valid_loss: 0.005476453986305457\n",
      "SEED: 5, FOLD: 1, EPOCH: 11, train_loss: 0.008882868607100603\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005456798280087801\n",
      "SEED: 5, FOLD: 1, EPOCH: 12, train_loss: 0.008885841577540379\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 12, valid_loss: 0.005454299864000999\n",
      "SEED: 5, FOLD: 1, EPOCH: 13, train_loss: 0.008880151725197965\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 13, valid_loss: 0.005471723225827401\n",
      "SEED: 5, FOLD: 1, EPOCH: 14, train_loss: 0.008864822287766918\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 14, valid_loss: 0.005523044186142774\n",
      "SEED: 5, FOLD: 1, EPOCH: 15, train_loss: 0.008849308542856897\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 15, valid_loss: 0.005499579478055239\n",
      "SEED: 5, FOLD: 1, EPOCH: 16, train_loss: 0.008828198065276485\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 16, valid_loss: 0.005475950678094075\n",
      "SEED: 5, FOLD: 2, EPOCH: 0, train_loss: 0.5873949182396\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 0, valid_loss: 0.07326280440275486\n",
      "SEED: 5, FOLD: 2, EPOCH: 1, train_loss: 0.016347088385373354\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 1, valid_loss: 0.006212316131075988\n",
      "SEED: 5, FOLD: 2, EPOCH: 2, train_loss: 0.009247263843143309\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 2, valid_loss: 0.006033803336322308\n",
      "SEED: 5, FOLD: 2, EPOCH: 3, train_loss: 0.009184694823783797\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 3, valid_loss: 0.0229732315414227\n",
      "SEED: 5, FOLD: 2, EPOCH: 4, train_loss: 0.009061492551621553\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 4, valid_loss: 0.009982359380676197\n",
      "SEED: 5, FOLD: 2, EPOCH: 5, train_loss: 0.00898847309243236\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 5, valid_loss: 0.005544371043260281\n",
      "SEED: 5, FOLD: 2, EPOCH: 6, train_loss: 0.008941918290597765\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 6, valid_loss: 0.0057448038401512\n",
      "SEED: 5, FOLD: 2, EPOCH: 7, train_loss: 0.008913876337779535\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 7, valid_loss: 0.0056104215148549815\n",
      "SEED: 5, FOLD: 2, EPOCH: 8, train_loss: 0.008913014197369685\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005627285545835128\n",
      "SEED: 5, FOLD: 2, EPOCH: 9, train_loss: 0.008916355543644042\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 9, valid_loss: 0.005776503087522892\n",
      "SEED: 5, FOLD: 2, EPOCH: 10, train_loss: 0.00891494649034497\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 10, valid_loss: 0.005767147020938305\n",
      "SEED: 5, FOLD: 2, EPOCH: 11, train_loss: 0.008913270411761227\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 11, valid_loss: 0.00569245469971345\n",
      "SEED: 5, FOLD: 2, EPOCH: 12, train_loss: 0.008904551986504245\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 12, valid_loss: 0.0056534749813950975\n",
      "SEED: 5, FOLD: 2, EPOCH: 13, train_loss: 0.008910994743928313\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 13, valid_loss: 0.005737633301088443\n",
      "SEED: 5, FOLD: 3, EPOCH: 0, train_loss: 0.5879552126736254\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 0, valid_loss: 0.07724373959578\n",
      "SEED: 5, FOLD: 3, EPOCH: 1, train_loss: 0.016880943704195118\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 1, valid_loss: 0.006033820816530631\n",
      "SEED: 5, FOLD: 3, EPOCH: 2, train_loss: 0.009332877256580302\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 2, valid_loss: 0.005781916399987845\n",
      "SEED: 5, FOLD: 3, EPOCH: 3, train_loss: 0.009212846074857423\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 3, valid_loss: 0.006709049885662703\n",
      "SEED: 5, FOLD: 3, EPOCH: 4, train_loss: 0.009045589299922859\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 4, valid_loss: 0.005663354021425431\n",
      "SEED: 5, FOLD: 3, EPOCH: 5, train_loss: 0.008941099387467713\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 5, valid_loss: 0.005624931771308184\n",
      "SEED: 5, FOLD: 3, EPOCH: 6, train_loss: 0.008912594353377417\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 6, valid_loss: 0.0056784613989293575\n",
      "SEED: 5, FOLD: 3, EPOCH: 7, train_loss: 0.008919023675844073\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 7, valid_loss: 0.00560231008925117\n",
      "SEED: 5, FOLD: 3, EPOCH: 8, train_loss: 0.008890567020185897\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 8, valid_loss: 0.005582628234361227\n",
      "SEED: 5, FOLD: 3, EPOCH: 9, train_loss: 0.008906240556137385\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 9, valid_loss: 0.005544035480572627\n",
      "SEED: 5, FOLD: 3, EPOCH: 10, train_loss: 0.008887653062875206\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 10, valid_loss: 0.005582719897994628\n",
      "SEED: 5, FOLD: 3, EPOCH: 11, train_loss: 0.008906465023756027\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 11, valid_loss: 0.005675146033844123\n",
      "SEED: 5, FOLD: 3, EPOCH: 12, train_loss: 0.008894082486025384\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 12, valid_loss: 0.0056527509139134334\n",
      "SEED: 5, FOLD: 3, EPOCH: 13, train_loss: 0.008878305126484987\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 13, valid_loss: 0.005590954974580269\n",
      "SEED: 5, FOLD: 3, EPOCH: 14, train_loss: 0.00885982544639626\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 14, valid_loss: 0.005575132735360127\n",
      "SEED: 5, FOLD: 3, EPOCH: 15, train_loss: nan\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 15, valid_loss: nan\n",
      "SEED: 5, FOLD: 3, EPOCH: 16, train_loss: nan\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 16, valid_loss: nan\n",
      "SEED: 5, FOLD: 3, EPOCH: 17, train_loss: nan\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 17, valid_loss: nan\n",
      "SEED: 5, FOLD: 4, EPOCH: 0, train_loss: 0.5900580600105427\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08844826485101993\n",
      "SEED: 5, FOLD: 4, EPOCH: 1, train_loss: 0.01672987374351234\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 1, valid_loss: 0.006092428838690886\n",
      "SEED: 5, FOLD: 4, EPOCH: 2, train_loss: 0.009478753696925737\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 2, valid_loss: 0.034168317197607115\n",
      "SEED: 5, FOLD: 4, EPOCH: 3, train_loss: 0.00944474047502956\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 3, valid_loss: 0.005536161255664551\n",
      "SEED: 5, FOLD: 4, EPOCH: 4, train_loss: 0.009094243202157118\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 4, valid_loss: 0.00566372092669973\n",
      "SEED: 5, FOLD: 4, EPOCH: 5, train_loss: 0.008994712657924439\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 5, valid_loss: 0.005506300080854159\n",
      "SEED: 5, FOLD: 4, EPOCH: 6, train_loss: 0.008958795762343987\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 6, valid_loss: 0.005499775987118483\n",
      "SEED: 5, FOLD: 4, EPOCH: 7, train_loss: 0.00894831253114987\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 7, valid_loss: 0.0058365159739668555\n",
      "SEED: 5, FOLD: 4, EPOCH: 8, train_loss: 0.00892847157209306\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 8, valid_loss: 0.005457179692502205\n",
      "SEED: 5, FOLD: 4, EPOCH: 9, train_loss: 0.008931294008082635\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 9, valid_loss: 0.005524231837346003\n",
      "SEED: 5, FOLD: 4, EPOCH: 10, train_loss: 0.008917472746877654\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 10, valid_loss: 0.005523632996930526\n",
      "SEED: 5, FOLD: 4, EPOCH: 11, train_loss: 0.008915865781238756\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005502138358469193\n",
      "SEED: 5, FOLD: 4, EPOCH: 12, train_loss: 0.008899284602218383\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 12, valid_loss: 0.00545665854588151\n",
      "SEED: 5, FOLD: 4, EPOCH: 13, train_loss: 0.008888194161291057\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 13, valid_loss: 0.005568097273890789\n",
      "SEED: 5, FOLD: 4, EPOCH: 14, train_loss: 0.008884630153408728\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005528224273942984\n",
      "SEED: 5, FOLD: 4, EPOCH: 15, train_loss: 0.008872295478107157\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 15, valid_loss: 0.005514717696664425\n",
      "SEED: 5, FOLD: 4, EPOCH: 16, train_loss: 0.008839746333054593\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 16, valid_loss: 0.005490957902601132\n",
      "SEED: 5, FOLD: 5, EPOCH: 0, train_loss: 0.5874968970546851\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 0, valid_loss: 0.07715854564538369\n",
      "SEED: 5, FOLD: 5, EPOCH: 1, train_loss: 0.01665157820979083\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 1, valid_loss: 0.006164985852172742\n",
      "SEED: 5, FOLD: 5, EPOCH: 2, train_loss: 0.009333543466857157\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 2, valid_loss: 0.0057740997737989975\n",
      "SEED: 5, FOLD: 5, EPOCH: 3, train_loss: 0.009332223682085404\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 3, valid_loss: 0.005929410565071381\n",
      "SEED: 5, FOLD: 5, EPOCH: 4, train_loss: 0.00908818861117234\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 4, valid_loss: 0.00580726728702967\n",
      "SEED: 5, FOLD: 5, EPOCH: 5, train_loss: 0.008995193044176779\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 5, valid_loss: 0.005575779646348495\n",
      "SEED: 5, FOLD: 5, EPOCH: 6, train_loss: 0.00896783101976522\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 6, valid_loss: 0.005706728615153294\n",
      "SEED: 5, FOLD: 5, EPOCH: 7, train_loss: 0.008936625647333425\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 7, valid_loss: 0.005535443205959522\n",
      "SEED: 5, FOLD: 5, EPOCH: 8, train_loss: 0.008920642698334681\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 8, valid_loss: 0.00542170275002718\n",
      "SEED: 5, FOLD: 5, EPOCH: 9, train_loss: 0.008915173808565817\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 9, valid_loss: 0.005566833003495748\n",
      "SEED: 5, FOLD: 5, EPOCH: 10, train_loss: 0.00891030126729527\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005699450365052774\n",
      "SEED: 5, FOLD: 5, EPOCH: 11, train_loss: 0.008890208322554827\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005586343136830972\n",
      "SEED: 5, FOLD: 5, EPOCH: 12, train_loss: 0.00889529231180613\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 12, valid_loss: 0.005654033810759966\n",
      "SEED: 5, FOLD: 5, EPOCH: 13, train_loss: 0.00887912224877525\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 13, valid_loss: 0.005545987998350308\n",
      "SEED: 5, FOLD: 5, EPOCH: 14, train_loss: 0.0088641291635262\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 14, valid_loss: 0.005549821680268416\n",
      "SEED: 5, FOLD: 5, EPOCH: 15, train_loss: 0.008849232444992743\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 15, valid_loss: 0.005592908602781021\n",
      "SEED: 5, FOLD: 6, EPOCH: 0, train_loss: 0.5888156642180842\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 0, valid_loss: 0.08270368896997891\n",
      "SEED: 5, FOLD: 6, EPOCH: 1, train_loss: 0.016576354014309676\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 1, valid_loss: 0.006004749259983118\n",
      "SEED: 5, FOLD: 6, EPOCH: 2, train_loss: 0.009304358831581634\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 2, valid_loss: 0.005614176392555237\n",
      "SEED: 5, FOLD: 6, EPOCH: 3, train_loss: 0.009239175457608056\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 3, valid_loss: 0.005613379861013248\n",
      "SEED: 5, FOLD: 6, EPOCH: 4, train_loss: 0.009094679325416282\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 4, valid_loss: 0.005992279853671789\n",
      "SEED: 5, FOLD: 6, EPOCH: 5, train_loss: 0.009020832323192342\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 5, valid_loss: 0.005501653533428907\n",
      "SEED: 5, FOLD: 6, EPOCH: 6, train_loss: 0.008946372410030785\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 6, valid_loss: 0.005556149551501641\n",
      "SEED: 5, FOLD: 6, EPOCH: 7, train_loss: 0.008925696042039105\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005640215240418911\n",
      "SEED: 5, FOLD: 6, EPOCH: 8, train_loss: 0.008933525356287891\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 8, valid_loss: 0.005364652472333266\n",
      "SEED: 5, FOLD: 6, EPOCH: 9, train_loss: 0.008902918987882298\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 9, valid_loss: 0.005568047412312948\n",
      "SEED: 5, FOLD: 6, EPOCH: 10, train_loss: 0.008901813457644469\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 10, valid_loss: 0.005403984373865219\n",
      "SEED: 5, FOLD: 6, EPOCH: 11, train_loss: 0.008892720483394491\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 11, valid_loss: 0.00534318509296729\n",
      "SEED: 5, FOLD: 6, EPOCH: 12, train_loss: 0.00888266253939553\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 12, valid_loss: 0.005476324425007288\n",
      "SEED: 5, FOLD: 6, EPOCH: 13, train_loss: 0.008892787683352426\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 13, valid_loss: 0.005408345220180659\n",
      "SEED: 5, FOLD: 6, EPOCH: 14, train_loss: 0.008874443435185665\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 14, valid_loss: 0.00535528168368798\n",
      "SEED: 5, FOLD: 6, EPOCH: 15, train_loss: 0.008845176818352696\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 15, valid_loss: 0.0054257981335887545\n",
      "SEED: 5, FOLD: 6, EPOCH: 16, train_loss: 0.008818153631747575\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 16, valid_loss: 0.00549909476047525\n",
      "SEED: 6, FOLD: 0, EPOCH: 0, train_loss: 0.5885158921214374\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08187056504763089\n",
      "SEED: 6, FOLD: 0, EPOCH: 1, train_loss: 0.016513696242425893\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 1, valid_loss: 0.006098264362663031\n",
      "SEED: 6, FOLD: 0, EPOCH: 2, train_loss: 0.009299343439272127\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 2, valid_loss: 0.006054559650902565\n",
      "SEED: 6, FOLD: 0, EPOCH: 3, train_loss: 0.009312786048630605\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 3, valid_loss: 0.00566192759344211\n",
      "SEED: 6, FOLD: 0, EPOCH: 4, train_loss: 0.009486752411199582\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 4, valid_loss: 0.005581970219142162\n",
      "SEED: 6, FOLD: 0, EPOCH: 5, train_loss: 0.008957721746048412\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 5, valid_loss: 0.00568782129826454\n",
      "SEED: 6, FOLD: 0, EPOCH: 6, train_loss: 0.008954539939106719\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 6, valid_loss: 0.005470836176895178\n",
      "SEED: 6, FOLD: 0, EPOCH: 7, train_loss: 0.00894101249758859\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 7, valid_loss: 0.005470204417808698\n",
      "SEED: 6, FOLD: 0, EPOCH: 8, train_loss: 0.008912690090821\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005521375865030747\n",
      "SEED: 6, FOLD: 0, EPOCH: 9, train_loss: 0.008914283992772972\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005557869704296956\n",
      "SEED: 6, FOLD: 0, EPOCH: 10, train_loss: 0.008914013103758162\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 10, valid_loss: 0.00547760882629798\n",
      "SEED: 6, FOLD: 0, EPOCH: 11, train_loss: 0.008912218797549203\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 11, valid_loss: 0.0055540047514324\n",
      "SEED: 6, FOLD: 0, EPOCH: 12, train_loss: 0.00890638872452483\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 12, valid_loss: 0.005569786764681339\n",
      "SEED: 6, FOLD: 0, EPOCH: 13, train_loss: 0.008895530327651146\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 13, valid_loss: 0.005557960400787683\n",
      "SEED: 6, FOLD: 0, EPOCH: 14, train_loss: 0.008884276861224222\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 14, valid_loss: 0.0056076635105105545\n",
      "SEED: 6, FOLD: 0, EPOCH: 15, train_loss: 0.00887577690033091\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 15, valid_loss: 0.005516431401841915\n",
      "SEED: 6, FOLD: 0, EPOCH: 16, train_loss: 0.008854268559229534\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 16, valid_loss: 0.0054570400299361116\n",
      "SEED: 6, FOLD: 0, EPOCH: 17, train_loss: 0.008829300512081466\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 17, valid_loss: 0.005499763879925013\n",
      "SEED: 6, FOLD: 1, EPOCH: 0, train_loss: 0.5895474939732939\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 0, valid_loss: 0.07322359486268117\n",
      "SEED: 6, FOLD: 1, EPOCH: 1, train_loss: 0.01670417466477768\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 1, valid_loss: 0.006008740048855543\n",
      "SEED: 6, FOLD: 1, EPOCH: 2, train_loss: 0.009303171728813165\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 2, valid_loss: 0.005686910142405675\n",
      "SEED: 6, FOLD: 1, EPOCH: 3, train_loss: 0.009244588342168042\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 3, valid_loss: 0.013346397676146947\n",
      "SEED: 6, FOLD: 1, EPOCH: 4, train_loss: 0.00956046675659112\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 4, valid_loss: 0.005455149874950831\n",
      "SEED: 6, FOLD: 1, EPOCH: 5, train_loss: 0.009027007545621411\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005501340394123242\n",
      "SEED: 6, FOLD: 1, EPOCH: 6, train_loss: 0.008993198119758352\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 6, valid_loss: 0.0054227614130538246\n",
      "SEED: 6, FOLD: 1, EPOCH: 7, train_loss: 0.008977144849612503\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 7, valid_loss: 0.005489656952424691\n",
      "SEED: 6, FOLD: 1, EPOCH: 8, train_loss: 0.008950970519485103\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 8, valid_loss: 0.00559236965357111\n",
      "SEED: 6, FOLD: 1, EPOCH: 9, train_loss: 0.008941290258253748\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 9, valid_loss: 0.005490246766175215\n",
      "SEED: 6, FOLD: 1, EPOCH: 10, train_loss: 0.008948232418530294\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 10, valid_loss: 0.00547272006336313\n",
      "SEED: 6, FOLD: 1, EPOCH: 11, train_loss: 0.00894751983090631\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005541621456639125\n",
      "SEED: 6, FOLD: 1, EPOCH: 12, train_loss: 0.00893080493787656\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 12, valid_loss: 0.0054989711094934205\n",
      "SEED: 6, FOLD: 1, EPOCH: 13, train_loss: 0.008897310198360198\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 13, valid_loss: 0.005589319034837759\n",
      "SEED: 6, FOLD: 1, EPOCH: 14, train_loss: 0.008881754745301363\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 14, valid_loss: 0.005587675787795048\n",
      "SEED: 6, FOLD: 2, EPOCH: 0, train_loss: 0.5884785358164761\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 0, valid_loss: 0.08063481690791938\n",
      "SEED: 6, FOLD: 2, EPOCH: 1, train_loss: 0.01716782886383904\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 1, valid_loss: 0.006351258283337722\n",
      "SEED: 6, FOLD: 2, EPOCH: 2, train_loss: 0.00948216555942152\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 2, valid_loss: 0.005678608619536345\n",
      "SEED: 6, FOLD: 2, EPOCH: 3, train_loss: 0.009384185793129978\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 3, valid_loss: 0.005669558313317024\n",
      "SEED: 6, FOLD: 2, EPOCH: 4, train_loss: 0.0091031427822403\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 4, valid_loss: 0.005638545343222527\n",
      "SEED: 6, FOLD: 2, EPOCH: 5, train_loss: 0.008987213208063229\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 5, valid_loss: 0.005421262592650377\n",
      "SEED: 6, FOLD: 2, EPOCH: 6, train_loss: 0.00898123883667427\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 6, valid_loss: 0.005501928381048716\n",
      "SEED: 6, FOLD: 2, EPOCH: 7, train_loss: 0.008947741020017781\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 7, valid_loss: 0.0058639826826178115\n",
      "SEED: 6, FOLD: 2, EPOCH: 8, train_loss: 0.008947588956436596\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005489911884069443\n",
      "SEED: 6, FOLD: 2, EPOCH: 9, train_loss: 0.008920559709942018\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 9, valid_loss: 0.005510564177082135\n",
      "SEED: 6, FOLD: 2, EPOCH: 10, train_loss: 0.008911171575655808\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 10, valid_loss: 0.005448810935307007\n",
      "SEED: 6, FOLD: 2, EPOCH: 11, train_loss: 0.008881488059823578\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 11, valid_loss: 0.0053835054859519005\n",
      "SEED: 6, FOLD: 2, EPOCH: 12, train_loss: 0.008878444434722533\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 12, valid_loss: 0.005502646251653249\n",
      "SEED: 6, FOLD: 2, EPOCH: 13, train_loss: 0.008851780637947691\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 13, valid_loss: 0.005527075595007493\n",
      "SEED: 6, FOLD: 2, EPOCH: 14, train_loss: 0.008863532802442441\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 14, valid_loss: 0.005441939708991692\n",
      "SEED: 6, FOLD: 2, EPOCH: 15, train_loss: 0.00882691134874885\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 15, valid_loss: 0.005529762926296546\n",
      "SEED: 6, FOLD: 2, EPOCH: 16, train_loss: 0.00880624951064788\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 16, valid_loss: 0.005450944129664164\n",
      "SEED: 6, FOLD: 3, EPOCH: 0, train_loss: 0.5889373662302623\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08678324692524396\n",
      "SEED: 6, FOLD: 3, EPOCH: 1, train_loss: 0.016689505742711795\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 1, valid_loss: 0.006105225640707291\n",
      "SEED: 6, FOLD: 3, EPOCH: 2, train_loss: 0.009283380941613703\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 2, valid_loss: 0.005772965530363413\n",
      "SEED: 6, FOLD: 3, EPOCH: 3, train_loss: 0.009369378506734565\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 3, valid_loss: 0.006906394739277088\n",
      "SEED: 6, FOLD: 3, EPOCH: 4, train_loss: 0.009111210162675864\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 4, valid_loss: 0.006000258458348421\n",
      "SEED: 6, FOLD: 3, EPOCH: 5, train_loss: 0.008976550086879649\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 5, valid_loss: 0.005649330954139049\n",
      "SEED: 6, FOLD: 3, EPOCH: 6, train_loss: 0.008948756350405715\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 6, valid_loss: 0.005524141964717553\n",
      "SEED: 6, FOLD: 3, EPOCH: 7, train_loss: 0.008917175642390912\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 7, valid_loss: 0.00554396090312646\n",
      "SEED: 6, FOLD: 3, EPOCH: 8, train_loss: 0.008922011100661915\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 8, valid_loss: 0.005562610709323333\n",
      "SEED: 6, FOLD: 3, EPOCH: 9, train_loss: 0.008918498063812385\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 9, valid_loss: 0.005561022911793911\n",
      "SEED: 6, FOLD: 3, EPOCH: 10, train_loss: 0.008912273745581106\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 10, valid_loss: 0.005604351655795024\n",
      "SEED: 6, FOLD: 3, EPOCH: 11, train_loss: 0.008910413479080071\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 11, valid_loss: 0.0056067085108504845\n",
      "SEED: 6, FOLD: 3, EPOCH: 12, train_loss: 0.008895351834645545\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 12, valid_loss: 0.00562866093017734\n",
      "SEED: 6, FOLD: 3, EPOCH: 13, train_loss: 0.008903357206617255\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 13, valid_loss: 0.005598255039121096\n",
      "SEED: 6, FOLD: 3, EPOCH: 14, train_loss: 0.008894967720717998\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 14, valid_loss: 0.005604471868047347\n",
      "SEED: 6, FOLD: 4, EPOCH: 0, train_loss: 0.5880625029472081\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 0, valid_loss: 0.0827487913461832\n",
      "SEED: 6, FOLD: 4, EPOCH: 1, train_loss: 0.016540492834472977\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 1, valid_loss: 0.006140368023457436\n",
      "SEED: 6, FOLD: 4, EPOCH: 2, train_loss: 0.009306119679397828\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 2, valid_loss: 0.005719778701089895\n",
      "SEED: 6, FOLD: 4, EPOCH: 3, train_loss: 0.009158100290979082\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 3, valid_loss: 0.010659750622625534\n",
      "SEED: 6, FOLD: 4, EPOCH: 4, train_loss: 0.009019354635195152\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 4, valid_loss: 0.005550227916011443\n",
      "SEED: 6, FOLD: 4, EPOCH: 5, train_loss: 0.008926482606880568\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 5, valid_loss: 0.005613643067100873\n",
      "SEED: 6, FOLD: 4, EPOCH: 6, train_loss: 0.008904460232352486\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 6, valid_loss: 0.005820636028567186\n",
      "SEED: 6, FOLD: 4, EPOCH: 7, train_loss: 0.008883920391216068\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 7, valid_loss: 0.005695662174660426\n",
      "SEED: 6, FOLD: 4, EPOCH: 8, train_loss: 0.008882167440763599\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 8, valid_loss: 0.005516051565511868\n",
      "SEED: 6, FOLD: 4, EPOCH: 9, train_loss: 0.008869295511898157\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 9, valid_loss: 0.005477706865909008\n",
      "SEED: 6, FOLD: 4, EPOCH: 10, train_loss: 0.008877824293449521\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 10, valid_loss: 0.005612579496720662\n",
      "SEED: 6, FOLD: 4, EPOCH: 11, train_loss: 0.008886619206719302\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005574344263340418\n",
      "SEED: 6, FOLD: 4, EPOCH: 12, train_loss: 0.008889227652469196\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 12, valid_loss: 0.005517907369022186\n",
      "SEED: 6, FOLD: 4, EPOCH: 13, train_loss: 0.008874098266902808\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 13, valid_loss: 0.005537513858423783\n",
      "SEED: 6, FOLD: 4, EPOCH: 14, train_loss: 0.00886219654962219\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005531142680690839\n",
      "SEED: 6, FOLD: 4, EPOCH: 15, train_loss: 0.008863159102966657\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 15, valid_loss: 0.005561474173401411\n",
      "SEED: 6, FOLD: 5, EPOCH: 0, train_loss: 0.5903458164350407\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 0, valid_loss: 0.0782708886724252\n",
      "SEED: 6, FOLD: 5, EPOCH: 1, train_loss: 0.01677500632767742\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 1, valid_loss: 0.0062032624219472594\n",
      "SEED: 6, FOLD: 5, EPOCH: 2, train_loss: 0.009340148998072019\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 2, valid_loss: 0.006065934108426938\n",
      "SEED: 6, FOLD: 5, EPOCH: 3, train_loss: 0.009288691525423044\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 3, valid_loss: 0.005685230323041861\n",
      "SEED: 6, FOLD: 5, EPOCH: 4, train_loss: 0.009146287735249545\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 4, valid_loss: 0.005669156590906473\n",
      "SEED: 6, FOLD: 5, EPOCH: 5, train_loss: 0.008994783035706024\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 5, valid_loss: 0.005540396301792218\n",
      "SEED: 6, FOLD: 5, EPOCH: 6, train_loss: 0.008937725942028133\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 6, valid_loss: 0.005483377474145248\n",
      "SEED: 6, FOLD: 5, EPOCH: 7, train_loss: 0.008928740881635127\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 7, valid_loss: 0.005593442967018256\n",
      "SEED: 6, FOLD: 5, EPOCH: 8, train_loss: 0.008917326145377514\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 8, valid_loss: 0.0055542392656207085\n",
      "SEED: 6, FOLD: 5, EPOCH: 9, train_loss: 0.008914290417640193\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 9, valid_loss: 0.005583098659721704\n",
      "SEED: 6, FOLD: 5, EPOCH: 10, train_loss: 0.008895262547240063\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005537877504069071\n",
      "SEED: 6, FOLD: 5, EPOCH: 11, train_loss: 0.008898828858257952\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005525160545053391\n",
      "SEED: 6, FOLD: 5, EPOCH: 12, train_loss: 0.008900822329058035\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 12, valid_loss: 0.005549026724810784\n",
      "SEED: 6, FOLD: 5, EPOCH: 13, train_loss: 0.008886853421761378\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 13, valid_loss: 0.005579329239061246\n",
      "SEED: 6, FOLD: 5, EPOCH: 14, train_loss: 0.008873358249311914\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 14, valid_loss: 0.005568771515614712\n",
      "SEED: 6, FOLD: 5, EPOCH: 15, train_loss: 0.008862353496354175\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 15, valid_loss: 0.005491802576356209\n",
      "SEED: 6, FOLD: 5, EPOCH: 16, train_loss: 0.0088322428810234\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 16, valid_loss: 0.005560007698547382\n",
      "SEED: 6, FOLD: 6, EPOCH: 0, train_loss: 0.5887958752746517\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 0, valid_loss: 0.07661628092710789\n",
      "SEED: 6, FOLD: 6, EPOCH: 1, train_loss: 0.016547790288019018\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 1, valid_loss: 0.006083485813668141\n",
      "SEED: 6, FOLD: 6, EPOCH: 2, train_loss: 0.009765720762614463\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 2, valid_loss: 0.006353903991671709\n",
      "SEED: 6, FOLD: 6, EPOCH: 3, train_loss: 0.009242784508780853\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 3, valid_loss: 0.005525230215145991\n",
      "SEED: 6, FOLD: 6, EPOCH: 4, train_loss: 0.00906308342677516\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 4, valid_loss: 0.0055767054884479595\n",
      "SEED: 6, FOLD: 6, EPOCH: 5, train_loss: 0.009016373729635332\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 5, valid_loss: 0.0054158220569101665\n",
      "SEED: 6, FOLD: 6, EPOCH: 6, train_loss: 0.008934263687429798\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 6, valid_loss: 0.005501306329209071\n",
      "SEED: 6, FOLD: 6, EPOCH: 7, train_loss: 0.00895272263929852\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005416053347289562\n",
      "SEED: 6, FOLD: 6, EPOCH: 8, train_loss: 0.008932225802611257\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 8, valid_loss: 0.005356608782536709\n",
      "SEED: 6, FOLD: 6, EPOCH: 9, train_loss: 0.00893523162734267\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 9, valid_loss: 0.0054189500828775074\n",
      "SEED: 6, FOLD: 6, EPOCH: 10, train_loss: 0.008937191992142313\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 10, valid_loss: 0.0055258411985750384\n",
      "SEED: 6, FOLD: 6, EPOCH: 11, train_loss: 0.008910943263185185\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 11, valid_loss: 0.005449883818912964\n",
      "SEED: 6, FOLD: 6, EPOCH: 12, train_loss: 0.00892011501599808\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 12, valid_loss: 0.005397213443827171\n",
      "SEED: 6, FOLD: 6, EPOCH: 13, train_loss: 0.008906210810449478\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 13, valid_loss: 0.005405882086891394\n",
      "SEED: 6, FOLD: 6, EPOCH: 14, train_loss: 0.008882841416257056\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 14, valid_loss: 0.005402063055393787\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [0,1,2,3,4,5,6]  #<-- Update\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test_[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5139398e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:34:06.907927Z",
     "iopub.status.busy": "2025-03-31T12:34:06.907470Z",
     "iopub.status.idle": "2025-03-31T12:34:07.237043Z",
     "shell.execute_reply": "2025-03-31T12:34:07.236090Z"
    },
    "papermill": {
     "duration": 0.373685,
     "end_time": "2025-03-31T12:34:07.239122",
     "exception": false,
     "start_time": "2025-03-31T12:34:06.865437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.merge(train_targets_scored, on='sig_id')\n",
    "target = train[train_targets_scored.columns]\n",
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ab55fbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:34:07.373658Z",
     "iopub.status.busy": "2025-03-31T12:34:07.373362Z",
     "iopub.status.idle": "2025-03-31T12:34:07.381693Z",
     "shell.execute_reply": "2025-03-31T12:34:07.380880Z"
    },
    "papermill": {
     "duration": 0.073861,
     "end_time": "2025-03-31T12:34:07.383083",
     "exception": false,
     "start_time": "2025-03-31T12:34:07.309222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_cols = [c for c in train.columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['sig_id','kfold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b54e1a21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:34:07.469697Z",
     "iopub.status.busy": "2025-03-31T12:34:07.469331Z",
     "iopub.status.idle": "2025-03-31T12:34:07.474746Z",
     "shell.execute_reply": "2025-03-31T12:34:07.473983Z"
    },
    "papermill": {
     "duration": 0.049858,
     "end_time": "2025-03-31T12:34:07.476086",
     "exception": false,
     "start_time": "2025-03-31T12:34:07.426228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1579"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0bcbfe4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:34:07.591690Z",
     "iopub.status.busy": "2025-03-31T12:34:07.591380Z",
     "iopub.status.idle": "2025-03-31T12:34:07.595618Z",
     "shell.execute_reply": "2025-03-31T12:34:07.594751Z"
    },
    "papermill": {
     "duration": 0.071924,
     "end_time": "2025-03-31T12:34:07.597219",
     "exception": false,
     "start_time": "2025-03-31T12:34:07.525295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 26\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 6e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 7\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = True\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98ec821c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:34:07.691140Z",
     "iopub.status.busy": "2025-03-31T12:34:07.690851Z",
     "iopub.status.idle": "2025-03-31T12:34:07.701401Z",
     "shell.execute_reply": "2025-03-31T12:34:07.700594Z"
    },
    "papermill": {
     "duration": 0.054742,
     "end_time": "2025-03-31T12:34:07.703009",
     "exception": false,
     "start_time": "2025-03-31T12:34:07.648267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    mskf = MultilabelStratifiedKFold(n_splits=7)\n",
    "    for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "         train.loc[v_idx, 'kfold'] = int(f)\n",
    "    train['kfold'] = train['kfold'].astype(int)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model1(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"SEED: {seed} ,FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"SEED{seed}_FOLD{fold}_scored.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model1(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"SEED{seed}_FOLD{fold}_scored.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "056592a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:34:07.789477Z",
     "iopub.status.busy": "2025-03-31T12:34:07.789230Z",
     "iopub.status.idle": "2025-03-31T12:34:07.793340Z",
     "shell.execute_reply": "2025-03-31T12:34:07.792584Z"
    },
    "papermill": {
     "duration": 0.047921,
     "end_time": "2025-03-31T12:34:07.794508",
     "exception": false,
     "start_time": "2025-03-31T12:34:07.746587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34cb4a9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:34:07.879415Z",
     "iopub.status.busy": "2025-03-31T12:34:07.879173Z",
     "iopub.status.idle": "2025-03-31T13:05:02.355851Z",
     "shell.execute_reply": "2025-03-31T13:05:02.355120Z"
    },
    "papermill": {
     "duration": 1854.521164,
     "end_time": "2025-03-31T13:05:02.357511",
     "exception": false,
     "start_time": "2025-03-31T12:34:07.836347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 0, FOLD: 0, EPOCH: 0, train_loss: 0.5875316946893125\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 0, valid_loss: 0.09912933179965386\n",
      "SEED: 0, FOLD: 0, EPOCH: 1, train_loss: 0.02939340449567582\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 1, valid_loss: 0.020019133790181234\n",
      "SEED: 0, FOLD: 0, EPOCH: 2, train_loss: 0.022236819328689896\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 2, valid_loss: 0.018378609504837256\n",
      "SEED: 0, FOLD: 0, EPOCH: 3, train_loss: 0.021010485704283457\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017901533354933444\n",
      "SEED: 0, FOLD: 0, EPOCH: 4, train_loss: 0.02045925530428822\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017702556716708038\n",
      "SEED: 0, FOLD: 0, EPOCH: 5, train_loss: 0.020231774529895268\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 5, valid_loss: 0.01721722073853016\n",
      "SEED: 0, FOLD: 0, EPOCH: 6, train_loss: 0.02011548020449039\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017415372654795647\n",
      "SEED: 0, FOLD: 0, EPOCH: 7, train_loss: 0.019949342250018508\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01694784900889947\n",
      "SEED: 0, FOLD: 0, EPOCH: 8, train_loss: 0.019984675646835082\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017337949373401128\n",
      "SEED: 0, FOLD: 0, EPOCH: 9, train_loss: 0.019912076862277212\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017056999584803216\n",
      "SEED: 0, FOLD: 0, EPOCH: 10, train_loss: 0.019816103542374598\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 10, valid_loss: 0.01705929121145835\n",
      "SEED: 0, FOLD: 0, EPOCH: 11, train_loss: 0.01981517984657674\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 11, valid_loss: 0.017111536115407944\n",
      "SEED: 0, FOLD: 0, EPOCH: 12, train_loss: 0.01971609580859139\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01683416418158091\n",
      "SEED: 0, FOLD: 0, EPOCH: 13, train_loss: 0.0196794908544099\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016790620481165554\n",
      "SEED: 0, FOLD: 0, EPOCH: 14, train_loss: 0.019516152153546747\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016747895484933488\n",
      "SEED: 0, FOLD: 0, EPOCH: 15, train_loss: 0.01936836659002143\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01660089037166192\n",
      "SEED: 0, FOLD: 0, EPOCH: 16, train_loss: 0.019099245577849245\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016456767200277403\n",
      "SEED: 0, FOLD: 0, EPOCH: 17, train_loss: 0.018889330251998192\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01643988869797725\n",
      "SEED: 0, FOLD: 0, EPOCH: 18, train_loss: 0.01862172570985717\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016364935928812392\n",
      "SEED: 0, FOLD: 0, EPOCH: 19, train_loss: 0.018314312665245018\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016213733702898026\n",
      "SEED: 0, FOLD: 0, EPOCH: 20, train_loss: 0.01795010769588722\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01614521615780317\n",
      "SEED: 0, FOLD: 0, EPOCH: 21, train_loss: 0.017506861757185008\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016053578458153285\n",
      "SEED: 0, FOLD: 0, EPOCH: 22, train_loss: 0.01708376397554939\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01600949802937416\n",
      "SEED: 0, FOLD: 0, EPOCH: 23, train_loss: 0.016733804365267623\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015958718597315825\n",
      "SEED: 0, FOLD: 0, EPOCH: 24, train_loss: 0.01642613159492612\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015975893188554507\n",
      "SEED: 0, FOLD: 0, EPOCH: 25, train_loss: 0.016313196751414925\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 25, valid_loss: 0.015981189333475553\n",
      "SEED: 0, FOLD: 1, EPOCH: 0, train_loss: 0.5885130114652015\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 0, valid_loss: 0.09342137609536831\n",
      "SEED: 0, FOLD: 1, EPOCH: 1, train_loss: 0.029541057735882902\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 1, valid_loss: 0.019833785123549975\n",
      "SEED: 0, FOLD: 1, EPOCH: 2, train_loss: 0.022037059949660622\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 2, valid_loss: 0.01839965281005089\n",
      "SEED: 0, FOLD: 1, EPOCH: 3, train_loss: 0.020972815266734845\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 3, valid_loss: 0.01767011029789081\n",
      "SEED: 0, FOLD: 1, EPOCH: 4, train_loss: 0.020395943844640576\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017445705974331267\n",
      "SEED: 0, FOLD: 1, EPOCH: 5, train_loss: 0.020079926461786836\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 5, valid_loss: 0.01804401338673555\n",
      "SEED: 0, FOLD: 1, EPOCH: 6, train_loss: 0.020049250659507675\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017178949828331288\n",
      "SEED: 0, FOLD: 1, EPOCH: 7, train_loss: 0.019901125339438785\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017188571393489838\n",
      "SEED: 0, FOLD: 1, EPOCH: 8, train_loss: 0.019871335375953366\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017130767210171774\n",
      "SEED: 0, FOLD: 1, EPOCH: 9, train_loss: 0.01991558135361285\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01712295226752758\n",
      "SEED: 0, FOLD: 1, EPOCH: 10, train_loss: 0.019883609326505982\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 10, valid_loss: 0.017450806326591052\n",
      "SEED: 0, FOLD: 1, EPOCH: 11, train_loss: 0.019769801481350047\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017004206991539553\n",
      "SEED: 0, FOLD: 1, EPOCH: 12, train_loss: 0.019677578597455413\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016955960900164567\n",
      "SEED: 0, FOLD: 1, EPOCH: 13, train_loss: 0.019576603798447428\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016850079409778118\n",
      "SEED: 0, FOLD: 1, EPOCH: 14, train_loss: 0.01944976335240377\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016878114010278996\n",
      "SEED: 0, FOLD: 1, EPOCH: 15, train_loss: 0.019257621059345233\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01676688429254752\n",
      "SEED: 0, FOLD: 1, EPOCH: 16, train_loss: 0.019083109935997305\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016740852537063453\n",
      "SEED: 0, FOLD: 1, EPOCH: 17, train_loss: 0.018814612784095713\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016505541638112985\n",
      "SEED: 0, FOLD: 1, EPOCH: 18, train_loss: 0.018588897998671274\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01634985050902917\n",
      "SEED: 0, FOLD: 1, EPOCH: 19, train_loss: 0.018176543324984407\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016305417610475652\n",
      "SEED: 0, FOLD: 1, EPOCH: 20, train_loss: 0.017815512630182342\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 20, valid_loss: 0.01620166877714487\n",
      "SEED: 0, FOLD: 1, EPOCH: 21, train_loss: 0.017392135325919936\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01616509108302685\n",
      "SEED: 0, FOLD: 1, EPOCH: 22, train_loss: 0.016950720015007095\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 22, valid_loss: 0.0161292885358517\n",
      "SEED: 0, FOLD: 1, EPOCH: 23, train_loss: 0.01659102554156168\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01610176616276686\n",
      "SEED: 0, FOLD: 1, EPOCH: 24, train_loss: 0.016259218905926555\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 24, valid_loss: 0.016117560104108773\n",
      "SEED: 0, FOLD: 1, EPOCH: 25, train_loss: 0.01613974442856537\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 25, valid_loss: 0.016107596313724153\n",
      "SEED: 0, FOLD: 2, EPOCH: 0, train_loss: 0.5866402728936156\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 0, valid_loss: 0.08485314307304528\n",
      "SEED: 0, FOLD: 2, EPOCH: 1, train_loss: 0.029721821305920947\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 1, valid_loss: 0.019643475516484335\n",
      "SEED: 0, FOLD: 2, EPOCH: 2, train_loss: 0.02202826295350049\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 2, valid_loss: 0.01860045512708334\n",
      "SEED: 0, FOLD: 2, EPOCH: 3, train_loss: 0.020965889901728242\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 3, valid_loss: 0.01757094829988021\n",
      "SEED: 0, FOLD: 2, EPOCH: 4, train_loss: 0.021230367968815403\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017622793594805095\n",
      "SEED: 0, FOLD: 2, EPOCH: 5, train_loss: 0.020379346090595465\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01724303628389652\n",
      "SEED: 0, FOLD: 2, EPOCH: 6, train_loss: 0.020181366972423887\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01725174715885749\n",
      "SEED: 0, FOLD: 2, EPOCH: 7, train_loss: 0.020035515514177246\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01698815242315714\n",
      "SEED: 0, FOLD: 2, EPOCH: 8, train_loss: 0.019988943445118697\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 8, valid_loss: 0.016936499410523817\n",
      "SEED: 0, FOLD: 2, EPOCH: 9, train_loss: 0.019914724108939234\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 9, valid_loss: 0.017247766686173584\n",
      "SEED: 0, FOLD: 2, EPOCH: 10, train_loss: 0.01985280407038895\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017024222761392593\n",
      "SEED: 0, FOLD: 2, EPOCH: 11, train_loss: 0.019813054794999393\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016763629749990426\n",
      "SEED: 0, FOLD: 2, EPOCH: 12, train_loss: 0.01974559489738297\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01667232668170562\n",
      "SEED: 0, FOLD: 2, EPOCH: 13, train_loss: 0.01961609995546373\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016709464602172375\n",
      "SEED: 0, FOLD: 2, EPOCH: 14, train_loss: 0.019478895827322394\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016527854264355622\n",
      "SEED: 0, FOLD: 2, EPOCH: 15, train_loss: 0.01933507900685072\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016419292857440617\n",
      "SEED: 0, FOLD: 2, EPOCH: 16, train_loss: 0.019196491839515196\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016332971576887827\n",
      "SEED: 0, FOLD: 2, EPOCH: 17, train_loss: 0.01895782572997583\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016290994074482184\n",
      "SEED: 0, FOLD: 2, EPOCH: 18, train_loss: 0.018715891257129812\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016400733174612887\n",
      "SEED: 0, FOLD: 2, EPOCH: 19, train_loss: 0.018333271523383824\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016104948205443528\n",
      "SEED: 0, FOLD: 2, EPOCH: 20, train_loss: 0.017961638325170892\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 20, valid_loss: 0.016063090772009812\n",
      "SEED: 0, FOLD: 2, EPOCH: 21, train_loss: 0.01754245414977541\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 21, valid_loss: 0.015909491393428583\n",
      "SEED: 0, FOLD: 2, EPOCH: 22, train_loss: 0.017152816233401362\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01589573876788983\n",
      "SEED: 0, FOLD: 2, EPOCH: 23, train_loss: 0.016745812888886477\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015891673115010444\n",
      "SEED: 0, FOLD: 2, EPOCH: 24, train_loss: 0.01651085543169363\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01590606369651281\n",
      "SEED: 0, FOLD: 2, EPOCH: 25, train_loss: 0.016349285161374388\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 25, valid_loss: 0.015903162913253673\n",
      "SEED: 0, FOLD: 3, EPOCH: 0, train_loss: 0.5879210980760085\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08475120537556134\n",
      "SEED: 0, FOLD: 3, EPOCH: 1, train_loss: 0.02973382575185718\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 1, valid_loss: 0.019948945738948308\n",
      "SEED: 0, FOLD: 3, EPOCH: 2, train_loss: 0.021840982189452327\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 2, valid_loss: 0.0196002429494491\n",
      "SEED: 0, FOLD: 3, EPOCH: 3, train_loss: 0.02095316310186644\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 3, valid_loss: 0.01847612069776425\n",
      "SEED: 0, FOLD: 3, EPOCH: 4, train_loss: 0.020376641328471737\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017593314727911584\n",
      "SEED: 0, FOLD: 3, EPOCH: 5, train_loss: 0.020080359677809315\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 5, valid_loss: 0.01738751421754177\n",
      "SEED: 0, FOLD: 3, EPOCH: 6, train_loss: 0.020001926987960533\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01737378551982916\n",
      "SEED: 0, FOLD: 3, EPOCH: 7, train_loss: 0.02006809750722872\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017552136801756345\n",
      "SEED: 0, FOLD: 3, EPOCH: 8, train_loss: 0.019987343005030543\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 8, valid_loss: 0.018057370128539894\n",
      "SEED: 0, FOLD: 3, EPOCH: 9, train_loss: 0.01996841311857507\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01713005969157586\n",
      "SEED: 0, FOLD: 3, EPOCH: 10, train_loss: 0.019941705153197854\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017402966435138997\n",
      "SEED: 0, FOLD: 3, EPOCH: 11, train_loss: 0.01986585879648054\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 11, valid_loss: 0.017032046587421343\n",
      "SEED: 0, FOLD: 3, EPOCH: 12, train_loss: 0.019709647331084754\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 12, valid_loss: 0.017350697603363257\n",
      "SEED: 0, FOLD: 3, EPOCH: 13, train_loss: 0.01968512890508046\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01690719649195671\n",
      "SEED: 0, FOLD: 3, EPOCH: 14, train_loss: 0.019545861117139057\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016872204840183258\n",
      "SEED: 0, FOLD: 3, EPOCH: 15, train_loss: 0.019410045263735024\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01663447106973483\n",
      "SEED: 0, FOLD: 3, EPOCH: 16, train_loss: 0.01916008784964278\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016603616639398612\n",
      "SEED: 0, FOLD: 3, EPOCH: 17, train_loss: 0.01890794185267107\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016550636277175866\n",
      "SEED: 0, FOLD: 3, EPOCH: 18, train_loss: 0.018745097281360947\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 18, valid_loss: 0.01631669234484434\n",
      "SEED: 0, FOLD: 3, EPOCH: 19, train_loss: 0.01838817638722626\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016335306474222586\n",
      "SEED: 0, FOLD: 3, EPOCH: 20, train_loss: 0.018036769577176183\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016266421486551944\n",
      "SEED: 0, FOLD: 3, EPOCH: 21, train_loss: 0.017628806580260798\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016181939783004615\n",
      "SEED: 0, FOLD: 3, EPOCH: 22, train_loss: 0.017194776506339375\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 22, valid_loss: 0.016196431807027414\n",
      "SEED: 0, FOLD: 3, EPOCH: 23, train_loss: 0.016837671411701956\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016138552114940606\n",
      "SEED: 0, FOLD: 3, EPOCH: 24, train_loss: 0.016635326429496746\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 24, valid_loss: 0.01612677940955529\n",
      "SEED: 0, FOLD: 3, EPOCH: 25, train_loss: 0.01648827370356869\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 25, valid_loss: 0.016134496348408554\n",
      "SEED: 0, FOLD: 4, EPOCH: 0, train_loss: 0.5870002783029467\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08842846980461708\n",
      "SEED: 0, FOLD: 4, EPOCH: 1, train_loss: 0.029919157257756672\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 1, valid_loss: 0.019941713804235824\n",
      "SEED: 0, FOLD: 4, EPOCH: 2, train_loss: 0.021898459819321696\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018842260711468183\n",
      "SEED: 0, FOLD: 4, EPOCH: 3, train_loss: 0.02096011071793131\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 3, valid_loss: 0.018508464097976685\n",
      "SEED: 0, FOLD: 4, EPOCH: 4, train_loss: 0.02044849462706495\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017362191055256587\n",
      "SEED: 0, FOLD: 4, EPOCH: 5, train_loss: 0.020116762333625072\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 5, valid_loss: 0.01701269270135806\n",
      "SEED: 0, FOLD: 4, EPOCH: 6, train_loss: 0.019948151138787333\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017024845386353824\n",
      "SEED: 0, FOLD: 4, EPOCH: 7, train_loss: 0.020011865131154254\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01715231565042184\n",
      "SEED: 0, FOLD: 4, EPOCH: 8, train_loss: 0.019870341856133292\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 8, valid_loss: 0.016939098301988382\n",
      "SEED: 0, FOLD: 4, EPOCH: 9, train_loss: 0.019903099214708484\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017051122294595607\n",
      "SEED: 0, FOLD: 4, EPOCH: 10, train_loss: 0.019801530080872612\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01688474266288372\n",
      "SEED: 0, FOLD: 4, EPOCH: 11, train_loss: 0.01981990087173275\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01675617522918261\n",
      "SEED: 0, FOLD: 4, EPOCH: 12, train_loss: 0.019727987816204894\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016586925834417343\n",
      "SEED: 0, FOLD: 4, EPOCH: 13, train_loss: 0.019499831203673337\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01661586030744589\n",
      "SEED: 0, FOLD: 4, EPOCH: 14, train_loss: 0.01945821862869166\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016498141850416478\n",
      "SEED: 0, FOLD: 4, EPOCH: 15, train_loss: 0.019347353611846228\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016461805440485477\n",
      "SEED: 0, FOLD: 4, EPOCH: 16, train_loss: 0.019140226716125332\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016264810441778257\n",
      "SEED: 0, FOLD: 4, EPOCH: 17, train_loss: 0.018942694607618694\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01639248437892932\n",
      "SEED: 0, FOLD: 4, EPOCH: 18, train_loss: 0.018628421541605447\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01609627537142772\n",
      "SEED: 0, FOLD: 4, EPOCH: 19, train_loss: 0.018318803527870693\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016029861397468127\n",
      "SEED: 0, FOLD: 4, EPOCH: 20, train_loss: 0.017947172418840834\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 20, valid_loss: 0.015939875004383233\n",
      "SEED: 0, FOLD: 4, EPOCH: 21, train_loss: 0.0175024324373619\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01582691539078951\n",
      "SEED: 0, FOLD: 4, EPOCH: 22, train_loss: 0.017126041955339746\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015784466567520913\n",
      "SEED: 0, FOLD: 4, EPOCH: 23, train_loss: 0.01672951043961016\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 23, valid_loss: 0.015761394841739766\n",
      "SEED: 0, FOLD: 4, EPOCH: 24, train_loss: 0.016409696822331565\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015763297175558712\n",
      "SEED: 0, FOLD: 4, EPOCH: 25, train_loss: 0.016343487426638603\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 25, valid_loss: 0.015766391387352578\n",
      "SEED: 0, FOLD: 5, EPOCH: 0, train_loss: 0.587765388895531\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 0, valid_loss: 0.08926665553679833\n",
      "SEED: 0, FOLD: 5, EPOCH: 1, train_loss: 0.029512976447271334\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 1, valid_loss: 0.01950878778902384\n",
      "SEED: 0, FOLD: 5, EPOCH: 2, train_loss: 0.021975086800552702\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 2, valid_loss: 0.01829590777365061\n",
      "SEED: 0, FOLD: 5, EPOCH: 3, train_loss: 0.02099684570488092\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 3, valid_loss: 0.017347610340668604\n",
      "SEED: 0, FOLD: 5, EPOCH: 4, train_loss: 0.020379772661505518\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 4, valid_loss: 0.017378434682121642\n",
      "SEED: 0, FOLD: 5, EPOCH: 5, train_loss: 0.020140200878518658\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 5, valid_loss: 0.017366105833878882\n",
      "SEED: 0, FOLD: 5, EPOCH: 6, train_loss: 0.020073236368999287\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 6, valid_loss: 0.016763478302611753\n",
      "SEED: 0, FOLD: 5, EPOCH: 7, train_loss: 0.01998324236656363\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 7, valid_loss: 0.016852825306929074\n",
      "SEED: 0, FOLD: 5, EPOCH: 8, train_loss: 0.019976789786203486\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 8, valid_loss: 0.016992916711247884\n",
      "SEED: 0, FOLD: 5, EPOCH: 9, train_loss: 0.019963055219803308\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 9, valid_loss: 0.01694030178567538\n",
      "SEED: 0, FOLD: 5, EPOCH: 10, train_loss: 0.019918648198851058\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 10, valid_loss: 0.01682604097116452\n",
      "SEED: 0, FOLD: 5, EPOCH: 11, train_loss: 0.019860493900204026\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 11, valid_loss: 0.016697397742133874\n",
      "SEED: 0, FOLD: 5, EPOCH: 12, train_loss: 0.019774739026419214\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 12, valid_loss: 0.01655010449198576\n",
      "SEED: 0, FOLD: 5, EPOCH: 13, train_loss: 0.019659785805521784\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 13, valid_loss: 0.01643123348745016\n",
      "SEED: 0, FOLD: 5, EPOCH: 14, train_loss: 0.019490532199474605\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 14, valid_loss: 0.016333617843114413\n",
      "SEED: 0, FOLD: 5, EPOCH: 15, train_loss: 0.019321218711902965\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 15, valid_loss: 0.016257704737094734\n",
      "SEED: 0, FOLD: 5, EPOCH: 16, train_loss: 0.019154962278097064\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 16, valid_loss: 0.016225445514115002\n",
      "SEED: 0, FOLD: 5, EPOCH: 17, train_loss: 0.018928612632727302\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 17, valid_loss: 0.016136136622383043\n",
      "SEED: 0, FOLD: 5, EPOCH: 18, train_loss: 0.01871366912146678\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 18, valid_loss: 0.016151379578961775\n",
      "SEED: 0, FOLD: 5, EPOCH: 19, train_loss: 0.018387620337307453\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 19, valid_loss: 0.015898490109695837\n",
      "SEED: 0, FOLD: 5, EPOCH: 20, train_loss: 0.01789509618302455\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 20, valid_loss: 0.01583946603708542\n",
      "SEED: 0, FOLD: 5, EPOCH: 21, train_loss: 0.017532440003108333\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 21, valid_loss: 0.015731175430119038\n",
      "SEED: 0, FOLD: 5, EPOCH: 22, train_loss: 0.0171147474666705\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 22, valid_loss: 0.0157233401416586\n",
      "SEED: 0, FOLD: 5, EPOCH: 23, train_loss: 0.016722232468325545\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 23, valid_loss: 0.015714466858368654\n",
      "SEED: 0, FOLD: 5, EPOCH: 24, train_loss: 0.016450286956151593\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 24, valid_loss: 0.01570868843163435\n",
      "SEED: 0, FOLD: 5, EPOCH: 25, train_loss: 0.016369325612243767\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 25, valid_loss: 0.01570327257594237\n",
      "SEED: 0, FOLD: 6, EPOCH: 0, train_loss: 0.5882562227748536\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 0, valid_loss: 0.08738984798009579\n",
      "SEED: 0, FOLD: 6, EPOCH: 1, train_loss: 0.029836196955796833\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 1, valid_loss: 0.020060368025532134\n",
      "SEED: 0, FOLD: 6, EPOCH: 2, train_loss: 0.02191617083106492\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 2, valid_loss: 0.0184668367012189\n",
      "SEED: 0, FOLD: 6, EPOCH: 3, train_loss: 0.02092560048441629\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 3, valid_loss: 0.01817665220453189\n",
      "SEED: 0, FOLD: 6, EPOCH: 4, train_loss: 0.020298756180784187\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 4, valid_loss: 0.01761570429572692\n",
      "SEED: 0, FOLD: 6, EPOCH: 5, train_loss: 0.020121028369947058\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 5, valid_loss: 0.01742717308493761\n",
      "SEED: 0, FOLD: 6, EPOCH: 6, train_loss: 0.02002940948649838\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 6, valid_loss: 0.017266708641098097\n",
      "SEED: 0, FOLD: 6, EPOCH: 7, train_loss: 0.019952444988932158\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 7, valid_loss: 0.017374937924054954\n",
      "SEED: 0, FOLD: 6, EPOCH: 8, train_loss: 0.019889351458766975\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 8, valid_loss: 0.017015649005770683\n",
      "SEED: 0, FOLD: 6, EPOCH: 9, train_loss: 0.019845043887963165\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 9, valid_loss: 0.01738593727350235\n",
      "SEED: 0, FOLD: 6, EPOCH: 10, train_loss: 0.019809850315387185\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 10, valid_loss: 0.017058308164660748\n",
      "SEED: 0, FOLD: 6, EPOCH: 11, train_loss: 0.01979106105864048\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 11, valid_loss: 0.016960664150806572\n",
      "SEED: 0, FOLD: 6, EPOCH: 12, train_loss: 0.01965965026033086\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 12, valid_loss: 0.01703463552089838\n",
      "SEED: 0, FOLD: 6, EPOCH: 13, train_loss: 0.01948933129677096\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 13, valid_loss: 0.01683630020572589\n",
      "SEED: 0, FOLD: 6, EPOCH: 14, train_loss: 0.019428386428468936\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 14, valid_loss: 0.016882682362428077\n",
      "SEED: 0, FOLD: 6, EPOCH: 15, train_loss: 0.01917759361802726\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 15, valid_loss: 0.016955845774366304\n",
      "SEED: 0, FOLD: 6, EPOCH: 16, train_loss: 0.018977849492551508\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 16, valid_loss: 0.01664477687042493\n",
      "SEED: 0, FOLD: 6, EPOCH: 17, train_loss: 0.018782310942943033\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 17, valid_loss: 0.016568791264524825\n",
      "SEED: 0, FOLD: 6, EPOCH: 18, train_loss: 0.0184646678736081\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 18, valid_loss: 0.016448785335971758\n",
      "SEED: 0, FOLD: 6, EPOCH: 19, train_loss: 0.018138910996148717\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 19, valid_loss: 0.01629276881710841\n",
      "SEED: 0, FOLD: 6, EPOCH: 20, train_loss: 0.01779744852132894\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 20, valid_loss: 0.01631083754965892\n",
      "SEED: 0, FOLD: 6, EPOCH: 21, train_loss: 0.01738297058319723\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 21, valid_loss: 0.01616867509885476\n",
      "SEED: 0, FOLD: 6, EPOCH: 22, train_loss: 0.0169573321032363\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 22, valid_loss: 0.016180402814195707\n",
      "SEED: 0, FOLD: 6, EPOCH: 23, train_loss: 0.01653449288946954\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 23, valid_loss: 0.01615361267557511\n",
      "SEED: 0, FOLD: 6, EPOCH: 24, train_loss: 0.016262937085451307\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 24, valid_loss: 0.016143757061889537\n",
      "SEED: 0, FOLD: 6, EPOCH: 25, train_loss: 0.01612789703633737\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 25, valid_loss: 0.016170068500706784\n",
      "SEED: 1, FOLD: 0, EPOCH: 0, train_loss: 0.5884508528822178\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 0, valid_loss: 0.07926188695889252\n",
      "SEED: 1, FOLD: 0, EPOCH: 1, train_loss: 0.029547412451860065\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 1, valid_loss: 0.020708997662250813\n",
      "SEED: 1, FOLD: 0, EPOCH: 2, train_loss: 0.021934658188272168\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 2, valid_loss: 0.018424075813247606\n",
      "SEED: 1, FOLD: 0, EPOCH: 3, train_loss: 0.02102877091415025\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017703849392441604\n",
      "SEED: 1, FOLD: 0, EPOCH: 4, train_loss: 0.020351189264171832\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 4, valid_loss: 0.01715255521524411\n",
      "SEED: 1, FOLD: 0, EPOCH: 5, train_loss: 0.020114926797514025\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017262891866266727\n",
      "SEED: 1, FOLD: 0, EPOCH: 6, train_loss: 0.019906054603288304\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017028933176054403\n",
      "SEED: 1, FOLD: 0, EPOCH: 7, train_loss: 0.019901268007988866\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017219574190676212\n",
      "SEED: 1, FOLD: 0, EPOCH: 8, train_loss: 0.019843040361396364\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017057780606242325\n",
      "SEED: 1, FOLD: 0, EPOCH: 9, train_loss: 0.01984250673873199\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017125225984133206\n",
      "SEED: 1, FOLD: 0, EPOCH: 10, train_loss: 0.01978687317790212\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 10, valid_loss: 0.016935410909354687\n",
      "SEED: 1, FOLD: 0, EPOCH: 11, train_loss: 0.019742826050197757\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 11, valid_loss: 0.016930497967852995\n",
      "SEED: 1, FOLD: 0, EPOCH: 12, train_loss: 0.019650541044570303\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016876678698911116\n",
      "SEED: 1, FOLD: 0, EPOCH: 13, train_loss: 0.01952352125600383\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016854332401775397\n",
      "SEED: 1, FOLD: 0, EPOCH: 14, train_loss: 0.019450549892074353\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016831479823360078\n",
      "SEED: 1, FOLD: 0, EPOCH: 15, train_loss: 0.019203717770004593\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01650524791330099\n",
      "SEED: 1, FOLD: 0, EPOCH: 16, train_loss: 0.019089266834025446\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01657570289591184\n",
      "SEED: 1, FOLD: 0, EPOCH: 17, train_loss: 0.018821188575915387\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016470539670151014\n",
      "SEED: 1, FOLD: 0, EPOCH: 18, train_loss: 0.01853797000807685\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016392631026414726\n",
      "SEED: 1, FOLD: 0, EPOCH: 19, train_loss: 0.018217687495052814\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 19, valid_loss: 0.01635486976458476\n",
      "SEED: 1, FOLD: 0, EPOCH: 20, train_loss: 0.017841677055568307\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 20, valid_loss: 0.0162275919260887\n",
      "SEED: 1, FOLD: 0, EPOCH: 21, train_loss: 0.017404473374119482\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 21, valid_loss: 0.01617049891501665\n",
      "SEED: 1, FOLD: 0, EPOCH: 22, train_loss: 0.016938247076059516\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 22, valid_loss: 0.016162228842194263\n",
      "SEED: 1, FOLD: 0, EPOCH: 23, train_loss: 0.016580797769632692\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 23, valid_loss: 0.016193053255287502\n",
      "SEED: 1, FOLD: 0, EPOCH: 24, train_loss: 0.01632297703543225\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 24, valid_loss: 0.016171439049335625\n",
      "SEED: 1, FOLD: 0, EPOCH: 25, train_loss: 0.01620392662447852\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 25, valid_loss: 0.01615967143040437\n",
      "SEED: 1, FOLD: 1, EPOCH: 0, train_loss: 0.5893721284495818\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 0, valid_loss: 0.09306792685618767\n",
      "SEED: 1, FOLD: 1, EPOCH: 1, train_loss: 0.029535305484927988\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 1, valid_loss: 0.01963425914828594\n",
      "SEED: 1, FOLD: 1, EPOCH: 2, train_loss: 0.02190914370018888\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 2, valid_loss: 0.017931187668671973\n",
      "SEED: 1, FOLD: 1, EPOCH: 3, train_loss: 0.020982602283962676\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 3, valid_loss: 0.01766107467791209\n",
      "SEED: 1, FOLD: 1, EPOCH: 4, train_loss: 0.020395373648686987\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 4, valid_loss: 0.0171615589553347\n",
      "SEED: 1, FOLD: 1, EPOCH: 5, train_loss: 0.020096846503784526\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017046159849717066\n",
      "SEED: 1, FOLD: 1, EPOCH: 6, train_loss: 0.020062734322572075\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 6, valid_loss: 0.016942925607928865\n",
      "SEED: 1, FOLD: 1, EPOCH: 7, train_loss: 0.02002490744800181\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01692696288228035\n",
      "SEED: 1, FOLD: 1, EPOCH: 8, train_loss: 0.019944068749208708\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 8, valid_loss: 0.016967212351468895\n",
      "SEED: 1, FOLD: 1, EPOCH: 9, train_loss: 0.01995636396915526\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01694922586186574\n",
      "SEED: 1, FOLD: 1, EPOCH: 10, train_loss: 0.019859561470110674\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01690483666383303\n",
      "SEED: 1, FOLD: 1, EPOCH: 11, train_loss: 0.01985653268324362\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01677872885305148\n",
      "SEED: 1, FOLD: 1, EPOCH: 12, train_loss: 0.01970837192257514\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016547430163392655\n",
      "SEED: 1, FOLD: 1, EPOCH: 13, train_loss: 0.019604550070456556\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016658424757994138\n",
      "SEED: 1, FOLD: 1, EPOCH: 14, train_loss: 0.01948494856824746\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016565432413839377\n",
      "SEED: 1, FOLD: 1, EPOCH: 15, train_loss: 0.019344148578474652\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016438002053361673\n",
      "SEED: 1, FOLD: 1, EPOCH: 16, train_loss: 0.019171294353499607\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016361439528946694\n",
      "SEED: 1, FOLD: 1, EPOCH: 17, train_loss: 0.01892284311454844\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016209513450471256\n",
      "SEED: 1, FOLD: 1, EPOCH: 18, train_loss: 0.01862366170295187\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016140633907455664\n",
      "SEED: 1, FOLD: 1, EPOCH: 19, train_loss: 0.018304775192125422\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01606108728223122\n",
      "SEED: 1, FOLD: 1, EPOCH: 20, train_loss: 0.017960416908199724\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 20, valid_loss: 0.01599440759477707\n",
      "SEED: 1, FOLD: 1, EPOCH: 21, train_loss: 0.017557516467530985\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 21, valid_loss: 0.015965668914409783\n",
      "SEED: 1, FOLD: 1, EPOCH: 22, train_loss: 0.017115224895344394\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015905642810349282\n",
      "SEED: 1, FOLD: 1, EPOCH: 23, train_loss: 0.016840559216467915\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 23, valid_loss: 0.015858523547649384\n",
      "SEED: 1, FOLD: 1, EPOCH: 24, train_loss: 0.0165644165858425\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 24, valid_loss: 0.01585413472583661\n",
      "SEED: 1, FOLD: 1, EPOCH: 25, train_loss: 0.016414066990585747\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 25, valid_loss: 0.01583535525088127\n",
      "SEED: 1, FOLD: 2, EPOCH: 0, train_loss: 0.5871503571602138\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 0, valid_loss: 0.09015799714968754\n",
      "SEED: 1, FOLD: 2, EPOCH: 1, train_loss: 0.02941037795028171\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 1, valid_loss: 0.01979039193919072\n",
      "SEED: 1, FOLD: 2, EPOCH: 2, train_loss: 0.021808420458959567\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 2, valid_loss: 0.026524297033364955\n",
      "SEED: 1, FOLD: 2, EPOCH: 3, train_loss: 0.021068237797432655\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017850086809350893\n",
      "SEED: 1, FOLD: 2, EPOCH: 4, train_loss: 0.020336877202262748\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017436472412485342\n",
      "SEED: 1, FOLD: 2, EPOCH: 5, train_loss: 0.020082450975236053\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017298158401480086\n",
      "SEED: 1, FOLD: 2, EPOCH: 6, train_loss: 0.019953339083774668\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01730752492753359\n",
      "SEED: 1, FOLD: 2, EPOCH: 7, train_loss: 0.01994271370003352\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017306750210431907\n",
      "SEED: 1, FOLD: 2, EPOCH: 8, train_loss: 0.019929615831052936\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017355195318277065\n",
      "SEED: 1, FOLD: 2, EPOCH: 9, train_loss: 0.01988201850169414\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01720256544649601\n",
      "SEED: 1, FOLD: 2, EPOCH: 10, train_loss: 0.019818107597529888\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 10, valid_loss: 0.01701682576766381\n",
      "SEED: 1, FOLD: 2, EPOCH: 11, train_loss: 0.01973206121977922\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 11, valid_loss: 0.017153520566912796\n",
      "SEED: 1, FOLD: 2, EPOCH: 12, train_loss: 0.019741812846749217\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016949734865472868\n",
      "SEED: 1, FOLD: 2, EPOCH: 13, train_loss: 0.019544580699624243\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016972975232280217\n",
      "SEED: 1, FOLD: 2, EPOCH: 14, train_loss: 0.019430832559796603\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01674920220214587\n",
      "SEED: 1, FOLD: 2, EPOCH: 15, train_loss: 0.019251121233242588\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016911354632331774\n",
      "SEED: 1, FOLD: 2, EPOCH: 16, train_loss: 0.019088479765766376\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01668262481689453\n",
      "SEED: 1, FOLD: 2, EPOCH: 17, train_loss: 0.018883953399553493\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016472992702172354\n",
      "SEED: 1, FOLD: 2, EPOCH: 18, train_loss: 0.018567537007903732\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016347420401871204\n",
      "SEED: 1, FOLD: 2, EPOCH: 19, train_loss: 0.01825271622353309\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016201648073127635\n",
      "SEED: 1, FOLD: 2, EPOCH: 20, train_loss: 0.017847328471976356\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01622488614744865\n",
      "SEED: 1, FOLD: 2, EPOCH: 21, train_loss: 0.017456485839510285\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016088886473041315\n",
      "SEED: 1, FOLD: 2, EPOCH: 22, train_loss: 0.017018952381771965\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 22, valid_loss: 0.016068346296938565\n",
      "SEED: 1, FOLD: 2, EPOCH: 23, train_loss: 0.0166342300992157\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 23, valid_loss: 0.016151799963643916\n",
      "SEED: 1, FOLD: 2, EPOCH: 24, train_loss: 0.016339537725355978\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 24, valid_loss: 0.016123324131163266\n",
      "SEED: 1, FOLD: 3, EPOCH: 0, train_loss: 0.5878287308119439\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08267429642952405\n",
      "SEED: 1, FOLD: 3, EPOCH: 1, train_loss: 0.029429877529273164\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 1, valid_loss: 0.01981601821115384\n",
      "SEED: 1, FOLD: 3, EPOCH: 2, train_loss: 0.02183206344174372\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018920232613499347\n",
      "SEED: 1, FOLD: 3, EPOCH: 3, train_loss: 0.021097851816464116\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 3, valid_loss: 0.017993833153293684\n",
      "SEED: 1, FOLD: 3, EPOCH: 4, train_loss: 0.020286962314433343\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017614436550782278\n",
      "SEED: 1, FOLD: 3, EPOCH: 5, train_loss: 0.020046568979081268\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017927362941778623\n",
      "SEED: 1, FOLD: 3, EPOCH: 6, train_loss: 0.019947839221237478\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017323979534781896\n",
      "SEED: 1, FOLD: 3, EPOCH: 7, train_loss: 0.01987417694181204\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01753630145237996\n",
      "SEED: 1, FOLD: 3, EPOCH: 8, train_loss: 0.019837940464148652\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 8, valid_loss: 0.01723089126440195\n",
      "SEED: 1, FOLD: 3, EPOCH: 9, train_loss: 0.01986059740286421\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01751010836316989\n",
      "SEED: 1, FOLD: 3, EPOCH: 10, train_loss: 0.01975594727775535\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 10, valid_loss: 0.01717621345932667\n",
      "SEED: 1, FOLD: 3, EPOCH: 11, train_loss: 0.01966927688870881\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01740604954270216\n",
      "SEED: 1, FOLD: 3, EPOCH: 12, train_loss: 0.019621091668267508\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 12, valid_loss: 0.017015750591571514\n",
      "SEED: 1, FOLD: 3, EPOCH: 13, train_loss: 0.019497093593550695\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 13, valid_loss: 0.017067397729708597\n",
      "SEED: 1, FOLD: 3, EPOCH: 14, train_loss: 0.01938288940771206\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01707208600754921\n",
      "SEED: 1, FOLD: 3, EPOCH: 15, train_loss: 0.019235887615060485\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016999229215658627\n",
      "SEED: 1, FOLD: 3, EPOCH: 16, train_loss: 0.0190368604569419\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016755985382657785\n",
      "SEED: 1, FOLD: 3, EPOCH: 17, train_loss: 0.018826679376935638\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01667021164813867\n",
      "SEED: 1, FOLD: 3, EPOCH: 18, train_loss: 0.01856304841065729\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016632363773309268\n",
      "SEED: 1, FOLD: 3, EPOCH: 19, train_loss: 0.018174412861667776\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 19, valid_loss: 0.0166386546423802\n",
      "SEED: 1, FOLD: 3, EPOCH: 20, train_loss: 0.017816908380671126\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016541755973146513\n",
      "SEED: 1, FOLD: 3, EPOCH: 21, train_loss: 0.017334702902951755\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016388782085134432\n",
      "SEED: 1, FOLD: 3, EPOCH: 22, train_loss: 0.016913713044109376\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01636869302735879\n",
      "SEED: 1, FOLD: 3, EPOCH: 23, train_loss: 0.01655206094319756\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016313458864505474\n",
      "SEED: 1, FOLD: 3, EPOCH: 24, train_loss: 0.016247908156868572\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016322213010146067\n",
      "SEED: 1, FOLD: 3, EPOCH: 25, train_loss: 0.016120239160954952\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 25, valid_loss: 0.016317603679803703\n",
      "SEED: 1, FOLD: 4, EPOCH: 0, train_loss: 0.5908092301640961\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 0, valid_loss: 0.0911864649790984\n",
      "SEED: 1, FOLD: 4, EPOCH: 1, train_loss: 0.029653551434544293\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 1, valid_loss: 0.019826154582775556\n",
      "SEED: 1, FOLD: 4, EPOCH: 2, train_loss: 0.021880343204011787\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018487824127078056\n",
      "SEED: 1, FOLD: 4, EPOCH: 3, train_loss: 0.020999550164954084\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 3, valid_loss: 0.017675303639127657\n",
      "SEED: 1, FOLD: 4, EPOCH: 4, train_loss: 0.020294443653846108\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017392609698268082\n",
      "SEED: 1, FOLD: 4, EPOCH: 5, train_loss: 0.02009973846174575\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017654165912132997\n",
      "SEED: 1, FOLD: 4, EPOCH: 6, train_loss: 0.020005593126690067\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01698445012936225\n",
      "SEED: 1, FOLD: 4, EPOCH: 7, train_loss: 0.01989050639944302\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01698577719239088\n",
      "SEED: 1, FOLD: 4, EPOCH: 8, train_loss: 0.019904238801147486\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017053001631910984\n",
      "SEED: 1, FOLD: 4, EPOCH: 9, train_loss: 0.01984351488283357\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017099234060599253\n",
      "SEED: 1, FOLD: 4, EPOCH: 10, train_loss: 0.019838485388538322\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01739744354899113\n",
      "SEED: 1, FOLD: 4, EPOCH: 11, train_loss: 0.019764060506949555\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 11, valid_loss: 0.017188609935916387\n",
      "SEED: 1, FOLD: 4, EPOCH: 12, train_loss: 0.01966571729831599\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016785947462687127\n",
      "SEED: 1, FOLD: 4, EPOCH: 13, train_loss: 0.01960884082458309\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016966053642905675\n",
      "SEED: 1, FOLD: 4, EPOCH: 14, train_loss: 0.019478316746048024\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016690448929484073\n",
      "SEED: 1, FOLD: 4, EPOCH: 15, train_loss: 0.01937591511051397\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016568474614849456\n",
      "SEED: 1, FOLD: 4, EPOCH: 16, train_loss: 0.01914950762246106\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01657789057263961\n",
      "SEED: 1, FOLD: 4, EPOCH: 17, train_loss: 0.01886569955260367\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01643989858432458\n",
      "SEED: 1, FOLD: 4, EPOCH: 18, train_loss: 0.018591528078792868\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01634780425005234\n",
      "SEED: 1, FOLD: 4, EPOCH: 19, train_loss: 0.01825416913709125\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016214926512195513\n",
      "SEED: 1, FOLD: 4, EPOCH: 20, train_loss: 0.017894008347915637\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016091276819889363\n",
      "SEED: 1, FOLD: 4, EPOCH: 21, train_loss: 0.017470337601529586\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 21, valid_loss: 0.016064649519438926\n",
      "SEED: 1, FOLD: 4, EPOCH: 22, train_loss: 0.01705065422464867\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015956721626795255\n",
      "SEED: 1, FOLD: 4, EPOCH: 23, train_loss: 0.016605314458846242\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01594649341243964\n",
      "SEED: 1, FOLD: 4, EPOCH: 24, train_loss: 0.01631656172056053\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01595867332071066\n",
      "SEED: 1, FOLD: 4, EPOCH: 25, train_loss: 0.016221296382010787\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 25, valid_loss: 0.015949146678814523\n",
      "SEED: 1, FOLD: 5, EPOCH: 0, train_loss: 0.5881888986237951\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 0, valid_loss: 0.08597782941964957\n",
      "SEED: 1, FOLD: 5, EPOCH: 1, train_loss: 0.029830086699410063\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 1, valid_loss: 0.01989182844184912\n",
      "SEED: 1, FOLD: 5, EPOCH: 2, train_loss: 0.02190878604714935\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 2, valid_loss: 0.07888568565249443\n",
      "SEED: 1, FOLD: 5, EPOCH: 3, train_loss: 0.021347297280020005\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 3, valid_loss: 0.01777958540389171\n",
      "SEED: 1, FOLD: 5, EPOCH: 4, train_loss: 0.02049682055272766\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 4, valid_loss: 0.017207314188663777\n",
      "SEED: 1, FOLD: 5, EPOCH: 5, train_loss: 0.02013461193623575\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 5, valid_loss: 0.0170731210651306\n",
      "SEED: 1, FOLD: 5, EPOCH: 6, train_loss: 0.0200229683840597\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 6, valid_loss: 0.017129472600152858\n",
      "SEED: 1, FOLD: 5, EPOCH: 7, train_loss: 0.020068883090405852\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 7, valid_loss: 0.017312687606765673\n",
      "SEED: 1, FOLD: 5, EPOCH: 8, train_loss: 0.01991045638616826\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 8, valid_loss: 0.017116894515661094\n",
      "SEED: 1, FOLD: 5, EPOCH: 9, train_loss: 0.019957785242916765\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 9, valid_loss: 0.016825841095011968\n",
      "SEED: 1, FOLD: 5, EPOCH: 10, train_loss: 0.019858551991952432\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 10, valid_loss: 0.016803443288573854\n",
      "SEED: 1, FOLD: 5, EPOCH: 11, train_loss: 0.0197755882164111\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 11, valid_loss: 0.016729706683411047\n",
      "SEED: 1, FOLD: 5, EPOCH: 12, train_loss: 0.01968870797773471\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 12, valid_loss: 0.016787643902576886\n",
      "SEED: 1, FOLD: 5, EPOCH: 13, train_loss: 0.01956672130807026\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 13, valid_loss: 0.016939160485680286\n",
      "SEED: 1, FOLD: 5, EPOCH: 14, train_loss: 0.01946433412062155\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 14, valid_loss: 0.016623802483081818\n",
      "SEED: 1, FOLD: 5, EPOCH: 15, train_loss: 0.019265599347449636\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 15, valid_loss: 0.01643467529748495\n",
      "SEED: 1, FOLD: 5, EPOCH: 16, train_loss: 0.019077666254865157\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 16, valid_loss: 0.016282196443241376\n",
      "SEED: 1, FOLD: 5, EPOCH: 17, train_loss: 0.018835642324710213\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 17, valid_loss: 0.01625458079461868\n",
      "SEED: 1, FOLD: 5, EPOCH: 18, train_loss: 0.018578786126061064\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 18, valid_loss: 0.016362944546227273\n",
      "SEED: 1, FOLD: 5, EPOCH: 19, train_loss: 0.0182344057169315\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 19, valid_loss: 0.0160113640416127\n",
      "SEED: 1, FOLD: 5, EPOCH: 20, train_loss: 0.017907269424884707\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 20, valid_loss: 0.016026012742748626\n",
      "SEED: 1, FOLD: 5, EPOCH: 21, train_loss: 0.01746622996555792\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 21, valid_loss: 0.01594995965178196\n",
      "SEED: 1, FOLD: 5, EPOCH: 22, train_loss: 0.017066484845771984\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 22, valid_loss: 0.015855177377278987\n",
      "SEED: 1, FOLD: 5, EPOCH: 23, train_loss: 0.01663760916405433\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 23, valid_loss: 0.01590186830323476\n",
      "SEED: 1, FOLD: 5, EPOCH: 24, train_loss: 0.01638207636219827\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 24, valid_loss: 0.015928358054504946\n",
      "SEED: 1, FOLD: 6, EPOCH: 0, train_loss: 0.5873774967684939\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 0, valid_loss: 0.10107385309842917\n",
      "SEED: 1, FOLD: 6, EPOCH: 1, train_loss: 0.029389939774331207\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 1, valid_loss: 0.019810182973742485\n",
      "SEED: 1, FOLD: 6, EPOCH: 2, train_loss: 0.02193382807780762\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 2, valid_loss: 0.01818769281873336\n",
      "SEED: 1, FOLD: 6, EPOCH: 3, train_loss: 0.0211469535086606\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 3, valid_loss: 0.01745382108940528\n",
      "SEED: 1, FOLD: 6, EPOCH: 4, train_loss: 0.020437488911321033\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 4, valid_loss: 0.019586581736803055\n",
      "SEED: 1, FOLD: 6, EPOCH: 5, train_loss: 0.020200586626054468\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 5, valid_loss: 0.017467447055073883\n",
      "SEED: 1, FOLD: 6, EPOCH: 6, train_loss: 0.020061130434073305\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 6, valid_loss: 0.017150314524769783\n",
      "SEED: 1, FOLD: 6, EPOCH: 7, train_loss: 0.01997404492686729\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 7, valid_loss: 0.01700773348028843\n",
      "SEED: 1, FOLD: 6, EPOCH: 8, train_loss: 0.019934882057478297\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 8, valid_loss: 0.0168306168455344\n",
      "SEED: 1, FOLD: 6, EPOCH: 9, train_loss: 0.01987463152791197\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 9, valid_loss: 0.016942736692726612\n",
      "SEED: 1, FOLD: 6, EPOCH: 10, train_loss: 0.019931715636237246\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 10, valid_loss: 0.01700856314542202\n",
      "SEED: 1, FOLD: 6, EPOCH: 11, train_loss: 0.019827659367709548\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 11, valid_loss: 0.01705160214064213\n",
      "SEED: 1, FOLD: 6, EPOCH: 12, train_loss: 0.01971388021735726\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 12, valid_loss: 0.016930818772659853\n",
      "SEED: 1, FOLD: 6, EPOCH: 13, train_loss: 0.0196377262976524\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 13, valid_loss: 0.016742754082840223\n",
      "SEED: 1, FOLD: 6, EPOCH: 14, train_loss: 0.019473619708741032\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 14, valid_loss: 0.01664891172773563\n",
      "SEED: 1, FOLD: 6, EPOCH: 15, train_loss: 0.019300255471387424\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 15, valid_loss: 0.01638628184222258\n",
      "SEED: 1, FOLD: 6, EPOCH: 16, train_loss: 0.019074669233649165\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 16, valid_loss: 0.01646614418579982\n",
      "SEED: 1, FOLD: 6, EPOCH: 17, train_loss: 0.01888418195114748\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 17, valid_loss: 0.01634845223564368\n",
      "SEED: 1, FOLD: 6, EPOCH: 18, train_loss: 0.018581704010029097\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 18, valid_loss: 0.016210882566296138\n",
      "SEED: 1, FOLD: 6, EPOCH: 19, train_loss: 0.018235079843450238\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 19, valid_loss: 0.016068480192468718\n",
      "SEED: 1, FOLD: 6, EPOCH: 20, train_loss: 0.017859882171693688\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 20, valid_loss: 0.01608710879316697\n",
      "SEED: 1, FOLD: 6, EPOCH: 21, train_loss: 0.017403353509065266\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 21, valid_loss: 0.01596400335144538\n",
      "SEED: 1, FOLD: 6, EPOCH: 22, train_loss: 0.01697874485791938\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 22, valid_loss: 0.015913374148882352\n",
      "SEED: 1, FOLD: 6, EPOCH: 23, train_loss: 0.016572024635467177\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 23, valid_loss: 0.015876896822681792\n",
      "SEED: 1, FOLD: 6, EPOCH: 24, train_loss: 0.016274406134176092\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 24, valid_loss: 0.015894903658101193\n",
      "SEED: 1, FOLD: 6, EPOCH: 25, train_loss: 0.016143805410310224\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 25, valid_loss: 0.015857173344836786\n",
      "SEED: 2, FOLD: 0, EPOCH: 0, train_loss: 0.5879236766816797\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 0, valid_loss: 0.09403615559522922\n",
      "SEED: 2, FOLD: 0, EPOCH: 1, train_loss: 0.030085341702844645\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 1, valid_loss: 0.01990205508012038\n",
      "SEED: 2, FOLD: 0, EPOCH: 2, train_loss: 0.021945442551293888\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 2, valid_loss: 0.0228695531304066\n",
      "SEED: 2, FOLD: 0, EPOCH: 3, train_loss: 0.021184360281237075\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017685582431463096\n",
      "SEED: 2, FOLD: 0, EPOCH: 4, train_loss: 0.020443066023290157\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 4, valid_loss: 0.01713390411952367\n",
      "SEED: 2, FOLD: 0, EPOCH: 5, train_loss: 0.02021350565592985\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017063860208369218\n",
      "SEED: 2, FOLD: 0, EPOCH: 6, train_loss: 0.020065754526168912\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017213234749551002\n",
      "SEED: 2, FOLD: 0, EPOCH: 7, train_loss: 0.020022305458582735\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017113275539416533\n",
      "SEED: 2, FOLD: 0, EPOCH: 8, train_loss: 0.019935393932502012\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017190890959822215\n",
      "SEED: 2, FOLD: 0, EPOCH: 9, train_loss: 0.01988329106589427\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017114764652573146\n",
      "SEED: 2, FOLD: 0, EPOCH: 10, train_loss: 0.019815237362038444\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 10, valid_loss: 0.016937298127091847\n",
      "SEED: 2, FOLD: 0, EPOCH: 11, train_loss: 0.019793825702288666\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01697384501592471\n",
      "SEED: 2, FOLD: 0, EPOCH: 12, train_loss: 0.01970790613543343\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016886809267676793\n",
      "SEED: 2, FOLD: 0, EPOCH: 13, train_loss: 0.019624606378980586\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016834862243670683\n",
      "SEED: 2, FOLD: 0, EPOCH: 14, train_loss: 0.01948070420405349\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016752796749082897\n",
      "SEED: 2, FOLD: 0, EPOCH: 15, train_loss: 0.019293604368293606\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016665245263049237\n",
      "SEED: 2, FOLD: 0, EPOCH: 16, train_loss: 0.01911992232340413\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016813792216663178\n",
      "SEED: 2, FOLD: 0, EPOCH: 17, train_loss: 0.01888455083039967\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01640134032529134\n",
      "SEED: 2, FOLD: 0, EPOCH: 18, train_loss: 0.018630478933856293\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016212864922216304\n",
      "SEED: 2, FOLD: 0, EPOCH: 19, train_loss: 0.01825358547471665\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016214763244184163\n",
      "SEED: 2, FOLD: 0, EPOCH: 20, train_loss: 0.017884823241950693\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01610988614937434\n",
      "SEED: 2, FOLD: 0, EPOCH: 21, train_loss: 0.017466986350513792\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 21, valid_loss: 0.01604442484676838\n",
      "SEED: 2, FOLD: 0, EPOCH: 22, train_loss: 0.017010120448429842\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 22, valid_loss: 0.016022356155400094\n",
      "SEED: 2, FOLD: 0, EPOCH: 23, train_loss: 0.016633714133923925\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015989513852848455\n",
      "SEED: 2, FOLD: 0, EPOCH: 24, train_loss: 0.016350165110182117\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015989191328676846\n",
      "SEED: 2, FOLD: 0, EPOCH: 25, train_loss: 0.016253797526194436\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 25, valid_loss: 0.015969843818591192\n",
      "SEED: 2, FOLD: 1, EPOCH: 0, train_loss: 0.5872781256566176\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 0, valid_loss: 0.08973732934548305\n",
      "SEED: 2, FOLD: 1, EPOCH: 1, train_loss: 0.030147795917818677\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 1, valid_loss: 0.020482847896906044\n",
      "SEED: 2, FOLD: 1, EPOCH: 2, train_loss: 0.021807260484107444\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 2, valid_loss: 0.019370700734166\n",
      "SEED: 2, FOLD: 1, EPOCH: 3, train_loss: 0.021074419589461508\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 3, valid_loss: 0.017633795093458433\n",
      "SEED: 2, FOLD: 1, EPOCH: 4, train_loss: 0.020321614411030267\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01741314700876291\n",
      "SEED: 2, FOLD: 1, EPOCH: 5, train_loss: 0.02012781111674534\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 5, valid_loss: 0.01709201430472044\n",
      "SEED: 2, FOLD: 1, EPOCH: 6, train_loss: 0.020005229331955716\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017222330475655887\n",
      "SEED: 2, FOLD: 1, EPOCH: 7, train_loss: 0.02004050851069592\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017129220713216525\n",
      "SEED: 2, FOLD: 1, EPOCH: 8, train_loss: 0.019916113868758484\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017165892757475376\n",
      "SEED: 2, FOLD: 1, EPOCH: 9, train_loss: 0.019879728631191963\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 9, valid_loss: 0.016901270844615422\n",
      "SEED: 2, FOLD: 1, EPOCH: 10, train_loss: 0.019915720775119355\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 10, valid_loss: 0.016948884066480856\n",
      "SEED: 2, FOLD: 1, EPOCH: 11, train_loss: 0.0197620525503078\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 11, valid_loss: 0.016971715725958347\n",
      "SEED: 2, FOLD: 1, EPOCH: 12, train_loss: 0.019665144207711156\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01699406775430991\n",
      "SEED: 2, FOLD: 1, EPOCH: 13, train_loss: 0.019566196042138176\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01693976606027438\n",
      "SEED: 2, FOLD: 1, EPOCH: 14, train_loss: 0.01944149212559333\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016516660053569537\n",
      "SEED: 2, FOLD: 1, EPOCH: 15, train_loss: 0.01928320272850829\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016708911324922856\n",
      "SEED: 2, FOLD: 1, EPOCH: 16, train_loss: 0.019106706226798328\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016615309895804294\n",
      "SEED: 2, FOLD: 1, EPOCH: 17, train_loss: 0.018878129411589454\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 17, valid_loss: 0.01647165209914629\n",
      "SEED: 2, FOLD: 1, EPOCH: 18, train_loss: 0.018542840875483847\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01634894497692585\n",
      "SEED: 2, FOLD: 1, EPOCH: 19, train_loss: 0.018228669701194442\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016257836268498346\n",
      "SEED: 2, FOLD: 1, EPOCH: 20, train_loss: 0.01782587533061569\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016151188801114377\n",
      "SEED: 2, FOLD: 1, EPOCH: 21, train_loss: 0.017426366552811216\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01613059496650329\n",
      "SEED: 2, FOLD: 1, EPOCH: 22, train_loss: 0.016988123162976793\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 22, valid_loss: 0.016089544918101568\n",
      "SEED: 2, FOLD: 1, EPOCH: 23, train_loss: 0.016589428877105582\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 23, valid_loss: 0.016065624757454947\n",
      "SEED: 2, FOLD: 1, EPOCH: 24, train_loss: 0.016336931821865006\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 24, valid_loss: 0.016048000409052923\n",
      "SEED: 2, FOLD: 1, EPOCH: 25, train_loss: 0.01619840063456748\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 25, valid_loss: 0.016057882672892168\n",
      "SEED: 2, FOLD: 2, EPOCH: 0, train_loss: 0.5862013371409597\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 0, valid_loss: 0.0996776343538211\n",
      "SEED: 2, FOLD: 2, EPOCH: 1, train_loss: 0.029729143791907543\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 1, valid_loss: 0.019573760863680106\n",
      "SEED: 2, FOLD: 2, EPOCH: 2, train_loss: 0.022359542624169105\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018327202218083236\n",
      "SEED: 2, FOLD: 2, EPOCH: 3, train_loss: 0.02113634712893415\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 3, valid_loss: 0.01877037937251421\n",
      "SEED: 2, FOLD: 2, EPOCH: 4, train_loss: 0.020534509088139277\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017271986732689235\n",
      "SEED: 2, FOLD: 2, EPOCH: 5, train_loss: 0.020147947317643744\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01708187349140644\n",
      "SEED: 2, FOLD: 2, EPOCH: 6, train_loss: 0.020140873620638978\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017057164285618525\n",
      "SEED: 2, FOLD: 2, EPOCH: 7, train_loss: 0.019954017338317795\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 7, valid_loss: 0.016819487039286356\n",
      "SEED: 2, FOLD: 2, EPOCH: 8, train_loss: 0.01991411900097454\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01694041032057542\n",
      "SEED: 2, FOLD: 2, EPOCH: 9, train_loss: 0.019861670915742178\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01708476388683686\n",
      "SEED: 2, FOLD: 2, EPOCH: 10, train_loss: 0.019803729814452095\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 10, valid_loss: 0.01675781629119928\n",
      "SEED: 2, FOLD: 2, EPOCH: 11, train_loss: 0.019820606436681102\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016897952327361472\n",
      "SEED: 2, FOLD: 2, EPOCH: 12, train_loss: 0.019742762418212118\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016738182721802823\n",
      "SEED: 2, FOLD: 2, EPOCH: 13, train_loss: 0.019638401582031638\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 13, valid_loss: 0.01652783750054928\n",
      "SEED: 2, FOLD: 2, EPOCH: 14, train_loss: 0.01941666903125273\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016592100119361512\n",
      "SEED: 2, FOLD: 2, EPOCH: 15, train_loss: 0.01929803069278195\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01642520188425596\n",
      "SEED: 2, FOLD: 2, EPOCH: 16, train_loss: 0.01912344143902128\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01634822929134736\n",
      "SEED: 2, FOLD: 2, EPOCH: 17, train_loss: 0.018875615847473208\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01634953557871855\n",
      "SEED: 2, FOLD: 2, EPOCH: 18, train_loss: 0.018600554859920126\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016141529051730268\n",
      "SEED: 2, FOLD: 2, EPOCH: 19, train_loss: 0.01830604317522532\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016121218625742655\n",
      "SEED: 2, FOLD: 2, EPOCH: 20, train_loss: 0.017911461609843617\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 20, valid_loss: 0.016078414395451546\n",
      "SEED: 2, FOLD: 2, EPOCH: 21, train_loss: 0.017490776444508416\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 21, valid_loss: 0.015957453574698705\n",
      "SEED: 2, FOLD: 2, EPOCH: 22, train_loss: 0.01707863576106123\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 22, valid_loss: 0.0159023548118197\n",
      "SEED: 2, FOLD: 2, EPOCH: 23, train_loss: 0.01669466242546568\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015831423851733025\n",
      "SEED: 2, FOLD: 2, EPOCH: 24, train_loss: 0.01640914975841706\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 24, valid_loss: 0.015871648533413045\n",
      "SEED: 2, FOLD: 2, EPOCH: 25, train_loss: 0.016312622087630065\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 25, valid_loss: 0.015896619799045417\n",
      "SEED: 2, FOLD: 3, EPOCH: 0, train_loss: 0.5875193927739117\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08963022667628068\n",
      "SEED: 2, FOLD: 3, EPOCH: 1, train_loss: 0.029818028715011234\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 1, valid_loss: 0.020244343063006036\n",
      "SEED: 2, FOLD: 3, EPOCH: 2, train_loss: 0.02200364731755611\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018885005408754714\n",
      "SEED: 2, FOLD: 3, EPOCH: 3, train_loss: 0.021264506957015476\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 3, valid_loss: 0.01943818837977373\n",
      "SEED: 2, FOLD: 3, EPOCH: 4, train_loss: 0.020555006415658706\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017854169727518007\n",
      "SEED: 2, FOLD: 3, EPOCH: 5, train_loss: 0.020169066667959496\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017373893266687028\n",
      "SEED: 2, FOLD: 3, EPOCH: 6, train_loss: 0.020017764505905075\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01716215779575018\n",
      "SEED: 2, FOLD: 3, EPOCH: 7, train_loss: 0.02002659281464042\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017178131267428398\n",
      "SEED: 2, FOLD: 3, EPOCH: 8, train_loss: 0.019938214455504675\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017102322039695885\n",
      "SEED: 2, FOLD: 3, EPOCH: 9, train_loss: 0.019891121399563713\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 9, valid_loss: 0.016895501444546077\n",
      "SEED: 2, FOLD: 3, EPOCH: 10, train_loss: 0.01989749655429576\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 10, valid_loss: 0.016890567942307547\n",
      "SEED: 2, FOLD: 3, EPOCH: 11, train_loss: 0.019820046938351682\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01684763225225302\n",
      "SEED: 2, FOLD: 3, EPOCH: 12, train_loss: 0.01973159716942826\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 12, valid_loss: 0.01686977895979698\n",
      "SEED: 2, FOLD: 3, EPOCH: 13, train_loss: 0.019630765542387962\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01656477561650368\n",
      "SEED: 2, FOLD: 3, EPOCH: 14, train_loss: 0.01943994265653797\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016705946208765872\n",
      "SEED: 2, FOLD: 3, EPOCH: 15, train_loss: 0.01934179089762069\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016725734449349917\n",
      "SEED: 2, FOLD: 3, EPOCH: 16, train_loss: 0.019165399761216062\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016584047617820594\n",
      "SEED: 2, FOLD: 3, EPOCH: 17, train_loss: 0.01883618893554887\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016364967737060327\n",
      "SEED: 2, FOLD: 3, EPOCH: 18, train_loss: 0.018607720984397707\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016370894172443792\n",
      "SEED: 2, FOLD: 3, EPOCH: 19, train_loss: 0.018231532133712963\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016343569956146754\n",
      "SEED: 2, FOLD: 3, EPOCH: 20, train_loss: 0.017897872078056272\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016305824383520164\n",
      "SEED: 2, FOLD: 3, EPOCH: 21, train_loss: 0.017442997746370936\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01606658545251076\n",
      "SEED: 2, FOLD: 3, EPOCH: 22, train_loss: 0.016999102147245728\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01606787805660413\n",
      "SEED: 2, FOLD: 3, EPOCH: 23, train_loss: 0.01659555670276687\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016086720718214147\n",
      "SEED: 2, FOLD: 3, EPOCH: 24, train_loss: 0.016321459105490026\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016078401786776688\n",
      "SEED: 2, FOLD: 4, EPOCH: 0, train_loss: 0.5866616444813239\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 0, valid_loss: 0.09673684778121802\n",
      "SEED: 2, FOLD: 4, EPOCH: 1, train_loss: 0.029534525917591276\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 1, valid_loss: 0.020189308633024875\n",
      "SEED: 2, FOLD: 4, EPOCH: 2, train_loss: 0.021806701640220912\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 2, valid_loss: 0.01884694812962642\n",
      "SEED: 2, FOLD: 4, EPOCH: 3, train_loss: 0.0220861150505575\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 3, valid_loss: 0.018448625333034076\n",
      "SEED: 2, FOLD: 4, EPOCH: 4, train_loss: 0.020592523914938037\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 4, valid_loss: 0.01761312883060712\n",
      "SEED: 2, FOLD: 4, EPOCH: 5, train_loss: 0.020225292348579782\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017377394896287184\n",
      "SEED: 2, FOLD: 4, EPOCH: 6, train_loss: 0.020137611977957392\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017452783022935573\n",
      "SEED: 2, FOLD: 4, EPOCH: 7, train_loss: 0.020024990033660386\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017282227197518714\n",
      "SEED: 2, FOLD: 4, EPOCH: 8, train_loss: 0.0198784630393257\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 8, valid_loss: 0.01724138526389232\n",
      "SEED: 2, FOLD: 4, EPOCH: 9, train_loss: 0.01991421960898348\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017022657279784862\n",
      "SEED: 2, FOLD: 4, EPOCH: 10, train_loss: 0.019806902050166518\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017106518435936708\n",
      "SEED: 2, FOLD: 4, EPOCH: 11, train_loss: 0.01976884206807291\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 11, valid_loss: 0.017305307949964818\n",
      "SEED: 2, FOLD: 4, EPOCH: 12, train_loss: 0.019675160028241778\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016982021240087655\n",
      "SEED: 2, FOLD: 4, EPOCH: 13, train_loss: 0.019571211491082166\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016927804368046615\n",
      "SEED: 2, FOLD: 4, EPOCH: 14, train_loss: 0.019503325450460653\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 14, valid_loss: 0.017053021691166438\n",
      "SEED: 2, FOLD: 4, EPOCH: 15, train_loss: 0.019339956620053667\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01672959356353833\n",
      "SEED: 2, FOLD: 4, EPOCH: 16, train_loss: 0.019091576488839614\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016610895426800616\n",
      "SEED: 2, FOLD: 4, EPOCH: 17, train_loss: 0.018864735231004858\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016449322135975726\n",
      "SEED: 2, FOLD: 4, EPOCH: 18, train_loss: 0.018659961837771778\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016282449619701274\n",
      "SEED: 2, FOLD: 4, EPOCH: 19, train_loss: 0.01830166543053614\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016362114164691705\n",
      "SEED: 2, FOLD: 4, EPOCH: 20, train_loss: 0.01787505064763733\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01623522160718074\n",
      "SEED: 2, FOLD: 4, EPOCH: 21, train_loss: 0.017462424380151\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 21, valid_loss: 0.016150641326720897\n",
      "SEED: 2, FOLD: 4, EPOCH: 22, train_loss: 0.017040592328821484\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 22, valid_loss: 0.016140032273072463\n",
      "SEED: 2, FOLD: 4, EPOCH: 23, train_loss: 0.016575373155442445\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01612590826474703\n",
      "SEED: 2, FOLD: 4, EPOCH: 24, train_loss: 0.016289947176905902\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 24, valid_loss: 0.0161081190722493\n",
      "SEED: 2, FOLD: 4, EPOCH: 25, train_loss: 0.016127243700965837\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 25, valid_loss: 0.01610254754240696\n",
      "SEED: 2, FOLD: 5, EPOCH: 0, train_loss: 0.5866002067923546\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 0, valid_loss: 0.08490043190809396\n",
      "SEED: 2, FOLD: 5, EPOCH: 1, train_loss: 0.029506757049947173\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 1, valid_loss: 0.01974823626761253\n",
      "SEED: 2, FOLD: 5, EPOCH: 2, train_loss: 0.021872728106540604\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 2, valid_loss: 0.018805915776353616\n",
      "SEED: 2, FOLD: 5, EPOCH: 3, train_loss: 0.02121777814888471\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 3, valid_loss: 0.017655386517827328\n",
      "SEED: 2, FOLD: 5, EPOCH: 4, train_loss: 0.020405347509359992\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 4, valid_loss: 0.017174153230511226\n",
      "SEED: 2, FOLD: 5, EPOCH: 5, train_loss: 0.020154588251701883\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 5, valid_loss: 0.017143120989203453\n",
      "SEED: 2, FOLD: 5, EPOCH: 6, train_loss: 0.02001069823431002\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 6, valid_loss: 0.017716483069727056\n",
      "SEED: 2, FOLD: 5, EPOCH: 7, train_loss: 0.020012231594001926\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 7, valid_loss: 0.01697335786257799\n",
      "SEED: 2, FOLD: 5, EPOCH: 8, train_loss: 0.019898128947494802\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 8, valid_loss: 0.016911023009855013\n",
      "SEED: 2, FOLD: 5, EPOCH: 9, train_loss: 0.019942039523173024\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 9, valid_loss: 0.016930728720930908\n",
      "SEED: 2, FOLD: 5, EPOCH: 10, train_loss: 0.019835333314699097\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 10, valid_loss: 0.01688762653905612\n",
      "SEED: 2, FOLD: 5, EPOCH: 11, train_loss: 0.019837340012796828\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 11, valid_loss: 0.01708430338364381\n",
      "SEED: 2, FOLD: 5, EPOCH: 12, train_loss: 0.019699398377859913\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 12, valid_loss: 0.016651330085901115\n",
      "SEED: 2, FOLD: 5, EPOCH: 13, train_loss: 0.01959725733645059\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 13, valid_loss: 0.01677416594555745\n",
      "SEED: 2, FOLD: 5, EPOCH: 14, train_loss: 0.019505708553903812\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 14, valid_loss: 0.01655682405600181\n",
      "SEED: 2, FOLD: 5, EPOCH: 15, train_loss: 0.01932744203588447\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 15, valid_loss: 0.016512382990465715\n",
      "SEED: 2, FOLD: 5, EPOCH: 16, train_loss: 0.0191060022979572\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 16, valid_loss: 0.016514578834176064\n",
      "SEED: 2, FOLD: 5, EPOCH: 17, train_loss: 0.018910489347134088\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 17, valid_loss: 0.016535453068522308\n",
      "SEED: 2, FOLD: 5, EPOCH: 18, train_loss: 0.01862455650257903\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 18, valid_loss: 0.01629067291147434\n",
      "SEED: 2, FOLD: 5, EPOCH: 19, train_loss: 0.01823488318336171\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 19, valid_loss: 0.01614736206829548\n",
      "SEED: 2, FOLD: 5, EPOCH: 20, train_loss: 0.01785644216815362\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 20, valid_loss: 0.016141900291236546\n",
      "SEED: 2, FOLD: 5, EPOCH: 21, train_loss: 0.01746349426842219\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 21, valid_loss: 0.016180420724245217\n",
      "SEED: 2, FOLD: 5, EPOCH: 22, train_loss: 0.01703622635151889\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 22, valid_loss: 0.015994957433297083\n",
      "SEED: 2, FOLD: 5, EPOCH: 23, train_loss: 0.016640155815292854\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 23, valid_loss: 0.01598969345482496\n",
      "SEED: 2, FOLD: 5, EPOCH: 24, train_loss: 0.01633683028253349\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 24, valid_loss: 0.01600653276993678\n",
      "SEED: 2, FOLD: 5, EPOCH: 25, train_loss: 0.016185673998316396\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 25, valid_loss: 0.01599379091595228\n",
      "SEED: 2, FOLD: 6, EPOCH: 0, train_loss: 0.5868785912926132\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 0, valid_loss: 0.08447704120324208\n",
      "SEED: 2, FOLD: 6, EPOCH: 1, train_loss: 0.029673879437551304\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 1, valid_loss: 0.019798308754196532\n",
      "SEED: 2, FOLD: 6, EPOCH: 2, train_loss: 0.021840406204196246\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 2, valid_loss: 0.0199609542122254\n",
      "SEED: 2, FOLD: 6, EPOCH: 3, train_loss: 0.020900250211156702\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 3, valid_loss: 0.01750711466257389\n",
      "SEED: 2, FOLD: 6, EPOCH: 4, train_loss: 0.020313295611255878\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 4, valid_loss: 0.017791790028031055\n",
      "SEED: 2, FOLD: 6, EPOCH: 5, train_loss: 0.020107295892729953\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 5, valid_loss: 0.017116927470152195\n",
      "SEED: 2, FOLD: 6, EPOCH: 6, train_loss: 0.020162177624533307\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 6, valid_loss: 0.017441944004251406\n",
      "SEED: 2, FOLD: 6, EPOCH: 7, train_loss: 0.020007896463613253\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 7, valid_loss: 0.01706575473340658\n",
      "SEED: 2, FOLD: 6, EPOCH: 8, train_loss: 0.01989076178319551\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 8, valid_loss: 0.01696561176616412\n",
      "SEED: 2, FOLD: 6, EPOCH: 9, train_loss: 0.01988114252988551\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 9, valid_loss: 0.016849631873460915\n",
      "SEED: 2, FOLD: 6, EPOCH: 10, train_loss: 0.019933965409526955\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 10, valid_loss: 0.016825789872270364\n",
      "SEED: 2, FOLD: 6, EPOCH: 11, train_loss: 0.019835032396823972\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 11, valid_loss: 0.017026536739789523\n",
      "SEED: 2, FOLD: 6, EPOCH: 12, train_loss: 0.019778535776847118\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 12, valid_loss: 0.016843904382907428\n",
      "SEED: 2, FOLD: 6, EPOCH: 13, train_loss: 0.019624758486610813\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 13, valid_loss: 0.016491657266250022\n",
      "SEED: 2, FOLD: 6, EPOCH: 14, train_loss: 0.019509469083434827\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 14, valid_loss: 0.01663362356619193\n",
      "SEED: 2, FOLD: 6, EPOCH: 15, train_loss: 0.019327103890277243\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 15, valid_loss: 0.01665037490714055\n",
      "SEED: 2, FOLD: 6, EPOCH: 16, train_loss: 0.01916628363668113\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 16, valid_loss: 0.016401992537654363\n",
      "SEED: 2, FOLD: 6, EPOCH: 17, train_loss: 0.018935413854951795\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 17, valid_loss: 0.01620120075173103\n",
      "SEED: 2, FOLD: 6, EPOCH: 18, train_loss: 0.01868021533497282\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 18, valid_loss: 0.016393338401730243\n",
      "SEED: 2, FOLD: 6, EPOCH: 19, train_loss: 0.018319171576483828\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 19, valid_loss: 0.01603683714683239\n",
      "SEED: 2, FOLD: 6, EPOCH: 20, train_loss: 0.01793536465816401\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 20, valid_loss: 0.01605442066032153\n",
      "SEED: 2, FOLD: 6, EPOCH: 21, train_loss: 0.017555439618189592\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 21, valid_loss: 0.015955231439035673\n",
      "SEED: 2, FOLD: 6, EPOCH: 22, train_loss: 0.01713946179763691\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 22, valid_loss: 0.015921578026161745\n",
      "SEED: 2, FOLD: 6, EPOCH: 23, train_loss: 0.01676052144250354\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 23, valid_loss: 0.015902588717066325\n",
      "SEED: 2, FOLD: 6, EPOCH: 24, train_loss: 0.016494982485734933\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 24, valid_loss: 0.01586271571711852\n",
      "SEED: 2, FOLD: 6, EPOCH: 25, train_loss: 0.016380332271895698\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 25, valid_loss: 0.015872639317352038\n",
      "SEED: 3, FOLD: 0, EPOCH: 0, train_loss: 0.5874854833693117\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08967137852540383\n",
      "SEED: 3, FOLD: 0, EPOCH: 1, train_loss: 0.030193020363111753\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 1, valid_loss: 0.02060349127994134\n",
      "SEED: 3, FOLD: 0, EPOCH: 2, train_loss: 0.021864686186450558\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 2, valid_loss: 0.01861854871878257\n",
      "SEED: 3, FOLD: 0, EPOCH: 3, train_loss: 0.020936807340665442\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 3, valid_loss: 0.0178099162876606\n",
      "SEED: 3, FOLD: 0, EPOCH: 4, train_loss: 0.020421211658095993\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017567790041749295\n",
      "SEED: 3, FOLD: 0, EPOCH: 5, train_loss: 0.020136515685432666\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 5, valid_loss: 0.01738749988950216\n",
      "SEED: 3, FOLD: 0, EPOCH: 6, train_loss: 0.02006302439179775\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017269836738705635\n",
      "SEED: 3, FOLD: 0, EPOCH: 7, train_loss: 0.01994315570069326\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01743807099186457\n",
      "SEED: 3, FOLD: 0, EPOCH: 8, train_loss: 0.019951160770614405\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017257007125478525\n",
      "SEED: 3, FOLD: 0, EPOCH: 9, train_loss: 0.019893884633642597\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017199669319849748\n",
      "SEED: 3, FOLD: 0, EPOCH: 10, train_loss: 0.019813287298421602\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017092090386610765\n",
      "SEED: 3, FOLD: 0, EPOCH: 11, train_loss: 0.019713488482945674\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 11, valid_loss: 0.017040868791250083\n",
      "SEED: 3, FOLD: 0, EPOCH: 12, train_loss: 0.01966501117960827\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016988740660823308\n",
      "SEED: 3, FOLD: 0, EPOCH: 13, train_loss: 0.019596424029284232\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01686761141396486\n",
      "SEED: 3, FOLD: 0, EPOCH: 14, train_loss: 0.019453745536707544\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016781199651841935\n",
      "SEED: 3, FOLD: 0, EPOCH: 15, train_loss: 0.01927200928833839\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016801737965299532\n",
      "SEED: 3, FOLD: 0, EPOCH: 16, train_loss: 0.019093936384731048\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016714525480683032\n",
      "SEED: 3, FOLD: 0, EPOCH: 17, train_loss: 0.018886674447236834\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016507238794404726\n",
      "SEED: 3, FOLD: 0, EPOCH: 18, train_loss: 0.01855388923069915\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016392163287561674\n",
      "SEED: 3, FOLD: 0, EPOCH: 19, train_loss: 0.018259713124181773\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016413485201505516\n",
      "SEED: 3, FOLD: 0, EPOCH: 20, train_loss: 0.017869733399837405\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016333829181698654\n",
      "SEED: 3, FOLD: 0, EPOCH: 21, train_loss: 0.017458174730072152\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016238130772343047\n",
      "SEED: 3, FOLD: 0, EPOCH: 22, train_loss: 0.017036759709889018\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 22, valid_loss: 0.016227716150192115\n",
      "SEED: 3, FOLD: 0, EPOCH: 23, train_loss: 0.016634905408765818\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 23, valid_loss: 0.016165201982053425\n",
      "SEED: 3, FOLD: 0, EPOCH: 24, train_loss: 0.016391323552139708\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01619705643791419\n",
      "SEED: 3, FOLD: 0, EPOCH: 25, train_loss: 0.016235634130803315\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 25, valid_loss: 0.016184866714936037\n",
      "SEED: 3, FOLD: 1, EPOCH: 0, train_loss: 0.5877752535649248\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 0, valid_loss: 0.08419532787341338\n",
      "SEED: 3, FOLD: 1, EPOCH: 1, train_loss: 0.02946568330800211\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 1, valid_loss: 0.01954480418219016\n",
      "SEED: 3, FOLD: 1, EPOCH: 2, train_loss: 0.02198909467237221\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 2, valid_loss: 0.017975724015671473\n",
      "SEED: 3, FOLD: 1, EPOCH: 3, train_loss: 0.021121344227041747\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 3, valid_loss: 0.017333914812367696\n",
      "SEED: 3, FOLD: 1, EPOCH: 4, train_loss: 0.02037387024107817\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017114975919517186\n",
      "SEED: 3, FOLD: 1, EPOCH: 5, train_loss: 0.02007107955177088\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 5, valid_loss: 0.01694586844398425\n",
      "SEED: 3, FOLD: 1, EPOCH: 6, train_loss: 0.020034872649891955\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 6, valid_loss: 0.016796498631055538\n",
      "SEED: 3, FOLD: 1, EPOCH: 7, train_loss: 0.019922469591570867\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01687376029216326\n",
      "SEED: 3, FOLD: 1, EPOCH: 8, train_loss: 0.01995926919217045\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 8, valid_loss: 0.01680323066046605\n",
      "SEED: 3, FOLD: 1, EPOCH: 9, train_loss: 0.019939136540366185\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01676187585466183\n",
      "SEED: 3, FOLD: 1, EPOCH: 10, train_loss: 0.01985164188049935\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 10, valid_loss: 0.016646147060852785\n",
      "SEED: 3, FOLD: 1, EPOCH: 11, train_loss: 0.019797425389893958\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 11, valid_loss: 0.016671896983797733\n",
      "SEED: 3, FOLD: 1, EPOCH: 12, train_loss: 0.019748191248524834\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 12, valid_loss: 0.0165996363099951\n",
      "SEED: 3, FOLD: 1, EPOCH: 13, train_loss: 0.0195355615956155\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01651382868966231\n",
      "SEED: 3, FOLD: 1, EPOCH: 14, train_loss: 0.0194913320797118\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 14, valid_loss: 0.01630885196992984\n",
      "SEED: 3, FOLD: 1, EPOCH: 15, train_loss: 0.019320400456923084\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01631938049999567\n",
      "SEED: 3, FOLD: 1, EPOCH: 16, train_loss: 0.01909742836613913\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 16, valid_loss: 0.01622418908832165\n",
      "SEED: 3, FOLD: 1, EPOCH: 17, train_loss: 0.01882252371492418\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016112997841376524\n",
      "SEED: 3, FOLD: 1, EPOCH: 18, train_loss: 0.018590062076376902\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016065358327558406\n",
      "SEED: 3, FOLD: 1, EPOCH: 19, train_loss: 0.018263876110919425\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 19, valid_loss: 0.015984552912414074\n",
      "SEED: 3, FOLD: 1, EPOCH: 20, train_loss: 0.017897459325959552\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 20, valid_loss: 0.015832925931765482\n",
      "SEED: 3, FOLD: 1, EPOCH: 21, train_loss: 0.017457420409128472\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01578646762153277\n",
      "SEED: 3, FOLD: 1, EPOCH: 22, train_loss: 0.01697523068838023\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015733821604114313\n",
      "SEED: 3, FOLD: 1, EPOCH: 23, train_loss: 0.016582654159818147\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01572034665598319\n",
      "SEED: 3, FOLD: 1, EPOCH: 24, train_loss: 0.016347097874795262\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015730781480669975\n",
      "SEED: 3, FOLD: 1, EPOCH: 25, train_loss: 0.016180002231251548\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 25, valid_loss: 0.015740519031309165\n",
      "SEED: 3, FOLD: 2, EPOCH: 0, train_loss: 0.5882720783151485\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 0, valid_loss: 0.09219885674806741\n",
      "SEED: 3, FOLD: 2, EPOCH: 1, train_loss: 0.029635731080496632\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 1, valid_loss: 0.020187863506949864\n",
      "SEED: 3, FOLD: 2, EPOCH: 2, train_loss: 0.02194620349217911\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 2, valid_loss: 0.01932944830220479\n",
      "SEED: 3, FOLD: 2, EPOCH: 3, train_loss: 0.021150186959956144\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 3, valid_loss: 0.01754460111260414\n",
      "SEED: 3, FOLD: 2, EPOCH: 4, train_loss: 0.020453508716781397\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017213048270115487\n",
      "SEED: 3, FOLD: 2, EPOCH: 5, train_loss: 0.0201631980771954\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017119868013721246\n",
      "SEED: 3, FOLD: 2, EPOCH: 6, train_loss: 0.020048506935504643\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017395393636364203\n",
      "SEED: 3, FOLD: 2, EPOCH: 7, train_loss: 0.020068340355882775\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01701051426621584\n",
      "SEED: 3, FOLD: 2, EPOCH: 8, train_loss: 0.01991957745741348\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 8, valid_loss: 0.016970047870507605\n",
      "SEED: 3, FOLD: 2, EPOCH: 9, train_loss: 0.019865994920601714\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01708763364989024\n",
      "SEED: 3, FOLD: 2, EPOCH: 10, train_loss: 0.019921573029982077\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 10, valid_loss: 0.01703531925494854\n",
      "SEED: 3, FOLD: 2, EPOCH: 11, train_loss: 0.019786024415815198\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016878744873863\n",
      "SEED: 3, FOLD: 2, EPOCH: 12, train_loss: 0.019737939073427302\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016708754719449923\n",
      "SEED: 3, FOLD: 2, EPOCH: 13, train_loss: 0.019676485400948976\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 13, valid_loss: 0.01685504070841349\n",
      "SEED: 3, FOLD: 2, EPOCH: 14, train_loss: 0.019504979756232853\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016627344159552686\n",
      "SEED: 3, FOLD: 2, EPOCH: 15, train_loss: 0.01929385698324925\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016482553874643948\n",
      "SEED: 3, FOLD: 2, EPOCH: 16, train_loss: 0.019144983056026535\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01651467984685531\n",
      "SEED: 3, FOLD: 2, EPOCH: 17, train_loss: 0.018874074533783102\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016285086767031595\n",
      "SEED: 3, FOLD: 2, EPOCH: 18, train_loss: 0.018617572338395828\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016217892344754476\n",
      "SEED: 3, FOLD: 2, EPOCH: 19, train_loss: 0.01829245193181811\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016172506774847325\n",
      "SEED: 3, FOLD: 2, EPOCH: 20, train_loss: 0.017870977546113567\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 20, valid_loss: 0.015949050824229535\n",
      "SEED: 3, FOLD: 2, EPOCH: 21, train_loss: 0.017452694274283743\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01592149556829379\n",
      "SEED: 3, FOLD: 2, EPOCH: 22, train_loss: 0.017025391017464368\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01587048373543299\n",
      "SEED: 3, FOLD: 2, EPOCH: 23, train_loss: 0.016670123560706507\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015869977812354382\n",
      "SEED: 3, FOLD: 2, EPOCH: 24, train_loss: 0.016360081291782694\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 24, valid_loss: 0.015854222126878224\n",
      "SEED: 3, FOLD: 2, EPOCH: 25, train_loss: 0.016220307783097833\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 25, valid_loss: 0.01585326143182241\n",
      "SEED: 3, FOLD: 3, EPOCH: 0, train_loss: 0.5863260271380076\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08590473120029156\n",
      "SEED: 3, FOLD: 3, EPOCH: 1, train_loss: 0.029494476353598607\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 1, valid_loss: 0.019876238245230455\n",
      "SEED: 3, FOLD: 3, EPOCH: 2, train_loss: 0.021846883477190056\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018214865516011532\n",
      "SEED: 3, FOLD: 3, EPOCH: 3, train_loss: 0.021288877629951852\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 3, valid_loss: 0.01852851790877489\n",
      "SEED: 3, FOLD: 3, EPOCH: 4, train_loss: 0.02042053164159124\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 4, valid_loss: 0.01745317618434246\n",
      "SEED: 3, FOLD: 3, EPOCH: 5, train_loss: 0.02010318113339914\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017396515092024438\n",
      "SEED: 3, FOLD: 3, EPOCH: 6, train_loss: 0.019999326483623403\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017137806289471112\n",
      "SEED: 3, FOLD: 3, EPOCH: 7, train_loss: 0.019948854463527333\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01702898074514591\n",
      "SEED: 3, FOLD: 3, EPOCH: 8, train_loss: 0.01991439502484895\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 8, valid_loss: 0.0169149161531375\n",
      "SEED: 3, FOLD: 3, EPOCH: 9, train_loss: 0.019894655617709096\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 9, valid_loss: 0.016891987707752448\n",
      "SEED: 3, FOLD: 3, EPOCH: 10, train_loss: 0.019888581582219213\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 10, valid_loss: 0.016991239972412586\n",
      "SEED: 3, FOLD: 3, EPOCH: 11, train_loss: 0.019820734480949672\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 11, valid_loss: 0.016781399886195477\n",
      "SEED: 3, FOLD: 3, EPOCH: 12, train_loss: 0.019709764400849473\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 12, valid_loss: 0.01683259690896823\n",
      "SEED: 3, FOLD: 3, EPOCH: 13, train_loss: 0.019551430098913813\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01678704499052121\n",
      "SEED: 3, FOLD: 3, EPOCH: 14, train_loss: 0.01945149296945011\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01667265694301862\n",
      "SEED: 3, FOLD: 3, EPOCH: 15, train_loss: 0.019294726184091053\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01659449003636837\n",
      "SEED: 3, FOLD: 3, EPOCH: 16, train_loss: 0.019099286153308442\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016369804596671693\n",
      "SEED: 3, FOLD: 3, EPOCH: 17, train_loss: 0.01888260220152301\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016304626702689208\n",
      "SEED: 3, FOLD: 3, EPOCH: 18, train_loss: 0.01861795428133494\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016237495180505972\n",
      "SEED: 3, FOLD: 3, EPOCH: 19, train_loss: 0.018176440401254473\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016173358003680523\n",
      "SEED: 3, FOLD: 3, EPOCH: 20, train_loss: 0.017831153236329556\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016088942925517376\n",
      "SEED: 3, FOLD: 3, EPOCH: 21, train_loss: 0.017426520497915713\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016091983908644088\n",
      "SEED: 3, FOLD: 3, EPOCH: 22, train_loss: 0.016993855503765313\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 22, valid_loss: 0.015968831685873177\n",
      "SEED: 3, FOLD: 3, EPOCH: 23, train_loss: 0.01663715815221941\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 23, valid_loss: 0.015946675808383867\n",
      "SEED: 3, FOLD: 3, EPOCH: 24, train_loss: 0.016262682255458186\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 24, valid_loss: 0.015976694842370655\n",
      "SEED: 3, FOLD: 3, EPOCH: 25, train_loss: 0.016185293553044666\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 25, valid_loss: 0.015974782407283783\n",
      "SEED: 3, FOLD: 4, EPOCH: 0, train_loss: 0.5883887930697685\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08669628489475983\n",
      "SEED: 3, FOLD: 4, EPOCH: 1, train_loss: 0.02945546737897235\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 1, valid_loss: 0.01981903283068767\n",
      "SEED: 3, FOLD: 4, EPOCH: 2, train_loss: 0.021653885273514566\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 2, valid_loss: 0.01837927346619276\n",
      "SEED: 3, FOLD: 4, EPOCH: 3, train_loss: 0.02088604517583106\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 3, valid_loss: 0.018744164504683934\n",
      "SEED: 3, FOLD: 4, EPOCH: 4, train_loss: 0.020430312567466014\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 4, valid_loss: 0.01749756488089378\n",
      "SEED: 3, FOLD: 4, EPOCH: 5, train_loss: 0.020200983973572385\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017195127331293546\n",
      "SEED: 3, FOLD: 4, EPOCH: 6, train_loss: 0.02000213588109693\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017173465341329575\n",
      "SEED: 3, FOLD: 4, EPOCH: 7, train_loss: 0.01992336315782489\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017289772199896667\n",
      "SEED: 3, FOLD: 4, EPOCH: 8, train_loss: 0.01989746977247902\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017482683062553406\n",
      "SEED: 3, FOLD: 4, EPOCH: 9, train_loss: 0.019908658455352526\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017237271827000838\n",
      "SEED: 3, FOLD: 4, EPOCH: 10, train_loss: 0.01985136097347414\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01718452415214135\n",
      "SEED: 3, FOLD: 4, EPOCH: 11, train_loss: 0.019788487562658014\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 11, valid_loss: 0.017112321721819732\n",
      "SEED: 3, FOLD: 4, EPOCH: 12, train_loss: 0.019640197977423668\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016947758885530326\n",
      "SEED: 3, FOLD: 4, EPOCH: 13, train_loss: 0.01960690873297485\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016941993998793457\n",
      "SEED: 3, FOLD: 4, EPOCH: 14, train_loss: 0.01947945638282879\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016692609884417973\n",
      "SEED: 3, FOLD: 4, EPOCH: 15, train_loss: 0.019348420076877683\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01678358749128305\n",
      "SEED: 3, FOLD: 4, EPOCH: 16, train_loss: 0.019131637253874057\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01669221672301109\n",
      "SEED: 3, FOLD: 4, EPOCH: 17, train_loss: 0.018828913066032772\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016646725197251026\n",
      "SEED: 3, FOLD: 4, EPOCH: 18, train_loss: 0.018553919939173234\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016441542010467786\n",
      "SEED: 3, FOLD: 4, EPOCH: 19, train_loss: 0.018183892592787743\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016361065280552093\n",
      "SEED: 3, FOLD: 4, EPOCH: 20, train_loss: 0.017815496671844174\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01633631244588357\n",
      "SEED: 3, FOLD: 4, EPOCH: 21, train_loss: 0.01741047282829075\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01618734231361976\n",
      "SEED: 3, FOLD: 4, EPOCH: 22, train_loss: 0.016980811689250374\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 22, valid_loss: 0.016217064542266037\n",
      "SEED: 3, FOLD: 4, EPOCH: 23, train_loss: 0.016587565036339534\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 23, valid_loss: 0.016188460832031872\n",
      "SEED: 3, FOLD: 4, EPOCH: 24, train_loss: 0.016274059707349218\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 24, valid_loss: 0.016177002197274797\n",
      "SEED: 3, FOLD: 4, EPOCH: 25, train_loss: 0.016171810481495952\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 25, valid_loss: 0.01618775503280071\n",
      "SEED: 3, FOLD: 5, EPOCH: 0, train_loss: 0.5876712363112617\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 0, valid_loss: 0.09039690632086533\n",
      "SEED: 3, FOLD: 5, EPOCH: 1, train_loss: 0.02957816900232354\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 1, valid_loss: 0.01980428684216279\n",
      "SEED: 3, FOLD: 5, EPOCH: 2, train_loss: 0.021921003916980448\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 2, valid_loss: 0.018817557881657895\n",
      "SEED: 3, FOLD: 5, EPOCH: 3, train_loss: 0.020987659340371955\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 3, valid_loss: 0.017834698853011314\n",
      "SEED: 3, FOLD: 5, EPOCH: 4, train_loss: 0.020389193064860395\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 4, valid_loss: 0.017206306425997846\n",
      "SEED: 3, FOLD: 5, EPOCH: 5, train_loss: 0.0200729363069341\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 5, valid_loss: 0.017089881504384372\n",
      "SEED: 3, FOLD: 5, EPOCH: 6, train_loss: 0.019999193027615547\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 6, valid_loss: 0.01722832418118532\n",
      "SEED: 3, FOLD: 5, EPOCH: 7, train_loss: 0.019934381232471078\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 7, valid_loss: 0.016991246706591204\n",
      "SEED: 3, FOLD: 5, EPOCH: 8, train_loss: 0.019909215889669752\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 8, valid_loss: 0.016733552472522624\n",
      "SEED: 3, FOLD: 5, EPOCH: 9, train_loss: 0.019882736324861244\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 9, valid_loss: 0.016985510404293355\n",
      "SEED: 3, FOLD: 5, EPOCH: 10, train_loss: 0.019796742050832993\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 10, valid_loss: 0.01697508954944519\n",
      "SEED: 3, FOLD: 5, EPOCH: 11, train_loss: 0.019819373743155518\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 11, valid_loss: 0.016976695149563827\n",
      "SEED: 3, FOLD: 5, EPOCH: 12, train_loss: 0.019711558228811703\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 12, valid_loss: 0.016856997560423154\n",
      "SEED: 3, FOLD: 5, EPOCH: 13, train_loss: 0.0195572419545135\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 13, valid_loss: 0.016652347663274177\n",
      "SEED: 3, FOLD: 5, EPOCH: 14, train_loss: 0.01947056152228568\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 14, valid_loss: 0.016626848552662592\n",
      "SEED: 3, FOLD: 5, EPOCH: 15, train_loss: 0.01925287672595398\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 15, valid_loss: 0.01653787551017908\n",
      "SEED: 3, FOLD: 5, EPOCH: 16, train_loss: 0.019124736959064328\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 16, valid_loss: 0.016377012316997234\n",
      "SEED: 3, FOLD: 5, EPOCH: 17, train_loss: 0.01885985625857437\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 17, valid_loss: 0.016401858570484016\n",
      "SEED: 3, FOLD: 5, EPOCH: 18, train_loss: 0.018579175192359333\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 18, valid_loss: 0.016236907229400598\n",
      "SEED: 3, FOLD: 5, EPOCH: 19, train_loss: 0.018225408234709018\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 19, valid_loss: 0.016176961434002105\n",
      "SEED: 3, FOLD: 5, EPOCH: 20, train_loss: 0.01784873054035612\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 20, valid_loss: 0.016174052841961384\n",
      "SEED: 3, FOLD: 5, EPOCH: 21, train_loss: 0.01743507176335599\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 21, valid_loss: 0.01600261039745349\n",
      "SEED: 3, FOLD: 5, EPOCH: 22, train_loss: 0.01696554333525332\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 22, valid_loss: 0.01594370582069342\n",
      "SEED: 3, FOLD: 5, EPOCH: 23, train_loss: 0.016597403830068337\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 23, valid_loss: 0.015955170329946738\n",
      "SEED: 3, FOLD: 5, EPOCH: 24, train_loss: 0.016337191232958355\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 24, valid_loss: 0.01592136360704899\n",
      "SEED: 3, FOLD: 5, EPOCH: 25, train_loss: 0.01619599713012576\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 25, valid_loss: 0.01593476326133196\n",
      "SEED: 3, FOLD: 6, EPOCH: 0, train_loss: 0.5867284405473117\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 0, valid_loss: 0.08394995331764221\n",
      "SEED: 3, FOLD: 6, EPOCH: 1, train_loss: 0.029659013616273534\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 1, valid_loss: 0.01987281470344617\n",
      "SEED: 3, FOLD: 6, EPOCH: 2, train_loss: 0.022658167331403977\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 2, valid_loss: 0.018535947283873193\n",
      "SEED: 3, FOLD: 6, EPOCH: 3, train_loss: 0.02100373260878228\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 3, valid_loss: 0.018338364620621387\n",
      "SEED: 3, FOLD: 6, EPOCH: 4, train_loss: 0.02042080255577693\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 4, valid_loss: 0.017347345128655434\n",
      "SEED: 3, FOLD: 6, EPOCH: 5, train_loss: 0.020084441161236248\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 5, valid_loss: 0.017285410601359148\n",
      "SEED: 3, FOLD: 6, EPOCH: 6, train_loss: 0.020145182447457635\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 6, valid_loss: 0.017283510846587326\n",
      "SEED: 3, FOLD: 6, EPOCH: 7, train_loss: 0.019970783737261553\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 7, valid_loss: 0.01720772239451225\n",
      "SEED: 3, FOLD: 6, EPOCH: 8, train_loss: 0.019939262747160486\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 8, valid_loss: 0.016922427484622367\n",
      "SEED: 3, FOLD: 6, EPOCH: 9, train_loss: 0.01987830866631624\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 9, valid_loss: 0.017264056807527177\n",
      "SEED: 3, FOLD: 6, EPOCH: 10, train_loss: 0.019874604771266114\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 10, valid_loss: 0.01716620073868678\n",
      "SEED: 3, FOLD: 6, EPOCH: 11, train_loss: 0.01981073260508679\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 11, valid_loss: 0.01701899918799217\n",
      "SEED: 3, FOLD: 6, EPOCH: 12, train_loss: 0.019663605864184933\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 12, valid_loss: 0.016874865986979924\n",
      "SEED: 3, FOLD: 6, EPOCH: 13, train_loss: 0.019560930822548027\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 13, valid_loss: 0.01690023736311839\n",
      "SEED: 3, FOLD: 6, EPOCH: 14, train_loss: 0.019450427184032427\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 14, valid_loss: 0.016733901861768503\n",
      "SEED: 3, FOLD: 6, EPOCH: 15, train_loss: 0.01933171849295094\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 15, valid_loss: 0.01666193061436598\n",
      "SEED: 3, FOLD: 6, EPOCH: 16, train_loss: 0.019131984309972944\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 16, valid_loss: 0.01654775204280248\n",
      "SEED: 3, FOLD: 6, EPOCH: 17, train_loss: 0.01886552740895265\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 17, valid_loss: 0.0165794686629222\n",
      "SEED: 3, FOLD: 6, EPOCH: 18, train_loss: 0.018593642055182845\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 18, valid_loss: 0.01644055065340721\n",
      "SEED: 3, FOLD: 6, EPOCH: 19, train_loss: 0.018321209385789728\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 19, valid_loss: 0.01624575608338301\n",
      "SEED: 3, FOLD: 6, EPOCH: 20, train_loss: 0.01786838809179293\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 20, valid_loss: 0.01618757263685648\n",
      "SEED: 3, FOLD: 6, EPOCH: 21, train_loss: 0.017476169342124783\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 21, valid_loss: 0.01612228613633376\n",
      "SEED: 3, FOLD: 6, EPOCH: 22, train_loss: 0.017055191653403075\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 22, valid_loss: 0.016058058191377383\n",
      "SEED: 3, FOLD: 6, EPOCH: 23, train_loss: 0.016647904897360382\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 23, valid_loss: 0.016051588221811332\n",
      "SEED: 3, FOLD: 6, EPOCH: 24, train_loss: 0.01644619065966155\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 24, valid_loss: 0.016022207931830332\n",
      "SEED: 3, FOLD: 6, EPOCH: 25, train_loss: 0.01629729149863124\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 25, valid_loss: 0.016066629726153154\n",
      "SEED: 4, FOLD: 0, EPOCH: 0, train_loss: 0.5872861948367711\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08430757144322762\n",
      "SEED: 4, FOLD: 0, EPOCH: 1, train_loss: 0.029305776757364337\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 1, valid_loss: 0.020014389203144953\n",
      "SEED: 4, FOLD: 0, EPOCH: 2, train_loss: 0.02173196617513895\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 2, valid_loss: 0.01852608214204128\n",
      "SEED: 4, FOLD: 0, EPOCH: 3, train_loss: 0.021669762133545167\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 3, valid_loss: 0.01767161015707713\n",
      "SEED: 4, FOLD: 0, EPOCH: 4, train_loss: 0.020419182331376785\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017380981491162226\n",
      "SEED: 4, FOLD: 0, EPOCH: 5, train_loss: 0.02008885973309343\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017581209253806334\n",
      "SEED: 4, FOLD: 0, EPOCH: 6, train_loss: 0.020023556098946044\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017099441673893195\n",
      "SEED: 4, FOLD: 0, EPOCH: 7, train_loss: 0.019944507452483114\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01720634002525073\n",
      "SEED: 4, FOLD: 0, EPOCH: 8, train_loss: 0.019874530819219513\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017146734664073356\n",
      "SEED: 4, FOLD: 0, EPOCH: 9, train_loss: 0.0198597250053206\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01706663003334632\n",
      "SEED: 4, FOLD: 0, EPOCH: 10, train_loss: 0.019773836247622967\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017343661676232632\n",
      "SEED: 4, FOLD: 0, EPOCH: 11, train_loss: 0.019729990411449124\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 11, valid_loss: 0.017110737327199716\n",
      "SEED: 4, FOLD: 0, EPOCH: 12, train_loss: 0.01971228206781922\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016957402372589477\n",
      "SEED: 4, FOLD: 0, EPOCH: 13, train_loss: 0.019564236665295588\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016866551282314155\n",
      "SEED: 4, FOLD: 0, EPOCH: 14, train_loss: 0.019387841702917137\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016908038407564163\n",
      "SEED: 4, FOLD: 0, EPOCH: 15, train_loss: 0.019279396010411752\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01662439272667353\n",
      "SEED: 4, FOLD: 0, EPOCH: 16, train_loss: 0.019094781270502386\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01659691011389861\n",
      "SEED: 4, FOLD: 0, EPOCH: 17, train_loss: 0.01880581727301752\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016519498868057363\n",
      "SEED: 4, FOLD: 0, EPOCH: 18, train_loss: 0.018589294414866616\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016411542104413875\n",
      "SEED: 4, FOLD: 0, EPOCH: 19, train_loss: 0.0182321742932136\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016386434722405214\n",
      "SEED: 4, FOLD: 0, EPOCH: 20, train_loss: 0.01777468714863062\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01626948009316738\n",
      "SEED: 4, FOLD: 0, EPOCH: 21, train_loss: 0.017389315960777772\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 21, valid_loss: 0.01625771834873236\n",
      "SEED: 4, FOLD: 0, EPOCH: 22, train_loss: 0.016895662565287704\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 22, valid_loss: 0.016218039207160473\n",
      "SEED: 4, FOLD: 0, EPOCH: 23, train_loss: 0.016512180439423065\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01616846304386854\n",
      "SEED: 4, FOLD: 0, EPOCH: 24, train_loss: 0.016216647848990316\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 24, valid_loss: 0.016171470212821778\n",
      "SEED: 4, FOLD: 0, EPOCH: 25, train_loss: 0.016068987925914494\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 25, valid_loss: 0.016172938478680756\n",
      "SEED: 4, FOLD: 1, EPOCH: 0, train_loss: 0.5881866197529677\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 0, valid_loss: 0.07833043371255581\n",
      "SEED: 4, FOLD: 1, EPOCH: 1, train_loss: 0.029419098452136323\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 1, valid_loss: 0.0196053132128257\n",
      "SEED: 4, FOLD: 1, EPOCH: 2, train_loss: 0.021890838731180976\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 2, valid_loss: 0.018337220526658572\n",
      "SEED: 4, FOLD: 1, EPOCH: 3, train_loss: 0.021160042895054496\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 3, valid_loss: 0.017701054851596173\n",
      "SEED: 4, FOLD: 1, EPOCH: 4, train_loss: 0.02046318123167431\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017145751975476742\n",
      "SEED: 4, FOLD: 1, EPOCH: 5, train_loss: 0.020243888494332094\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 5, valid_loss: 0.01748145665400303\n",
      "SEED: 4, FOLD: 1, EPOCH: 6, train_loss: 0.02007314716339917\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017006061827907197\n",
      "SEED: 4, FOLD: 1, EPOCH: 7, train_loss: 0.020015931335856784\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01714822191458482\n",
      "SEED: 4, FOLD: 1, EPOCH: 8, train_loss: 0.01993975352898643\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017012199888435695\n",
      "SEED: 4, FOLD: 1, EPOCH: 9, train_loss: 0.019899882854440727\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 9, valid_loss: 0.017195615630883437\n",
      "SEED: 4, FOLD: 1, EPOCH: 10, train_loss: 0.019849326360870053\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 10, valid_loss: 0.016921769039562114\n",
      "SEED: 4, FOLD: 1, EPOCH: 11, train_loss: 0.019748043042381067\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 11, valid_loss: 0.016846363575985797\n",
      "SEED: 4, FOLD: 1, EPOCH: 12, train_loss: 0.019693499707893747\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016856939531862736\n",
      "SEED: 4, FOLD: 1, EPOCH: 13, train_loss: 0.019524722611783323\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016749628962805636\n",
      "SEED: 4, FOLD: 1, EPOCH: 14, train_loss: 0.019470912781921593\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016683784528420523\n",
      "SEED: 4, FOLD: 1, EPOCH: 15, train_loss: 0.019276641032381636\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01663127154684984\n",
      "SEED: 4, FOLD: 1, EPOCH: 16, train_loss: 0.019097901402494392\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016431244734961253\n",
      "SEED: 4, FOLD: 1, EPOCH: 17, train_loss: 0.018860987739989888\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016291119946310155\n",
      "SEED: 4, FOLD: 1, EPOCH: 18, train_loss: 0.018591422159728165\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01633804112386245\n",
      "SEED: 4, FOLD: 1, EPOCH: 19, train_loss: 0.0182481607975992\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016254277183459356\n",
      "SEED: 4, FOLD: 1, EPOCH: 20, train_loss: 0.01789101993514074\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016200923934005775\n",
      "SEED: 4, FOLD: 1, EPOCH: 21, train_loss: 0.017486864625400788\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 21, valid_loss: 0.016020791820035532\n",
      "SEED: 4, FOLD: 1, EPOCH: 22, train_loss: 0.0170769374565901\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015964560497265596\n",
      "SEED: 4, FOLD: 1, EPOCH: 23, train_loss: 0.016691099650956488\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 23, valid_loss: 0.015929017072686784\n",
      "SEED: 4, FOLD: 1, EPOCH: 24, train_loss: 0.016443111405179307\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015946088573680475\n",
      "SEED: 4, FOLD: 1, EPOCH: 25, train_loss: 0.01631557152329667\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 25, valid_loss: 0.01592604722827673\n",
      "SEED: 4, FOLD: 2, EPOCH: 0, train_loss: 0.5865562552133122\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 0, valid_loss: 0.08808132318349984\n",
      "SEED: 4, FOLD: 2, EPOCH: 1, train_loss: 0.029446994508239063\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 1, valid_loss: 0.01974690375992885\n",
      "SEED: 4, FOLD: 2, EPOCH: 2, train_loss: 0.021784912140385526\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 2, valid_loss: 0.017979756857340153\n",
      "SEED: 4, FOLD: 2, EPOCH: 3, train_loss: 0.02119174413383007\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 3, valid_loss: 0.018766220085895978\n",
      "SEED: 4, FOLD: 2, EPOCH: 4, train_loss: 0.02056437126688055\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 4, valid_loss: 0.01722028672408599\n",
      "SEED: 4, FOLD: 2, EPOCH: 5, train_loss: 0.020213077348229046\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017103555970467053\n",
      "SEED: 4, FOLD: 2, EPOCH: 6, train_loss: 0.020012482774217386\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017050034581468657\n",
      "SEED: 4, FOLD: 2, EPOCH: 7, train_loss: 0.019897206283703044\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 7, valid_loss: 0.016872586539158456\n",
      "SEED: 4, FOLD: 2, EPOCH: 8, train_loss: 0.01993143684356599\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 8, valid_loss: 0.016804384927336987\n",
      "SEED: 4, FOLD: 2, EPOCH: 9, train_loss: 0.019843380017256416\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01670268550515175\n",
      "SEED: 4, FOLD: 2, EPOCH: 10, train_loss: 0.01983309366010331\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 10, valid_loss: 0.016688455899174396\n",
      "SEED: 4, FOLD: 2, EPOCH: 11, train_loss: 0.01974206614131863\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016946063448603336\n",
      "SEED: 4, FOLD: 2, EPOCH: 12, train_loss: 0.019717426039278507\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01653499800998431\n",
      "SEED: 4, FOLD: 2, EPOCH: 13, train_loss: 0.019580407747747126\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016714964276896074\n",
      "SEED: 4, FOLD: 2, EPOCH: 14, train_loss: 0.01943139059821496\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016539928503334522\n",
      "SEED: 4, FOLD: 2, EPOCH: 15, train_loss: 0.019278132658753847\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01620765610669668\n",
      "SEED: 4, FOLD: 2, EPOCH: 16, train_loss: 0.01908211480524089\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 16, valid_loss: 0.0163313363177272\n",
      "SEED: 4, FOLD: 2, EPOCH: 17, train_loss: 0.018853579245104984\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016133813474040765\n",
      "SEED: 4, FOLD: 2, EPOCH: 18, train_loss: 0.01862413841425567\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016182323058064167\n",
      "SEED: 4, FOLD: 2, EPOCH: 19, train_loss: 0.018204671783825836\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 19, valid_loss: 0.015961973283153314\n",
      "SEED: 4, FOLD: 2, EPOCH: 20, train_loss: 0.017765393984076137\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01587040600581811\n",
      "SEED: 4, FOLD: 2, EPOCH: 21, train_loss: 0.017357748329035333\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 21, valid_loss: 0.0158893963895165\n",
      "SEED: 4, FOLD: 2, EPOCH: 22, train_loss: 0.01690872506918134\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01582083485734004\n",
      "SEED: 4, FOLD: 2, EPOCH: 23, train_loss: 0.016489899666929566\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01578723481641366\n",
      "SEED: 4, FOLD: 2, EPOCH: 24, train_loss: 0.016186456523231557\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 24, valid_loss: 0.0158169510989235\n",
      "SEED: 4, FOLD: 2, EPOCH: 25, train_loss: 0.01605217015320385\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 25, valid_loss: 0.015830987491286717\n",
      "SEED: 4, FOLD: 3, EPOCH: 0, train_loss: 0.5876611151002549\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 0, valid_loss: 0.09354212650885949\n",
      "SEED: 4, FOLD: 3, EPOCH: 1, train_loss: 0.0299388196671734\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 1, valid_loss: 0.019879394998917214\n",
      "SEED: 4, FOLD: 3, EPOCH: 2, train_loss: 0.02181347509896433\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 2, valid_loss: 0.01835026018894636\n",
      "SEED: 4, FOLD: 3, EPOCH: 3, train_loss: 0.020920245706833696\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 3, valid_loss: 0.020907735881897118\n",
      "SEED: 4, FOLD: 3, EPOCH: 4, train_loss: 0.020381034930815566\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 4, valid_loss: 0.018080982737816297\n",
      "SEED: 4, FOLD: 3, EPOCH: 5, train_loss: 0.02010489343287977\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 5, valid_loss: 0.019847552506969526\n",
      "SEED: 4, FOLD: 3, EPOCH: 6, train_loss: 0.02003755868488067\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017134405529269807\n",
      "SEED: 4, FOLD: 3, EPOCH: 7, train_loss: 0.02001628898889632\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017095012590289116\n",
      "SEED: 4, FOLD: 3, EPOCH: 8, train_loss: 0.019929598437974583\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017034771493994273\n",
      "SEED: 4, FOLD: 3, EPOCH: 9, train_loss: 0.019941995725841134\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 9, valid_loss: 0.017098944419278547\n",
      "SEED: 4, FOLD: 3, EPOCH: 10, train_loss: 0.019861292823947763\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017284360212775376\n",
      "SEED: 4, FOLD: 3, EPOCH: 11, train_loss: 0.01979515777045005\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 11, valid_loss: 0.017090145498514175\n",
      "SEED: 4, FOLD: 3, EPOCH: 12, train_loss: 0.019744365450900955\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 12, valid_loss: 0.01698361050624114\n",
      "SEED: 4, FOLD: 3, EPOCH: 13, train_loss: 0.01964297880594795\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016952624186300315\n",
      "SEED: 4, FOLD: 3, EPOCH: 14, train_loss: 0.01948090489148288\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01684472280052992\n",
      "SEED: 4, FOLD: 3, EPOCH: 15, train_loss: 0.019309822671316767\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016745380484140836\n",
      "SEED: 4, FOLD: 3, EPOCH: 16, train_loss: 0.01912249662485477\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016557997307525232\n",
      "SEED: 4, FOLD: 3, EPOCH: 17, train_loss: 0.018852966636217928\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016498128955180828\n",
      "SEED: 4, FOLD: 3, EPOCH: 18, train_loss: 0.018554542767437728\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 18, valid_loss: 0.01637285826011346\n",
      "SEED: 4, FOLD: 3, EPOCH: 19, train_loss: 0.01830639476208268\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016283494850190785\n",
      "SEED: 4, FOLD: 3, EPOCH: 20, train_loss: 0.017905252683605696\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016218928333658438\n",
      "SEED: 4, FOLD: 3, EPOCH: 21, train_loss: 0.01750723582163856\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016176413744688034\n",
      "SEED: 4, FOLD: 3, EPOCH: 22, train_loss: 0.017056629829410766\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 22, valid_loss: 0.016065559206673734\n",
      "SEED: 4, FOLD: 3, EPOCH: 23, train_loss: 0.016725739187284094\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016070115451629344\n",
      "SEED: 4, FOLD: 3, EPOCH: 24, train_loss: 0.01644358108122204\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016074212482915476\n",
      "SEED: 4, FOLD: 3, EPOCH: 25, train_loss: 0.016335084530952816\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 25, valid_loss: 0.016050525511113498\n",
      "SEED: 4, FOLD: 4, EPOCH: 0, train_loss: 0.5877167509012932\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 0, valid_loss: 0.0947807259284533\n",
      "SEED: 4, FOLD: 4, EPOCH: 1, train_loss: 0.029936011276535085\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 1, valid_loss: 0.019686862683066957\n",
      "SEED: 4, FOLD: 4, EPOCH: 2, train_loss: 0.021968537186448638\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 2, valid_loss: 0.01811515883757518\n",
      "SEED: 4, FOLD: 4, EPOCH: 3, train_loss: 0.020988644956535584\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 3, valid_loss: 0.0177360217158611\n",
      "SEED: 4, FOLD: 4, EPOCH: 4, train_loss: 0.020516598370631\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 4, valid_loss: 0.01726497788555347\n",
      "SEED: 4, FOLD: 4, EPOCH: 5, train_loss: 0.020188622831090075\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 5, valid_loss: 0.016877372605869405\n",
      "SEED: 4, FOLD: 4, EPOCH: 6, train_loss: 0.02016404245954913\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 6, valid_loss: 0.016969530986478694\n",
      "SEED: 4, FOLD: 4, EPOCH: 7, train_loss: 0.020033522534209328\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 7, valid_loss: 0.016863403268731557\n",
      "SEED: 4, FOLD: 4, EPOCH: 8, train_loss: 0.019990222780285654\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 8, valid_loss: 0.01684720699603741\n",
      "SEED: 4, FOLD: 4, EPOCH: 9, train_loss: 0.0199063500339115\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 9, valid_loss: 0.016858399988940127\n",
      "SEED: 4, FOLD: 4, EPOCH: 10, train_loss: 0.019892130802209314\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017039951223593492\n",
      "SEED: 4, FOLD: 4, EPOCH: 11, train_loss: 0.01984777314135352\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01678603894722003\n",
      "SEED: 4, FOLD: 4, EPOCH: 12, train_loss: 0.019761022457198518\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016632100495581444\n",
      "SEED: 4, FOLD: 4, EPOCH: 13, train_loss: 0.01972233994889098\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01650481613782736\n",
      "SEED: 4, FOLD: 4, EPOCH: 14, train_loss: 0.01952283295827943\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016693335957825184\n",
      "SEED: 4, FOLD: 4, EPOCH: 15, train_loss: 0.019408595068631945\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016448076957693465\n",
      "SEED: 4, FOLD: 4, EPOCH: 16, train_loss: 0.019201913873690205\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016163440564504035\n",
      "SEED: 4, FOLD: 4, EPOCH: 17, train_loss: 0.018926768186124595\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01601211060411655\n",
      "SEED: 4, FOLD: 4, EPOCH: 18, train_loss: 0.01869084149901126\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01611057869516886\n",
      "SEED: 4, FOLD: 4, EPOCH: 19, train_loss: 0.01832759672322789\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 19, valid_loss: 0.015914274379611015\n",
      "SEED: 4, FOLD: 4, EPOCH: 20, train_loss: 0.01801375609293983\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 20, valid_loss: 0.015790658214917548\n",
      "SEED: 4, FOLD: 4, EPOCH: 21, train_loss: 0.017591110317388903\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 21, valid_loss: 0.015746983842780955\n",
      "SEED: 4, FOLD: 4, EPOCH: 22, train_loss: 0.0171623272015839\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 22, valid_loss: 0.01571820841099207\n",
      "SEED: 4, FOLD: 4, EPOCH: 23, train_loss: 0.016803763907503436\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01571044519257087\n",
      "SEED: 4, FOLD: 4, EPOCH: 24, train_loss: 0.01654730593735302\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01567527701934943\n",
      "SEED: 4, FOLD: 4, EPOCH: 25, train_loss: 0.016438841190491174\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 25, valid_loss: 0.01569211855530739\n",
      "SEED: 4, FOLD: 5, EPOCH: 0, train_loss: 0.5863211367379975\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 0, valid_loss: 0.08739590759460743\n",
      "SEED: 4, FOLD: 5, EPOCH: 1, train_loss: 0.029337443209983206\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 1, valid_loss: 0.020611825900582168\n",
      "SEED: 4, FOLD: 5, EPOCH: 2, train_loss: 0.022120299698734604\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 2, valid_loss: 0.01880405069543765\n",
      "SEED: 4, FOLD: 5, EPOCH: 3, train_loss: 0.02089457181156487\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 3, valid_loss: 0.017896117069400273\n",
      "SEED: 4, FOLD: 5, EPOCH: 4, train_loss: 0.020357221188778814\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 4, valid_loss: 0.017411361663387373\n",
      "SEED: 4, FOLD: 5, EPOCH: 5, train_loss: 0.020111913239029614\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 5, valid_loss: 0.017088547635536928\n",
      "SEED: 4, FOLD: 5, EPOCH: 6, train_loss: 0.020034376129105285\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 6, valid_loss: 0.017188094126490448\n",
      "SEED: 4, FOLD: 5, EPOCH: 7, train_loss: 0.01995632367057575\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 7, valid_loss: 0.017454422293947294\n",
      "SEED: 4, FOLD: 5, EPOCH: 8, train_loss: 0.0199648235496637\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 8, valid_loss: 0.017053476463143643\n",
      "SEED: 4, FOLD: 5, EPOCH: 9, train_loss: 0.01989471320868344\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 9, valid_loss: 0.017033741164665956\n",
      "SEED: 4, FOLD: 5, EPOCH: 10, train_loss: 0.01982278555530954\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 10, valid_loss: 0.017045497321165524\n",
      "SEED: 4, FOLD: 5, EPOCH: 11, train_loss: 0.01985027117503656\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 11, valid_loss: 0.01682974498432416\n",
      "SEED: 4, FOLD: 5, EPOCH: 12, train_loss: 0.019725537582023722\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 12, valid_loss: 0.016842369849865254\n",
      "SEED: 4, FOLD: 5, EPOCH: 13, train_loss: 0.019610488963489596\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 13, valid_loss: 0.01676442875311925\n",
      "SEED: 4, FOLD: 5, EPOCH: 14, train_loss: 0.019515999164935703\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 14, valid_loss: 0.017016798974229738\n",
      "SEED: 4, FOLD: 5, EPOCH: 15, train_loss: 0.01936737334708104\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 15, valid_loss: 0.016674633639363143\n",
      "SEED: 4, FOLD: 5, EPOCH: 16, train_loss: 0.0191679039617648\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 16, valid_loss: 0.016650707962421272\n",
      "SEED: 4, FOLD: 5, EPOCH: 17, train_loss: 0.01889191857362921\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 17, valid_loss: 0.016424662791765653\n",
      "SEED: 4, FOLD: 5, EPOCH: 18, train_loss: 0.018632299946369352\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 18, valid_loss: 0.016308794156290017\n",
      "SEED: 4, FOLD: 5, EPOCH: 19, train_loss: 0.018288719316793454\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 19, valid_loss: 0.01616230929413667\n",
      "SEED: 4, FOLD: 5, EPOCH: 20, train_loss: 0.017959996680351527\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 20, valid_loss: 0.016102177950625237\n",
      "SEED: 4, FOLD: 5, EPOCH: 21, train_loss: 0.017510972753469203\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 21, valid_loss: 0.016019735628595717\n",
      "SEED: 4, FOLD: 5, EPOCH: 22, train_loss: 0.017086160482486356\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 22, valid_loss: 0.01594536894789109\n",
      "SEED: 4, FOLD: 5, EPOCH: 23, train_loss: 0.016728676704538835\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 23, valid_loss: 0.015974043008799736\n",
      "SEED: 4, FOLD: 5, EPOCH: 24, train_loss: 0.016472023106305987\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 24, valid_loss: 0.01593405782030179\n",
      "SEED: 4, FOLD: 5, EPOCH: 25, train_loss: 0.016364552584048862\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 25, valid_loss: 0.015930773117221318\n",
      "SEED: 4, FOLD: 6, EPOCH: 0, train_loss: 0.5876278538961668\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 0, valid_loss: 0.08090759985722028\n",
      "SEED: 4, FOLD: 6, EPOCH: 1, train_loss: 0.02976152492133347\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 1, valid_loss: 0.020391171224988423\n",
      "SEED: 4, FOLD: 6, EPOCH: 2, train_loss: 0.02191455924027675\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 2, valid_loss: 0.019556947482319977\n",
      "SEED: 4, FOLD: 6, EPOCH: 3, train_loss: 0.020981419705659955\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 3, valid_loss: 0.017763110164266366\n",
      "SEED: 4, FOLD: 6, EPOCH: 4, train_loss: 0.020319239387439715\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 4, valid_loss: 0.017418455619078416\n",
      "SEED: 4, FOLD: 6, EPOCH: 5, train_loss: 0.020135319514854533\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 5, valid_loss: 0.017281712391055547\n",
      "SEED: 4, FOLD: 6, EPOCH: 6, train_loss: 0.01997352688497788\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 6, valid_loss: 0.01764014220008483\n",
      "SEED: 4, FOLD: 6, EPOCH: 7, train_loss: 0.019993936643004417\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 7, valid_loss: 0.01732487389101432\n",
      "SEED: 4, FOLD: 6, EPOCH: 8, train_loss: 0.019896046812268527\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 8, valid_loss: 0.01738396602181288\n",
      "SEED: 4, FOLD: 6, EPOCH: 9, train_loss: 0.019898024035265315\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 9, valid_loss: 0.017325554472895768\n",
      "SEED: 4, FOLD: 6, EPOCH: 10, train_loss: 0.019814059893424447\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 10, valid_loss: 0.017093420315247316\n",
      "SEED: 4, FOLD: 6, EPOCH: 11, train_loss: 0.019755694612457946\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 11, valid_loss: 0.01721623382316186\n",
      "SEED: 4, FOLD: 6, EPOCH: 12, train_loss: 0.019709289451507298\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 12, valid_loss: 0.01714243539250814\n",
      "SEED: 4, FOLD: 6, EPOCH: 13, train_loss: 0.01963009896713334\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 13, valid_loss: 0.017136796449239437\n",
      "SEED: 4, FOLD: 6, EPOCH: 14, train_loss: 0.019472121009351435\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 14, valid_loss: 0.016810785692471724\n",
      "SEED: 4, FOLD: 6, EPOCH: 15, train_loss: 0.019308573213984836\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 15, valid_loss: 0.016831871551962998\n",
      "SEED: 4, FOLD: 6, EPOCH: 16, train_loss: 0.019133744534809847\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 16, valid_loss: 0.016701253417592783\n",
      "SEED: 4, FOLD: 6, EPOCH: 17, train_loss: 0.018836970441043377\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 17, valid_loss: 0.01663106171270976\n",
      "SEED: 4, FOLD: 6, EPOCH: 18, train_loss: 0.018615915364510304\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 18, valid_loss: 0.01650072469447668\n",
      "SEED: 4, FOLD: 6, EPOCH: 19, train_loss: 0.018198332044522505\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 19, valid_loss: 0.016444251586038332\n",
      "SEED: 4, FOLD: 6, EPOCH: 20, train_loss: 0.0178765220366217\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 20, valid_loss: 0.016349455914818324\n",
      "SEED: 4, FOLD: 6, EPOCH: 21, train_loss: 0.017478033963188127\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 21, valid_loss: 0.016293810608868416\n",
      "SEED: 4, FOLD: 6, EPOCH: 22, train_loss: 0.017044487698758777\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 22, valid_loss: 0.01627640913312252\n",
      "SEED: 4, FOLD: 6, EPOCH: 23, train_loss: 0.016687428692003358\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 23, valid_loss: 0.016255664782455333\n",
      "SEED: 4, FOLD: 6, EPOCH: 24, train_loss: 0.016406736777138872\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 24, valid_loss: 0.016264063234512623\n",
      "SEED: 4, FOLD: 6, EPOCH: 25, train_loss: 0.016311380508783703\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 25, valid_loss: 0.016257226825333558\n",
      "SEED: 5, FOLD: 0, EPOCH: 0, train_loss: 0.5872845188588709\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08759733232168052\n",
      "SEED: 5, FOLD: 0, EPOCH: 1, train_loss: 0.02967602845180679\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 1, valid_loss: 0.020054557002507724\n",
      "SEED: 5, FOLD: 0, EPOCH: 2, train_loss: 0.021860231041304162\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 2, valid_loss: 0.018338821541804533\n",
      "SEED: 5, FOLD: 0, EPOCH: 3, train_loss: 0.020968100634982455\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017735543445898935\n",
      "SEED: 5, FOLD: 0, EPOCH: 4, train_loss: 0.020411816828355595\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 4, valid_loss: 0.0174797885119915\n",
      "SEED: 5, FOLD: 0, EPOCH: 5, train_loss: 0.020159083947136596\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017555595017396487\n",
      "SEED: 5, FOLD: 0, EPOCH: 6, train_loss: 0.020012614367580093\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01821139555137891\n",
      "SEED: 5, FOLD: 0, EPOCH: 7, train_loss: 0.019987901421012106\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017252448516396377\n",
      "SEED: 5, FOLD: 0, EPOCH: 8, train_loss: 0.019917316407569358\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017433575712717496\n",
      "SEED: 5, FOLD: 0, EPOCH: 9, train_loss: 0.019904434429229918\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01739263591858057\n",
      "SEED: 5, FOLD: 0, EPOCH: 10, train_loss: 0.019838451709900354\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 10, valid_loss: 0.01727158146408888\n",
      "SEED: 5, FOLD: 0, EPOCH: 11, train_loss: 0.019830978097947868\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01717169826420454\n",
      "SEED: 5, FOLD: 0, EPOCH: 12, train_loss: 0.019717758521437645\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 12, valid_loss: 0.017008905227367695\n",
      "SEED: 5, FOLD: 0, EPOCH: 13, train_loss: 0.01961408057124228\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 13, valid_loss: 0.017092581695088975\n",
      "SEED: 5, FOLD: 0, EPOCH: 14, train_loss: 0.01952826282059824\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 14, valid_loss: 0.01694060403567094\n",
      "SEED: 5, FOLD: 0, EPOCH: 15, train_loss: 0.0193187180101066\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01672807901811141\n",
      "SEED: 5, FOLD: 0, EPOCH: 16, train_loss: 0.019115392395572084\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016734473335628327\n",
      "SEED: 5, FOLD: 0, EPOCH: 17, train_loss: 0.018967974024849968\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016649459417049702\n",
      "SEED: 5, FOLD: 0, EPOCH: 18, train_loss: 0.01864877949796013\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 18, valid_loss: 0.01632828673777672\n",
      "SEED: 5, FOLD: 0, EPOCH: 19, train_loss: 0.01832199189811945\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016376929715848886\n",
      "SEED: 5, FOLD: 0, EPOCH: 20, train_loss: 0.017933998458288813\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016301417508377478\n",
      "SEED: 5, FOLD: 0, EPOCH: 21, train_loss: 0.017480650841182954\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016167564890705623\n",
      "SEED: 5, FOLD: 0, EPOCH: 22, train_loss: 0.017016214947845484\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 22, valid_loss: 0.016144034452736378\n",
      "SEED: 5, FOLD: 0, EPOCH: 23, train_loss: 0.016658415791352053\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 23, valid_loss: 0.016120816939152204\n",
      "SEED: 5, FOLD: 0, EPOCH: 24, train_loss: 0.016346078303113982\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 24, valid_loss: 0.0161289913723102\n",
      "SEED: 5, FOLD: 0, EPOCH: 25, train_loss: 0.016235411104217574\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 25, valid_loss: 0.016128884270214118\n",
      "SEED: 5, FOLD: 1, EPOCH: 0, train_loss: 0.5889823486071986\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 0, valid_loss: 0.087307731119486\n",
      "SEED: 5, FOLD: 1, EPOCH: 1, train_loss: 0.02966224336744966\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 1, valid_loss: 0.020313754247931335\n",
      "SEED: 5, FOLD: 1, EPOCH: 2, train_loss: 0.022525898986370176\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 2, valid_loss: 0.04598856373475148\n",
      "SEED: 5, FOLD: 1, EPOCH: 3, train_loss: 0.021489808839317913\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 3, valid_loss: 0.01759671548811289\n",
      "SEED: 5, FOLD: 1, EPOCH: 4, train_loss: 0.020536045996925316\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017246298778515596\n",
      "SEED: 5, FOLD: 1, EPOCH: 5, train_loss: 0.020203055889421218\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017149625775905755\n",
      "SEED: 5, FOLD: 1, EPOCH: 6, train_loss: 0.0200850920298615\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017234374769032\n",
      "SEED: 5, FOLD: 1, EPOCH: 7, train_loss: 0.019939884795127687\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 7, valid_loss: 0.016882203590984527\n",
      "SEED: 5, FOLD: 1, EPOCH: 8, train_loss: 0.019990225876303943\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017233055299864367\n",
      "SEED: 5, FOLD: 1, EPOCH: 9, train_loss: 0.019917439216294804\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01678643970248791\n",
      "SEED: 5, FOLD: 1, EPOCH: 10, train_loss: 0.019919997257356707\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 10, valid_loss: 0.016821620770944998\n",
      "SEED: 5, FOLD: 1, EPOCH: 11, train_loss: 0.01985317435921044\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017081867187069014\n",
      "SEED: 5, FOLD: 1, EPOCH: 12, train_loss: 0.019773581996560097\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01691525407995169\n",
      "SEED: 5, FOLD: 1, EPOCH: 13, train_loss: 0.01962907728109811\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016626799980608318\n",
      "SEED: 5, FOLD: 1, EPOCH: 14, train_loss: 0.01947739176653527\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016586370622882478\n",
      "SEED: 5, FOLD: 1, EPOCH: 15, train_loss: 0.01928880317388354\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016535432937626656\n",
      "SEED: 5, FOLD: 1, EPOCH: 16, train_loss: 0.01918624122501225\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016309067893486757\n",
      "SEED: 5, FOLD: 1, EPOCH: 17, train_loss: 0.0189216120319592\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016294561684704743\n",
      "SEED: 5, FOLD: 1, EPOCH: 18, train_loss: 0.018660892556245263\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016152027564553115\n",
      "SEED: 5, FOLD: 1, EPOCH: 19, train_loss: 0.018324439841750507\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01602520328015089\n",
      "SEED: 5, FOLD: 1, EPOCH: 20, train_loss: 0.017979017635052268\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 20, valid_loss: 0.015980463904830124\n",
      "SEED: 5, FOLD: 1, EPOCH: 21, train_loss: 0.01751583387974549\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 21, valid_loss: 0.015860478178812906\n",
      "SEED: 5, FOLD: 1, EPOCH: 22, train_loss: 0.017072365745096595\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015830146363721445\n",
      "SEED: 5, FOLD: 1, EPOCH: 23, train_loss: 0.01665031672077807\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01583906442213517\n",
      "SEED: 5, FOLD: 1, EPOCH: 24, train_loss: 0.016351068304297892\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 24, valid_loss: 0.01579600329009386\n",
      "SEED: 5, FOLD: 1, EPOCH: 25, train_loss: 0.01618694409577025\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 25, valid_loss: 0.015810952808421392\n",
      "SEED: 5, FOLD: 2, EPOCH: 0, train_loss: 0.5861709171251671\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 0, valid_loss: 0.08293499969519101\n",
      "SEED: 5, FOLD: 2, EPOCH: 1, train_loss: 0.029321215090316696\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 1, valid_loss: 0.01996134278865961\n",
      "SEED: 5, FOLD: 2, EPOCH: 2, train_loss: 0.021877751610166318\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018228906994828813\n",
      "SEED: 5, FOLD: 2, EPOCH: 3, train_loss: 0.020968252163682435\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 3, valid_loss: 0.018017697506226026\n",
      "SEED: 5, FOLD: 2, EPOCH: 4, train_loss: 0.020335558650864137\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017416018419540845\n",
      "SEED: 5, FOLD: 2, EPOCH: 5, train_loss: 0.02015264707340582\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 5, valid_loss: 0.0172410777841623\n",
      "SEED: 5, FOLD: 2, EPOCH: 6, train_loss: 0.02011371134604151\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01705582282291009\n",
      "SEED: 5, FOLD: 2, EPOCH: 7, train_loss: 0.020003843951869656\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01728216100197572\n",
      "SEED: 5, FOLD: 2, EPOCH: 8, train_loss: 0.02000337778716474\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017020968433756094\n",
      "SEED: 5, FOLD: 2, EPOCH: 9, train_loss: 0.019865841478914827\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01687286178079935\n",
      "SEED: 5, FOLD: 2, EPOCH: 10, train_loss: 0.019847422334793453\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 10, valid_loss: 0.016944867128936145\n",
      "SEED: 5, FOLD: 2, EPOCH: 11, train_loss: 0.01985531219759503\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 11, valid_loss: 0.017164722084999084\n",
      "SEED: 5, FOLD: 2, EPOCH: 12, train_loss: 0.019766642535860475\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01701307540329603\n",
      "SEED: 5, FOLD: 2, EPOCH: 13, train_loss: 0.01963996290657166\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016865194058762148\n",
      "SEED: 5, FOLD: 2, EPOCH: 14, train_loss: 0.01952590453564315\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 14, valid_loss: 0.0168774569980227\n",
      "SEED: 5, FOLD: 2, EPOCH: 15, train_loss: 0.01930675356069932\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016547755983013373\n",
      "SEED: 5, FOLD: 2, EPOCH: 16, train_loss: 0.019119750330778392\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01647118178124611\n",
      "SEED: 5, FOLD: 2, EPOCH: 17, train_loss: 0.018927002275312268\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016423326630431872\n",
      "SEED: 5, FOLD: 2, EPOCH: 18, train_loss: 0.018698281910572503\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016426904915043943\n",
      "SEED: 5, FOLD: 2, EPOCH: 19, train_loss: 0.018375272409537353\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016242726491047785\n",
      "SEED: 5, FOLD: 2, EPOCH: 20, train_loss: 0.017943681268071807\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 20, valid_loss: 0.016225343211912192\n",
      "SEED: 5, FOLD: 2, EPOCH: 21, train_loss: 0.01759418102635725\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016041445187651195\n",
      "SEED: 5, FOLD: 2, EPOCH: 22, train_loss: 0.01713153688438438\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 22, valid_loss: 0.015919739237198464\n",
      "SEED: 5, FOLD: 2, EPOCH: 23, train_loss: 0.01678193668910378\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015990877524018288\n",
      "SEED: 5, FOLD: 2, EPOCH: 24, train_loss: 0.0165239035126728\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01590218409322775\n",
      "SEED: 5, FOLD: 2, EPOCH: 25, train_loss: 0.01643395079048099\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 25, valid_loss: 0.015938133789369695\n",
      "SEED: 5, FOLD: 3, EPOCH: 0, train_loss: 0.587172689671452\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 0, valid_loss: 0.07997359048861724\n",
      "SEED: 5, FOLD: 3, EPOCH: 1, train_loss: 0.029613401237371807\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 1, valid_loss: 0.020401836587832525\n",
      "SEED: 5, FOLD: 3, EPOCH: 2, train_loss: 0.021947143674903625\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 2, valid_loss: 0.02772536128759384\n",
      "SEED: 5, FOLD: 3, EPOCH: 3, train_loss: 0.022665414078211463\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 3, valid_loss: 0.017787020438565657\n",
      "SEED: 5, FOLD: 3, EPOCH: 4, train_loss: 0.02072442662776322\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017620613153737325\n",
      "SEED: 5, FOLD: 3, EPOCH: 5, train_loss: 0.020332437235157232\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017446272003536042\n",
      "SEED: 5, FOLD: 3, EPOCH: 6, train_loss: 0.020176098833011614\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017178485170006752\n",
      "SEED: 5, FOLD: 3, EPOCH: 7, train_loss: 0.020086882283558715\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017058338325184125\n",
      "SEED: 5, FOLD: 3, EPOCH: 8, train_loss: 0.01997478847467416\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017162264682925664\n",
      "SEED: 5, FOLD: 3, EPOCH: 9, train_loss: 0.01993301062769181\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01719554986518163\n",
      "SEED: 5, FOLD: 3, EPOCH: 10, train_loss: 0.019848014580438268\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 10, valid_loss: 0.016794658767489288\n",
      "SEED: 5, FOLD: 3, EPOCH: 11, train_loss: 0.01984128763748182\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 11, valid_loss: 0.016914050596264694\n",
      "SEED: 5, FOLD: 3, EPOCH: 12, train_loss: 0.019752665297002404\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 12, valid_loss: 0.01689541146445733\n",
      "SEED: 5, FOLD: 3, EPOCH: 13, train_loss: 0.019662032860356407\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01688417921272608\n",
      "SEED: 5, FOLD: 3, EPOCH: 14, train_loss: 0.01951673989360397\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016536203642877247\n",
      "SEED: 5, FOLD: 3, EPOCH: 15, train_loss: 0.019350748937073593\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016472626978961322\n",
      "SEED: 5, FOLD: 3, EPOCH: 16, train_loss: 0.019184698375898437\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 16, valid_loss: 0.01653820527001069\n",
      "SEED: 5, FOLD: 3, EPOCH: 17, train_loss: 0.01897526260566067\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016338819494614236\n",
      "SEED: 5, FOLD: 3, EPOCH: 18, train_loss: 0.01865850600439149\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016336944240790147\n",
      "SEED: 5, FOLD: 3, EPOCH: 19, train_loss: 0.018323655315750354\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01614195853471756\n",
      "SEED: 5, FOLD: 3, EPOCH: 20, train_loss: 0.017992134331851393\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 20, valid_loss: 0.01605818126923763\n",
      "SEED: 5, FOLD: 3, EPOCH: 21, train_loss: 0.01750549637536342\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016052455856249884\n",
      "SEED: 5, FOLD: 3, EPOCH: 22, train_loss: 0.017045462667639996\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01596582315575618\n",
      "SEED: 5, FOLD: 3, EPOCH: 23, train_loss: 0.016595814893072523\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 23, valid_loss: 0.015968231197733145\n",
      "SEED: 5, FOLD: 3, EPOCH: 24, train_loss: 0.016287836409803177\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 24, valid_loss: 0.015968577578090705\n",
      "SEED: 5, FOLD: 3, EPOCH: 25, train_loss: 0.016139969921897392\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 25, valid_loss: 0.015961178506796177\n",
      "SEED: 5, FOLD: 4, EPOCH: 0, train_loss: 0.5877057655236205\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 0, valid_loss: 0.096707556110162\n",
      "SEED: 5, FOLD: 4, EPOCH: 1, train_loss: 0.029655620455741882\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 1, valid_loss: 0.020034786886893786\n",
      "SEED: 5, FOLD: 4, EPOCH: 2, train_loss: 0.02185048459953553\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 2, valid_loss: 0.019612273774467982\n",
      "SEED: 5, FOLD: 4, EPOCH: 3, train_loss: 0.020916468715546904\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 3, valid_loss: 0.018191127393108148\n",
      "SEED: 5, FOLD: 4, EPOCH: 4, train_loss: 0.02034141100641038\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 4, valid_loss: 0.01733421305051217\n",
      "SEED: 5, FOLD: 4, EPOCH: 5, train_loss: 0.020172390935791505\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017671518171062835\n",
      "SEED: 5, FOLD: 4, EPOCH: 6, train_loss: 0.01999815628939384\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 6, valid_loss: 0.0170368360212216\n",
      "SEED: 5, FOLD: 4, EPOCH: 7, train_loss: 0.019970281930589997\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017280350367610272\n",
      "SEED: 5, FOLD: 4, EPOCH: 8, train_loss: 0.019932542096924136\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017185153296360604\n",
      "SEED: 5, FOLD: 4, EPOCH: 9, train_loss: 0.019872766994946712\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 9, valid_loss: 0.01721690595149994\n",
      "SEED: 5, FOLD: 4, EPOCH: 10, train_loss: 0.01985018725532132\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017092873700536214\n",
      "SEED: 5, FOLD: 4, EPOCH: 11, train_loss: 0.019810144336441078\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 11, valid_loss: 0.017025558277964592\n",
      "SEED: 5, FOLD: 4, EPOCH: 12, train_loss: 0.01970392551172424\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 12, valid_loss: 0.017024761638962306\n",
      "SEED: 5, FOLD: 4, EPOCH: 13, train_loss: 0.019569418065854022\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01697817645393885\n",
      "SEED: 5, FOLD: 4, EPOCH: 14, train_loss: 0.019449362380279077\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 14, valid_loss: 0.01678794722717542\n",
      "SEED: 5, FOLD: 4, EPOCH: 15, train_loss: 0.01925637129996274\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016642628237605095\n",
      "SEED: 5, FOLD: 4, EPOCH: 16, train_loss: 0.019142490811645985\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01669400171018564\n",
      "SEED: 5, FOLD: 4, EPOCH: 17, train_loss: 0.018971099820290063\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016509693689071216\n",
      "SEED: 5, FOLD: 4, EPOCH: 18, train_loss: 0.018635899810170806\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016343519521447327\n",
      "SEED: 5, FOLD: 4, EPOCH: 19, train_loss: 0.01826435055684399\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01626119318489845\n",
      "SEED: 5, FOLD: 4, EPOCH: 20, train_loss: 0.01791848655085306\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016202501522806976\n",
      "SEED: 5, FOLD: 4, EPOCH: 21, train_loss: 0.017523850968762023\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 21, valid_loss: 0.01605968141498474\n",
      "SEED: 5, FOLD: 4, EPOCH: 22, train_loss: 0.017107628839644225\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 22, valid_loss: 0.016116101581316728\n",
      "SEED: 5, FOLD: 4, EPOCH: 23, train_loss: 0.016732478350702976\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 23, valid_loss: 0.016048421438496847\n",
      "SEED: 5, FOLD: 4, EPOCH: 24, train_loss: 0.016441575503228483\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 24, valid_loss: 0.016047814216178197\n",
      "SEED: 5, FOLD: 4, EPOCH: 25, train_loss: 0.016334657381112512\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 25, valid_loss: 0.016011910083202217\n",
      "SEED: 5, FOLD: 5, EPOCH: 0, train_loss: 0.5876313068375394\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 0, valid_loss: 0.0841419232579378\n",
      "SEED: 5, FOLD: 5, EPOCH: 1, train_loss: 0.02956203046582035\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 1, valid_loss: 0.019717238556880217\n",
      "SEED: 5, FOLD: 5, EPOCH: 2, train_loss: 0.021850942382337275\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 2, valid_loss: 0.018360882710952025\n",
      "SEED: 5, FOLD: 5, EPOCH: 3, train_loss: 0.021010177386169497\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 3, valid_loss: 0.01769983610854699\n",
      "SEED: 5, FOLD: 5, EPOCH: 4, train_loss: 0.020428631228168268\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 4, valid_loss: 0.017300209746910974\n",
      "SEED: 5, FOLD: 5, EPOCH: 5, train_loss: 0.020137937714320583\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 5, valid_loss: 0.01737029434969792\n",
      "SEED: 5, FOLD: 5, EPOCH: 6, train_loss: 0.02023026342126163\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 6, valid_loss: 0.017202084740767114\n",
      "SEED: 5, FOLD: 5, EPOCH: 7, train_loss: 0.020088535834204505\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 7, valid_loss: 0.01720559597015381\n",
      "SEED: 5, FOLD: 5, EPOCH: 8, train_loss: 0.019994772039353848\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 8, valid_loss: 0.01720014479584419\n",
      "SEED: 5, FOLD: 5, EPOCH: 9, train_loss: 0.01997784854894554\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 9, valid_loss: 0.017014167199914273\n",
      "SEED: 5, FOLD: 5, EPOCH: 10, train_loss: 0.019920513738651533\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 10, valid_loss: 0.016997960181190416\n",
      "SEED: 5, FOLD: 5, EPOCH: 11, train_loss: 0.01993218235470153\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 11, valid_loss: 0.016887803561985493\n",
      "SEED: 5, FOLD: 5, EPOCH: 12, train_loss: 0.01975374578221424\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 12, valid_loss: 0.016665172261687424\n",
      "SEED: 5, FOLD: 5, EPOCH: 13, train_loss: 0.019652827139440422\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 13, valid_loss: 0.016861030115531042\n",
      "SEED: 5, FOLD: 5, EPOCH: 14, train_loss: 0.019567638509780973\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 14, valid_loss: 0.01680592927508629\n",
      "SEED: 5, FOLD: 5, EPOCH: 15, train_loss: 0.019414235435023502\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 15, valid_loss: 0.016593054295159303\n",
      "SEED: 5, FOLD: 5, EPOCH: 16, train_loss: 0.019273568624378862\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 16, valid_loss: 0.016567859297188427\n",
      "SEED: 5, FOLD: 5, EPOCH: 17, train_loss: 0.018969268487716042\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 17, valid_loss: 0.016403053027506057\n",
      "SEED: 5, FOLD: 5, EPOCH: 18, train_loss: 0.018695452200198494\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 18, valid_loss: 0.016322107555774543\n",
      "SEED: 5, FOLD: 5, EPOCH: 19, train_loss: 0.018415173213626887\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 19, valid_loss: 0.01627751110264888\n",
      "SEED: 5, FOLD: 5, EPOCH: 20, train_loss: 0.01803583835528509\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 20, valid_loss: 0.01611594232515647\n",
      "SEED: 5, FOLD: 5, EPOCH: 21, train_loss: 0.017661312595009804\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 21, valid_loss: 0.016043354112368364\n",
      "SEED: 5, FOLD: 5, EPOCH: 22, train_loss: 0.017259857793514792\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 22, valid_loss: 0.015961036229362853\n",
      "SEED: 5, FOLD: 5, EPOCH: 23, train_loss: 0.01694844085471453\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 23, valid_loss: 0.015906483293152772\n",
      "SEED: 5, FOLD: 5, EPOCH: 24, train_loss: 0.016671014924508495\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 24, valid_loss: 0.015956654070088498\n",
      "SEED: 5, FOLD: 5, EPOCH: 25, train_loss: 0.01655620478748067\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 25, valid_loss: 0.01594193845700759\n",
      "SEED: 5, FOLD: 6, EPOCH: 0, train_loss: 0.5873803665509095\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 0, valid_loss: 0.08414764129198514\n",
      "SEED: 5, FOLD: 6, EPOCH: 1, train_loss: 0.02980619646306779\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 1, valid_loss: 0.01973766117141797\n",
      "SEED: 5, FOLD: 6, EPOCH: 2, train_loss: 0.02175193337874638\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 2, valid_loss: 0.018197384877846792\n",
      "SEED: 5, FOLD: 6, EPOCH: 3, train_loss: 0.02095001596151977\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 3, valid_loss: 0.01812424768622105\n",
      "SEED: 5, FOLD: 6, EPOCH: 4, train_loss: 0.02040306856301991\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 4, valid_loss: 0.0175339115353731\n",
      "SEED: 5, FOLD: 6, EPOCH: 5, train_loss: 0.020091679626824083\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 5, valid_loss: 0.017415733864674203\n",
      "SEED: 5, FOLD: 6, EPOCH: 6, train_loss: 0.02016751317156328\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 6, valid_loss: 0.017162552963082608\n",
      "SEED: 5, FOLD: 6, EPOCH: 7, train_loss: 0.019988774447827727\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 7, valid_loss: 0.017107513160086595\n",
      "SEED: 5, FOLD: 6, EPOCH: 8, train_loss: 0.01996149548102875\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 8, valid_loss: 0.017213931163916223\n",
      "SEED: 5, FOLD: 6, EPOCH: 9, train_loss: 0.01996927069047013\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 9, valid_loss: 0.017127403058111668\n",
      "SEED: 5, FOLD: 6, EPOCH: 10, train_loss: 0.019878214829274127\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 10, valid_loss: 0.016944960977595586\n",
      "SEED: 5, FOLD: 6, EPOCH: 11, train_loss: 0.019818224717636366\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 11, valid_loss: 0.016962728248192713\n",
      "SEED: 5, FOLD: 6, EPOCH: 12, train_loss: 0.019751892450290756\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 12, valid_loss: 0.016860761464788362\n",
      "SEED: 5, FOLD: 6, EPOCH: 13, train_loss: 0.019687112194259424\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 13, valid_loss: 0.017106186885100145\n",
      "SEED: 5, FOLD: 6, EPOCH: 14, train_loss: 0.019469320597882207\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 14, valid_loss: 0.0165807233693508\n",
      "SEED: 5, FOLD: 6, EPOCH: 15, train_loss: 0.01930867027289964\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 15, valid_loss: 0.01657715318008111\n",
      "SEED: 5, FOLD: 6, EPOCH: 16, train_loss: 0.019199105332026612\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 16, valid_loss: 0.016720132902264595\n",
      "SEED: 5, FOLD: 6, EPOCH: 17, train_loss: 0.01888299751019961\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 17, valid_loss: 0.016504153465995423\n",
      "SEED: 5, FOLD: 6, EPOCH: 18, train_loss: 0.018635635490755777\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 18, valid_loss: 0.01641080893862706\n",
      "SEED: 5, FOLD: 6, EPOCH: 19, train_loss: 0.018292584859237477\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 19, valid_loss: 0.01629264194231767\n",
      "SEED: 5, FOLD: 6, EPOCH: 20, train_loss: 0.017908562125789153\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 20, valid_loss: 0.016236275219573423\n",
      "SEED: 5, FOLD: 6, EPOCH: 21, train_loss: 0.017505613482884458\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 21, valid_loss: 0.016126966963593777\n",
      "SEED: 5, FOLD: 6, EPOCH: 22, train_loss: 0.017060305759612773\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 22, valid_loss: 0.01610516097683173\n",
      "SEED: 5, FOLD: 6, EPOCH: 23, train_loss: 0.016676211402424285\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 23, valid_loss: 0.016036573654183976\n",
      "SEED: 5, FOLD: 6, EPOCH: 24, train_loss: 0.016427842031761602\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 24, valid_loss: 0.016036498217055432\n",
      "SEED: 5, FOLD: 6, EPOCH: 25, train_loss: 0.016286274934237874\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 25, valid_loss: 0.01603125136059064\n",
      "SEED: 6, FOLD: 0, EPOCH: 0, train_loss: 0.5878890744737677\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 0, valid_loss: 0.0980277072924834\n",
      "SEED: 6, FOLD: 0, EPOCH: 1, train_loss: 0.029680325121090218\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 1, valid_loss: 0.019835423964720506\n",
      "SEED: 6, FOLD: 0, EPOCH: 2, train_loss: 0.022194884113363317\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 2, valid_loss: 0.021266940264747694\n",
      "SEED: 6, FOLD: 0, EPOCH: 3, train_loss: 0.021205449124445785\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 3, valid_loss: 0.01992358467899836\n",
      "SEED: 6, FOLD: 0, EPOCH: 4, train_loss: 0.02079733826119352\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 4, valid_loss: 0.03711520078090521\n",
      "SEED: 6, FOLD: 0, EPOCH: 5, train_loss: 0.020553352009202983\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017201835934359293\n",
      "SEED: 6, FOLD: 0, EPOCH: 6, train_loss: 0.02016691199025592\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017081590942465343\n",
      "SEED: 6, FOLD: 0, EPOCH: 7, train_loss: 0.020086101080114778\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017699705365185555\n",
      "SEED: 6, FOLD: 0, EPOCH: 8, train_loss: 0.020034791020726837\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01714720491033334\n",
      "SEED: 6, FOLD: 0, EPOCH: 9, train_loss: 0.019905065010125574\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 9, valid_loss: 0.016858097738944568\n",
      "SEED: 6, FOLD: 0, EPOCH: 10, train_loss: 0.01982344261597137\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 10, valid_loss: 0.016769704194023058\n",
      "SEED: 6, FOLD: 0, EPOCH: 11, train_loss: 0.019779790369038645\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 11, valid_loss: 0.016889453364106324\n",
      "SEED: 6, FOLD: 0, EPOCH: 12, train_loss: 0.019772596707617916\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01661574073995535\n",
      "SEED: 6, FOLD: 0, EPOCH: 13, train_loss: 0.019587256115030597\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016521523993175764\n",
      "SEED: 6, FOLD: 0, EPOCH: 14, train_loss: 0.019515466977011512\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016457205781569846\n",
      "SEED: 6, FOLD: 0, EPOCH: 15, train_loss: 0.019338429100006015\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01632368707886109\n",
      "SEED: 6, FOLD: 0, EPOCH: 16, train_loss: 0.019156236780454982\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016296789050102234\n",
      "SEED: 6, FOLD: 0, EPOCH: 17, train_loss: 0.01890659284450718\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 17, valid_loss: 0.0161041128807343\n",
      "SEED: 6, FOLD: 0, EPOCH: 18, train_loss: 0.01863956791222901\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016110001919934384\n",
      "SEED: 6, FOLD: 0, EPOCH: 19, train_loss: 0.018315710454575113\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 19, valid_loss: 0.015915110492362425\n",
      "SEED: 6, FOLD: 0, EPOCH: 20, train_loss: 0.017962342505720822\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01589444301162775\n",
      "SEED: 6, FOLD: 0, EPOCH: 21, train_loss: 0.017530147288296674\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015763755959387008\n",
      "SEED: 6, FOLD: 0, EPOCH: 22, train_loss: 0.017073612144166552\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01578403228464035\n",
      "SEED: 6, FOLD: 0, EPOCH: 23, train_loss: 0.016718810764015525\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01569622905495075\n",
      "SEED: 6, FOLD: 0, EPOCH: 24, train_loss: 0.016390845494193805\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01574915196173466\n",
      "SEED: 6, FOLD: 0, EPOCH: 25, train_loss: 0.016258851423658228\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 25, valid_loss: 0.015744339459790632\n",
      "SEED: 6, FOLD: 1, EPOCH: 0, train_loss: 0.589285912042534\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 0, valid_loss: 0.09866802680950898\n",
      "SEED: 6, FOLD: 1, EPOCH: 1, train_loss: 0.029579773998341045\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 1, valid_loss: 0.019648291027316682\n",
      "SEED: 6, FOLD: 1, EPOCH: 2, train_loss: 0.021777261149238895\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 2, valid_loss: 0.02474538064919985\n",
      "SEED: 6, FOLD: 1, EPOCH: 3, train_loss: 0.021609800741881936\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 3, valid_loss: 0.01758532441006257\n",
      "SEED: 6, FOLD: 1, EPOCH: 4, train_loss: 0.020588789563122635\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017504759562703278\n",
      "SEED: 6, FOLD: 1, EPOCH: 5, train_loss: 0.02028694685951278\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 5, valid_loss: 0.01725268320968518\n",
      "SEED: 6, FOLD: 1, EPOCH: 6, train_loss: 0.0201353353473383\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017711991014388893\n",
      "SEED: 6, FOLD: 1, EPOCH: 7, train_loss: 0.02003096743814043\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017177400107567128\n",
      "SEED: 6, FOLD: 1, EPOCH: 8, train_loss: 0.020004894559246464\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 8, valid_loss: 0.016995195442667373\n",
      "SEED: 6, FOLD: 1, EPOCH: 9, train_loss: 0.019882735972468916\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01710533293393942\n",
      "SEED: 6, FOLD: 1, EPOCH: 10, train_loss: 0.019851556047797203\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01714855690415089\n",
      "SEED: 6, FOLD: 1, EPOCH: 11, train_loss: 0.01984612477590909\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017091801246771447\n",
      "SEED: 6, FOLD: 1, EPOCH: 12, train_loss: 0.019747262946455867\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016895585048657197\n",
      "SEED: 6, FOLD: 1, EPOCH: 13, train_loss: 0.019578625397706353\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01718071002799731\n",
      "SEED: 6, FOLD: 1, EPOCH: 14, train_loss: 0.019573408757915366\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016588862268970564\n",
      "SEED: 6, FOLD: 1, EPOCH: 15, train_loss: 0.019319100003387477\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01667975505384115\n",
      "SEED: 6, FOLD: 1, EPOCH: 16, train_loss: 0.01915003832530331\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016499856486916542\n",
      "SEED: 6, FOLD: 1, EPOCH: 17, train_loss: 0.018918310996849794\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016575449361250952\n",
      "SEED: 6, FOLD: 1, EPOCH: 18, train_loss: 0.018645672580680332\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 18, valid_loss: 0.0162900542983642\n",
      "SEED: 6, FOLD: 1, EPOCH: 19, train_loss: 0.018301145047754853\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016220439583636247\n",
      "SEED: 6, FOLD: 1, EPOCH: 20, train_loss: 0.01795830116984812\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 20, valid_loss: 0.01625505741685629\n",
      "SEED: 6, FOLD: 1, EPOCH: 21, train_loss: 0.017551212470877816\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 21, valid_loss: 0.016119527272306956\n",
      "SEED: 6, FOLD: 1, EPOCH: 22, train_loss: 0.017161691007581917\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 22, valid_loss: 0.016017983166071083\n",
      "SEED: 6, FOLD: 1, EPOCH: 23, train_loss: 0.016813496240993608\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 23, valid_loss: 0.016042848475850545\n",
      "SEED: 6, FOLD: 2, EPOCH: 0, train_loss: 0.5882958193888536\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 0, valid_loss: 0.08708630215663177\n",
      "SEED: 6, FOLD: 2, EPOCH: 1, train_loss: 0.02963861045301766\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 1, valid_loss: 0.01986218630694426\n",
      "SEED: 6, FOLD: 2, EPOCH: 2, train_loss: 0.021771027303829387\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 2, valid_loss: 0.01824775839654299\n",
      "SEED: 6, FOLD: 2, EPOCH: 3, train_loss: 0.0210216563648066\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 3, valid_loss: 0.018658624675411444\n",
      "SEED: 6, FOLD: 2, EPOCH: 4, train_loss: 0.020509219023625593\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 4, valid_loss: 0.018798283372934047\n",
      "SEED: 6, FOLD: 2, EPOCH: 5, train_loss: 0.020164787643463224\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01720503459756191\n",
      "SEED: 6, FOLD: 2, EPOCH: 6, train_loss: 0.0201230023207294\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 6, valid_loss: 0.0172253017528699\n",
      "SEED: 6, FOLD: 2, EPOCH: 7, train_loss: 0.019996548373554204\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017162123121894322\n",
      "SEED: 6, FOLD: 2, EPOCH: 8, train_loss: 0.019986771852583497\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017193139745638922\n",
      "SEED: 6, FOLD: 2, EPOCH: 9, train_loss: 0.019986116453199775\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 9, valid_loss: 0.016996501586758174\n",
      "SEED: 6, FOLD: 2, EPOCH: 10, train_loss: 0.019925341589023936\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017356069901814826\n",
      "SEED: 6, FOLD: 2, EPOCH: 11, train_loss: 0.019935349002480507\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016939409363728303\n",
      "SEED: 6, FOLD: 2, EPOCH: 12, train_loss: 0.019825760199612862\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016933214635803148\n",
      "SEED: 6, FOLD: 2, EPOCH: 13, train_loss: 0.019699035086543172\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 13, valid_loss: 0.01684932539669367\n",
      "SEED: 6, FOLD: 2, EPOCH: 14, train_loss: 0.01960780647759502\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01676619568696389\n",
      "SEED: 6, FOLD: 2, EPOCH: 15, train_loss: 0.019393963462396246\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016541757334310275\n",
      "SEED: 6, FOLD: 2, EPOCH: 16, train_loss: 0.019187550186305434\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01651220080944208\n",
      "SEED: 6, FOLD: 2, EPOCH: 17, train_loss: 0.019000531979710668\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016407038300083235\n",
      "SEED: 6, FOLD: 2, EPOCH: 18, train_loss: 0.01868908089661115\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016313797507721644\n",
      "SEED: 6, FOLD: 2, EPOCH: 19, train_loss: 0.018350148724543082\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 19, valid_loss: 0.0161414470237035\n",
      "SEED: 6, FOLD: 2, EPOCH: 20, train_loss: 0.017981179373187793\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 20, valid_loss: 0.016070334384074576\n",
      "SEED: 6, FOLD: 2, EPOCH: 21, train_loss: 0.017597058951552655\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 21, valid_loss: 0.015962492674589157\n",
      "SEED: 6, FOLD: 2, EPOCH: 22, train_loss: 0.017159822824839\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01597417962665741\n",
      "SEED: 6, FOLD: 2, EPOCH: 23, train_loss: 0.01676156515305912\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015963685555526845\n",
      "SEED: 6, FOLD: 2, EPOCH: 24, train_loss: 0.01647284420559535\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 24, valid_loss: 0.015930922988515634\n",
      "SEED: 6, FOLD: 2, EPOCH: 25, train_loss: 0.016368326718440733\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 25, valid_loss: 0.015921498648822308\n",
      "SEED: 6, FOLD: 3, EPOCH: 0, train_loss: 0.5863452221493464\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 0, valid_loss: 0.07933423095024549\n",
      "SEED: 6, FOLD: 3, EPOCH: 1, train_loss: 0.030172888642630062\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 1, valid_loss: 0.019753769040107727\n",
      "SEED: 6, FOLD: 3, EPOCH: 2, train_loss: 0.021946435013936984\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018235723273112223\n",
      "SEED: 6, FOLD: 3, EPOCH: 3, train_loss: 0.021137389731970994\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 3, valid_loss: 0.017869358882308006\n",
      "SEED: 6, FOLD: 3, EPOCH: 4, train_loss: 0.020478295565054223\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017537745718772594\n",
      "SEED: 6, FOLD: 3, EPOCH: 5, train_loss: 0.020274640035790367\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 5, valid_loss: 0.01747297108746492\n",
      "SEED: 6, FOLD: 3, EPOCH: 6, train_loss: 0.020091454825691274\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01724167397389045\n",
      "SEED: 6, FOLD: 3, EPOCH: 7, train_loss: 0.019946347469010868\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017372642285548724\n",
      "SEED: 6, FOLD: 3, EPOCH: 8, train_loss: 0.019976760789349273\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 8, valid_loss: 0.01706273237673136\n",
      "SEED: 6, FOLD: 3, EPOCH: 9, train_loss: 0.020003220720871073\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 9, valid_loss: 0.016967710967247304\n",
      "SEED: 6, FOLD: 3, EPOCH: 10, train_loss: 0.019866800086723792\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 10, valid_loss: 0.01713551924778865\n",
      "SEED: 6, FOLD: 3, EPOCH: 11, train_loss: 0.019814280516191107\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01699390892799084\n",
      "SEED: 6, FOLD: 3, EPOCH: 12, train_loss: 0.019717884124130815\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016707623878923748\n",
      "SEED: 6, FOLD: 3, EPOCH: 13, train_loss: 0.019603490124683123\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016659424711878482\n",
      "SEED: 6, FOLD: 3, EPOCH: 14, train_loss: 0.01951161545474787\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01677312171803071\n",
      "SEED: 6, FOLD: 3, EPOCH: 15, train_loss: 0.01936209080992518\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016824695496604994\n",
      "SEED: 6, FOLD: 3, EPOCH: 16, train_loss: 0.0191548755644141\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016580647717301663\n",
      "SEED: 6, FOLD: 3, EPOCH: 17, train_loss: 0.018903744960757526\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016374641169722263\n",
      "SEED: 6, FOLD: 3, EPOCH: 18, train_loss: 0.01856642752583768\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016368472160628207\n",
      "SEED: 6, FOLD: 3, EPOCH: 19, train_loss: 0.018279818792802258\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01627039622802001\n",
      "SEED: 6, FOLD: 3, EPOCH: 20, train_loss: 0.017907319741474616\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 20, valid_loss: 0.01620104708350622\n",
      "SEED: 6, FOLD: 3, EPOCH: 21, train_loss: 0.017444028657533833\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016132505109103825\n",
      "SEED: 6, FOLD: 3, EPOCH: 22, train_loss: 0.017013384444588744\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 22, valid_loss: 0.016129785432265356\n",
      "SEED: 6, FOLD: 3, EPOCH: 23, train_loss: 0.01655611053511903\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01608763377253826\n",
      "SEED: 6, FOLD: 3, EPOCH: 24, train_loss: 0.016245773414502274\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016073027195838783\n",
      "SEED: 6, FOLD: 3, EPOCH: 25, train_loss: 0.016174562149555295\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 25, valid_loss: 0.016070836152021702\n",
      "SEED: 6, FOLD: 4, EPOCH: 0, train_loss: 0.5866546764768459\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 0, valid_loss: 0.0911297551714457\n",
      "SEED: 6, FOLD: 4, EPOCH: 1, train_loss: 0.029877974777608306\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 1, valid_loss: 0.020025096403864715\n",
      "SEED: 6, FOLD: 4, EPOCH: 2, train_loss: 0.021897557367746893\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018513367869533025\n",
      "SEED: 6, FOLD: 4, EPOCH: 3, train_loss: 0.02113549461638605\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01801519038585516\n",
      "SEED: 6, FOLD: 4, EPOCH: 4, train_loss: 0.02038102753057673\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017663385145939313\n",
      "SEED: 6, FOLD: 4, EPOCH: 5, train_loss: 0.020127468893455493\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 5, valid_loss: 0.01732157156444513\n",
      "SEED: 6, FOLD: 4, EPOCH: 6, train_loss: 0.020036858707867766\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017210753348011237\n",
      "SEED: 6, FOLD: 4, EPOCH: 7, train_loss: 0.01995341369026416\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01780978848154728\n",
      "SEED: 6, FOLD: 4, EPOCH: 8, train_loss: 0.01988836093428167\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017191895212118443\n",
      "SEED: 6, FOLD: 4, EPOCH: 9, train_loss: 0.019882170659666125\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017135518674667064\n",
      "SEED: 6, FOLD: 4, EPOCH: 10, train_loss: 0.019824109896010644\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 10, valid_loss: 0.0169550608843565\n",
      "SEED: 6, FOLD: 4, EPOCH: 11, train_loss: 0.01972169814178267\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 11, valid_loss: 0.017084526757781323\n",
      "SEED: 6, FOLD: 4, EPOCH: 12, train_loss: 0.019714313659917663\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 12, valid_loss: 0.017007416830613062\n",
      "SEED: 6, FOLD: 4, EPOCH: 13, train_loss: 0.019633394464649057\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01695834257854865\n",
      "SEED: 6, FOLD: 4, EPOCH: 14, train_loss: 0.019465254972109925\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016794849688617084\n",
      "SEED: 6, FOLD: 4, EPOCH: 15, train_loss: 0.019296571134111366\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016664327767032843\n",
      "SEED: 6, FOLD: 4, EPOCH: 16, train_loss: 0.01912819083175949\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016743274190678045\n",
      "SEED: 6, FOLD: 4, EPOCH: 17, train_loss: 0.01890880455942573\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01658885574971254\n",
      "SEED: 6, FOLD: 4, EPOCH: 18, train_loss: 0.018622729700763483\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016317778553527135\n",
      "SEED: 6, FOLD: 4, EPOCH: 19, train_loss: 0.018244744354003185\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01632201148626896\n",
      "SEED: 6, FOLD: 4, EPOCH: 20, train_loss: 0.017888323202527857\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 20, valid_loss: 0.0162707634556752\n",
      "SEED: 6, FOLD: 4, EPOCH: 21, train_loss: 0.01756942126195173\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 21, valid_loss: 0.016208809442245044\n",
      "SEED: 6, FOLD: 4, EPOCH: 22, train_loss: 0.017110372138385836\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 22, valid_loss: 0.016164429414157685\n",
      "SEED: 6, FOLD: 4, EPOCH: 23, train_loss: 0.016749042350597477\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 23, valid_loss: 0.016119808460084293\n",
      "SEED: 6, FOLD: 4, EPOCH: 24, train_loss: 0.016458824390193093\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01610615956955231\n",
      "SEED: 6, FOLD: 4, EPOCH: 25, train_loss: 0.016368684170113224\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 25, valid_loss: 0.016114672645926476\n",
      "SEED: 6, FOLD: 5, EPOCH: 0, train_loss: 0.5881206542253494\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 0, valid_loss: 0.09034576668189122\n",
      "SEED: 6, FOLD: 5, EPOCH: 1, train_loss: 0.029451346931022568\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 1, valid_loss: 0.020153693568248015\n",
      "SEED: 6, FOLD: 5, EPOCH: 2, train_loss: 0.021800636112488603\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 2, valid_loss: 0.01863067031193238\n",
      "SEED: 6, FOLD: 5, EPOCH: 3, train_loss: 0.020914208773221518\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 3, valid_loss: 0.03291937422293883\n",
      "SEED: 6, FOLD: 5, EPOCH: 4, train_loss: 0.0203302876419715\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 4, valid_loss: 0.017879207690174762\n",
      "SEED: 6, FOLD: 5, EPOCH: 5, train_loss: 0.02008599760262547\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 5, valid_loss: 0.017176454815153893\n",
      "SEED: 6, FOLD: 5, EPOCH: 6, train_loss: 0.01998039986938238\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 6, valid_loss: 0.017044036649167538\n",
      "SEED: 6, FOLD: 5, EPOCH: 7, train_loss: 0.019928133039659745\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 7, valid_loss: 0.017183579289569303\n",
      "SEED: 6, FOLD: 5, EPOCH: 8, train_loss: 0.019953768876557414\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 8, valid_loss: 0.017136874608695507\n",
      "SEED: 6, FOLD: 5, EPOCH: 9, train_loss: 0.01992879984145229\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 9, valid_loss: 0.01705520277699599\n",
      "SEED: 6, FOLD: 5, EPOCH: 10, train_loss: 0.01984179573687347\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 10, valid_loss: 0.016968066732470807\n",
      "SEED: 6, FOLD: 5, EPOCH: 11, train_loss: 0.019856934460836487\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 11, valid_loss: 0.016931330498594504\n",
      "SEED: 6, FOLD: 5, EPOCH: 12, train_loss: 0.019693861287590618\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 12, valid_loss: 0.016776220872998238\n",
      "SEED: 6, FOLD: 5, EPOCH: 13, train_loss: 0.01957532456396399\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 13, valid_loss: 0.016772297569192372\n",
      "SEED: 6, FOLD: 5, EPOCH: 14, train_loss: 0.01950583151365454\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 14, valid_loss: 0.016699635352079686\n",
      "SEED: 6, FOLD: 5, EPOCH: 15, train_loss: 0.01929170243140008\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 15, valid_loss: 0.01672528075197568\n",
      "SEED: 6, FOLD: 5, EPOCH: 16, train_loss: 0.01913527416921145\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 16, valid_loss: 0.01658662250981881\n",
      "SEED: 6, FOLD: 5, EPOCH: 17, train_loss: 0.018866376724798937\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 17, valid_loss: 0.01645176220112122\n",
      "SEED: 6, FOLD: 5, EPOCH: 18, train_loss: 0.018597821251967468\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 18, valid_loss: 0.016293040476739407\n",
      "SEED: 6, FOLD: 5, EPOCH: 19, train_loss: 0.018277360629793758\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 19, valid_loss: 0.01607706268819479\n",
      "SEED: 6, FOLD: 5, EPOCH: 20, train_loss: 0.017898384683035517\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 20, valid_loss: 0.016110913971295722\n",
      "SEED: 6, FOLD: 5, EPOCH: 21, train_loss: 0.0174826482763967\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 21, valid_loss: 0.016043294579363786\n",
      "SEED: 6, FOLD: 5, EPOCH: 22, train_loss: 0.017093167879392166\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 22, valid_loss: 0.01602768382200828\n",
      "SEED: 6, FOLD: 5, EPOCH: 23, train_loss: 0.016700658292786497\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 23, valid_loss: 0.015955757421369735\n",
      "SEED: 6, FOLD: 5, EPOCH: 24, train_loss: 0.016476676069401407\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 24, valid_loss: 0.015946425282611296\n",
      "SEED: 6, FOLD: 5, EPOCH: 25, train_loss: 0.016374527111750196\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 25, valid_loss: 0.01595685423280184\n",
      "SEED: 6, FOLD: 6, EPOCH: 0, train_loss: 0.5884976709211195\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 0, valid_loss: 0.09229978919029236\n",
      "SEED: 6, FOLD: 6, EPOCH: 1, train_loss: 0.029509963190837485\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 1, valid_loss: 0.019929712208417747\n",
      "SEED: 6, FOLD: 6, EPOCH: 2, train_loss: 0.021832366801194242\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 2, valid_loss: 0.01801747241272376\n",
      "SEED: 6, FOLD: 6, EPOCH: 3, train_loss: 0.021214472230624507\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 3, valid_loss: 0.017553066834807396\n",
      "SEED: 6, FOLD: 6, EPOCH: 4, train_loss: 0.02034252096672316\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 4, valid_loss: 0.01739288981144245\n",
      "SEED: 6, FOLD: 6, EPOCH: 5, train_loss: 0.020157286444225826\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 5, valid_loss: 0.018335886156329743\n",
      "SEED: 6, FOLD: 6, EPOCH: 6, train_loss: 0.02002665030493124\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 6, valid_loss: 0.017621321317095023\n",
      "SEED: 6, FOLD: 6, EPOCH: 7, train_loss: 0.01997523143182735\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 7, valid_loss: 0.01700177315909129\n",
      "SEED: 6, FOLD: 6, EPOCH: 8, train_loss: 0.0199587013874505\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 8, valid_loss: 0.0170821097607796\n",
      "SEED: 6, FOLD: 6, EPOCH: 9, train_loss: 0.019867629265865765\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 9, valid_loss: 0.017123195844200943\n",
      "SEED: 6, FOLD: 6, EPOCH: 10, train_loss: 0.019842873503630225\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 10, valid_loss: 0.01720800895530444\n",
      "SEED: 6, FOLD: 6, EPOCH: 11, train_loss: 0.01983824636585809\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 11, valid_loss: 0.017022136097344067\n",
      "SEED: 6, FOLD: 6, EPOCH: 12, train_loss: 0.019652197917772306\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 12, valid_loss: 0.016762265720619604\n",
      "SEED: 6, FOLD: 6, EPOCH: 13, train_loss: 0.01953293936880859\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 13, valid_loss: 0.01683658741127986\n",
      "SEED: 6, FOLD: 6, EPOCH: 14, train_loss: 0.019410678990990728\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 14, valid_loss: 0.016698676591309216\n",
      "SEED: 6, FOLD: 6, EPOCH: 15, train_loss: 0.019309685792069178\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 15, valid_loss: 0.016829201378501378\n",
      "SEED: 6, FOLD: 6, EPOCH: 16, train_loss: 0.019124013447278255\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 16, valid_loss: 0.01662954344199254\n",
      "SEED: 6, FOLD: 6, EPOCH: 17, train_loss: 0.018879718751319358\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 17, valid_loss: 0.01656271545932843\n",
      "SEED: 6, FOLD: 6, EPOCH: 18, train_loss: 0.01854512344643071\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 18, valid_loss: 0.01631865607431302\n",
      "SEED: 6, FOLD: 6, EPOCH: 19, train_loss: 0.018192487517120066\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 19, valid_loss: 0.016332976161860503\n",
      "SEED: 6, FOLD: 6, EPOCH: 20, train_loss: 0.017852826950115128\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 20, valid_loss: 0.01618184005984893\n",
      "SEED: 6, FOLD: 6, EPOCH: 21, train_loss: 0.017378664575517178\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 21, valid_loss: 0.016118094253425416\n",
      "SEED: 6, FOLD: 6, EPOCH: 22, train_loss: 0.016961647562581946\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 22, valid_loss: 0.016111878033440847\n",
      "SEED: 6, FOLD: 6, EPOCH: 23, train_loss: 0.01655415617986708\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 23, valid_loss: 0.01610974272569785\n",
      "SEED: 6, FOLD: 6, EPOCH: 24, train_loss: 0.016252236981951707\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 24, valid_loss: 0.016066758463589046\n",
      "SEED: 6, FOLD: 6, EPOCH: 25, train_loss: 0.016134424890215333\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 25, valid_loss: 0.016098897331036054\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "SEED = [0,1,2,3,4,5,6]  #<-- Update\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d41197f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T13:05:02.564070Z",
     "iopub.status.busy": "2025-03-31T13:05:02.563679Z",
     "iopub.status.idle": "2025-03-31T13:05:05.389217Z",
     "shell.execute_reply": "2025-03-31T13:05:05.388296Z"
    },
    "papermill": {
     "duration": 2.934009,
     "end_time": "2025-03-31T13:05:05.390841",
     "exception": false,
     "start_time": "2025-03-31T13:05:02.456832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.014527721324469592\n",
      "Overall AUC:  0.8259878304530845\n"
     ]
    }
   ],
   "source": [
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "cv_score = 0\n",
    "roc_score = 0\n",
    "\n",
    "for i in range(len(target_cols)):\n",
    "    cv_score += log_loss(y_true[:, i], y_pred[:, i])\n",
    "    roc_score +=roc_auc_score(y_true[:, i], y_pred[:, i], average='micro')\n",
    "\n",
    "print(\"CV log_loss: \", cv_score / y_pred.shape[1])\n",
    "print(\"Overall AUC: \", roc_score / y_pred.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39f166f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T13:05:05.590216Z",
     "iopub.status.busy": "2025-03-31T13:05:05.589884Z",
     "iopub.status.idle": "2025-03-31T13:05:12.292670Z",
     "shell.execute_reply": "2025-03-31T13:05:12.291970Z"
    },
    "papermill": {
     "duration": 6.802024,
     "end_time": "2025-03-31T13:05:12.294390",
     "exception": false,
     "start_time": "2025-03-31T13:05:05.492366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "oof_pretrain= valid_results[target_cols]\n",
    "oof_pretrain.to_csv('off_pretrain_last.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38c8b016",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T13:05:12.541017Z",
     "iopub.status.busy": "2025-03-31T13:05:12.540674Z",
     "iopub.status.idle": "2025-03-31T13:05:13.519117Z",
     "shell.execute_reply": "2025-03-31T13:05:13.518349Z"
    },
    "papermill": {
     "duration": 1.127507,
     "end_time": "2025-03-31T13:05:13.520737",
     "exception": false,
     "start_time": "2025-03-31T13:05:12.393230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "public_id = list(df['sig_id'].values)\n",
    "test_id = list(test_features['sig_id'].values)\n",
    "private_id = list(set(test_id)-set(public_id))\n",
    "df_submit = pd.DataFrame(index = public_id+private_id, columns=target_cols)\n",
    "df_submit.index.name = 'sig_id'\n",
    "df_submit[:] = 0\n",
    "df_submit.loc[test.sig_id,:] = test[target_cols].values\n",
    "df_submit.loc[test_features[test_features.cp_type=='ctl_vehicle'].sig_id]= 0\n",
    "df_submit.to_csv('submission.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fc6a6d",
   "metadata": {
    "papermill": {
     "duration": 0.097758,
     "end_time": "2025-03-31T13:05:13.723600",
     "exception": false,
     "start_time": "2025-03-31T13:05:13.625842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Your support motivates me to share kernels like these ... so please \" Do UPVOTE \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c23812",
   "metadata": {
    "papermill": {
     "duration": 0.096574,
     "end_time": "2025-03-31T13:05:13.917356",
     "exception": false,
     "start_time": "2025-03-31T13:05:13.820782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1651354,
     "sourceId": 19988,
     "sourceType": "competition"
    },
    {
     "datasetId": 877310,
     "sourceId": 1494119,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3389.645303,
   "end_time": "2025-03-31T13:05:16.486877",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-31T12:08:46.841574",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
