{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9681825",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-21T11:52:49.031192Z",
     "iopub.status.busy": "2025-03-21T11:52:49.030968Z",
     "iopub.status.idle": "2025-03-21T11:52:54.421048Z",
     "shell.execute_reply": "2025-03-21T11:52:54.420309Z"
    },
    "papermill": {
     "duration": 5.399277,
     "end_time": "2025-03-21T11:52:54.422592",
     "exception": false,
     "start_time": "2025-03-21T11:52:49.023315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/iterative-stratification/iterative_stratification-0.1.9-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from iterative-stratification==0.1.9) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from iterative-stratification==0.1.9) (1.13.1)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from iterative-stratification==0.1.9) (1.2.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->iterative-stratification==0.1.9) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->iterative-stratification==0.1.9) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->iterative-stratification==0.1.9) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->iterative-stratification==0.1.9) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->iterative-stratification==0.1.9) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->iterative-stratification==0.1.9) (2.4.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->iterative-stratification==0.1.9) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->iterative-stratification==0.1.9) (3.5.0)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->iterative-stratification==0.1.9) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->iterative-stratification==0.1.9) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->iterative-stratification==0.1.9) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->iterative-stratification==0.1.9) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->iterative-stratification==0.1.9) (2024.2.0)\r\n",
      "Installing collected packages: iterative-stratification\r\n",
      "Successfully installed iterative-stratification-0.1.9\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#sys.path.append('../input/iterativestratification')\n",
    "#!pip install iterative-stratification\n",
    "#!pip download iterative-stratification -d ./package\n",
    "!pip install /kaggle/input/iterative-stratification/iterative_stratification-0.1.9-py3-none-any.whl\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e04803e",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2025-03-21T11:52:54.436814Z",
     "iopub.status.busy": "2025-03-21T11:52:54.436477Z",
     "iopub.status.idle": "2025-03-21T11:52:58.747705Z",
     "shell.execute_reply": "2025-03-21T11:52:58.746998Z"
    },
    "papermill": {
     "duration": 4.319851,
     "end_time": "2025-03-21T11:52:58.749405",
     "exception": false,
     "start_time": "2025-03-21T11:52:54.429554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA,FactorAnalysis\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "740ce76a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T11:52:58.763480Z",
     "iopub.status.busy": "2025-03-21T11:52:58.763131Z",
     "iopub.status.idle": "2025-03-21T11:52:58.766626Z",
     "shell.execute_reply": "2025-03-21T11:52:58.765802Z"
    },
    "papermill": {
     "duration": 0.011712,
     "end_time": "2025-03-21T11:52:58.767962",
     "exception": false,
     "start_time": "2025-03-21T11:52:58.756250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71293a52",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-03-21T11:52:58.781558Z",
     "iopub.status.busy": "2025-03-21T11:52:58.781355Z",
     "iopub.status.idle": "2025-03-21T11:52:58.787449Z",
     "shell.execute_reply": "2025-03-21T11:52:58.786825Z"
    },
    "papermill": {
     "duration": 0.014139,
     "end_time": "2025-03-21T11:52:58.788508",
     "exception": false,
     "start_time": "2025-03-21T11:52:58.774369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_targets_scored.csv',\n",
       " 'sample_submission.csv',\n",
       " 'train_drug.csv',\n",
       " 'train_targets_nonscored.csv',\n",
       " 'train_features.csv',\n",
       " 'test_features.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/lish-moa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a517ae90",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-03-21T11:52:58.802293Z",
     "iopub.status.busy": "2025-03-21T11:52:58.802070Z",
     "iopub.status.idle": "2025-03-21T11:53:05.008644Z",
     "shell.execute_reply": "2025-03-21T11:53:05.007956Z"
    },
    "papermill": {
     "duration": 6.21511,
     "end_time": "2025-03-21T11:53:05.010234",
     "exception": false,
     "start_time": "2025-03-21T11:52:58.795124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "sample_submission = pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adfbf6fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T11:53:05.025678Z",
     "iopub.status.busy": "2025-03-21T11:53:05.025388Z",
     "iopub.status.idle": "2025-03-21T11:53:05.030767Z",
     "shell.execute_reply": "2025-03-21T11:53:05.029935Z"
    },
    "papermill": {
     "duration": 0.014294,
     "end_time": "2025-03-21T11:53:05.031940",
     "exception": false,
     "start_time": "2025-03-21T11:53:05.017646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772 100\n"
     ]
    }
   ],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]\n",
    "print(len(GENES),len(CELLS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8f88b62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T11:53:05.045827Z",
     "iopub.status.busy": "2025-03-21T11:53:05.045579Z",
     "iopub.status.idle": "2025-03-21T11:53:05.048768Z",
     "shell.execute_reply": "2025-03-21T11:53:05.047970Z"
    },
    "papermill": {
     "duration": 0.011444,
     "end_time": "2025-03-21T11:53:05.050001",
     "exception": false,
     "start_time": "2025-03-21T11:53:05.038557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IS_TRAIN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e33a2a7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T11:53:05.064243Z",
     "iopub.status.busy": "2025-03-21T11:53:05.064027Z",
     "iopub.status.idle": "2025-03-21T12:14:25.310980Z",
     "shell.execute_reply": "2025-03-21T12:14:25.309972Z"
    },
    "papermill": {
     "duration": 1280.262547,
     "end_time": "2025-03-21T12:14:25.319357",
     "exception": false,
     "start_time": "2025-03-21T11:53:05.056810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 876)\n",
      "(3982, 876)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for col in (GENES + CELLS):\n",
    "\n",
    "  #  transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n",
    "    vec_len = len(train_features[col].values)\n",
    "    vec_len_test = len(test_features[col].values)\n",
    "    raw_vec = train_features[col].values.reshape(vec_len, 1)\n",
    "    if IS_TRAIN:\n",
    "        transformer = QuantileTransformer(n_quantiles=100, random_state=0, output_distribution=\"normal\")\n",
    "        transformer.fit(raw_vec)\n",
    "        #pd.to_pickle(transformer, f'{col}_quantile_transformer.pkl')\n",
    "    #else:\n",
    "        #transformer = pd.read_pickle(f'{col}_quantile_transformer.pkl')        \n",
    "\n",
    "\n",
    "    train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]\n",
    "    test_train_features=np.array(train_features)\n",
    "    test_test_feature=np.array(test_features)\n",
    "print(test_train_features.shape)\n",
    "print(test_test_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b94ca3c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:14:25.333164Z",
     "iopub.status.busy": "2025-03-21T12:14:25.332886Z",
     "iopub.status.idle": "2025-03-21T12:14:25.340865Z",
     "shell.execute_reply": "2025-03-21T12:14:25.340293Z"
    },
    "papermill": {
     "duration": 0.016107,
     "end_time": "2025-03-21T12:14:25.341988",
     "exception": false,
     "start_time": "2025-03-21T12:14:25.325881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f3988e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:14:25.355849Z",
     "iopub.status.busy": "2025-03-21T12:14:25.355637Z",
     "iopub.status.idle": "2025-03-21T12:14:31.925580Z",
     "shell.execute_reply": "2025-03-21T12:14:31.924807Z"
    },
    "papermill": {
     "duration": 6.57863,
     "end_time": "2025-03-21T12:14:31.927162",
     "exception": false,
     "start_time": "2025-03-21T12:14:25.348532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GENES\n",
    "n_comp = 90  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "#data2 = (FactorAnalysis(n_components=n_comp, random_state=42).fit_transform(data[GENES]))\n",
    "if IS_TRAIN:\n",
    "    fa = FactorAnalysis(n_components=n_comp, random_state=1903).fit(data[GENES])\n",
    "    #pd.to_pickle(fa, f'factor_analysis_g.pkl')\n",
    "    #umap = UMAP(n_components=n_dim, random_state=1903).fit(data[GENES])\n",
    "    #pd.to_pickle(umap, f'{MODEL_DIR}/{NB}_umap_g.pkl')\n",
    "#else:\n",
    "    #fa = pd.read_pickle(f'factor_analysis_g.pkl')\n",
    "    #umap = pd.read_pickle(f'{MODEL_DIR}/{NB}_umap_g.pkl')\n",
    "data2 = fa.transform(data[GENES])\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4248852f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:14:31.941655Z",
     "iopub.status.busy": "2025-03-21T12:14:31.941423Z",
     "iopub.status.idle": "2025-03-21T12:14:33.638381Z",
     "shell.execute_reply": "2025-03-21T12:14:33.637650Z"
    },
    "papermill": {
     "duration": 1.705777,
     "end_time": "2025-03-21T12:14:33.639983",
     "exception": false,
     "start_time": "2025-03-21T12:14:31.934206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CELLS\n",
    "n_comp = 50  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "if IS_TRAIN:\n",
    "    fa = FactorAnalysis(n_components=n_comp, random_state=1903).fit(data[CELLS])\n",
    "    #pd.to_pickle(fa, f'factor_analysis_c.pkl')\n",
    "    #umap = UMAP(n_components=n_dim, random_state=1903).fit(data[GENES])\n",
    "    #pd.to_pickle(umap, f'{MODEL_DIR}/{NB}_umap_g.pkl')\n",
    "#else:\n",
    "    #fa = pd.read_pickle(f'factor_analysis_c.pkl')\n",
    "    #umap = pd.read_pickle(f'{MODEL_DIR}/{NB}_umap_g.pkl')\n",
    "data2 = fa.transform(data[CELLS])\n",
    "#data2 = (FactorAnalysis(n_components=n_comp, random_state=42).fit_transform(data[CELLS]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b34bc6d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:14:33.654569Z",
     "iopub.status.busy": "2025-03-21T12:14:33.654342Z",
     "iopub.status.idle": "2025-03-21T12:14:33.658991Z",
     "shell.execute_reply": "2025-03-21T12:14:33.658208Z"
    },
    "papermill": {
     "duration": 0.013167,
     "end_time": "2025-03-21T12:14:33.660316",
     "exception": false,
     "start_time": "2025-03-21T12:14:33.647149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sig_id', 'cp_type', 'cp_time', 'cp_dose', 'g-0', 'g-1', 'g-2', 'g-3',\n",
       "       'g-4', 'g-5',\n",
       "       ...\n",
       "       'pca_C-40', 'pca_C-41', 'pca_C-42', 'pca_C-43', 'pca_C-44', 'pca_C-45',\n",
       "       'pca_C-46', 'pca_C-47', 'pca_C-48', 'pca_C-49'],\n",
       "      dtype='object', length=1016)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape\n",
    "train_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b6d2c31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:14:33.674142Z",
     "iopub.status.busy": "2025-03-21T12:14:33.673936Z",
     "iopub.status.idle": "2025-03-21T12:14:40.702856Z",
     "shell.execute_reply": "2025-03-21T12:14:40.702046Z"
    },
    "papermill": {
     "duration": 7.037394,
     "end_time": "2025-03-21T12:14:40.704248",
     "exception": false,
     "start_time": "2025-03-21T12:14:33.666854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23814, 1015)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "#var_thresh = VarianceThreshold(0.8)  #<-- Update\n",
    "var_thresh = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n",
    "\n",
    "data = pd.concat([train_features, test_features], ignore_index=True)\n",
    "if IS_TRAIN:\n",
    "    transformer = QuantileTransformer(n_quantiles=100, random_state=123, output_distribution=\"normal\")\n",
    "    transformer.fit(data.iloc[:,5:])\n",
    "    #pd.to_pickle(transformer, f'{col}_quantile_transformer2.pkl')\n",
    "#else:\n",
    "    #transformer = pd.read_pickle(f'{col}_quantile_transformer2.pkl')  \n",
    "data_transformed = transformer.transform(data.iloc[:, 5:])\n",
    "\n",
    "train_features_transformed = data_transformed[ : train_features.shape[0]]\n",
    "test_features_transformed = data_transformed[-test_features.shape[0] : ]\n",
    "\n",
    "\n",
    "train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n",
    "\n",
    "\n",
    "test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n",
    "\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "890841e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:14:40.718791Z",
     "iopub.status.busy": "2025-03-21T12:14:40.718572Z",
     "iopub.status.idle": "2025-03-21T12:14:40.749251Z",
     "shell.execute_reply": "2025-03-21T12:14:40.748595Z"
    },
    "papermill": {
     "duration": 0.038975,
     "end_time": "2025-03-21T12:14:40.750329",
     "exception": false,
     "start_time": "2025-03-21T12:14:40.711354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>1001</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>1007</th>\n",
       "      <th>1008</th>\n",
       "      <th>1009</th>\n",
       "      <th>1010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.890073</td>\n",
       "      <td>-0.412189</td>\n",
       "      <td>-0.944830</td>\n",
       "      <td>-0.261746</td>\n",
       "      <td>-1.019905</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564399</td>\n",
       "      <td>-0.264961</td>\n",
       "      <td>2.052781</td>\n",
       "      <td>0.725427</td>\n",
       "      <td>2.004088</td>\n",
       "      <td>-0.538631</td>\n",
       "      <td>-0.391831</td>\n",
       "      <td>0.118504</td>\n",
       "      <td>1.139026</td>\n",
       "      <td>-0.492681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.666238</td>\n",
       "      <td>0.291031</td>\n",
       "      <td>0.094330</td>\n",
       "      <td>1.230592</td>\n",
       "      <td>0.663497</td>\n",
       "      <td>0.298448</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.317965</td>\n",
       "      <td>-0.490015</td>\n",
       "      <td>0.581155</td>\n",
       "      <td>0.757636</td>\n",
       "      <td>0.642792</td>\n",
       "      <td>0.302269</td>\n",
       "      <td>0.285574</td>\n",
       "      <td>1.135923</td>\n",
       "      <td>0.514133</td>\n",
       "      <td>0.889294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.928918</td>\n",
       "      <td>1.434467</td>\n",
       "      <td>-0.107724</td>\n",
       "      <td>-0.007338</td>\n",
       "      <td>1.469665</td>\n",
       "      <td>0.224107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232821</td>\n",
       "      <td>-0.269213</td>\n",
       "      <td>-1.666802</td>\n",
       "      <td>1.578149</td>\n",
       "      <td>-0.288255</td>\n",
       "      <td>0.206113</td>\n",
       "      <td>-0.813300</td>\n",
       "      <td>0.671201</td>\n",
       "      <td>0.840813</td>\n",
       "      <td>-0.571809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.281437</td>\n",
       "      <td>-0.437950</td>\n",
       "      <td>0.769865</td>\n",
       "      <td>2.327620</td>\n",
       "      <td>-0.850179</td>\n",
       "      <td>-2.326113</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.907963</td>\n",
       "      <td>0.201992</td>\n",
       "      <td>-0.597280</td>\n",
       "      <td>0.377508</td>\n",
       "      <td>-0.195342</td>\n",
       "      <td>-0.193072</td>\n",
       "      <td>0.343032</td>\n",
       "      <td>0.159275</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.231893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.496357</td>\n",
       "      <td>0.982277</td>\n",
       "      <td>0.987313</td>\n",
       "      <td>1.487840</td>\n",
       "      <td>-0.861976</td>\n",
       "      <td>-0.388252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317295</td>\n",
       "      <td>-1.804858</td>\n",
       "      <td>0.495281</td>\n",
       "      <td>-0.030676</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-0.895828</td>\n",
       "      <td>-2.334076</td>\n",
       "      <td>-0.251194</td>\n",
       "      <td>1.490739</td>\n",
       "      <td>0.997273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.033938</td>\n",
       "      <td>-0.234157</td>\n",
       "      <td>-0.765638</td>\n",
       "      <td>-0.702918</td>\n",
       "      <td>0.894022</td>\n",
       "      <td>0.725918</td>\n",
       "      <td>...</td>\n",
       "      <td>1.291270</td>\n",
       "      <td>0.614803</td>\n",
       "      <td>0.880556</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>-0.183727</td>\n",
       "      <td>0.949953</td>\n",
       "      <td>-0.887562</td>\n",
       "      <td>-0.628253</td>\n",
       "      <td>-0.303959</td>\n",
       "      <td>-0.925261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.574460</td>\n",
       "      <td>-0.584423</td>\n",
       "      <td>1.313386</td>\n",
       "      <td>-1.009899</td>\n",
       "      <td>0.827632</td>\n",
       "      <td>-0.317398</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.232952</td>\n",
       "      <td>1.464645</td>\n",
       "      <td>0.562763</td>\n",
       "      <td>1.259711</td>\n",
       "      <td>-0.983095</td>\n",
       "      <td>1.576557</td>\n",
       "      <td>-0.832365</td>\n",
       "      <td>-0.055082</td>\n",
       "      <td>-0.990865</td>\n",
       "      <td>-1.913727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.616060</td>\n",
       "      <td>0.307320</td>\n",
       "      <td>-1.124344</td>\n",
       "      <td>0.780588</td>\n",
       "      <td>-0.018413</td>\n",
       "      <td>-0.351035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.363167</td>\n",
       "      <td>-0.569549</td>\n",
       "      <td>2.009670</td>\n",
       "      <td>1.083905</td>\n",
       "      <td>-0.939400</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>-1.168008</td>\n",
       "      <td>1.222020</td>\n",
       "      <td>-0.427585</td>\n",
       "      <td>0.688047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.404122</td>\n",
       "      <td>0.452794</td>\n",
       "      <td>0.313924</td>\n",
       "      <td>1.089796</td>\n",
       "      <td>-0.041223</td>\n",
       "      <td>0.040732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.843405</td>\n",
       "      <td>0.226004</td>\n",
       "      <td>-1.963314</td>\n",
       "      <td>-0.509632</td>\n",
       "      <td>-1.475090</td>\n",
       "      <td>-0.732285</td>\n",
       "      <td>1.396649</td>\n",
       "      <td>0.453370</td>\n",
       "      <td>0.310334</td>\n",
       "      <td>1.618901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.544298</td>\n",
       "      <td>-0.265196</td>\n",
       "      <td>1.103513</td>\n",
       "      <td>-0.527464</td>\n",
       "      <td>-2.120578</td>\n",
       "      <td>-1.619244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647490</td>\n",
       "      <td>-0.836719</td>\n",
       "      <td>-0.407389</td>\n",
       "      <td>0.130110</td>\n",
       "      <td>0.200374</td>\n",
       "      <td>-0.360941</td>\n",
       "      <td>-0.399136</td>\n",
       "      <td>0.578968</td>\n",
       "      <td>-0.431915</td>\n",
       "      <td>-0.769602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 1015 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id      cp_type cp_time cp_dose         0         1  \\\n",
       "0      id_000644bb2       trt_cp      24      D1  0.890073 -0.412189   \n",
       "1      id_000779bfc       trt_cp      72      D1  0.666238  0.291031   \n",
       "2      id_000a6266a       trt_cp      48      D1  0.928918  1.434467   \n",
       "3      id_0015fd391       trt_cp      48      D1 -0.281437 -0.437950   \n",
       "4      id_001626bd3       trt_cp      72      D2 -0.496357  0.982277   \n",
       "...             ...          ...     ...     ...       ...       ...   \n",
       "23809  id_fffb1ceed       trt_cp      24      D2 -0.033938 -0.234157   \n",
       "23810  id_fffb70c0c       trt_cp      24      D2  0.574460 -0.584423   \n",
       "23811  id_fffc1c3f4  ctl_vehicle      48      D2  0.616060  0.307320   \n",
       "23812  id_fffcb9e7c       trt_cp      24      D1  0.404122  0.452794   \n",
       "23813  id_ffffdd77b       trt_cp      72      D1  1.544298 -0.265196   \n",
       "\n",
       "              2         3         4         5  ...      1001      1002  \\\n",
       "0     -0.944830 -0.261746 -1.019905 -1.357832  ...  0.564399 -0.264961   \n",
       "1      0.094330  1.230592  0.663497  0.298448  ... -0.317965 -0.490015   \n",
       "2     -0.107724 -0.007338  1.469665  0.224107  ...  0.232821 -0.269213   \n",
       "3      0.769865  2.327620 -0.850179 -2.326113  ... -0.907963  0.201992   \n",
       "4      0.987313  1.487840 -0.861976 -0.388252  ...  0.317295 -1.804858   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "23809 -0.765638 -0.702918  0.894022  0.725918  ...  1.291270  0.614803   \n",
       "23810  1.313386 -1.009899  0.827632 -0.317398  ... -3.232952  1.464645   \n",
       "23811 -1.124344  0.780588 -0.018413 -0.351035  ... -0.363167 -0.569549   \n",
       "23812  0.313924  1.089796 -0.041223  0.040732  ... -0.843405  0.226004   \n",
       "23813  1.103513 -0.527464 -2.120578 -1.619244  ...  0.647490 -0.836719   \n",
       "\n",
       "           1003      1004      1005      1006      1007      1008      1009  \\\n",
       "0      2.052781  0.725427  2.004088 -0.538631 -0.391831  0.118504  1.139026   \n",
       "1      0.581155  0.757636  0.642792  0.302269  0.285574  1.135923  0.514133   \n",
       "2     -1.666802  1.578149 -0.288255  0.206113 -0.813300  0.671201  0.840813   \n",
       "3     -0.597280  0.377508 -0.195342 -0.193072  0.343032  0.159275  0.547945   \n",
       "4      0.495281 -0.030676 -1.087009 -0.895828 -2.334076 -0.251194  1.490739   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "23809  0.880556  0.002841 -0.183727  0.949953 -0.887562 -0.628253 -0.303959   \n",
       "23810  0.562763  1.259711 -0.983095  1.576557 -0.832365 -0.055082 -0.990865   \n",
       "23811  2.009670  1.083905 -0.939400 -0.000248 -1.168008  1.222020 -0.427585   \n",
       "23812 -1.963314 -0.509632 -1.475090 -0.732285  1.396649  0.453370  0.310334   \n",
       "23813 -0.407389  0.130110  0.200374 -0.360941 -0.399136  0.578968 -0.431915   \n",
       "\n",
       "           1010  \n",
       "0     -0.492681  \n",
       "1      0.889294  \n",
       "2     -0.571809  \n",
       "3      0.231893  \n",
       "4      0.997273  \n",
       "...         ...  \n",
       "23809 -0.925261  \n",
       "23810 -1.913727  \n",
       "23811  0.688047  \n",
       "23812  1.618901  \n",
       "23813 -0.769602  \n",
       "\n",
       "[23814 rows x 1015 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce7ca774",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:14:40.765084Z",
     "iopub.status.busy": "2025-03-21T12:14:40.764862Z",
     "iopub.status.idle": "2025-03-21T12:14:40.767677Z",
     "shell.execute_reply": "2025-03-21T12:14:40.767081Z"
    },
    "papermill": {
     "duration": 0.011522,
     "end_time": "2025-03-21T12:14:40.768967",
     "exception": false,
     "start_time": "2025-03-21T12:14:40.757445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pickle import load,dump\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13f01329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:14:40.783812Z",
     "iopub.status.busy": "2025-03-21T12:14:40.783604Z",
     "iopub.status.idle": "2025-03-21T12:15:22.993587Z",
     "shell.execute_reply": "2025-03-21T12:15:22.992854Z"
    },
    "papermill": {
     "duration": 42.218901,
     "end_time": "2025-03-21T12:15:22.995178",
     "exception": false,
     "start_time": "2025-03-21T12:14:40.776277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def fe_cluster_genes(train, test, n_clusters_g = 45, SEED = 123):\n",
    "    \n",
    "    #features_g = GENES\n",
    "    #features_c = CELLS\n",
    "    features_g = list(train.columns[4:776])\n",
    "    \n",
    "    def create_cluster(train, test, features, kind = 'g', n_clusters = n_clusters_g):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans_genes = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        #dump(kmeans_genes, open('kmeans_genes.pkl', 'wb'))\n",
    "        train[f'clusters_{kind}'] = kmeans_genes.predict(train_.values)\n",
    "        test[f'clusters_{kind}'] = kmeans_genes.predict(test_.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "    train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "   # train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features ,test_features=fe_cluster_genes(train_features,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb3051a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:15:23.010499Z",
     "iopub.status.busy": "2025-03-21T12:15:23.010248Z",
     "iopub.status.idle": "2025-03-21T12:15:27.741788Z",
     "shell.execute_reply": "2025-03-21T12:15:27.741111Z"
    },
    "papermill": {
     "duration": 4.740727,
     "end_time": "2025-03-21T12:15:27.743404",
     "exception": false,
     "start_time": "2025-03-21T12:15:23.002677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_cluster_cells(train, test, n_clusters_c = 15, SEED = 123):\n",
    "    \n",
    "    #features_g = GENES\n",
    "    #features_c = CELLS\n",
    "    features_c = list(train.columns[776:876])\n",
    "\n",
    "    def create_cluster(train, test, features, kind = 'c', n_clusters = n_clusters_c):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans_cells = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        #dump(kmeans_cells, open('kmeans_cells.pkl', 'wb'))\n",
    "        train[f'clusters_{kind}'] = kmeans_cells.predict(train_.values)\n",
    "        test[f'clusters_{kind}'] = kmeans_cells.predict(test_.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "   # train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "    train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features ,test_features=fe_cluster_cells(train_features,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "790b57da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:15:27.759032Z",
     "iopub.status.busy": "2025-03-21T12:15:27.758750Z",
     "iopub.status.idle": "2025-03-21T12:15:30.472670Z",
     "shell.execute_reply": "2025-03-21T12:15:30.471945Z"
    },
    "papermill": {
     "duration": 2.723347,
     "end_time": "2025-03-21T12:15:30.474531",
     "exception": false,
     "start_time": "2025-03-21T12:15:27.751184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_stats(train, test):\n",
    "    \n",
    "    features_g = list(train.columns[4:776])\n",
    "    features_c = list(train.columns[776:876])\n",
    "    \n",
    "    for df in train, test:\n",
    "        df['g_sum'] = df[features_g].sum(axis = 1)\n",
    "        df['g_mean'] = df[features_g].mean(axis = 1)\n",
    "        df['g_std'] = df[features_g].std(axis = 1)\n",
    "        df['g_kurt'] = df[features_g].kurtosis(axis = 1)\n",
    "        df['g_skew'] = df[features_g].skew(axis = 1)\n",
    "        df['c_sum'] = df[features_c].sum(axis = 1)\n",
    "        df['c_mean'] = df[features_c].mean(axis = 1)\n",
    "        df['c_std'] = df[features_c].std(axis = 1)\n",
    "        df['c_kurt'] = df[features_c].kurtosis(axis = 1)\n",
    "        df['c_skew'] = df[features_c].skew(axis = 1)\n",
    "        df['gc_sum'] = df[features_g + features_c].sum(axis = 1)\n",
    "        df['gc_mean'] = df[features_g + features_c].mean(axis = 1)\n",
    "        df['gc_std'] = df[features_g + features_c].std(axis = 1)\n",
    "        df['gc_kurt'] = df[features_g + features_c].kurtosis(axis = 1)\n",
    "        df['gc_skew'] = df[features_g + features_c].skew(axis = 1)\n",
    "        \n",
    "    return train, test\n",
    "\n",
    "train_features,test_features=fe_stats(train_features,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "468a1045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:15:30.489996Z",
     "iopub.status.busy": "2025-03-21T12:15:30.489719Z",
     "iopub.status.idle": "2025-03-21T12:15:30.830597Z",
     "shell.execute_reply": "2025-03-21T12:15:30.829833Z"
    },
    "papermill": {
     "duration": 0.349774,
     "end_time": "2025-03-21T12:15:30.832073",
     "exception": false,
     "start_time": "2025-03-21T12:15:30.482299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4bbb981",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:15:30.847299Z",
     "iopub.status.busy": "2025-03-21T12:15:30.847069Z",
     "iopub.status.idle": "2025-03-21T12:15:30.907902Z",
     "shell.execute_reply": "2025-03-21T12:15:30.907193Z"
    },
    "papermill": {
     "duration": 0.069886,
     "end_time": "2025-03-21T12:15:30.909401",
     "exception": false,
     "start_time": "2025-03-21T12:15:30.839515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51b8f707",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:15:30.924823Z",
     "iopub.status.busy": "2025-03-21T12:15:30.924593Z",
     "iopub.status.idle": "2025-03-21T12:15:30.944775Z",
     "shell.execute_reply": "2025-03-21T12:15:30.944065Z"
    },
    "papermill": {
     "duration": 0.028874,
     "end_time": "2025-03-21T12:15:30.945857",
     "exception": false,
     "start_time": "2025-03-21T12:15:30.916983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.890073</td>\n",
       "      <td>-0.412189</td>\n",
       "      <td>-0.944830</td>\n",
       "      <td>-0.261746</td>\n",
       "      <td>-1.019905</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>-0.029436</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.666238</td>\n",
       "      <td>0.291031</td>\n",
       "      <td>0.094330</td>\n",
       "      <td>1.230592</td>\n",
       "      <td>0.663497</td>\n",
       "      <td>0.298448</td>\n",
       "      <td>0.570563</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.928918</td>\n",
       "      <td>1.434467</td>\n",
       "      <td>-0.107724</td>\n",
       "      <td>-0.007338</td>\n",
       "      <td>1.469665</td>\n",
       "      <td>0.224107</td>\n",
       "      <td>0.365146</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.281437</td>\n",
       "      <td>-0.437950</td>\n",
       "      <td>0.769865</td>\n",
       "      <td>2.327620</td>\n",
       "      <td>-0.850179</td>\n",
       "      <td>-2.326113</td>\n",
       "      <td>0.310265</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.496357</td>\n",
       "      <td>0.982277</td>\n",
       "      <td>0.987313</td>\n",
       "      <td>1.487840</td>\n",
       "      <td>-0.861976</td>\n",
       "      <td>-0.388252</td>\n",
       "      <td>-0.215173</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.247670</td>\n",
       "      <td>0.232367</td>\n",
       "      <td>-0.333729</td>\n",
       "      <td>-0.336437</td>\n",
       "      <td>0.544847</td>\n",
       "      <td>-0.161153</td>\n",
       "      <td>-0.261668</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.033938</td>\n",
       "      <td>-0.234157</td>\n",
       "      <td>-0.765638</td>\n",
       "      <td>-0.702918</td>\n",
       "      <td>0.894022</td>\n",
       "      <td>0.725918</td>\n",
       "      <td>0.519715</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.574460</td>\n",
       "      <td>-0.584423</td>\n",
       "      <td>1.313386</td>\n",
       "      <td>-1.009899</td>\n",
       "      <td>0.827632</td>\n",
       "      <td>-0.317398</td>\n",
       "      <td>-0.710768</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.404122</td>\n",
       "      <td>0.452794</td>\n",
       "      <td>0.313924</td>\n",
       "      <td>1.089796</td>\n",
       "      <td>-0.041223</td>\n",
       "      <td>0.040732</td>\n",
       "      <td>0.096359</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.544298</td>\n",
       "      <td>-0.265196</td>\n",
       "      <td>1.103513</td>\n",
       "      <td>-0.527464</td>\n",
       "      <td>-2.120578</td>\n",
       "      <td>-1.619244</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 1295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose         0         1         2         3  \\\n",
       "0      id_000644bb2      24      D1  0.890073 -0.412189 -0.944830 -0.261746   \n",
       "1      id_000779bfc      72      D1  0.666238  0.291031  0.094330  1.230592   \n",
       "2      id_000a6266a      48      D1  0.928918  1.434467 -0.107724 -0.007338   \n",
       "3      id_0015fd391      48      D1 -0.281437 -0.437950  0.769865  2.327620   \n",
       "4      id_001626bd3      72      D2 -0.496357  0.982277  0.987313  1.487840   \n",
       "...             ...     ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444      72      D1 -1.247670  0.232367 -0.333729 -0.336437   \n",
       "21944  id_fffb1ceed      24      D2 -0.033938 -0.234157 -0.765638 -0.702918   \n",
       "21945  id_fffb70c0c      24      D2  0.574460 -0.584423  1.313386 -1.009899   \n",
       "21946  id_fffcb9e7c      24      D1  0.404122  0.452794  0.313924  1.089796   \n",
       "21947  id_ffffdd77b      72      D1  1.544298 -0.265196  1.103513 -0.527464   \n",
       "\n",
       "              4         5         6  ...  \\\n",
       "0     -1.019905 -1.357832 -0.029436  ...   \n",
       "1      0.663497  0.298448  0.570563  ...   \n",
       "2      1.469665  0.224107  0.365146  ...   \n",
       "3     -0.850179 -2.326113  0.310265  ...   \n",
       "4     -0.861976 -0.388252 -0.215173  ...   \n",
       "...         ...       ...       ...  ...   \n",
       "21943  0.544847 -0.161153 -0.261668  ...   \n",
       "21944  0.894022  0.725918  0.519715  ...   \n",
       "21945  0.827632 -0.317398 -0.710768  ...   \n",
       "21946 -0.041223  0.040732  0.096359  ...   \n",
       "21947 -2.120578 -1.619244  1.422976  ...   \n",
       "\n",
       "       tropomyosin_receptor_kinase_inhibitor  trpv_agonist  trpv_antagonist  \\\n",
       "0                                          0             0                0   \n",
       "1                                          0             0                0   \n",
       "2                                          0             0                0   \n",
       "3                                          0             0                0   \n",
       "4                                          0             0                0   \n",
       "...                                      ...           ...              ...   \n",
       "21943                                      0             0                0   \n",
       "21944                                      0             0                0   \n",
       "21945                                      0             0                0   \n",
       "21946                                      0             0                0   \n",
       "21947                                      0             0                0   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "...                  ...                        ...   \n",
       "21943                  0                          0   \n",
       "21944                  0                          0   \n",
       "21945                  0                          0   \n",
       "21946                  0                          0   \n",
       "21947                  0                          0   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                          0                0          0   \n",
       "1                                          0                0          0   \n",
       "2                                          0                0          0   \n",
       "3                                          0                0          0   \n",
       "4                                          0                0          0   \n",
       "...                                      ...              ...        ...   \n",
       "21943                                      0                0          0   \n",
       "21944                                      0                0          0   \n",
       "21945                                      0                0          0   \n",
       "21946                                      0                0          0   \n",
       "21947                                      0                0          0   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                               0              0  \n",
       "1                               0              0  \n",
       "2                               0              0  \n",
       "3                               0              0  \n",
       "4                               0              0  \n",
       "...                           ...            ...  \n",
       "21943                           0              0  \n",
       "21944                           0              0  \n",
       "21945                           0              0  \n",
       "21946                           0              0  \n",
       "21947                           0              0  \n",
       "\n",
       "[21948 rows x 1295 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "936b03de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:15:30.961572Z",
     "iopub.status.busy": "2025-03-21T12:15:30.961361Z",
     "iopub.status.idle": "2025-03-21T12:15:30.972157Z",
     "shell.execute_reply": "2025-03-21T12:15:30.971546Z"
    },
    "papermill": {
     "duration": 0.019889,
     "end_time": "2025-03-21T12:15:30.973375",
     "exception": false,
     "start_time": "2025-03-21T12:15:30.953486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de9dd7ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:15:30.988780Z",
     "iopub.status.busy": "2025-03-21T12:15:30.988575Z",
     "iopub.status.idle": "2025-03-21T12:15:33.239478Z",
     "shell.execute_reply": "2025-03-21T12:15:33.238593Z"
    },
    "papermill": {
     "duration": 2.259973,
     "end_time": "2025-03-21T12:15:33.240681",
     "exception": false,
     "start_time": "2025-03-21T12:15:30.980708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.890073</td>\n",
       "      <td>-0.412189</td>\n",
       "      <td>-0.944830</td>\n",
       "      <td>-0.261746</td>\n",
       "      <td>-1.019905</td>\n",
       "      <td>-1.357832</td>\n",
       "      <td>-0.029436</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.666238</td>\n",
       "      <td>0.291031</td>\n",
       "      <td>0.094330</td>\n",
       "      <td>1.230592</td>\n",
       "      <td>0.663497</td>\n",
       "      <td>0.298448</td>\n",
       "      <td>0.570563</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.928918</td>\n",
       "      <td>1.434467</td>\n",
       "      <td>-0.107724</td>\n",
       "      <td>-0.007338</td>\n",
       "      <td>1.469665</td>\n",
       "      <td>0.224107</td>\n",
       "      <td>0.365146</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.281437</td>\n",
       "      <td>-0.437950</td>\n",
       "      <td>0.769865</td>\n",
       "      <td>2.327620</td>\n",
       "      <td>-0.850179</td>\n",
       "      <td>-2.326113</td>\n",
       "      <td>0.310265</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.496357</td>\n",
       "      <td>0.982277</td>\n",
       "      <td>0.987313</td>\n",
       "      <td>1.487840</td>\n",
       "      <td>-0.861976</td>\n",
       "      <td>-0.388252</td>\n",
       "      <td>-0.215173</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.247670</td>\n",
       "      <td>0.232367</td>\n",
       "      <td>-0.333729</td>\n",
       "      <td>-0.336437</td>\n",
       "      <td>0.544847</td>\n",
       "      <td>-0.161153</td>\n",
       "      <td>-0.261668</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.033938</td>\n",
       "      <td>-0.234157</td>\n",
       "      <td>-0.765638</td>\n",
       "      <td>-0.702918</td>\n",
       "      <td>0.894022</td>\n",
       "      <td>0.725918</td>\n",
       "      <td>0.519715</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.574460</td>\n",
       "      <td>-0.584423</td>\n",
       "      <td>1.313386</td>\n",
       "      <td>-1.009899</td>\n",
       "      <td>0.827632</td>\n",
       "      <td>-0.317398</td>\n",
       "      <td>-0.710768</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.404122</td>\n",
       "      <td>0.452794</td>\n",
       "      <td>0.313924</td>\n",
       "      <td>1.089796</td>\n",
       "      <td>-0.041223</td>\n",
       "      <td>0.040732</td>\n",
       "      <td>0.096359</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.544298</td>\n",
       "      <td>-0.265196</td>\n",
       "      <td>1.103513</td>\n",
       "      <td>-0.527464</td>\n",
       "      <td>-2.120578</td>\n",
       "      <td>-1.619244</td>\n",
       "      <td>1.422976</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 1296 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose         0         1         2         3  \\\n",
       "0      id_000644bb2      24      D1  0.890073 -0.412189 -0.944830 -0.261746   \n",
       "1      id_000779bfc      72      D1  0.666238  0.291031  0.094330  1.230592   \n",
       "2      id_000a6266a      48      D1  0.928918  1.434467 -0.107724 -0.007338   \n",
       "3      id_0015fd391      48      D1 -0.281437 -0.437950  0.769865  2.327620   \n",
       "4      id_001626bd3      72      D2 -0.496357  0.982277  0.987313  1.487840   \n",
       "...             ...     ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444      72      D1 -1.247670  0.232367 -0.333729 -0.336437   \n",
       "21944  id_fffb1ceed      24      D2 -0.033938 -0.234157 -0.765638 -0.702918   \n",
       "21945  id_fffb70c0c      24      D2  0.574460 -0.584423  1.313386 -1.009899   \n",
       "21946  id_fffcb9e7c      24      D1  0.404122  0.452794  0.313924  1.089796   \n",
       "21947  id_ffffdd77b      72      D1  1.544298 -0.265196  1.103513 -0.527464   \n",
       "\n",
       "              4         5         6  ...  trpv_agonist  trpv_antagonist  \\\n",
       "0     -1.019905 -1.357832 -0.029436  ...             0                0   \n",
       "1      0.663497  0.298448  0.570563  ...             0                0   \n",
       "2      1.469665  0.224107  0.365146  ...             0                0   \n",
       "3     -0.850179 -2.326113  0.310265  ...             0                0   \n",
       "4     -0.861976 -0.388252 -0.215173  ...             0                0   \n",
       "...         ...       ...       ...  ...           ...              ...   \n",
       "21943  0.544847 -0.161153 -0.261668  ...             0                0   \n",
       "21944  0.894022  0.725918  0.519715  ...             0                0   \n",
       "21945  0.827632 -0.317398 -0.710768  ...             0                0   \n",
       "21946 -0.041223  0.040732  0.096359  ...             0                0   \n",
       "21947 -2.120578 -1.619244  1.422976  ...             0                0   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "...                  ...                        ...   \n",
       "21943                  0                          0   \n",
       "21944                  0                          0   \n",
       "21945                  0                          0   \n",
       "21946                  0                          0   \n",
       "21947                  0                          0   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                          0                0          0   \n",
       "1                                          0                0          0   \n",
       "2                                          0                0          0   \n",
       "3                                          0                0          0   \n",
       "4                                          0                0          0   \n",
       "...                                      ...              ...        ...   \n",
       "21943                                      0                0          0   \n",
       "21944                                      0                0          0   \n",
       "21945                                      0                0          0   \n",
       "21946                                      0                0          0   \n",
       "21947                                      0                0          0   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  kfold  \n",
       "0                               0              0      0  \n",
       "1                               0              0      2  \n",
       "2                               0              0      1  \n",
       "3                               0              0      2  \n",
       "4                               0              0      2  \n",
       "...                           ...            ...    ...  \n",
       "21943                           0              0      0  \n",
       "21944                           0              0      4  \n",
       "21945                           0              0      0  \n",
       "21946                           0              0      1  \n",
       "21947                           0              0      2  \n",
       "\n",
       "[21948 rows x 1296 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=5)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8341ab43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:15:33.257337Z",
     "iopub.status.busy": "2025-03-21T12:15:33.257100Z",
     "iopub.status.idle": "2025-03-21T12:15:33.262145Z",
     "shell.execute_reply": "2025-03-21T12:15:33.261245Z"
    },
    "papermill": {
     "duration": 0.014653,
     "end_time": "2025-03-21T12:15:33.263417",
     "exception": false,
     "start_time": "2025-03-21T12:15:33.248764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1295)\n",
      "(21948, 1296)\n",
      "(3624, 1089)\n",
      "(21948, 207)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda2aebb",
   "metadata": {
    "papermill": {
     "duration": 0.00741,
     "end_time": "2025-03-21T12:15:33.278704",
     "exception": false,
     "start_time": "2025-03-21T12:15:33.271294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b8241ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:15:33.294628Z",
     "iopub.status.busy": "2025-03-21T12:15:33.294410Z",
     "iopub.status.idle": "2025-03-21T12:15:33.299852Z",
     "shell.execute_reply": "2025-03-21T12:15:33.299078Z"
    },
    "papermill": {
     "duration": 0.014983,
     "end_time": "2025-03-21T12:15:33.301299",
     "exception": false,
     "start_time": "2025-03-21T12:15:33.286316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features.astype(np.float32)\n",
    "        self.targets = targets.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db51dbef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:15:33.318010Z",
     "iopub.status.busy": "2025-03-21T12:15:33.317757Z",
     "iopub.status.idle": "2025-03-21T12:15:33.324408Z",
     "shell.execute_reply": "2025-03-21T12:15:33.323628Z"
    },
    "papermill": {
     "duration": 0.016199,
     "end_time": "2025-03-21T12:15:33.325508",
     "exception": false,
     "start_time": "2025-03-21T12:15:33.309309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "#         print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67febee6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:15:33.342006Z",
     "iopub.status.busy": "2025-03-21T12:15:33.341789Z",
     "iopub.status.idle": "2025-03-21T12:15:33.346847Z",
     "shell.execute_reply": "2025-03-21T12:15:33.346286Z"
    },
    "papermill": {
     "duration": 0.014733,
     "end_time": "2025-03-21T12:15:33.348035",
     "exception": false,
     "start_time": "2025-03-21T12:15:33.333302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28cc7b51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:15:33.364126Z",
     "iopub.status.busy": "2025-03-21T12:15:33.363885Z",
     "iopub.status.idle": "2025-03-21T12:15:33.373650Z",
     "shell.execute_reply": "2025-03-21T12:15:33.373104Z"
    },
    "papermill": {
     "duration": 0.019122,
     "end_time": "2025-03-21T12:15:33.374805",
     "exception": false,
     "start_time": "2025-03-21T12:15:33.355683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        cha_1 = 256\n",
    "        cha_2 = 512\n",
    "        cha_3 = 512\n",
    "\n",
    "        cha_1_reshape = int(hidden_size/cha_1)\n",
    "        cha_po_1 = int(hidden_size/cha_1/2)\n",
    "        cha_po_2 = int(hidden_size/cha_1/2/2) * cha_3\n",
    "\n",
    "        self.cha_1 = cha_1\n",
    "        self.cha_2 = cha_2\n",
    "        self.cha_3 = cha_3\n",
    "        self.cha_1_reshape = cha_1_reshape\n",
    "        self.cha_po_1 = cha_po_1\n",
    "        self.cha_po_2 = cha_po_2\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "\n",
    "        self.batch_norm_c1 = nn.BatchNorm1d(cha_1)\n",
    "        self.dropout_c1 = nn.Dropout(0.1)\n",
    "        self.conv1 = nn.utils.weight_norm(nn.Conv1d(cha_1,cha_2, kernel_size = 5, stride = 1, padding=2,  bias=False),dim=None)\n",
    "\n",
    "        self.ave_po_c1 = nn.AdaptiveAvgPool1d(output_size = cha_po_1)\n",
    "\n",
    "        self.batch_norm_c2 = nn.BatchNorm1d(cha_2)\n",
    "        self.dropout_c2 = nn.Dropout(0.1)\n",
    "        self.conv2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "\n",
    "        self.batch_norm_c2_1 = nn.BatchNorm1d(cha_2)\n",
    "        self.dropout_c2_1 = nn.Dropout(0.3)\n",
    "        self.conv2_1 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "\n",
    "        self.batch_norm_c2_2 = nn.BatchNorm1d(cha_2)\n",
    "        self.dropout_c2_2 = nn.Dropout(0.2)\n",
    "        self.conv2_2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_3, kernel_size = 5, stride = 1, padding=2, bias=True),dim=None)\n",
    "\n",
    "        self.max_po_c2 = nn.MaxPool1d(kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        self.flt = nn.Flatten()\n",
    "\n",
    "        self.batch_norm3 = nn.BatchNorm1d(cha_po_2)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(cha_po_2, num_targets))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.celu(self.dense1(x), alpha=0.06)\n",
    "\n",
    "        x = x.reshape(x.shape[0],self.cha_1,\n",
    "                        self.cha_1_reshape)\n",
    "\n",
    "        x = self.batch_norm_c1(x)\n",
    "        x = self.dropout_c1(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        x = self.ave_po_c1(x)\n",
    "\n",
    "        x = self.batch_norm_c2(x)\n",
    "        x = self.dropout_c2(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x_s = x\n",
    "\n",
    "        x = self.batch_norm_c2_1(x)\n",
    "        x = self.dropout_c2_1(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "\n",
    "        x = self.batch_norm_c2_2(x)\n",
    "        x = self.dropout_c2_2(x)\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x =  x * x_s\n",
    "\n",
    "        x = self.max_po_c2(x)\n",
    "\n",
    "        x = self.flt(x)\n",
    "\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e86f112",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:15:33.391054Z",
     "iopub.status.busy": "2025-03-21T12:15:33.390814Z",
     "iopub.status.idle": "2025-03-21T12:15:33.394015Z",
     "shell.execute_reply": "2025-03-21T12:15:33.393234Z"
    },
    "papermill": {
     "duration": 0.012561,
     "end_time": "2025-03-21T12:15:33.395197",
     "exception": false,
     "start_time": "2025-03-21T12:15:33.382636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa01a0d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:15:33.411604Z",
     "iopub.status.busy": "2025-03-21T12:15:33.411392Z",
     "iopub.status.idle": "2025-03-21T12:15:33.596619Z",
     "shell.execute_reply": "2025-03-21T12:15:33.595763Z"
    },
    "papermill": {
     "duration": 0.194936,
     "end_time": "2025-03-21T12:15:33.597943",
     "exception": false,
     "start_time": "2025-03-21T12:15:33.403007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1091"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ca0eae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:15:33.615151Z",
     "iopub.status.busy": "2025-03-21T12:15:33.614916Z",
     "iopub.status.idle": "2025-03-21T12:15:33.683686Z",
     "shell.execute_reply": "2025-03-21T12:15:33.682856Z"
    },
    "papermill": {
     "duration": 0.078592,
     "end_time": "2025-03-21T12:15:33.684915",
     "exception": false,
     "start_time": "2025-03-21T12:15:33.606323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 5e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 5            #<-- Update\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=2048\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1be4121c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:15:33.701707Z",
     "iopub.status.busy": "2025-03-21T12:15:33.701464Z",
     "iopub.status.idle": "2025-03-21T12:15:33.710670Z",
     "shell.execute_reply": "2025-03-21T12:15:33.709870Z"
    },
    "papermill": {
     "duration": 0.018853,
     "end_time": "2025-03-21T12:15:33.711819",
     "exception": false,
     "start_time": "2025-03-21T12:15:33.692966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-3, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"SEED: {seed} ,FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"SEED{seed}_FOLD{fold}_.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"SEED{seed}_FOLD{fold}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f292e6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:15:33.728421Z",
     "iopub.status.busy": "2025-03-21T12:15:33.728199Z",
     "iopub.status.idle": "2025-03-21T12:15:33.731880Z",
     "shell.execute_reply": "2025-03-21T12:15:33.731263Z"
    },
    "papermill": {
     "duration": 0.013313,
     "end_time": "2025-03-21T12:15:33.733030",
     "exception": false,
     "start_time": "2025-03-21T12:15:33.719717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f126c660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:15:33.749209Z",
     "iopub.status.busy": "2025-03-21T12:15:33.749008Z",
     "iopub.status.idle": "2025-03-21T12:42:20.968737Z",
     "shell.execute_reply": "2025-03-21T12:42:20.968001Z"
    },
    "papermill": {
     "duration": 1607.22958,
     "end_time": "2025-03-21T12:42:20.970396",
     "exception": false,
     "start_time": "2025-03-21T12:15:33.740816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 940, FOLD: 0, EPOCH: 0, train_loss: 0.4995919527027054\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 0, valid_loss: 0.02933384052344731\n",
      "SEED: 940, FOLD: 0, EPOCH: 1, train_loss: 0.024749219741510307\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 1, valid_loss: 0.02031315208545753\n",
      "SEED: 940, FOLD: 0, EPOCH: 2, train_loss: 0.02184787431758815\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 2, valid_loss: 0.01810588434870754\n",
      "SEED: 940, FOLD: 0, EPOCH: 3, train_loss: 0.0210773973469285\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 3, valid_loss: 0.01840652288602931\n",
      "SEED: 940, FOLD: 0, EPOCH: 4, train_loss: 0.020586530273051365\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017847515722470623\n",
      "SEED: 940, FOLD: 0, EPOCH: 5, train_loss: 0.020359370601026043\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017632983279015337\n",
      "SEED: 940, FOLD: 0, EPOCH: 6, train_loss: 0.020375595428049564\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01717494430818728\n",
      "SEED: 940, FOLD: 0, EPOCH: 7, train_loss: 0.02027921899613263\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01726655936134713\n",
      "SEED: 940, FOLD: 0, EPOCH: 8, train_loss: 0.020288358496475048\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017119900722588812\n",
      "SEED: 940, FOLD: 0, EPOCH: 9, train_loss: 0.020283159489432972\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017233660284961972\n",
      "SEED: 940, FOLD: 0, EPOCH: 10, train_loss: 0.020129294350635315\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017064218329531807\n",
      "SEED: 940, FOLD: 0, EPOCH: 11, train_loss: 0.019943334688634975\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01718819947647197\n",
      "SEED: 940, FOLD: 0, EPOCH: 12, train_loss: 0.02000192600045947\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 12, valid_loss: 0.017273084313741752\n",
      "SEED: 940, FOLD: 0, EPOCH: 13, train_loss: 0.01989046648900578\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016906092023210865\n",
      "SEED: 940, FOLD: 0, EPOCH: 14, train_loss: 0.019674354489298836\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016579113554741655\n",
      "SEED: 940, FOLD: 0, EPOCH: 15, train_loss: 0.019597632783478584\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01659682946545737\n",
      "SEED: 940, FOLD: 0, EPOCH: 16, train_loss: 0.019315561482115932\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016429933266980307\n",
      "SEED: 940, FOLD: 0, EPOCH: 17, train_loss: 0.019088203384392502\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016356698130922658\n",
      "SEED: 940, FOLD: 0, EPOCH: 18, train_loss: 0.018678654660133347\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016319511458277702\n",
      "SEED: 940, FOLD: 0, EPOCH: 19, train_loss: 0.018295672519699387\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 19, valid_loss: 0.01614037188036101\n",
      "SEED: 940, FOLD: 0, EPOCH: 20, train_loss: 0.017738560849017856\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 20, valid_loss: 0.0159959505711283\n",
      "SEED: 940, FOLD: 0, EPOCH: 21, train_loss: 0.017132540867812393\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 21, valid_loss: 0.01581096018531493\n",
      "SEED: 940, FOLD: 0, EPOCH: 22, train_loss: 0.016526056669544483\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 22, valid_loss: 0.015827562500323567\n",
      "SEED: 940, FOLD: 0, EPOCH: 23, train_loss: 0.015936681548592405\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015815271862915585\n",
      "SEED: 940, FOLD: 0, EPOCH: 24, train_loss: 0.015641133962334065\n",
      "SEED: 940 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015820150609527316\n",
      "SEED: 940, FOLD: 1, EPOCH: 0, train_loss: 0.49900682849566574\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 0, valid_loss: 0.029701085707971028\n",
      "SEED: 940, FOLD: 1, EPOCH: 1, train_loss: 0.024609825627851314\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 1, valid_loss: 0.019060534451689037\n",
      "SEED: 940, FOLD: 1, EPOCH: 2, train_loss: 0.021699824950833252\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 2, valid_loss: 0.0180452006735972\n",
      "SEED: 940, FOLD: 1, EPOCH: 3, train_loss: 0.020884660018634968\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 3, valid_loss: 0.01807195898145437\n",
      "SEED: 940, FOLD: 1, EPOCH: 4, train_loss: 0.020677905070824898\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017379139523421017\n",
      "SEED: 940, FOLD: 1, EPOCH: 5, train_loss: 0.020364871464561726\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017404629502977643\n",
      "SEED: 940, FOLD: 1, EPOCH: 6, train_loss: 0.020341540200878746\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 6, valid_loss: 0.01894908621907234\n",
      "SEED: 940, FOLD: 1, EPOCH: 7, train_loss: 0.020369356700583645\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017392385112387793\n",
      "SEED: 940, FOLD: 1, EPOCH: 8, train_loss: 0.02022319768919893\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017145197332969733\n",
      "SEED: 940, FOLD: 1, EPOCH: 9, train_loss: 0.02022432747796394\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 9, valid_loss: 0.016992867791226933\n",
      "SEED: 940, FOLD: 1, EPOCH: 10, train_loss: 0.020139014564346577\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01747624586735453\n",
      "SEED: 940, FOLD: 1, EPOCH: 11, train_loss: 0.020049738387266796\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017060846968420914\n",
      "SEED: 940, FOLD: 1, EPOCH: 12, train_loss: 0.019965165065250534\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 12, valid_loss: 0.017004822460668426\n",
      "SEED: 940, FOLD: 1, EPOCH: 13, train_loss: 0.019853614608122818\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01687573761280094\n",
      "SEED: 940, FOLD: 1, EPOCH: 14, train_loss: 0.019771551551378292\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 14, valid_loss: 0.01697400507650205\n",
      "SEED: 940, FOLD: 1, EPOCH: 15, train_loss: 0.01955874196753122\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016752486542931624\n",
      "SEED: 940, FOLD: 1, EPOCH: 16, train_loss: 0.01932215621775907\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016495180183223317\n",
      "SEED: 940, FOLD: 1, EPOCH: 17, train_loss: 0.01903630131720633\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 17, valid_loss: 0.01649855649364846\n",
      "SEED: 940, FOLD: 1, EPOCH: 18, train_loss: 0.018713469428104767\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 18, valid_loss: 0.0164005043517266\n",
      "SEED: 940, FOLD: 1, EPOCH: 19, train_loss: 0.01833080389685389\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016106381746275083\n",
      "SEED: 940, FOLD: 1, EPOCH: 20, train_loss: 0.01785683260042814\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016055765827851638\n",
      "SEED: 940, FOLD: 1, EPOCH: 21, train_loss: 0.01729813000133288\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01590953538460391\n",
      "SEED: 940, FOLD: 1, EPOCH: 22, train_loss: 0.016591064787159365\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015906310134700365\n",
      "SEED: 940, FOLD: 1, EPOCH: 23, train_loss: 0.016095756485626316\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 23, valid_loss: 0.015915549972227643\n",
      "SEED: 940, FOLD: 1, EPOCH: 24, train_loss: 0.01581639626427837\n",
      "SEED: 940 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015875309120331492\n",
      "SEED: 940, FOLD: 2, EPOCH: 0, train_loss: 0.4998352515605697\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 0, valid_loss: 0.028729314995663505\n",
      "SEED: 940, FOLD: 2, EPOCH: 1, train_loss: 0.02463603620349929\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 1, valid_loss: 0.018947578008685795\n",
      "SEED: 940, FOLD: 2, EPOCH: 2, train_loss: 0.021911430928478207\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018044431773679596\n",
      "SEED: 940, FOLD: 2, EPOCH: 3, train_loss: 0.021158165635838024\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 3, valid_loss: 0.018429734877177646\n",
      "SEED: 940, FOLD: 2, EPOCH: 4, train_loss: 0.0205963635277273\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 4, valid_loss: 0.0174737880804709\n",
      "SEED: 940, FOLD: 2, EPOCH: 5, train_loss: 0.020217456760397857\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01722699832171202\n",
      "SEED: 940, FOLD: 2, EPOCH: 6, train_loss: 0.02024399053197408\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017330320073025568\n",
      "SEED: 940, FOLD: 2, EPOCH: 7, train_loss: 0.02027757155398528\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017201804742217063\n",
      "SEED: 940, FOLD: 2, EPOCH: 8, train_loss: 0.020144600988082264\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017238471444164002\n",
      "SEED: 940, FOLD: 2, EPOCH: 9, train_loss: 0.02010899998139644\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01722213671143566\n",
      "SEED: 940, FOLD: 2, EPOCH: 10, train_loss: 0.020168335487445194\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017066653365535395\n",
      "SEED: 940, FOLD: 2, EPOCH: 11, train_loss: 0.020034605218772438\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 11, valid_loss: 0.017030153184064797\n",
      "SEED: 940, FOLD: 2, EPOCH: 12, train_loss: 0.01993622575495122\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016865215929491178\n",
      "SEED: 940, FOLD: 2, EPOCH: 13, train_loss: 0.0197702515060487\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016830375364848545\n",
      "SEED: 940, FOLD: 2, EPOCH: 14, train_loss: 0.019593680439435917\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01698340281311955\n",
      "SEED: 940, FOLD: 2, EPOCH: 15, train_loss: 0.01942260578220737\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016607036920530456\n",
      "SEED: 940, FOLD: 2, EPOCH: 16, train_loss: 0.019276997101479683\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016509038396179676\n",
      "SEED: 940, FOLD: 2, EPOCH: 17, train_loss: 0.018939428962767124\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01642268877476454\n",
      "SEED: 940, FOLD: 2, EPOCH: 18, train_loss: 0.018721432924486588\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016213775452758584\n",
      "SEED: 940, FOLD: 2, EPOCH: 19, train_loss: 0.018229185468584732\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01599161465253149\n",
      "SEED: 940, FOLD: 2, EPOCH: 20, train_loss: 0.01771697279173827\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 20, valid_loss: 0.015979327687195368\n",
      "SEED: 940, FOLD: 2, EPOCH: 21, train_loss: 0.01706786153406121\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01579160166106054\n",
      "SEED: 940, FOLD: 2, EPOCH: 22, train_loss: 0.016435588460307623\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 22, valid_loss: 0.015826949211103575\n",
      "SEED: 940, FOLD: 2, EPOCH: 23, train_loss: 0.015886364248243794\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015844926078404698\n",
      "SEED: 940, FOLD: 2, EPOCH: 24, train_loss: 0.015618565715039555\n",
      "SEED: 940 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01590499702308859\n",
      "SEED: 940, FOLD: 3, EPOCH: 0, train_loss: 0.5010049138488113\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 0, valid_loss: 0.02914894696857248\n",
      "SEED: 940, FOLD: 3, EPOCH: 1, train_loss: 0.024562565839269024\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 1, valid_loss: 0.01913315536720412\n",
      "SEED: 940, FOLD: 3, EPOCH: 2, train_loss: 0.02172418263997289\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 2, valid_loss: 0.01865494256573064\n",
      "SEED: 940, FOLD: 3, EPOCH: 3, train_loss: 0.021010691286537094\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 3, valid_loss: 0.0377588436539684\n",
      "SEED: 940, FOLD: 3, EPOCH: 4, train_loss: 0.020765527259504448\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017575356337640968\n",
      "SEED: 940, FOLD: 3, EPOCH: 5, train_loss: 0.020461064398936604\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017618657409080436\n",
      "SEED: 940, FOLD: 3, EPOCH: 6, train_loss: 0.02032286692680656\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01766221249209983\n",
      "SEED: 940, FOLD: 3, EPOCH: 7, train_loss: 0.02038056751632172\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01800541215177093\n",
      "SEED: 940, FOLD: 3, EPOCH: 8, train_loss: 0.020305611571108086\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017423118810568537\n",
      "SEED: 940, FOLD: 3, EPOCH: 9, train_loss: 0.020247147040630596\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 9, valid_loss: 0.017314832364874227\n",
      "SEED: 940, FOLD: 3, EPOCH: 10, train_loss: 0.020072769198188747\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017337986853505884\n",
      "SEED: 940, FOLD: 3, EPOCH: 11, train_loss: 0.02006597039492234\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 11, valid_loss: 0.017231451719999312\n",
      "SEED: 940, FOLD: 3, EPOCH: 12, train_loss: 0.019948549379689106\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 12, valid_loss: 0.01750406154564449\n",
      "SEED: 940, FOLD: 3, EPOCH: 13, train_loss: 0.019898477901259193\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 13, valid_loss: 0.0171353207635028\n",
      "SEED: 940, FOLD: 3, EPOCH: 14, train_loss: 0.019718967958528927\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 14, valid_loss: 0.017040769064000674\n",
      "SEED: 940, FOLD: 3, EPOCH: 15, train_loss: 0.019524148071481697\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016751917371792453\n",
      "SEED: 940, FOLD: 3, EPOCH: 16, train_loss: 0.019284029626220032\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016707300314945835\n",
      "SEED: 940, FOLD: 3, EPOCH: 17, train_loss: 0.01900139035306115\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016680657890226158\n",
      "SEED: 940, FOLD: 3, EPOCH: 18, train_loss: 0.01867339166853091\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016534880229404993\n",
      "SEED: 940, FOLD: 3, EPOCH: 19, train_loss: 0.018279878017695053\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016444401629269124\n",
      "SEED: 940, FOLD: 3, EPOCH: 20, train_loss: 0.017782818917455017\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016228841112128325\n",
      "SEED: 940, FOLD: 3, EPOCH: 21, train_loss: 0.01718648703282942\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016052732137697083\n",
      "SEED: 940, FOLD: 3, EPOCH: 22, train_loss: 0.016557552440064974\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 22, valid_loss: 0.016052746879202977\n",
      "SEED: 940, FOLD: 3, EPOCH: 23, train_loss: 0.016006023049408544\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01607247998139688\n",
      "SEED: 940, FOLD: 3, EPOCH: 24, train_loss: 0.0157690838964629\n",
      "SEED: 940 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016057256822075164\n",
      "SEED: 940, FOLD: 4, EPOCH: 0, train_loss: 0.4978067850343127\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 0, valid_loss: 0.029260427025812014\n",
      "SEED: 940, FOLD: 4, EPOCH: 1, train_loss: 0.024842605993583584\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 1, valid_loss: 0.020055695303848813\n",
      "SEED: 940, FOLD: 4, EPOCH: 2, train_loss: 0.02173745385168687\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 2, valid_loss: 0.017795126512646676\n",
      "SEED: 940, FOLD: 4, EPOCH: 3, train_loss: 0.021070177383396938\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 3, valid_loss: 0.017633940332702228\n",
      "SEED: 940, FOLD: 4, EPOCH: 4, train_loss: 0.020551211646069652\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017474372312426566\n",
      "SEED: 940, FOLD: 4, EPOCH: 5, train_loss: 0.020308883131846138\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017361328804067204\n",
      "SEED: 940, FOLD: 4, EPOCH: 6, train_loss: 0.02025080260321282\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01736558899283409\n",
      "SEED: 940, FOLD: 4, EPOCH: 7, train_loss: 0.020336707770500496\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017279773551438535\n",
      "SEED: 940, FOLD: 4, EPOCH: 8, train_loss: 0.020247866750519344\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017069093271025588\n",
      "SEED: 940, FOLD: 4, EPOCH: 9, train_loss: 0.02012532597164745\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 9, valid_loss: 0.01698902603238821\n",
      "SEED: 940, FOLD: 4, EPOCH: 10, train_loss: 0.020121291576736214\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017160019172089442\n",
      "SEED: 940, FOLD: 4, EPOCH: 11, train_loss: 0.02001096227246782\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01706772569034781\n",
      "SEED: 940, FOLD: 4, EPOCH: 12, train_loss: 0.01994154657628657\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 12, valid_loss: 0.01687915383705071\n",
      "SEED: 940, FOLD: 4, EPOCH: 13, train_loss: 0.019801897631175278\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01689461405788149\n",
      "SEED: 940, FOLD: 4, EPOCH: 14, train_loss: 0.019679903079742107\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 14, valid_loss: 0.01679995802364179\n",
      "SEED: 940, FOLD: 4, EPOCH: 15, train_loss: 0.019528868257243565\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016612919553049974\n",
      "SEED: 940, FOLD: 4, EPOCH: 16, train_loss: 0.019326180921516556\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016559149803859845\n",
      "SEED: 940, FOLD: 4, EPOCH: 17, train_loss: 0.01899054657289947\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 17, valid_loss: 0.0163506775030068\n",
      "SEED: 940, FOLD: 4, EPOCH: 18, train_loss: 0.018662470588595537\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01622558637921299\n",
      "SEED: 940, FOLD: 4, EPOCH: 19, train_loss: 0.018223431960180187\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016109614526586873\n",
      "SEED: 940, FOLD: 4, EPOCH: 20, train_loss: 0.017763000163857057\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 20, valid_loss: 0.015887554681726864\n",
      "SEED: 940, FOLD: 4, EPOCH: 21, train_loss: 0.017125045725454886\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 21, valid_loss: 0.015862525094832693\n",
      "SEED: 940, FOLD: 4, EPOCH: 22, train_loss: 0.016491019322226446\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015796287464244024\n",
      "SEED: 940, FOLD: 4, EPOCH: 23, train_loss: 0.015878564725373533\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 23, valid_loss: 0.015800701108361993\n",
      "SEED: 940, FOLD: 4, EPOCH: 24, train_loss: 0.015597845414194508\n",
      "SEED: 940 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015831146841602667\n",
      "SEED: 1513, FOLD: 0, EPOCH: 0, train_loss: 0.5001509967867447\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 0, valid_loss: 0.028986173548868725\n",
      "SEED: 1513, FOLD: 0, EPOCH: 1, train_loss: 0.02477748986279619\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 1, valid_loss: 0.0238682359457016\n",
      "SEED: 1513, FOLD: 0, EPOCH: 2, train_loss: 0.021828039103875988\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 2, valid_loss: 0.018061266866113458\n",
      "SEED: 1513, FOLD: 0, EPOCH: 3, train_loss: 0.02092434527973334\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 3, valid_loss: 0.019622745577778135\n",
      "SEED: 1513, FOLD: 0, EPOCH: 4, train_loss: 0.020808022793220436\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017613554799130984\n",
      "SEED: 1513, FOLD: 0, EPOCH: 5, train_loss: 0.020510719346719376\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017492137210709708\n",
      "SEED: 1513, FOLD: 0, EPOCH: 6, train_loss: 0.020433245469694553\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01741249526717833\n",
      "SEED: 1513, FOLD: 0, EPOCH: 7, train_loss: 0.020324564727860085\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01802703735551664\n",
      "SEED: 1513, FOLD: 0, EPOCH: 8, train_loss: 0.020357271251471146\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017587791117174286\n",
      "SEED: 1513, FOLD: 0, EPOCH: 9, train_loss: 0.02021592922940634\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017225372285715173\n",
      "SEED: 1513, FOLD: 0, EPOCH: 10, train_loss: 0.020209592929028946\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017267741316131183\n",
      "SEED: 1513, FOLD: 0, EPOCH: 11, train_loss: 0.020160033475553642\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 11, valid_loss: 0.017010298504361084\n",
      "SEED: 1513, FOLD: 0, EPOCH: 12, train_loss: 0.020029329141412956\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01706434592072453\n",
      "SEED: 1513, FOLD: 0, EPOCH: 13, train_loss: 0.019903246205354084\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016915525575833663\n",
      "SEED: 1513, FOLD: 0, EPOCH: 14, train_loss: 0.019769834111566128\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016808099326278483\n",
      "SEED: 1513, FOLD: 0, EPOCH: 15, train_loss: 0.019565373240713623\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016792551108769007\n",
      "SEED: 1513, FOLD: 0, EPOCH: 16, train_loss: 0.019378426444271336\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016804057120212487\n",
      "SEED: 1513, FOLD: 0, EPOCH: 17, train_loss: 0.01906504370002211\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01642307098954916\n",
      "SEED: 1513, FOLD: 0, EPOCH: 18, train_loss: 0.018731931717121515\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016305510140955447\n",
      "SEED: 1513, FOLD: 0, EPOCH: 19, train_loss: 0.018375793600157984\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016299822740256785\n",
      "SEED: 1513, FOLD: 0, EPOCH: 20, train_loss: 0.017842323478797207\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 20, valid_loss: 0.015991643363876002\n",
      "SEED: 1513, FOLD: 0, EPOCH: 21, train_loss: 0.017313349040468103\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015884304898125784\n",
      "SEED: 1513, FOLD: 0, EPOCH: 22, train_loss: 0.016675006841187893\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 22, valid_loss: 0.015856361176286426\n",
      "SEED: 1513, FOLD: 0, EPOCH: 23, train_loss: 0.016194331749895777\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01582330446690321\n",
      "SEED: 1513, FOLD: 0, EPOCH: 24, train_loss: 0.015944994878077854\n",
      "SEED: 1513 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015820209229631083\n",
      "SEED: 1513, FOLD: 1, EPOCH: 0, train_loss: 0.49872069332100777\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 0, valid_loss: 0.029161862443600382\n",
      "SEED: 1513, FOLD: 1, EPOCH: 1, train_loss: 0.024427874148755833\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 1, valid_loss: 0.01935445671635015\n",
      "SEED: 1513, FOLD: 1, EPOCH: 2, train_loss: 0.021896840694049995\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 2, valid_loss: 0.018315976964575903\n",
      "SEED: 1513, FOLD: 1, EPOCH: 3, train_loss: 0.021007439553521683\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 3, valid_loss: 0.019546476272600036\n",
      "SEED: 1513, FOLD: 1, EPOCH: 4, train_loss: 0.0206453794532496\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017524091340601445\n",
      "SEED: 1513, FOLD: 1, EPOCH: 5, train_loss: 0.020327597586573033\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017513957672885487\n",
      "SEED: 1513, FOLD: 1, EPOCH: 6, train_loss: 0.02023708808195332\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017564950324594975\n",
      "SEED: 1513, FOLD: 1, EPOCH: 7, train_loss: 0.020224639133590717\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017469152116349765\n",
      "SEED: 1513, FOLD: 1, EPOCH: 8, train_loss: 0.02016711229647415\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017364875759397234\n",
      "SEED: 1513, FOLD: 1, EPOCH: 9, train_loss: 0.020228925201555958\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01788621326642377\n",
      "SEED: 1513, FOLD: 1, EPOCH: 10, train_loss: 0.020097267368565434\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 10, valid_loss: 0.017254556103476457\n",
      "SEED: 1513, FOLD: 1, EPOCH: 11, train_loss: 0.02014015582592591\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01706628307167973\n",
      "SEED: 1513, FOLD: 1, EPOCH: 12, train_loss: 0.01997529785486235\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01686301218079669\n",
      "SEED: 1513, FOLD: 1, EPOCH: 13, train_loss: 0.019853504253146442\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016871261330587525\n",
      "SEED: 1513, FOLD: 1, EPOCH: 14, train_loss: 0.019679647640905518\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016814234320606504\n",
      "SEED: 1513, FOLD: 1, EPOCH: 15, train_loss: 0.019539551957901836\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016647037863731385\n",
      "SEED: 1513, FOLD: 1, EPOCH: 16, train_loss: 0.019318267028184906\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016425716504454613\n",
      "SEED: 1513, FOLD: 1, EPOCH: 17, train_loss: 0.01903438222581062\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016572707359279903\n",
      "SEED: 1513, FOLD: 1, EPOCH: 18, train_loss: 0.01863292420444929\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016276020051113196\n",
      "SEED: 1513, FOLD: 1, EPOCH: 19, train_loss: 0.018267893151420612\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01598653607070446\n",
      "SEED: 1513, FOLD: 1, EPOCH: 20, train_loss: 0.01781884680731573\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 20, valid_loss: 0.01597263594823224\n",
      "SEED: 1513, FOLD: 1, EPOCH: 21, train_loss: 0.017130694230613502\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01588565358625991\n",
      "SEED: 1513, FOLD: 1, EPOCH: 22, train_loss: 0.016471581810248503\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015917066670954227\n",
      "SEED: 1513, FOLD: 1, EPOCH: 23, train_loss: 0.015973965353939846\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01581647539777415\n",
      "SEED: 1513, FOLD: 1, EPOCH: 24, train_loss: 0.015685329402702442\n",
      "SEED: 1513 ,FOLD: 1, EPOCH: 24, valid_loss: 0.01582024408770459\n",
      "SEED: 1513, FOLD: 2, EPOCH: 0, train_loss: 0.4988603966337615\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 0, valid_loss: 0.029623578009860856\n",
      "SEED: 1513, FOLD: 2, EPOCH: 1, train_loss: 0.02426827535627113\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 1, valid_loss: 0.019090755922453743\n",
      "SEED: 1513, FOLD: 2, EPOCH: 2, train_loss: 0.02182754365376372\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 2, valid_loss: 0.01802440873746361\n",
      "SEED: 1513, FOLD: 2, EPOCH: 3, train_loss: 0.020815485170569973\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017800596968403883\n",
      "SEED: 1513, FOLD: 2, EPOCH: 4, train_loss: 0.020561483904611374\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 4, valid_loss: 0.01747504310416324\n",
      "SEED: 1513, FOLD: 2, EPOCH: 5, train_loss: 0.020375171311847542\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01805948827947889\n",
      "SEED: 1513, FOLD: 2, EPOCH: 6, train_loss: 0.020351390961719597\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01750404252005475\n",
      "SEED: 1513, FOLD: 2, EPOCH: 7, train_loss: 0.020345781092950398\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01844888630190066\n",
      "SEED: 1513, FOLD: 2, EPOCH: 8, train_loss: 0.020445462316274643\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017532705622059958\n",
      "SEED: 1513, FOLD: 2, EPOCH: 9, train_loss: 0.0202157788005644\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 9, valid_loss: 0.017035607434809207\n",
      "SEED: 1513, FOLD: 2, EPOCH: 10, train_loss: 0.02014973001095696\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017476936536175863\n",
      "SEED: 1513, FOLD: 2, EPOCH: 11, train_loss: 0.020118520824589592\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 11, valid_loss: 0.017924043695841517\n",
      "SEED: 1513, FOLD: 2, EPOCH: 12, train_loss: 0.019957727833610515\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016996569159839835\n",
      "SEED: 1513, FOLD: 2, EPOCH: 13, train_loss: 0.019925421886685966\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016859030510698047\n",
      "SEED: 1513, FOLD: 2, EPOCH: 14, train_loss: 0.01982916369224372\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01691034220691238\n",
      "SEED: 1513, FOLD: 2, EPOCH: 15, train_loss: 0.019571291431244732\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016637843661010267\n",
      "SEED: 1513, FOLD: 2, EPOCH: 16, train_loss: 0.01933629032008458\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016773663807128157\n",
      "SEED: 1513, FOLD: 2, EPOCH: 17, train_loss: 0.01918729220557472\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016365862850631987\n",
      "SEED: 1513, FOLD: 2, EPOCH: 18, train_loss: 0.018809604674469734\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016172639253948417\n",
      "SEED: 1513, FOLD: 2, EPOCH: 19, train_loss: 0.01833390791401051\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01616201757320336\n",
      "SEED: 1513, FOLD: 2, EPOCH: 20, train_loss: 0.017844617670482916\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 20, valid_loss: 0.015938456569399153\n",
      "SEED: 1513, FOLD: 2, EPOCH: 21, train_loss: 0.01732001490081134\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01586660114782197\n",
      "SEED: 1513, FOLD: 2, EPOCH: 22, train_loss: 0.01672760002396029\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 22, valid_loss: 0.015804914252034254\n",
      "SEED: 1513, FOLD: 2, EPOCH: 23, train_loss: 0.0162305967423363\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015800726200853075\n",
      "SEED: 1513, FOLD: 2, EPOCH: 24, train_loss: 0.015936449305086895\n",
      "SEED: 1513 ,FOLD: 2, EPOCH: 24, valid_loss: 0.015822179881589755\n",
      "SEED: 1513, FOLD: 3, EPOCH: 0, train_loss: 0.49926974729675316\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 0, valid_loss: 0.030886118752615793\n",
      "SEED: 1513, FOLD: 3, EPOCH: 1, train_loss: 0.024613246834580448\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 1, valid_loss: 0.019096292714987483\n",
      "SEED: 1513, FOLD: 3, EPOCH: 2, train_loss: 0.021832315062267193\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 2, valid_loss: 0.017899386930678572\n",
      "SEED: 1513, FOLD: 3, EPOCH: 3, train_loss: 0.02090190517027741\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 3, valid_loss: 0.017748403123446874\n",
      "SEED: 1513, FOLD: 3, EPOCH: 4, train_loss: 0.020430087030905743\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 4, valid_loss: 0.01777472094233547\n",
      "SEED: 1513, FOLD: 3, EPOCH: 5, train_loss: 0.020318940457334553\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 5, valid_loss: 0.01754194548619645\n",
      "SEED: 1513, FOLD: 3, EPOCH: 6, train_loss: 0.020240699858877106\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01784383502921888\n",
      "SEED: 1513, FOLD: 3, EPOCH: 7, train_loss: 0.020163155471285183\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01738806021000658\n",
      "SEED: 1513, FOLD: 3, EPOCH: 8, train_loss: 0.020129347517006638\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 8, valid_loss: 0.01797544719385249\n",
      "SEED: 1513, FOLD: 3, EPOCH: 9, train_loss: 0.020116920097042686\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01731478992317404\n",
      "SEED: 1513, FOLD: 3, EPOCH: 10, train_loss: 0.02012197106428768\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017314609938434193\n",
      "SEED: 1513, FOLD: 3, EPOCH: 11, train_loss: 0.019982903601898663\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 11, valid_loss: 0.017288438124316078\n",
      "SEED: 1513, FOLD: 3, EPOCH: 12, train_loss: 0.019959939603248367\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 12, valid_loss: 0.017045923295829976\n",
      "SEED: 1513, FOLD: 3, EPOCH: 13, train_loss: 0.019759326174423313\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 13, valid_loss: 0.017003916283803325\n",
      "SEED: 1513, FOLD: 3, EPOCH: 14, train_loss: 0.019743589657372322\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 14, valid_loss: 0.017587025729673248\n",
      "SEED: 1513, FOLD: 3, EPOCH: 15, train_loss: 0.019430481855744038\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01701033828513963\n",
      "SEED: 1513, FOLD: 3, EPOCH: 16, train_loss: 0.01929121226936147\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016771661224109786\n",
      "SEED: 1513, FOLD: 3, EPOCH: 17, train_loss: 0.018977211477855842\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01660427288817508\n",
      "SEED: 1513, FOLD: 3, EPOCH: 18, train_loss: 0.0186807904932378\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016518380120396615\n",
      "SEED: 1513, FOLD: 3, EPOCH: 19, train_loss: 0.018234786557276613\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01629770597709077\n",
      "SEED: 1513, FOLD: 3, EPOCH: 20, train_loss: 0.017739304496596258\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016179978980549743\n",
      "SEED: 1513, FOLD: 3, EPOCH: 21, train_loss: 0.01709533148728635\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016125614808074066\n",
      "SEED: 1513, FOLD: 3, EPOCH: 22, train_loss: 0.01637791380610155\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 22, valid_loss: 0.016111982800066472\n",
      "SEED: 1513, FOLD: 3, EPOCH: 23, train_loss: 0.015867784943269646\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01606353529329811\n",
      "SEED: 1513, FOLD: 3, EPOCH: 24, train_loss: 0.015534984730723976\n",
      "SEED: 1513 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016074926698846477\n",
      "SEED: 1513, FOLD: 4, EPOCH: 0, train_loss: 0.4991933287971694\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 0, valid_loss: 0.030286328813859394\n",
      "SEED: 1513, FOLD: 4, EPOCH: 1, train_loss: 0.02467806205369424\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 1, valid_loss: 0.020491044276526996\n",
      "SEED: 1513, FOLD: 4, EPOCH: 2, train_loss: 0.021811903656824776\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 2, valid_loss: 0.019708950285400664\n",
      "SEED: 1513, FOLD: 4, EPOCH: 3, train_loss: 0.021221824084827\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01793551208185298\n",
      "SEED: 1513, FOLD: 4, EPOCH: 4, train_loss: 0.020613337974941384\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017296453139611652\n",
      "SEED: 1513, FOLD: 4, EPOCH: 5, train_loss: 0.02038772884702337\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017521446836846217\n",
      "SEED: 1513, FOLD: 4, EPOCH: 6, train_loss: 0.0203644880970967\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017370554112962313\n",
      "SEED: 1513, FOLD: 4, EPOCH: 7, train_loss: 0.02033742536129295\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017497117098953043\n",
      "SEED: 1513, FOLD: 4, EPOCH: 8, train_loss: 0.020333153209176617\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017325692703681332\n",
      "SEED: 1513, FOLD: 4, EPOCH: 9, train_loss: 0.02024440726508265\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017270998976060322\n",
      "SEED: 1513, FOLD: 4, EPOCH: 10, train_loss: 0.020253842035173508\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01734934505075216\n",
      "SEED: 1513, FOLD: 4, EPOCH: 11, train_loss: 0.020106076816285866\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 11, valid_loss: 0.017214293511850495\n",
      "SEED: 1513, FOLD: 4, EPOCH: 12, train_loss: 0.020036815760144287\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016969025268086364\n",
      "SEED: 1513, FOLD: 4, EPOCH: 13, train_loss: 0.01988545896323479\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01700655256531068\n",
      "SEED: 1513, FOLD: 4, EPOCH: 14, train_loss: 0.019711489330275334\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016840004681476523\n",
      "SEED: 1513, FOLD: 4, EPOCH: 15, train_loss: 0.01962036225080922\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016733120275395256\n",
      "SEED: 1513, FOLD: 4, EPOCH: 16, train_loss: 0.019359822654961677\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016717222066862242\n",
      "SEED: 1513, FOLD: 4, EPOCH: 17, train_loss: 0.019242678998389107\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01633422010179077\n",
      "SEED: 1513, FOLD: 4, EPOCH: 18, train_loss: 0.018792176848628384\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016246679345411914\n",
      "SEED: 1513, FOLD: 4, EPOCH: 19, train_loss: 0.018405950958908037\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016130416175084455\n",
      "SEED: 1513, FOLD: 4, EPOCH: 20, train_loss: 0.0178429178920561\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016011825017631053\n",
      "SEED: 1513, FOLD: 4, EPOCH: 21, train_loss: 0.01726270232187665\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 21, valid_loss: 0.015922925035868372\n",
      "SEED: 1513, FOLD: 4, EPOCH: 22, train_loss: 0.01667484374500919\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 22, valid_loss: 0.01585256201880319\n",
      "SEED: 1513, FOLD: 4, EPOCH: 23, train_loss: 0.016168181649476723\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 23, valid_loss: 0.015889156609773636\n",
      "SEED: 1513, FOLD: 4, EPOCH: 24, train_loss: 0.015862073243150244\n",
      "SEED: 1513 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015887226616697652\n",
      "SEED: 1269, FOLD: 0, EPOCH: 0, train_loss: 0.49889947897822096\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 0, valid_loss: 0.02815013825893402\n",
      "SEED: 1269, FOLD: 0, EPOCH: 1, train_loss: 0.02462571597509626\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 1, valid_loss: 0.02051243271146502\n",
      "SEED: 1269, FOLD: 0, EPOCH: 2, train_loss: 0.022013855544661266\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 2, valid_loss: 0.017943594764385905\n",
      "SEED: 1269, FOLD: 0, EPOCH: 3, train_loss: 0.020871633690768394\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017502557512904915\n",
      "SEED: 1269, FOLD: 0, EPOCH: 4, train_loss: 0.02069963837393384\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 4, valid_loss: 0.018229483014770915\n",
      "SEED: 1269, FOLD: 0, EPOCH: 5, train_loss: 0.020370158231884674\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 5, valid_loss: 0.01874436086841992\n",
      "SEED: 1269, FOLD: 0, EPOCH: 6, train_loss: 0.02031313008426324\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 6, valid_loss: 0.018132325261831284\n",
      "SEED: 1269, FOLD: 0, EPOCH: 7, train_loss: 0.020187818148321865\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01903565414249897\n",
      "SEED: 1269, FOLD: 0, EPOCH: 8, train_loss: 0.0202382637484782\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017190337819712503\n",
      "SEED: 1269, FOLD: 0, EPOCH: 9, train_loss: 0.020075624309264233\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01742716370416539\n",
      "SEED: 1269, FOLD: 0, EPOCH: 10, train_loss: 0.02007310730877562\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017337719750191483\n",
      "SEED: 1269, FOLD: 0, EPOCH: 11, train_loss: 0.019936726023645504\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 11, valid_loss: 0.016970697816993507\n",
      "SEED: 1269, FOLD: 0, EPOCH: 12, train_loss: 0.019886016629744267\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01680625392390149\n",
      "SEED: 1269, FOLD: 0, EPOCH: 13, train_loss: 0.019785548344362473\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01720963181661708\n",
      "SEED: 1269, FOLD: 0, EPOCH: 14, train_loss: 0.01966632801391508\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016915473421769484\n",
      "SEED: 1269, FOLD: 0, EPOCH: 15, train_loss: 0.01941480013825323\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016598846098142012\n",
      "SEED: 1269, FOLD: 0, EPOCH: 16, train_loss: 0.01915848973220673\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016422395088842936\n",
      "SEED: 1269, FOLD: 0, EPOCH: 17, train_loss: 0.0189283841923959\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01645586775349719\n",
      "SEED: 1269, FOLD: 0, EPOCH: 18, train_loss: 0.01863017576355217\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 18, valid_loss: 0.01628231658999409\n",
      "SEED: 1269, FOLD: 0, EPOCH: 19, train_loss: 0.018135534855874554\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016057276486286094\n",
      "SEED: 1269, FOLD: 0, EPOCH: 20, train_loss: 0.01755650465687116\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 20, valid_loss: 0.015982093635414328\n",
      "SEED: 1269, FOLD: 0, EPOCH: 21, train_loss: 0.01700948728788374\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 21, valid_loss: 0.01587601522249835\n",
      "SEED: 1269, FOLD: 0, EPOCH: 22, train_loss: 0.01633571668703487\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 22, valid_loss: 0.015854044045720782\n",
      "SEED: 1269, FOLD: 0, EPOCH: 23, train_loss: 0.01570453588594345\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015886615110295158\n",
      "SEED: 1269, FOLD: 0, EPOCH: 24, train_loss: 0.01543653586987352\n",
      "SEED: 1269 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015881936092461857\n",
      "SEED: 1269, FOLD: 1, EPOCH: 0, train_loss: 0.500821459390547\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 0, valid_loss: 0.02825784534215927\n",
      "SEED: 1269, FOLD: 1, EPOCH: 1, train_loss: 0.024545946428417297\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 1, valid_loss: 0.018882413740668978\n",
      "SEED: 1269, FOLD: 1, EPOCH: 2, train_loss: 0.021687250678845936\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 2, valid_loss: 0.01796637140214443\n",
      "SEED: 1269, FOLD: 1, EPOCH: 3, train_loss: 0.020770886804962505\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 3, valid_loss: 0.017559334901826724\n",
      "SEED: 1269, FOLD: 1, EPOCH: 4, train_loss: 0.02036715286743382\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01796503993017333\n",
      "SEED: 1269, FOLD: 1, EPOCH: 5, train_loss: 0.020329844517012436\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017481627528156553\n",
      "SEED: 1269, FOLD: 1, EPOCH: 6, train_loss: 0.020304878242313862\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017371792426066738\n",
      "SEED: 1269, FOLD: 1, EPOCH: 7, train_loss: 0.02030205933134193\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017613344985459533\n",
      "SEED: 1269, FOLD: 1, EPOCH: 8, train_loss: 0.020246049605201984\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017337975358324393\n",
      "SEED: 1269, FOLD: 1, EPOCH: 9, train_loss: 0.020182918338779953\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 9, valid_loss: 0.017596551749323095\n",
      "SEED: 1269, FOLD: 1, EPOCH: 10, train_loss: 0.020242676840744156\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 10, valid_loss: 0.017231571860611437\n",
      "SEED: 1269, FOLD: 1, EPOCH: 11, train_loss: 0.020064400009594967\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017204280091183525\n",
      "SEED: 1269, FOLD: 1, EPOCH: 12, train_loss: 0.020048119424693825\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 12, valid_loss: 0.017019782188747612\n",
      "SEED: 1269, FOLD: 1, EPOCH: 13, train_loss: 0.01984937084109887\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 13, valid_loss: 0.017094290788684574\n",
      "SEED: 1269, FOLD: 1, EPOCH: 14, train_loss: 0.019786781509933266\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016828580626419613\n",
      "SEED: 1269, FOLD: 1, EPOCH: 15, train_loss: 0.019573469403321327\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01679231104041849\n",
      "SEED: 1269, FOLD: 1, EPOCH: 16, train_loss: 0.019344353872904743\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016585293492036208\n",
      "SEED: 1269, FOLD: 1, EPOCH: 17, train_loss: 0.019115309602162546\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016294230946472713\n",
      "SEED: 1269, FOLD: 1, EPOCH: 18, train_loss: 0.01876001562788219\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016222684564335007\n",
      "SEED: 1269, FOLD: 1, EPOCH: 19, train_loss: 0.018306382432364036\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016222819260188513\n",
      "SEED: 1269, FOLD: 1, EPOCH: 20, train_loss: 0.017810787546677864\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 20, valid_loss: 0.0160622863098979\n",
      "SEED: 1269, FOLD: 1, EPOCH: 21, train_loss: 0.017198284507553646\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01596853355211871\n",
      "SEED: 1269, FOLD: 1, EPOCH: 22, train_loss: 0.01661559244941758\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015914405483220304\n",
      "SEED: 1269, FOLD: 1, EPOCH: 23, train_loss: 0.016083995433713215\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 23, valid_loss: 0.015868903590100153\n",
      "SEED: 1269, FOLD: 1, EPOCH: 24, train_loss: 0.015805895102844723\n",
      "SEED: 1269 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015884013580424444\n",
      "SEED: 1269, FOLD: 2, EPOCH: 0, train_loss: 0.49922502281117265\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 0, valid_loss: 0.04297365642019681\n",
      "SEED: 1269, FOLD: 2, EPOCH: 1, train_loss: 0.024554871819049553\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 1, valid_loss: 0.019198994232075554\n",
      "SEED: 1269, FOLD: 2, EPOCH: 2, train_loss: 0.021671641604515953\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018095866750393597\n",
      "SEED: 1269, FOLD: 2, EPOCH: 3, train_loss: 0.020877429108688797\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017682980267064913\n",
      "SEED: 1269, FOLD: 2, EPOCH: 4, train_loss: 0.02142638969572558\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017665860189923218\n",
      "SEED: 1269, FOLD: 2, EPOCH: 5, train_loss: 0.02071810235687788\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01766966605292899\n",
      "SEED: 1269, FOLD: 2, EPOCH: 6, train_loss: 0.02052431695325219\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017535589156406267\n",
      "SEED: 1269, FOLD: 2, EPOCH: 7, train_loss: 0.020409826128541128\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017130271744515216\n",
      "SEED: 1269, FOLD: 2, EPOCH: 8, train_loss: 0.0202927201770354\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017094644052641734\n",
      "SEED: 1269, FOLD: 2, EPOCH: 9, train_loss: 0.020216482300041378\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01731679851987532\n",
      "SEED: 1269, FOLD: 2, EPOCH: 10, train_loss: 0.020251042479514213\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 10, valid_loss: 0.01705881508865527\n",
      "SEED: 1269, FOLD: 2, EPOCH: 11, train_loss: 0.020136543644079262\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 11, valid_loss: 0.017227676856730666\n",
      "SEED: 1269, FOLD: 2, EPOCH: 12, train_loss: 0.020041747491104878\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 12, valid_loss: 0.017006289852516992\n",
      "SEED: 1269, FOLD: 2, EPOCH: 13, train_loss: 0.01995173879507659\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 13, valid_loss: 0.017144793777593544\n",
      "SEED: 1269, FOLD: 2, EPOCH: 14, train_loss: 0.01980623733792184\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01688359813498599\n",
      "SEED: 1269, FOLD: 2, EPOCH: 15, train_loss: 0.019576413273487404\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016698204326842513\n",
      "SEED: 1269, FOLD: 2, EPOCH: 16, train_loss: 0.019460236869644428\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016671310551464556\n",
      "SEED: 1269, FOLD: 2, EPOCH: 17, train_loss: 0.019204209936593754\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01653052568435669\n",
      "SEED: 1269, FOLD: 2, EPOCH: 18, train_loss: 0.018828996686615806\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016362717268722397\n",
      "SEED: 1269, FOLD: 2, EPOCH: 19, train_loss: 0.01843405305745377\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016197942915771688\n",
      "SEED: 1269, FOLD: 2, EPOCH: 20, train_loss: 0.01802212055907517\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01601386783378465\n",
      "SEED: 1269, FOLD: 2, EPOCH: 21, train_loss: 0.017425474400321644\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01599401735833713\n",
      "SEED: 1269, FOLD: 2, EPOCH: 22, train_loss: 0.016892639299233753\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 22, valid_loss: 0.015964493794100625\n",
      "SEED: 1269, FOLD: 2, EPOCH: 23, train_loss: 0.016469789743153513\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01595731731504202\n",
      "SEED: 1269, FOLD: 2, EPOCH: 24, train_loss: 0.016225361103272957\n",
      "SEED: 1269 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01591188787881817\n",
      "SEED: 1269, FOLD: 3, EPOCH: 0, train_loss: 0.49837170515641355\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 0, valid_loss: 0.02975464447268418\n",
      "SEED: 1269, FOLD: 3, EPOCH: 1, train_loss: 0.024488108664535095\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 1, valid_loss: 0.019442289748362134\n",
      "SEED: 1269, FOLD: 3, EPOCH: 2, train_loss: 0.022077909346831882\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 2, valid_loss: 0.019704241145934377\n",
      "SEED: 1269, FOLD: 3, EPOCH: 3, train_loss: 0.021188953230022522\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 3, valid_loss: 0.01776437626353332\n",
      "SEED: 1269, FOLD: 3, EPOCH: 4, train_loss: 0.020672414897252685\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 4, valid_loss: 0.019139042496681212\n",
      "SEED: 1269, FOLD: 3, EPOCH: 5, train_loss: 0.020437541026352108\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017548803186842373\n",
      "SEED: 1269, FOLD: 3, EPOCH: 6, train_loss: 0.02045627614564222\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01842535084911755\n",
      "SEED: 1269, FOLD: 3, EPOCH: 7, train_loss: 0.020338766749246395\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017683036412511552\n",
      "SEED: 1269, FOLD: 3, EPOCH: 8, train_loss: 0.020299579462279446\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 8, valid_loss: 0.01791696117392608\n",
      "SEED: 1269, FOLD: 3, EPOCH: 9, train_loss: 0.020295894556287407\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 9, valid_loss: 0.017517220175692013\n",
      "SEED: 1269, FOLD: 3, EPOCH: 10, train_loss: 0.02007183471046712\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017375839767711503\n",
      "SEED: 1269, FOLD: 3, EPOCH: 11, train_loss: 0.02004932308488566\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 11, valid_loss: 0.017466553007917746\n",
      "SEED: 1269, FOLD: 3, EPOCH: 12, train_loss: 0.019950183567361557\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 12, valid_loss: 0.01719392120305981\n",
      "SEED: 1269, FOLD: 3, EPOCH: 13, train_loss: 0.019873396722950798\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01730519716760942\n",
      "SEED: 1269, FOLD: 3, EPOCH: 14, train_loss: 0.01968718623823446\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 14, valid_loss: 0.017113077454268932\n",
      "SEED: 1269, FOLD: 3, EPOCH: 15, train_loss: 0.019605571039668892\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016873126822922913\n",
      "SEED: 1269, FOLD: 3, EPOCH: 16, train_loss: 0.019372680008519386\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 16, valid_loss: 0.017257961178464547\n",
      "SEED: 1269, FOLD: 3, EPOCH: 17, train_loss: 0.01905971938285275\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016652361543050834\n",
      "SEED: 1269, FOLD: 3, EPOCH: 18, train_loss: 0.01876206466577191\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016473885838474547\n",
      "SEED: 1269, FOLD: 3, EPOCH: 19, train_loss: 0.01830212028859102\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016427273782236237\n",
      "SEED: 1269, FOLD: 3, EPOCH: 20, train_loss: 0.017815102107714916\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 20, valid_loss: 0.01625188634331737\n",
      "SEED: 1269, FOLD: 3, EPOCH: 21, train_loss: 0.017281877423596124\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016155981032976083\n",
      "SEED: 1269, FOLD: 3, EPOCH: 22, train_loss: 0.01664786303307915\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 22, valid_loss: 0.016162351944616862\n",
      "SEED: 1269, FOLD: 3, EPOCH: 23, train_loss: 0.01615237928522022\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016128012165427207\n",
      "SEED: 1269, FOLD: 3, EPOCH: 24, train_loss: 0.01586637445523039\n",
      "SEED: 1269 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016122778292213168\n",
      "SEED: 1269, FOLD: 4, EPOCH: 0, train_loss: 0.4981237344875716\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 0, valid_loss: 0.028201242802398545\n",
      "SEED: 1269, FOLD: 4, EPOCH: 1, train_loss: 0.024460560102285683\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 1, valid_loss: 0.01920389878962721\n",
      "SEED: 1269, FOLD: 4, EPOCH: 2, train_loss: 0.021885611170875854\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 2, valid_loss: 0.021552014138017384\n",
      "SEED: 1269, FOLD: 4, EPOCH: 3, train_loss: 0.02116791121121766\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01781927256711892\n",
      "SEED: 1269, FOLD: 4, EPOCH: 4, train_loss: 0.02062193510810966\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017679157267723764\n",
      "SEED: 1269, FOLD: 4, EPOCH: 5, train_loss: 0.020512467776627644\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017548902119909015\n",
      "SEED: 1269, FOLD: 4, EPOCH: 6, train_loss: 0.020397150754064754\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01728655541581767\n",
      "SEED: 1269, FOLD: 4, EPOCH: 7, train_loss: 0.02032253007148055\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01772911673677819\n",
      "SEED: 1269, FOLD: 4, EPOCH: 8, train_loss: 0.020239915523300137\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 8, valid_loss: 0.01768323199025222\n",
      "SEED: 1269, FOLD: 4, EPOCH: 9, train_loss: 0.020302341279128323\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017140973545610904\n",
      "SEED: 1269, FOLD: 4, EPOCH: 10, train_loss: 0.020185789579282635\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017014117485710554\n",
      "SEED: 1269, FOLD: 4, EPOCH: 11, train_loss: 0.02011716755889896\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 11, valid_loss: 0.017299963267786163\n",
      "SEED: 1269, FOLD: 4, EPOCH: 12, train_loss: 0.020119603196887867\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016961553932300637\n",
      "SEED: 1269, FOLD: 4, EPOCH: 13, train_loss: 0.01987880450821873\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016930800756173474\n",
      "SEED: 1269, FOLD: 4, EPOCH: 14, train_loss: 0.019860056863314865\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 14, valid_loss: 0.017098318918475082\n",
      "SEED: 1269, FOLD: 4, EPOCH: 15, train_loss: 0.019697763795114082\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01660887434014252\n",
      "SEED: 1269, FOLD: 4, EPOCH: 16, train_loss: 0.01935642047960689\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016573630166905266\n",
      "SEED: 1269, FOLD: 4, EPOCH: 17, train_loss: 0.01911234186179396\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016500759390848024\n",
      "SEED: 1269, FOLD: 4, EPOCH: 18, train_loss: 0.01885582726664733\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016209595410951547\n",
      "SEED: 1269, FOLD: 4, EPOCH: 19, train_loss: 0.01843169315353684\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016136976810438294\n",
      "SEED: 1269, FOLD: 4, EPOCH: 20, train_loss: 0.017944597058754036\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01599253000957625\n",
      "SEED: 1269, FOLD: 4, EPOCH: 21, train_loss: 0.017369614279680493\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 21, valid_loss: 0.015885194204747675\n",
      "SEED: 1269, FOLD: 4, EPOCH: 22, train_loss: 0.01674923563942961\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 22, valid_loss: 0.01583796249968665\n",
      "SEED: 1269, FOLD: 4, EPOCH: 23, train_loss: 0.016174842016366514\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 23, valid_loss: 0.015834415437919754\n",
      "SEED: 1269, FOLD: 4, EPOCH: 24, train_loss: 0.015951371974433245\n",
      "SEED: 1269 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015841685794293882\n",
      "SEED: 1392, FOLD: 0, EPOCH: 0, train_loss: 0.5021849016024582\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 0, valid_loss: 0.028279315627046994\n",
      "SEED: 1392, FOLD: 0, EPOCH: 1, train_loss: 0.024264337144036224\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 1, valid_loss: 0.01925002309892859\n",
      "SEED: 1392, FOLD: 0, EPOCH: 2, train_loss: 0.02188112648824851\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 2, valid_loss: 0.018391557836106846\n",
      "SEED: 1392, FOLD: 0, EPOCH: 3, train_loss: 0.02125921027491922\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017542012301938876\n",
      "SEED: 1392, FOLD: 0, EPOCH: 4, train_loss: 0.020473035754284996\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 4, valid_loss: 0.01904795143221106\n",
      "SEED: 1392, FOLD: 0, EPOCH: 5, train_loss: 0.020409912221889565\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017284292355179788\n",
      "SEED: 1392, FOLD: 0, EPOCH: 6, train_loss: 0.020310727258523304\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01750387975147792\n",
      "SEED: 1392, FOLD: 0, EPOCH: 7, train_loss: 0.02024198366680007\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01800726976777826\n",
      "SEED: 1392, FOLD: 0, EPOCH: 8, train_loss: 0.020252647121315418\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01712909505835601\n",
      "SEED: 1392, FOLD: 0, EPOCH: 9, train_loss: 0.02014207402649133\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017245716920920782\n",
      "SEED: 1392, FOLD: 0, EPOCH: 10, train_loss: 0.02011426134655873\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017135689141494888\n",
      "SEED: 1392, FOLD: 0, EPOCH: 11, train_loss: 0.019982932189452476\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 11, valid_loss: 0.016926817116992815\n",
      "SEED: 1392, FOLD: 0, EPOCH: 12, train_loss: 0.019933649541243263\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016816347118999278\n",
      "SEED: 1392, FOLD: 0, EPOCH: 13, train_loss: 0.019800873095358627\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016723808167236193\n",
      "SEED: 1392, FOLD: 0, EPOCH: 14, train_loss: 0.019658449942758983\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016848380863666534\n",
      "SEED: 1392, FOLD: 0, EPOCH: 15, train_loss: 0.019454626487972942\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016759132114904266\n",
      "SEED: 1392, FOLD: 0, EPOCH: 16, train_loss: 0.01931420918149145\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016501245275139808\n",
      "SEED: 1392, FOLD: 0, EPOCH: 17, train_loss: 0.018986610385278862\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016268869249948432\n",
      "SEED: 1392, FOLD: 0, EPOCH: 18, train_loss: 0.0185554474187286\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016252495774200983\n",
      "SEED: 1392, FOLD: 0, EPOCH: 19, train_loss: 0.018155659582681845\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 19, valid_loss: 0.01614370904862881\n",
      "SEED: 1392, FOLD: 0, EPOCH: 20, train_loss: 0.017699861966505432\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 20, valid_loss: 0.015923953615128994\n",
      "SEED: 1392, FOLD: 0, EPOCH: 21, train_loss: 0.017072496429571638\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 21, valid_loss: 0.01589350633855377\n",
      "SEED: 1392, FOLD: 0, EPOCH: 22, train_loss: 0.016389133597629658\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01588691637984344\n",
      "SEED: 1392, FOLD: 0, EPOCH: 23, train_loss: 0.015856610320886408\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015873424389532636\n",
      "SEED: 1392, FOLD: 0, EPOCH: 24, train_loss: 0.015563497623509687\n",
      "SEED: 1392 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01588196789047548\n",
      "SEED: 1392, FOLD: 1, EPOCH: 0, train_loss: 0.5004290986968123\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 0, valid_loss: 0.028927442112139292\n",
      "SEED: 1392, FOLD: 1, EPOCH: 1, train_loss: 0.02463286888340245\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 1, valid_loss: 0.01935334775064673\n",
      "SEED: 1392, FOLD: 1, EPOCH: 2, train_loss: 0.021935886878898178\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 2, valid_loss: 0.01795488606606211\n",
      "SEED: 1392, FOLD: 1, EPOCH: 3, train_loss: 0.021148060003052586\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 3, valid_loss: 0.01814217556800161\n",
      "SEED: 1392, FOLD: 1, EPOCH: 4, train_loss: 0.020756800254078014\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01759347806551627\n",
      "SEED: 1392, FOLD: 1, EPOCH: 5, train_loss: 0.020310430018150288\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017648519203066825\n",
      "SEED: 1392, FOLD: 1, EPOCH: 6, train_loss: 0.02038340383897657\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017797956988215447\n",
      "SEED: 1392, FOLD: 1, EPOCH: 7, train_loss: 0.020275486822145573\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017660720672990595\n",
      "SEED: 1392, FOLD: 1, EPOCH: 8, train_loss: 0.020247041801179665\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017114030702837877\n",
      "SEED: 1392, FOLD: 1, EPOCH: 9, train_loss: 0.02027192078800737\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01728955635002681\n",
      "SEED: 1392, FOLD: 1, EPOCH: 10, train_loss: 0.02023181262547555\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01734639839934451\n",
      "SEED: 1392, FOLD: 1, EPOCH: 11, train_loss: 0.02000610708542492\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 11, valid_loss: 0.0170043287266578\n",
      "SEED: 1392, FOLD: 1, EPOCH: 12, train_loss: 0.01993014919909014\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01754086118723665\n",
      "SEED: 1392, FOLD: 1, EPOCH: 13, train_loss: 0.019864566070770008\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016918918011443955\n",
      "SEED: 1392, FOLD: 1, EPOCH: 14, train_loss: 0.019741099462776943\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016822851821780206\n",
      "SEED: 1392, FOLD: 1, EPOCH: 15, train_loss: 0.019486653712996536\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01661513668618032\n",
      "SEED: 1392, FOLD: 1, EPOCH: 16, train_loss: 0.019293296069878597\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 16, valid_loss: 0.01660142383937325\n",
      "SEED: 1392, FOLD: 1, EPOCH: 17, train_loss: 0.019048330617015777\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016442763965044703\n",
      "SEED: 1392, FOLD: 1, EPOCH: 18, train_loss: 0.018631966298689014\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01628494081752641\n",
      "SEED: 1392, FOLD: 1, EPOCH: 19, train_loss: 0.018248531171053215\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016147299110889433\n",
      "SEED: 1392, FOLD: 1, EPOCH: 20, train_loss: 0.01779251879054135\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016017466011856284\n",
      "SEED: 1392, FOLD: 1, EPOCH: 21, train_loss: 0.017142105753115124\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 21, valid_loss: 0.015932404489389488\n",
      "SEED: 1392, FOLD: 1, EPOCH: 22, train_loss: 0.016498963598269915\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015921058665428842\n",
      "SEED: 1392, FOLD: 1, EPOCH: 23, train_loss: 0.015955563189218872\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 23, valid_loss: 0.015900185251874584\n",
      "SEED: 1392, FOLD: 1, EPOCH: 24, train_loss: 0.015704304081104372\n",
      "SEED: 1392 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015870493650436402\n",
      "SEED: 1392, FOLD: 2, EPOCH: 0, train_loss: 0.4999573267996311\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 0, valid_loss: 0.027665835991501807\n",
      "SEED: 1392, FOLD: 2, EPOCH: 1, train_loss: 0.02461887871765572\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 1, valid_loss: 0.020035396037357194\n",
      "SEED: 1392, FOLD: 2, EPOCH: 2, train_loss: 0.02177501588627912\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 2, valid_loss: 0.017933190347892897\n",
      "SEED: 1392, FOLD: 2, EPOCH: 3, train_loss: 0.02090040563295285\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 3, valid_loss: 0.01761158263044698\n",
      "SEED: 1392, FOLD: 2, EPOCH: 4, train_loss: 0.020588677956898144\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 4, valid_loss: 0.019200670240180833\n",
      "SEED: 1392, FOLD: 2, EPOCH: 5, train_loss: 0.020497997412862984\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01751849672624043\n",
      "SEED: 1392, FOLD: 2, EPOCH: 6, train_loss: 0.02035762535651093\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017638550299618926\n",
      "SEED: 1392, FOLD: 2, EPOCH: 7, train_loss: 0.020255539201847885\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01724618950060436\n",
      "SEED: 1392, FOLD: 2, EPOCH: 8, train_loss: 0.02014593731449998\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017116102549646583\n",
      "SEED: 1392, FOLD: 2, EPOCH: 9, train_loss: 0.02021998555763908\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01709767050508942\n",
      "SEED: 1392, FOLD: 2, EPOCH: 10, train_loss: 0.02009141739403856\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017124591687960284\n",
      "SEED: 1392, FOLD: 2, EPOCH: 11, train_loss: 0.020056209594443226\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 11, valid_loss: 0.017467925591128215\n",
      "SEED: 1392, FOLD: 2, EPOCH: 12, train_loss: 0.019910018418686115\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01693469403045518\n",
      "SEED: 1392, FOLD: 2, EPOCH: 13, train_loss: 0.019820763041143833\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 13, valid_loss: 0.0171419447021825\n",
      "SEED: 1392, FOLD: 2, EPOCH: 14, train_loss: 0.019757631356301514\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016919618153146337\n",
      "SEED: 1392, FOLD: 2, EPOCH: 15, train_loss: 0.019592723768690357\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01654381685491119\n",
      "SEED: 1392, FOLD: 2, EPOCH: 16, train_loss: 0.01928550873518638\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016474679085825172\n",
      "SEED: 1392, FOLD: 2, EPOCH: 17, train_loss: 0.019028315833513287\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01639898767960923\n",
      "SEED: 1392, FOLD: 2, EPOCH: 18, train_loss: 0.018654650765592636\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016540231396045005\n",
      "SEED: 1392, FOLD: 2, EPOCH: 19, train_loss: 0.018251734137859032\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016206909423427923\n",
      "SEED: 1392, FOLD: 2, EPOCH: 20, train_loss: 0.01774867480971675\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 20, valid_loss: 0.015981963463127614\n",
      "SEED: 1392, FOLD: 2, EPOCH: 21, train_loss: 0.017116224062561556\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 21, valid_loss: 0.015883821727974073\n",
      "SEED: 1392, FOLD: 2, EPOCH: 22, train_loss: 0.016469141441410866\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 22, valid_loss: 0.015880093430834158\n",
      "SEED: 1392, FOLD: 2, EPOCH: 23, train_loss: 0.015955083274646946\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01590361555239984\n",
      "SEED: 1392, FOLD: 2, EPOCH: 24, train_loss: 0.015652586712731398\n",
      "SEED: 1392 ,FOLD: 2, EPOCH: 24, valid_loss: 0.015894777460822036\n",
      "SEED: 1392, FOLD: 3, EPOCH: 0, train_loss: 0.4973878998417353\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 0, valid_loss: 0.031380437367728775\n",
      "SEED: 1392, FOLD: 3, EPOCH: 1, train_loss: 0.024229562571407227\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 1, valid_loss: 0.02002762465604714\n",
      "SEED: 1392, FOLD: 3, EPOCH: 2, train_loss: 0.022146663372067436\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018020189021314893\n",
      "SEED: 1392, FOLD: 3, EPOCH: 3, train_loss: 0.020825645319469597\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 3, valid_loss: 0.01784642104591642\n",
      "SEED: 1392, FOLD: 3, EPOCH: 4, train_loss: 0.020431199394490406\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 4, valid_loss: 0.019255241325923374\n",
      "SEED: 1392, FOLD: 3, EPOCH: 5, train_loss: 0.020341429832404938\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017806211300194264\n",
      "SEED: 1392, FOLD: 3, EPOCH: 6, train_loss: 0.02022105000535215\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01775412665946143\n",
      "SEED: 1392, FOLD: 3, EPOCH: 7, train_loss: 0.020110819684476523\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017371048964560033\n",
      "SEED: 1392, FOLD: 3, EPOCH: 8, train_loss: 0.020143064400316147\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 8, valid_loss: 0.01732709924025195\n",
      "SEED: 1392, FOLD: 3, EPOCH: 9, train_loss: 0.020058286092851475\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 9, valid_loss: 0.017350626710270132\n",
      "SEED: 1392, FOLD: 3, EPOCH: 10, train_loss: 0.020030224074920017\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017330676609916346\n",
      "SEED: 1392, FOLD: 3, EPOCH: 11, train_loss: 0.01994954661020766\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01716016727898802\n",
      "SEED: 1392, FOLD: 3, EPOCH: 12, train_loss: 0.01987097797024509\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 12, valid_loss: 0.01729022227227688\n",
      "SEED: 1392, FOLD: 3, EPOCH: 13, train_loss: 0.019738843893983227\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01722683935825314\n",
      "SEED: 1392, FOLD: 3, EPOCH: 14, train_loss: 0.019676624925510176\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016943919525614807\n",
      "SEED: 1392, FOLD: 3, EPOCH: 15, train_loss: 0.019398421400051186\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01689310371875763\n",
      "SEED: 1392, FOLD: 3, EPOCH: 16, train_loss: 0.01923843724248202\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016788020942892348\n",
      "SEED: 1392, FOLD: 3, EPOCH: 17, train_loss: 0.018914143851809742\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01649997452540057\n",
      "SEED: 1392, FOLD: 3, EPOCH: 18, train_loss: 0.018554987932514887\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 18, valid_loss: 0.01649358160793781\n",
      "SEED: 1392, FOLD: 3, EPOCH: 19, train_loss: 0.01819564854942154\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 19, valid_loss: 0.0162450178659388\n",
      "SEED: 1392, FOLD: 3, EPOCH: 20, train_loss: 0.017650827940931355\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016134658402630262\n",
      "SEED: 1392, FOLD: 3, EPOCH: 21, train_loss: 0.017030672244457663\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01614201068878174\n",
      "SEED: 1392, FOLD: 3, EPOCH: 22, train_loss: 0.016349116036587435\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01611076154346977\n",
      "SEED: 1392, FOLD: 3, EPOCH: 23, train_loss: 0.015715184095113174\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016133513620921542\n",
      "SEED: 1392, FOLD: 3, EPOCH: 24, train_loss: 0.015415884142714565\n",
      "SEED: 1392 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016109277148331914\n",
      "SEED: 1392, FOLD: 4, EPOCH: 0, train_loss: 0.49973075747813867\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 0, valid_loss: 0.029387352083410534\n",
      "SEED: 1392, FOLD: 4, EPOCH: 1, train_loss: 0.02424341946354379\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 1, valid_loss: 0.0190937340259552\n",
      "SEED: 1392, FOLD: 4, EPOCH: 2, train_loss: 0.021629705957636452\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 2, valid_loss: 0.0181429814015116\n",
      "SEED: 1392, FOLD: 4, EPOCH: 3, train_loss: 0.020826959672073524\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 3, valid_loss: 0.017532875362251486\n",
      "SEED: 1392, FOLD: 4, EPOCH: 4, train_loss: 0.02043264922078537\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017899930317487035\n",
      "SEED: 1392, FOLD: 4, EPOCH: 5, train_loss: 0.020404762318492798\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017286389374307223\n",
      "SEED: 1392, FOLD: 4, EPOCH: 6, train_loss: 0.020323539544166862\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 6, valid_loss: 0.018613214045763014\n",
      "SEED: 1392, FOLD: 4, EPOCH: 7, train_loss: 0.020264524224119774\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017771353891917637\n",
      "SEED: 1392, FOLD: 4, EPOCH: 8, train_loss: 0.02025707610005486\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 8, valid_loss: 0.0172657009480255\n",
      "SEED: 1392, FOLD: 4, EPOCH: 9, train_loss: 0.020223021979673184\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 9, valid_loss: 0.01713840171162571\n",
      "SEED: 1392, FOLD: 4, EPOCH: 10, train_loss: 0.020096878548139248\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017150630269731792\n",
      "SEED: 1392, FOLD: 4, EPOCH: 11, train_loss: 0.020051191965846912\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01714702948395695\n",
      "SEED: 1392, FOLD: 4, EPOCH: 12, train_loss: 0.019982468012882316\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016959189942904882\n",
      "SEED: 1392, FOLD: 4, EPOCH: 13, train_loss: 0.01984160460963629\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01685550920665264\n",
      "SEED: 1392, FOLD: 4, EPOCH: 14, train_loss: 0.019755767604363136\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 14, valid_loss: 0.01681098046579531\n",
      "SEED: 1392, FOLD: 4, EPOCH: 15, train_loss: 0.01948202804972728\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01664504339652402\n",
      "SEED: 1392, FOLD: 4, EPOCH: 16, train_loss: 0.019250765652058348\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016452264466456003\n",
      "SEED: 1392, FOLD: 4, EPOCH: 17, train_loss: 0.0189941864312235\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016424326199506012\n",
      "SEED: 1392, FOLD: 4, EPOCH: 18, train_loss: 0.018766845077060272\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016262990848294325\n",
      "SEED: 1392, FOLD: 4, EPOCH: 19, train_loss: 0.018320441286525\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016039808919387204\n",
      "SEED: 1392, FOLD: 4, EPOCH: 20, train_loss: 0.017717227164277996\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 20, valid_loss: 0.015937734714576175\n",
      "SEED: 1392, FOLD: 4, EPOCH: 21, train_loss: 0.01710172906598967\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 21, valid_loss: 0.015892721872244563\n",
      "SEED: 1392, FOLD: 4, EPOCH: 22, train_loss: 0.016512953575052645\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 22, valid_loss: 0.01583921584699835\n",
      "SEED: 1392, FOLD: 4, EPOCH: 23, train_loss: 0.015951047347777563\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 23, valid_loss: 0.0158683662169746\n",
      "SEED: 1392, FOLD: 4, EPOCH: 24, train_loss: 0.015672278023608353\n",
      "SEED: 1392 ,FOLD: 4, EPOCH: 24, valid_loss: 0.015857783944479058\n",
      "SEED: 1119, FOLD: 0, EPOCH: 0, train_loss: 0.4975810268272956\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 0, valid_loss: 0.0317600030452013\n",
      "SEED: 1119, FOLD: 0, EPOCH: 1, train_loss: 0.02448741889194302\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 1, valid_loss: 0.019230958712952478\n",
      "SEED: 1119, FOLD: 0, EPOCH: 2, train_loss: 0.021780001674441322\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 2, valid_loss: 0.018000437771635396\n",
      "SEED: 1119, FOLD: 0, EPOCH: 3, train_loss: 0.0210306563185177\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 3, valid_loss: 0.01825821101665497\n",
      "SEED: 1119, FOLD: 0, EPOCH: 4, train_loss: 0.020666293435446594\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017622410878539087\n",
      "SEED: 1119, FOLD: 0, EPOCH: 5, train_loss: 0.020375237759688625\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017194433669958795\n",
      "SEED: 1119, FOLD: 0, EPOCH: 6, train_loss: 0.020321435956419377\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017203365372759957\n",
      "SEED: 1119, FOLD: 0, EPOCH: 7, train_loss: 0.020283529993848526\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 7, valid_loss: 0.01709556829716478\n",
      "SEED: 1119, FOLD: 0, EPOCH: 8, train_loss: 0.02026348536753136\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01712195934461696\n",
      "SEED: 1119, FOLD: 0, EPOCH: 9, train_loss: 0.020217051743057327\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017302988735692842\n",
      "SEED: 1119, FOLD: 0, EPOCH: 10, train_loss: 0.020173611794260964\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017214764255498137\n",
      "SEED: 1119, FOLD: 0, EPOCH: 11, train_loss: 0.020078779387193314\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01702785225851195\n",
      "SEED: 1119, FOLD: 0, EPOCH: 12, train_loss: 0.019997723090151947\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01724643332085439\n",
      "SEED: 1119, FOLD: 0, EPOCH: 13, train_loss: 0.019793344891049724\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016820227008845126\n",
      "SEED: 1119, FOLD: 0, EPOCH: 14, train_loss: 0.01975633934194195\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016957560687192848\n",
      "SEED: 1119, FOLD: 0, EPOCH: 15, train_loss: 0.019576021969534348\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016605076725993838\n",
      "SEED: 1119, FOLD: 0, EPOCH: 16, train_loss: 0.019222934851827828\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016772664338350295\n",
      "SEED: 1119, FOLD: 0, EPOCH: 17, train_loss: 0.019059073780595823\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01663196866533586\n",
      "SEED: 1119, FOLD: 0, EPOCH: 18, train_loss: 0.018707019519870697\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 18, valid_loss: 0.01631858061466898\n",
      "SEED: 1119, FOLD: 0, EPOCH: 19, train_loss: 0.018182088155299425\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 19, valid_loss: 0.01612600732062544\n",
      "SEED: 1119, FOLD: 0, EPOCH: 20, train_loss: 0.0177581490530376\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01603035269571202\n",
      "SEED: 1119, FOLD: 0, EPOCH: 21, train_loss: 0.01713183093681068\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 21, valid_loss: 0.0159456998908094\n",
      "SEED: 1119, FOLD: 0, EPOCH: 22, train_loss: 0.016537160815104195\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 22, valid_loss: 0.015895363981170314\n",
      "SEED: 1119, FOLD: 0, EPOCH: 23, train_loss: 0.01599903301457348\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01589843939457621\n",
      "SEED: 1119, FOLD: 0, EPOCH: 24, train_loss: 0.015724545810371637\n",
      "SEED: 1119 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015868816391697953\n",
      "SEED: 1119, FOLD: 1, EPOCH: 0, train_loss: 0.49936328353225323\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 0, valid_loss: 0.027980106590049608\n",
      "SEED: 1119, FOLD: 1, EPOCH: 1, train_loss: 0.02467959715674321\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 1, valid_loss: 0.018984502394284522\n",
      "SEED: 1119, FOLD: 1, EPOCH: 2, train_loss: 0.021764227756015633\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 2, valid_loss: 0.01795784245644297\n",
      "SEED: 1119, FOLD: 1, EPOCH: 3, train_loss: 0.02119299167416234\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 3, valid_loss: 0.018642166895525798\n",
      "SEED: 1119, FOLD: 1, EPOCH: 4, train_loss: 0.020799644898785198\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01756167507597378\n",
      "SEED: 1119, FOLD: 1, EPOCH: 5, train_loss: 0.02067450392127469\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017705616913735865\n",
      "SEED: 1119, FOLD: 1, EPOCH: 6, train_loss: 0.02041477720806564\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 6, valid_loss: 0.0174617842904159\n",
      "SEED: 1119, FOLD: 1, EPOCH: 7, train_loss: 0.02036062785950692\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01748618499508926\n",
      "SEED: 1119, FOLD: 1, EPOCH: 8, train_loss: 0.020350320845086506\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017281747476330826\n",
      "SEED: 1119, FOLD: 1, EPOCH: 9, train_loss: 0.020290049548814262\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01752126520233495\n",
      "SEED: 1119, FOLD: 1, EPOCH: 10, train_loss: 0.02015596586347058\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01718600198094334\n",
      "SEED: 1119, FOLD: 1, EPOCH: 11, train_loss: 0.020101291437943775\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01705768406391144\n",
      "SEED: 1119, FOLD: 1, EPOCH: 12, train_loss: 0.020042522162522957\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 12, valid_loss: 0.017051232286861964\n",
      "SEED: 1119, FOLD: 1, EPOCH: 13, train_loss: 0.01992000395135171\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016976900318903584\n",
      "SEED: 1119, FOLD: 1, EPOCH: 14, train_loss: 0.019780735404271145\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016937536666435854\n",
      "SEED: 1119, FOLD: 1, EPOCH: 15, train_loss: 0.019637873436769714\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01673996363367353\n",
      "SEED: 1119, FOLD: 1, EPOCH: 16, train_loss: 0.019324710261940523\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 16, valid_loss: 0.01647370031901768\n",
      "SEED: 1119, FOLD: 1, EPOCH: 17, train_loss: 0.019134748335657776\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016621157260877744\n",
      "SEED: 1119, FOLD: 1, EPOCH: 18, train_loss: 0.018798828232979427\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016267843704138484\n",
      "SEED: 1119, FOLD: 1, EPOCH: 19, train_loss: 0.018405999023251345\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016089389446590628\n",
      "SEED: 1119, FOLD: 1, EPOCH: 20, train_loss: 0.01787000832458337\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 20, valid_loss: 0.01593162739383323\n",
      "SEED: 1119, FOLD: 1, EPOCH: 21, train_loss: 0.017352696852353605\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 21, valid_loss: 0.015882026005004133\n",
      "SEED: 1119, FOLD: 1, EPOCH: 22, train_loss: 0.016764111081273226\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 22, valid_loss: 0.01584038141050509\n",
      "SEED: 1119, FOLD: 1, EPOCH: 23, train_loss: 0.01630662063109702\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01586574999881642\n",
      "SEED: 1119, FOLD: 1, EPOCH: 24, train_loss: 0.0160374418778372\n",
      "SEED: 1119 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015829174885792392\n",
      "SEED: 1119, FOLD: 2, EPOCH: 0, train_loss: 0.498081941805456\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 0, valid_loss: 0.03050022827727454\n",
      "SEED: 1119, FOLD: 2, EPOCH: 1, train_loss: 0.025274279311407303\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 1, valid_loss: 0.019569035938807895\n",
      "SEED: 1119, FOLD: 2, EPOCH: 2, train_loss: 0.022183849611252113\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018695782923272678\n",
      "SEED: 1119, FOLD: 2, EPOCH: 3, train_loss: 0.02127641053411408\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017752389290503094\n",
      "SEED: 1119, FOLD: 2, EPOCH: 4, train_loss: 0.0207509758706758\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 4, valid_loss: 0.01757724689585822\n",
      "SEED: 1119, FOLD: 2, EPOCH: 5, train_loss: 0.020624362620646538\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017616415875298636\n",
      "SEED: 1119, FOLD: 2, EPOCH: 6, train_loss: 0.020374094662459\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017356011564178125\n",
      "SEED: 1119, FOLD: 2, EPOCH: 7, train_loss: 0.020301144111199654\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017434120470924037\n",
      "SEED: 1119, FOLD: 2, EPOCH: 8, train_loss: 0.020392304556309315\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017437036841043405\n",
      "SEED: 1119, FOLD: 2, EPOCH: 9, train_loss: 0.020232286722655746\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 9, valid_loss: 0.017228133071746143\n",
      "SEED: 1119, FOLD: 2, EPOCH: 10, train_loss: 0.02021986946625554\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 10, valid_loss: 0.01706564695175205\n",
      "SEED: 1119, FOLD: 2, EPOCH: 11, train_loss: 0.020093528027443783\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 11, valid_loss: 0.01703699648912464\n",
      "SEED: 1119, FOLD: 2, EPOCH: 12, train_loss: 0.01996841230362222\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01713797018996307\n",
      "SEED: 1119, FOLD: 2, EPOCH: 13, train_loss: 0.019858582485197247\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016862071145858082\n",
      "SEED: 1119, FOLD: 2, EPOCH: 14, train_loss: 0.019695152812030003\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01672713008842298\n",
      "SEED: 1119, FOLD: 2, EPOCH: 15, train_loss: 0.019557855658881042\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01675349473953247\n",
      "SEED: 1119, FOLD: 2, EPOCH: 16, train_loss: 0.019310158798876015\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016493073824260917\n",
      "SEED: 1119, FOLD: 2, EPOCH: 17, train_loss: 0.019008019372172977\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016317941035543168\n",
      "SEED: 1119, FOLD: 2, EPOCH: 18, train_loss: 0.018665929932309235\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 18, valid_loss: 0.01625918775264706\n",
      "SEED: 1119, FOLD: 2, EPOCH: 19, train_loss: 0.018265175970568173\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016017272961991173\n",
      "SEED: 1119, FOLD: 2, EPOCH: 20, train_loss: 0.01775451565998188\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 20, valid_loss: 0.015973636215286597\n",
      "SEED: 1119, FOLD: 2, EPOCH: 21, train_loss: 0.01714304346672219\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 21, valid_loss: 0.015872753571186747\n",
      "SEED: 1119, FOLD: 2, EPOCH: 22, train_loss: 0.016495550705956808\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 22, valid_loss: 0.015849265456199645\n",
      "SEED: 1119, FOLD: 2, EPOCH: 23, train_loss: 0.015934808247223282\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015872644606445517\n",
      "SEED: 1119, FOLD: 2, EPOCH: 24, train_loss: 0.015652909652208506\n",
      "SEED: 1119 ,FOLD: 2, EPOCH: 24, valid_loss: 0.015849552037460465\n",
      "SEED: 1119, FOLD: 3, EPOCH: 0, train_loss: 0.49927454764374357\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 0, valid_loss: 0.0343712428850787\n",
      "SEED: 1119, FOLD: 3, EPOCH: 1, train_loss: 0.024702683185645634\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 1, valid_loss: 0.019512336860810008\n",
      "SEED: 1119, FOLD: 3, EPOCH: 2, train_loss: 0.022474195632705654\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018601044373852866\n",
      "SEED: 1119, FOLD: 3, EPOCH: 3, train_loss: 0.021140085951681587\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 3, valid_loss: 0.01811719914632184\n",
      "SEED: 1119, FOLD: 3, EPOCH: 4, train_loss: 0.02061552339759858\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017872663933251584\n",
      "SEED: 1119, FOLD: 3, EPOCH: 5, train_loss: 0.020356732218161873\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017617100370781763\n",
      "SEED: 1119, FOLD: 3, EPOCH: 6, train_loss: 0.020324279243747394\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017673602301095215\n",
      "SEED: 1119, FOLD: 3, EPOCH: 7, train_loss: 0.02027488725286895\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017408781072923114\n",
      "SEED: 1119, FOLD: 3, EPOCH: 8, train_loss: 0.020168692534924416\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017437614127993585\n",
      "SEED: 1119, FOLD: 3, EPOCH: 9, train_loss: 0.02018873540657586\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01730482525059155\n",
      "SEED: 1119, FOLD: 3, EPOCH: 10, train_loss: 0.020210952052603596\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 10, valid_loss: 0.01727699533637081\n",
      "SEED: 1119, FOLD: 3, EPOCH: 11, train_loss: 0.020031748191062092\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 11, valid_loss: 0.0174198324659041\n",
      "SEED: 1119, FOLD: 3, EPOCH: 12, train_loss: 0.019890294599252335\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 12, valid_loss: 0.017042766591267928\n",
      "SEED: 1119, FOLD: 3, EPOCH: 13, train_loss: 0.019791494906488537\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016987223151539055\n",
      "SEED: 1119, FOLD: 3, EPOCH: 14, train_loss: 0.019705799138308434\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016976371008370603\n",
      "SEED: 1119, FOLD: 3, EPOCH: 15, train_loss: 0.019532736863239086\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016924259838249002\n",
      "SEED: 1119, FOLD: 3, EPOCH: 16, train_loss: 0.019280098662104294\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016927743303988663\n",
      "SEED: 1119, FOLD: 3, EPOCH: 17, train_loss: 0.019027589226438515\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016620246187916823\n",
      "SEED: 1119, FOLD: 3, EPOCH: 18, train_loss: 0.018644342104485935\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016392544151416846\n",
      "SEED: 1119, FOLD: 3, EPOCH: 19, train_loss: 0.018268106788720772\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016260566376149654\n",
      "SEED: 1119, FOLD: 3, EPOCH: 20, train_loss: 0.01775734531490699\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016235799635095256\n",
      "SEED: 1119, FOLD: 3, EPOCH: 21, train_loss: 0.017188700941809708\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01610301003924438\n",
      "SEED: 1119, FOLD: 3, EPOCH: 22, train_loss: 0.016587791363776163\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 22, valid_loss: 0.016109539701470308\n",
      "SEED: 1119, FOLD: 3, EPOCH: 23, train_loss: 0.016064836832600227\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016114031949213573\n",
      "SEED: 1119, FOLD: 3, EPOCH: 24, train_loss: 0.01578945538326018\n",
      "SEED: 1119 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016117674032492296\n",
      "SEED: 1119, FOLD: 4, EPOCH: 0, train_loss: 0.4983741138940272\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 0, valid_loss: 0.027426389125841003\n",
      "SEED: 1119, FOLD: 4, EPOCH: 1, train_loss: 0.02484473717007516\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 1, valid_loss: 0.01958005449601582\n",
      "SEED: 1119, FOLD: 4, EPOCH: 2, train_loss: 0.021772373832114365\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018245651466505867\n",
      "SEED: 1119, FOLD: 4, EPOCH: 3, train_loss: 0.020877844667521076\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 3, valid_loss: 0.017381155118346214\n",
      "SEED: 1119, FOLD: 4, EPOCH: 4, train_loss: 0.020510958750610767\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017462111424122538\n",
      "SEED: 1119, FOLD: 4, EPOCH: 5, train_loss: 0.02046121862055599\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017491357906588487\n",
      "SEED: 1119, FOLD: 4, EPOCH: 6, train_loss: 0.02031785161976797\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01759627940399306\n",
      "SEED: 1119, FOLD: 4, EPOCH: 7, train_loss: 0.020386250757112884\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 7, valid_loss: 0.022440587250249725\n",
      "SEED: 1119, FOLD: 4, EPOCH: 8, train_loss: 0.020300277778743835\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017110141207064902\n",
      "SEED: 1119, FOLD: 4, EPOCH: 9, train_loss: 0.020224152119371338\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017597838145281586\n",
      "SEED: 1119, FOLD: 4, EPOCH: 10, train_loss: 0.020174682005376057\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017138174814837318\n",
      "SEED: 1119, FOLD: 4, EPOCH: 11, train_loss: 0.020044828036233135\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 11, valid_loss: 0.017166103768561567\n",
      "SEED: 1119, FOLD: 4, EPOCH: 12, train_loss: 0.019983904962630375\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 12, valid_loss: 0.017014749933566366\n",
      "SEED: 1119, FOLD: 4, EPOCH: 13, train_loss: 0.01986350208196951\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01708390172570944\n",
      "SEED: 1119, FOLD: 4, EPOCH: 14, train_loss: 0.01975042740072029\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 14, valid_loss: 0.01675424642328705\n",
      "SEED: 1119, FOLD: 4, EPOCH: 15, train_loss: 0.019589753389574478\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01653974697526012\n",
      "SEED: 1119, FOLD: 4, EPOCH: 16, train_loss: 0.01928571996319553\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016399255421544825\n",
      "SEED: 1119, FOLD: 4, EPOCH: 17, train_loss: 0.01903089269509782\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016536473855376245\n",
      "SEED: 1119, FOLD: 4, EPOCH: 18, train_loss: 0.018710329372813736\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016207904528294292\n",
      "SEED: 1119, FOLD: 4, EPOCH: 19, train_loss: 0.01831183394930069\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 19, valid_loss: 0.01605150494724512\n",
      "SEED: 1119, FOLD: 4, EPOCH: 20, train_loss: 0.01784701220880168\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 20, valid_loss: 0.015919763248945985\n",
      "SEED: 1119, FOLD: 4, EPOCH: 21, train_loss: 0.017256670725950295\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 21, valid_loss: 0.015920952893793583\n",
      "SEED: 1119, FOLD: 4, EPOCH: 22, train_loss: 0.016604722045577953\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015835736958043915\n",
      "SEED: 1119, FOLD: 4, EPOCH: 23, train_loss: 0.016069785867264305\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01586752635027681\n",
      "SEED: 1119, FOLD: 4, EPOCH: 24, train_loss: 0.015839590070148308\n",
      "SEED: 1119 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01584231959921973\n",
      "SEED: 1303, FOLD: 0, EPOCH: 0, train_loss: 0.4985224851069675\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 0, valid_loss: 0.047708643334252496\n",
      "SEED: 1303, FOLD: 0, EPOCH: 1, train_loss: 0.024595026291258957\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 1, valid_loss: 0.018789030611515045\n",
      "SEED: 1303, FOLD: 0, EPOCH: 2, train_loss: 0.021506250323052856\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 2, valid_loss: 0.017839382934783186\n",
      "SEED: 1303, FOLD: 0, EPOCH: 3, train_loss: 0.02097016763266014\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017626500049872058\n",
      "SEED: 1303, FOLD: 0, EPOCH: 4, train_loss: 0.020463630705531956\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 4, valid_loss: 0.018119199068418572\n",
      "SEED: 1303, FOLD: 0, EPOCH: 5, train_loss: 0.02042130927514771\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017591113703591482\n",
      "SEED: 1303, FOLD: 0, EPOCH: 6, train_loss: 0.020351325755641945\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017406656087509225\n",
      "SEED: 1303, FOLD: 0, EPOCH: 7, train_loss: 0.02029490955443918\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017402652677680763\n",
      "SEED: 1303, FOLD: 0, EPOCH: 8, train_loss: 0.020198382680182873\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017350537569395134\n",
      "SEED: 1303, FOLD: 0, EPOCH: 9, train_loss: 0.020161368249767067\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017253782813038146\n",
      "SEED: 1303, FOLD: 0, EPOCH: 10, train_loss: 0.020111262514863327\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017267584295145102\n",
      "SEED: 1303, FOLD: 0, EPOCH: 11, train_loss: 0.02005762795823208\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 11, valid_loss: 0.017090074797826153\n",
      "SEED: 1303, FOLD: 0, EPOCH: 12, train_loss: 0.020019359792164272\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016925802480961594\n",
      "SEED: 1303, FOLD: 0, EPOCH: 13, train_loss: 0.019802379799817783\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01686780420797212\n",
      "SEED: 1303, FOLD: 0, EPOCH: 14, train_loss: 0.019715755570517933\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016916407431874957\n",
      "SEED: 1303, FOLD: 0, EPOCH: 15, train_loss: 0.01949448674323334\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01669128614344767\n",
      "SEED: 1303, FOLD: 0, EPOCH: 16, train_loss: 0.019331367132996304\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016517763611461435\n",
      "SEED: 1303, FOLD: 0, EPOCH: 17, train_loss: 0.01901339016098907\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016497067974082062\n",
      "SEED: 1303, FOLD: 0, EPOCH: 18, train_loss: 0.018724883690584396\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016320090182125567\n",
      "SEED: 1303, FOLD: 0, EPOCH: 19, train_loss: 0.018201539191700842\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016072842106223107\n",
      "SEED: 1303, FOLD: 0, EPOCH: 20, train_loss: 0.01771624413980306\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 20, valid_loss: 0.015970440049256598\n",
      "SEED: 1303, FOLD: 0, EPOCH: 21, train_loss: 0.01712217121857448\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 21, valid_loss: 0.01578200078968491\n",
      "SEED: 1303, FOLD: 0, EPOCH: 22, train_loss: 0.016468739629709635\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 22, valid_loss: 0.015871259862823145\n",
      "SEED: 1303, FOLD: 0, EPOCH: 23, train_loss: 0.015968531012481104\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 23, valid_loss: 0.015824652915554387\n",
      "SEED: 1303, FOLD: 0, EPOCH: 24, train_loss: 0.01568864929098366\n",
      "SEED: 1303 ,FOLD: 0, EPOCH: 24, valid_loss: 0.015812395380011626\n",
      "SEED: 1303, FOLD: 1, EPOCH: 0, train_loss: 0.49949839554619097\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 0, valid_loss: 0.0302652579333101\n",
      "SEED: 1303, FOLD: 1, EPOCH: 1, train_loss: 0.02451147865234078\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 1, valid_loss: 0.01895913401884692\n",
      "SEED: 1303, FOLD: 1, EPOCH: 2, train_loss: 0.021771994878308498\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 2, valid_loss: 0.019844829982944897\n",
      "SEED: 1303, FOLD: 1, EPOCH: 3, train_loss: 0.021194239902863468\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 3, valid_loss: 0.017542139094855105\n",
      "SEED: 1303, FOLD: 1, EPOCH: 4, train_loss: 0.02044219485875489\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017732185897018228\n",
      "SEED: 1303, FOLD: 1, EPOCH: 5, train_loss: 0.02021043462867754\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 5, valid_loss: 0.0173093495624406\n",
      "SEED: 1303, FOLD: 1, EPOCH: 6, train_loss: 0.020179902108899063\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 6, valid_loss: 0.01753394047596625\n",
      "SEED: 1303, FOLD: 1, EPOCH: 7, train_loss: 0.020120803266763687\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017234646795051437\n",
      "SEED: 1303, FOLD: 1, EPOCH: 8, train_loss: 0.020163362670311893\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017880729985024248\n",
      "SEED: 1303, FOLD: 1, EPOCH: 9, train_loss: 0.02015253210413283\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 9, valid_loss: 0.017152755547847065\n",
      "SEED: 1303, FOLD: 1, EPOCH: 10, train_loss: 0.020079210549053074\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 10, valid_loss: 0.017259135150483676\n",
      "SEED: 1303, FOLD: 1, EPOCH: 11, train_loss: 0.01998049711835557\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 11, valid_loss: 0.017086910509637423\n",
      "SEED: 1303, FOLD: 1, EPOCH: 12, train_loss: 0.01998882980990237\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016784780632172314\n",
      "SEED: 1303, FOLD: 1, EPOCH: 13, train_loss: 0.01981450159750555\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01698652170598507\n",
      "SEED: 1303, FOLD: 1, EPOCH: 14, train_loss: 0.01974644962752211\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016740370914340018\n",
      "SEED: 1303, FOLD: 1, EPOCH: 15, train_loss: 0.01945385083799129\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01668818268392767\n",
      "SEED: 1303, FOLD: 1, EPOCH: 16, train_loss: 0.019209528976268528\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016618625234280315\n",
      "SEED: 1303, FOLD: 1, EPOCH: 17, train_loss: 0.019043453483153946\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016391664370894433\n",
      "SEED: 1303, FOLD: 1, EPOCH: 18, train_loss: 0.01871604627619187\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01613735772137131\n",
      "SEED: 1303, FOLD: 1, EPOCH: 19, train_loss: 0.018231402596701748\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016229618181075368\n",
      "SEED: 1303, FOLD: 1, EPOCH: 20, train_loss: 0.017711301023761433\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016005865298211575\n",
      "SEED: 1303, FOLD: 1, EPOCH: 21, train_loss: 0.01707932197124414\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 21, valid_loss: 0.015943673625588416\n",
      "SEED: 1303, FOLD: 1, EPOCH: 22, train_loss: 0.016385031492867762\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 22, valid_loss: 0.01584715260458844\n",
      "SEED: 1303, FOLD: 1, EPOCH: 23, train_loss: 0.01582701876759529\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 23, valid_loss: 0.015863758378795216\n",
      "SEED: 1303, FOLD: 1, EPOCH: 24, train_loss: 0.015556943521875402\n",
      "SEED: 1303 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015844303742051126\n",
      "SEED: 1303, FOLD: 2, EPOCH: 0, train_loss: 0.5004744371264309\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 0, valid_loss: 0.02901832546506609\n",
      "SEED: 1303, FOLD: 2, EPOCH: 1, train_loss: 0.024460728374728256\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 1, valid_loss: 0.019258507660457065\n",
      "SEED: 1303, FOLD: 2, EPOCH: 2, train_loss: 0.021884858729722706\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018081662085439477\n",
      "SEED: 1303, FOLD: 2, EPOCH: 3, train_loss: 0.021031218297455623\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017579355144074986\n",
      "SEED: 1303, FOLD: 2, EPOCH: 4, train_loss: 0.020472260057062344\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 4, valid_loss: 0.0175801548574652\n",
      "SEED: 1303, FOLD: 2, EPOCH: 5, train_loss: 0.02041752691772105\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01745899873120444\n",
      "SEED: 1303, FOLD: 2, EPOCH: 6, train_loss: 0.02028208215167557\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 6, valid_loss: 0.018331904735948357\n",
      "SEED: 1303, FOLD: 2, EPOCH: 7, train_loss: 0.020396327221955078\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017990580440631936\n",
      "SEED: 1303, FOLD: 2, EPOCH: 8, train_loss: 0.02035438836268757\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01725203115493059\n",
      "SEED: 1303, FOLD: 2, EPOCH: 9, train_loss: 0.020228127044612083\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01724160300301654\n",
      "SEED: 1303, FOLD: 2, EPOCH: 10, train_loss: 0.020227614641729473\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017221427629036563\n",
      "SEED: 1303, FOLD: 2, EPOCH: 11, train_loss: 0.02015960602548675\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 11, valid_loss: 0.017214538795607432\n",
      "SEED: 1303, FOLD: 2, EPOCH: 12, train_loss: 0.02004813033061615\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 12, valid_loss: 0.017052798212638925\n",
      "SEED: 1303, FOLD: 2, EPOCH: 13, train_loss: 0.01992274040653222\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016887389602405684\n",
      "SEED: 1303, FOLD: 2, EPOCH: 14, train_loss: 0.019767248004242993\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 14, valid_loss: 0.017179987233664307\n",
      "SEED: 1303, FOLD: 2, EPOCH: 15, train_loss: 0.019553218063884888\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016603478443409717\n",
      "SEED: 1303, FOLD: 2, EPOCH: 16, train_loss: 0.01935296571827021\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016646661636020455\n",
      "SEED: 1303, FOLD: 2, EPOCH: 17, train_loss: 0.019051713234596493\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016365184767970015\n",
      "SEED: 1303, FOLD: 2, EPOCH: 18, train_loss: 0.018923382531257645\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 18, valid_loss: 0.01627362495554345\n",
      "SEED: 1303, FOLD: 2, EPOCH: 19, train_loss: 0.01840858430048262\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01626941716032369\n",
      "SEED: 1303, FOLD: 2, EPOCH: 20, train_loss: 0.017919421229727457\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01601199994661978\n",
      "SEED: 1303, FOLD: 2, EPOCH: 21, train_loss: 0.017284174706192985\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 21, valid_loss: 0.015921501123479436\n",
      "SEED: 1303, FOLD: 2, EPOCH: 22, train_loss: 0.016659925502819427\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 22, valid_loss: 0.015908535410250935\n",
      "SEED: 1303, FOLD: 2, EPOCH: 23, train_loss: 0.016199738637584706\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 23, valid_loss: 0.015889529564550944\n",
      "SEED: 1303, FOLD: 2, EPOCH: 24, train_loss: 0.015928851346066898\n",
      "SEED: 1303 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01590595000556537\n",
      "SEED: 1303, FOLD: 3, EPOCH: 0, train_loss: 0.5005336193016906\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 0, valid_loss: 0.029155147661055838\n",
      "SEED: 1303, FOLD: 3, EPOCH: 1, train_loss: 0.024433348381864853\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 1, valid_loss: 0.02292407862842083\n",
      "SEED: 1303, FOLD: 3, EPOCH: 2, train_loss: 0.021677508977228317\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 2, valid_loss: 0.020930950024298258\n",
      "SEED: 1303, FOLD: 3, EPOCH: 3, train_loss: 0.020984740752348865\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 3, valid_loss: 0.01840746338878359\n",
      "SEED: 1303, FOLD: 3, EPOCH: 4, train_loss: 0.020613377225463806\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017870113546294825\n",
      "SEED: 1303, FOLD: 3, EPOCH: 5, train_loss: 0.020434937331879486\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017398905461387976\n",
      "SEED: 1303, FOLD: 3, EPOCH: 6, train_loss: 0.02031937037743088\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01753675046243838\n",
      "SEED: 1303, FOLD: 3, EPOCH: 7, train_loss: 0.020213775593193546\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 7, valid_loss: 0.018597486881273134\n",
      "SEED: 1303, FOLD: 3, EPOCH: 8, train_loss: 0.020168618542020737\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 8, valid_loss: 0.01734402943402529\n",
      "SEED: 1303, FOLD: 3, EPOCH: 9, train_loss: 0.020143131064116093\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 9, valid_loss: 0.017297863800610814\n",
      "SEED: 1303, FOLD: 3, EPOCH: 10, train_loss: 0.020043711137512455\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 10, valid_loss: 0.01731095119778599\n",
      "SEED: 1303, FOLD: 3, EPOCH: 11, train_loss: 0.020113417473824127\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01730296076940639\n",
      "SEED: 1303, FOLD: 3, EPOCH: 12, train_loss: 0.01995327760991843\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 12, valid_loss: 0.017467827589384147\n",
      "SEED: 1303, FOLD: 3, EPOCH: 13, train_loss: 0.019956541315153026\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 13, valid_loss: 0.017287522181868555\n",
      "SEED: 1303, FOLD: 3, EPOCH: 14, train_loss: 0.019673661517816177\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016860443220606872\n",
      "SEED: 1303, FOLD: 3, EPOCH: 15, train_loss: 0.019575704550505547\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01678466929921082\n",
      "SEED: 1303, FOLD: 3, EPOCH: 16, train_loss: 0.019352287607456463\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 16, valid_loss: 0.0168325061244624\n",
      "SEED: 1303, FOLD: 3, EPOCH: 17, train_loss: 0.018999139089947163\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016726135702005453\n",
      "SEED: 1303, FOLD: 3, EPOCH: 18, train_loss: 0.01869220046353513\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016475931288940565\n",
      "SEED: 1303, FOLD: 3, EPOCH: 19, train_loss: 0.0182584967477706\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01629707728113447\n",
      "SEED: 1303, FOLD: 3, EPOCH: 20, train_loss: 0.017812946230928967\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016281085195285934\n",
      "SEED: 1303, FOLD: 3, EPOCH: 21, train_loss: 0.017164062357683113\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016138866836471217\n",
      "SEED: 1303, FOLD: 3, EPOCH: 22, train_loss: 0.016527600174742765\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01609332039952278\n",
      "SEED: 1303, FOLD: 3, EPOCH: 23, train_loss: 0.015987081216999155\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016116865378405367\n",
      "SEED: 1303, FOLD: 3, EPOCH: 24, train_loss: 0.01574771838478636\n",
      "SEED: 1303 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016129680536687376\n",
      "SEED: 1303, FOLD: 4, EPOCH: 0, train_loss: 0.5004456116399472\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 0, valid_loss: 0.03287997378834656\n",
      "SEED: 1303, FOLD: 4, EPOCH: 1, train_loss: 0.02488271689609341\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 1, valid_loss: 0.018973172189933912\n",
      "SEED: 1303, FOLD: 4, EPOCH: 2, train_loss: 0.021974922225311184\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018094497440116746\n",
      "SEED: 1303, FOLD: 4, EPOCH: 3, train_loss: 0.020974720922717148\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 3, valid_loss: 0.017799355887940953\n",
      "SEED: 1303, FOLD: 4, EPOCH: 4, train_loss: 0.020425615764722443\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017477014314915454\n",
      "SEED: 1303, FOLD: 4, EPOCH: 5, train_loss: 0.020390577371353687\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017731790031705583\n",
      "SEED: 1303, FOLD: 4, EPOCH: 6, train_loss: 0.020398359394807747\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01745529856000628\n",
      "SEED: 1303, FOLD: 4, EPOCH: 7, train_loss: 0.020233859267571697\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01708218308963946\n",
      "SEED: 1303, FOLD: 4, EPOCH: 8, train_loss: 0.020146886183731796\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017278078863663334\n",
      "SEED: 1303, FOLD: 4, EPOCH: 9, train_loss: 0.020065497337044148\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 9, valid_loss: 0.01784215569496155\n",
      "SEED: 1303, FOLD: 4, EPOCH: 10, train_loss: 0.020081880367428497\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01694095227867365\n",
      "SEED: 1303, FOLD: 4, EPOCH: 11, train_loss: 0.020088050487464752\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 11, valid_loss: 0.01705168155687196\n",
      "SEED: 1303, FOLD: 4, EPOCH: 12, train_loss: 0.0199852774216645\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 12, valid_loss: 0.01699365084724767\n",
      "SEED: 1303, FOLD: 4, EPOCH: 13, train_loss: 0.019770819045927212\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01694584715047053\n",
      "SEED: 1303, FOLD: 4, EPOCH: 14, train_loss: 0.01966692594325413\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016887219888823374\n",
      "SEED: 1303, FOLD: 4, EPOCH: 15, train_loss: 0.0194502337768242\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016684324986168318\n",
      "SEED: 1303, FOLD: 4, EPOCH: 16, train_loss: 0.019196366391860058\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016567705571651457\n",
      "SEED: 1303, FOLD: 4, EPOCH: 17, train_loss: 0.018926889689612217\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016341958913419927\n",
      "SEED: 1303, FOLD: 4, EPOCH: 18, train_loss: 0.01857162557164396\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016221365492258753\n",
      "SEED: 1303, FOLD: 4, EPOCH: 19, train_loss: 0.01809434905189319\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016096833002354417\n",
      "SEED: 1303, FOLD: 4, EPOCH: 20, train_loss: 0.017606185580455305\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016040225327014924\n",
      "SEED: 1303, FOLD: 4, EPOCH: 21, train_loss: 0.016943025544447744\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 21, valid_loss: 0.015906084195843766\n",
      "SEED: 1303, FOLD: 4, EPOCH: 22, train_loss: 0.01622306212000009\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 22, valid_loss: 0.01592851895838976\n",
      "SEED: 1303, FOLD: 4, EPOCH: 23, train_loss: 0.0156351493847003\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01596412876886981\n",
      "SEED: 1303, FOLD: 4, EPOCH: 24, train_loss: 0.015351720316254574\n",
      "SEED: 1303 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01592693842415299\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [940, 1513, 1269,1392,1119,1303]  #<-- Update\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4acc11c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:42:21.103503Z",
     "iopub.status.busy": "2025-03-21T12:42:21.103028Z",
     "iopub.status.idle": "2025-03-21T12:42:21.122415Z",
     "shell.execute_reply": "2025-03-21T12:42:21.121603Z"
    },
    "papermill": {
     "duration": 0.086243,
     "end_time": "2025-03-21T12:42:21.123621",
     "exception": false,
     "start_time": "2025-03-21T12:42:21.037378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0      id_000644bb2                            0                       0   \n",
       "1      id_000779bfc                            0                       0   \n",
       "2      id_000a6266a                            0                       0   \n",
       "3      id_0015fd391                            0                       0   \n",
       "4      id_001626bd3                            0                       0   \n",
       "...             ...                          ...                     ...   \n",
       "23809  id_fffb1ceed                            0                       0   \n",
       "23810  id_fffb70c0c                            0                       0   \n",
       "23811  id_fffc1c3f4                            0                       0   \n",
       "23812  id_fffcb9e7c                            0                       0   \n",
       "23813  id_ffffdd77b                            0                       0   \n",
       "\n",
       "       acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0                   0                               0   \n",
       "1                   0                               0   \n",
       "2                   0                               0   \n",
       "3                   0                               0   \n",
       "4                   0                               0   \n",
       "...               ...                             ...   \n",
       "23809               0                               0   \n",
       "23810               0                               0   \n",
       "23811               0                               0   \n",
       "23812               0                               0   \n",
       "23813               0                               0   \n",
       "\n",
       "       acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                      0                               0   \n",
       "1                                      0                               0   \n",
       "2                                      0                               0   \n",
       "3                                      0                               0   \n",
       "4                                      0                               0   \n",
       "...                                  ...                             ...   \n",
       "23809                                  0                               0   \n",
       "23810                                  0                               0   \n",
       "23811                                  0                               0   \n",
       "23812                                  0                               0   \n",
       "23813                                  0                               0   \n",
       "\n",
       "       adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                               0                              0   \n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              0   \n",
       "4                               0                              0   \n",
       "...                           ...                            ...   \n",
       "23809                           0                              0   \n",
       "23810                           0                              0   \n",
       "23811                           0                              0   \n",
       "23812                           0                              0   \n",
       "23813                           0                              0   \n",
       "\n",
       "       adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                               0  ...                                      0   \n",
       "1                               0  ...                                      0   \n",
       "2                               0  ...                                      0   \n",
       "3                               0  ...                                      0   \n",
       "4                               0  ...                                      0   \n",
       "...                           ...  ...                                    ...   \n",
       "23809                           0  ...                                      0   \n",
       "23810                           0  ...                                      0   \n",
       "23811                           0  ...                                      0   \n",
       "23812                           0  ...                                      0   \n",
       "23813                           0  ...                                      0   \n",
       "\n",
       "       trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0                 0                0                  0   \n",
       "1                 0                0                  0   \n",
       "2                 0                0                  0   \n",
       "3                 0                0                  0   \n",
       "4                 0                0                  0   \n",
       "...             ...              ...                ...   \n",
       "23809             0                0                  0   \n",
       "23810             0                0                  0   \n",
       "23811             0                0                  0   \n",
       "23812             0                0                  0   \n",
       "23813             0                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "23809                          0                                      0   \n",
       "23810                          0                                      0   \n",
       "23811                          0                                      0   \n",
       "23812                          0                                      0   \n",
       "23813                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                    0          0                           0              0  \n",
       "1                    0          0                           0              0  \n",
       "2                    0          0                           0              0  \n",
       "3                    0          0                           0              0  \n",
       "4                    0          0                           0              0  \n",
       "...                ...        ...                         ...            ...  \n",
       "23809                0          0                           0              0  \n",
       "23810                0          0                           0              0  \n",
       "23811                0          0                           0              0  \n",
       "23812                0          0                           0              0  \n",
       "23813                0          0                           0              0  \n",
       "\n",
       "[23814 rows x 207 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da20a692",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:42:21.255348Z",
     "iopub.status.busy": "2025-03-21T12:42:21.255057Z",
     "iopub.status.idle": "2025-03-21T12:42:21.259573Z",
     "shell.execute_reply": "2025-03-21T12:42:21.258812Z"
    },
    "papermill": {
     "duration": 0.07108,
     "end_time": "2025-03-21T12:42:21.260640",
     "exception": false,
     "start_time": "2025-03-21T12:42:21.189560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fe0e625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:42:21.390527Z",
     "iopub.status.busy": "2025-03-21T12:42:21.390266Z",
     "iopub.status.idle": "2025-03-21T12:42:22.669369Z",
     "shell.execute_reply": "2025-03-21T12:42:22.668500Z"
    },
    "papermill": {
     "duration": 1.345514,
     "end_time": "2025-03-21T12:42:22.670773",
     "exception": false,
     "start_time": "2025-03-21T12:42:21.325259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.014329836230456998\n"
     ]
    }
   ],
   "source": [
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2de95926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:42:22.846831Z",
     "iopub.status.busy": "2025-03-21T12:42:22.846528Z",
     "iopub.status.idle": "2025-03-21T12:42:23.982792Z",
     "shell.execute_reply": "2025-03-21T12:42:23.981997Z"
    },
    "papermill": {
     "duration": 1.203489,
     "end_time": "2025-03-21T12:42:23.984251",
     "exception": false,
     "start_time": "2025-03-21T12:42:22.780762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.011836</td>\n",
       "      <td>0.013822</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>0.002149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.003838</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>0.020444</td>\n",
       "      <td>0.010834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.009981</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.003329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.013347</td>\n",
       "      <td>0.027456</td>\n",
       "      <td>0.006230</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.005948</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.002408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>0.016015</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.004930</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.002158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_0004d9e33                     0.001306                0.002119   \n",
       "1  id_001897cda                     0.000557                0.001100   \n",
       "2  id_002429b5b                     0.000000                0.000000   \n",
       "3  id_00276f245                     0.001509                0.001322   \n",
       "4  id_0027f1083                     0.001678                0.001632   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0        0.003201                        0.011836   \n",
       "1        0.003383                        0.003838   \n",
       "2        0.000000                        0.000000   \n",
       "3        0.001928                        0.013347   \n",
       "4        0.002289                        0.016015   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                           0.013822                        0.006336   \n",
       "1                           0.001701                        0.001536   \n",
       "2                           0.000000                        0.000000   \n",
       "3                           0.027456                        0.006230   \n",
       "4                           0.021200                        0.004930   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                    0.002468                       0.007281   \n",
       "1                    0.007250                       0.020444   \n",
       "2                    0.000000                       0.000000   \n",
       "3                    0.003564                       0.004022   \n",
       "4                    0.003934                       0.003220   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                    0.000712  ...                               0.001134   \n",
       "1                    0.010834  ...                               0.001484   \n",
       "2                    0.000000  ...                               0.000000   \n",
       "3                    0.000515  ...                               0.000837   \n",
       "4                    0.000710  ...                               0.001086   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0      0.003505         0.004570           0.001683   \n",
       "1      0.001818         0.009981           0.000797   \n",
       "2      0.000000         0.000000           0.000000   \n",
       "3      0.001281         0.002481           0.005948   \n",
       "4      0.001161         0.002890           0.001969   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                   0.001418                               0.001124   \n",
       "1                   0.009858                               0.000703   \n",
       "2                   0.000000                               0.000000   \n",
       "3                   0.004083                               0.000846   \n",
       "4                   0.002470                               0.001044   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0         0.001287   0.002173                    0.004736       0.002149  \n",
       "1         0.004277   0.001526                    0.001387       0.003329  \n",
       "2         0.000000   0.000000                    0.000000       0.000000  \n",
       "3         0.001475   0.002212                    0.000603       0.002408  \n",
       "4         0.001784   0.002578                    0.000651       0.002158  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "file_path = '/kaggle/working/submission.csv'\n",
    "sub.to_csv(file_path, index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfdf3931",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T12:42:24.119281Z",
     "iopub.status.busy": "2025-03-21T12:42:24.119030Z",
     "iopub.status.idle": "2025-03-21T12:42:24.123322Z",
     "shell.execute_reply": "2025-03-21T12:42:24.122683Z"
    },
    "papermill": {
     "duration": 0.07083,
     "end_time": "2025-03-21T12:42:24.124480",
     "exception": false,
     "start_time": "2025-03-21T12:42:24.053650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3982, 207)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53eaa99",
   "metadata": {
    "papermill": {
     "duration": 0.064668,
     "end_time": "2025-03-21T12:42:24.255127",
     "exception": false,
     "start_time": "2025-03-21T12:42:24.190459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1651354,
     "isSourceIdPinned": false,
     "sourceId": 19988,
     "sourceType": "competition"
    },
    {
     "datasetId": 6874007,
     "sourceId": 11036227,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "duration": 2979.987332,
   "end_time": "2025-03-21T12:42:26.346385",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-21T11:52:46.359053",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
