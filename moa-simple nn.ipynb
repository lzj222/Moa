{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed15e8ca",
   "metadata": {
    "papermill": {
     "duration": 0.007681,
     "end_time": "2025-03-31T12:36:53.663306",
     "exception": false,
     "start_time": "2025-03-31T12:36:53.655625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# This Notebook is an Updated version of my previous kernel https://www.kaggle.com/kushal1506/moa-pytorch-feature-engineering-0-01846"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ef9208",
   "metadata": {
    "papermill": {
     "duration": 0.006521,
     "end_time": "2025-03-31T12:36:53.676833",
     "exception": false,
     "start_time": "2025-03-31T12:36:53.670312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# If U find my work helpful and consider forking it, please do Upvote :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1546c94b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-31T12:36:53.691260Z",
     "iopub.status.busy": "2025-03-31T12:36:53.690966Z",
     "iopub.status.idle": "2025-03-31T12:36:54.788476Z",
     "shell.execute_reply": "2025-03-31T12:36:54.787777Z"
    },
    "papermill": {
     "duration": 1.106564,
     "end_time": "2025-03-31T12:36:54.790067",
     "exception": false,
     "start_time": "2025-03-31T12:36:53.683503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/iterativestratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead9660c",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2025-03-31T12:36:54.805062Z",
     "iopub.status.busy": "2025-03-31T12:36:54.804646Z",
     "iopub.status.idle": "2025-03-31T12:36:58.895338Z",
     "shell.execute_reply": "2025-03-31T12:36:58.894620Z"
    },
    "papermill": {
     "duration": 4.099699,
     "end_time": "2025-03-31T12:36:58.896919",
     "exception": false,
     "start_time": "2025-03-31T12:36:54.797220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss ,roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from pickle import load,dump\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc27d9d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:36:58.912547Z",
     "iopub.status.busy": "2025-03-31T12:36:58.912131Z",
     "iopub.status.idle": "2025-03-31T12:36:58.915367Z",
     "shell.execute_reply": "2025-03-31T12:36:58.914764Z"
    },
    "papermill": {
     "duration": 0.012343,
     "end_time": "2025-03-31T12:36:58.916594",
     "exception": false,
     "start_time": "2025-03-31T12:36:58.904251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc51629c",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-03-31T12:36:58.931259Z",
     "iopub.status.busy": "2025-03-31T12:36:58.931033Z",
     "iopub.status.idle": "2025-03-31T12:36:58.936448Z",
     "shell.execute_reply": "2025-03-31T12:36:58.935745Z"
    },
    "papermill": {
     "duration": 0.014133,
     "end_time": "2025-03-31T12:36:58.937635",
     "exception": false,
     "start_time": "2025-03-31T12:36:58.923502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_targets_scored.csv',\n",
       " 'sample_submission.csv',\n",
       " 'train_drug.csv',\n",
       " 'train_targets_nonscored.csv',\n",
       " 'train_features.csv',\n",
       " 'test_features.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/lish-moa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc274e4",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-03-31T12:36:58.952608Z",
     "iopub.status.busy": "2025-03-31T12:36:58.952359Z",
     "iopub.status.idle": "2025-03-31T12:37:05.633050Z",
     "shell.execute_reply": "2025-03-31T12:37:05.632094Z"
    },
    "papermill": {
     "duration": 6.689735,
     "end_time": "2025-03-31T12:37:05.634679",
     "exception": false,
     "start_time": "2025-03-31T12:36:58.944944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "df = pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b6bef2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:05.649868Z",
     "iopub.status.busy": "2025-03-31T12:37:05.649565Z",
     "iopub.status.idle": "2025-03-31T12:37:05.723125Z",
     "shell.execute_reply": "2025-03-31T12:37:05.722175Z"
    },
    "papermill": {
     "duration": 0.082638,
     "end_time": "2025-03-31T12:37:05.724704",
     "exception": false,
     "start_time": "2025-03-31T12:37:05.642066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features2=train_features.copy()\n",
    "test_features2=test_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a807a001",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:05.739730Z",
     "iopub.status.busy": "2025-03-31T12:37:05.739464Z",
     "iopub.status.idle": "2025-03-31T12:37:05.743537Z",
     "shell.execute_reply": "2025-03-31T12:37:05.742723Z"
    },
    "papermill": {
     "duration": 0.012797,
     "end_time": "2025-03-31T12:37:05.744776",
     "exception": false,
     "start_time": "2025-03-31T12:37:05.731979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afe3e85c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:05.759675Z",
     "iopub.status.busy": "2025-03-31T12:37:05.759390Z",
     "iopub.status.idle": "2025-03-31T12:37:13.061739Z",
     "shell.execute_reply": "2025-03-31T12:37:13.061054Z"
    },
    "papermill": {
     "duration": 7.311347,
     "end_time": "2025-03-31T12:37:13.063273",
     "exception": false,
     "start_time": "2025-03-31T12:37:05.751926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in (GENES + CELLS):\n",
    "\n",
    "    transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n",
    "    vec_len = len(train_features[col].values)\n",
    "    vec_len_test = len(test_features[col].values)\n",
    "    raw_vec = train_features[col].values.reshape(vec_len, 1)\n",
    "    transformer.fit(raw_vec)\n",
    "\n",
    "    train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "415c507c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:13.079385Z",
     "iopub.status.busy": "2025-03-31T12:37:13.079148Z",
     "iopub.status.idle": "2025-03-31T12:37:13.141192Z",
     "shell.execute_reply": "2025-03-31T12:37:13.140429Z"
    },
    "papermill": {
     "duration": 0.071356,
     "end_time": "2025-03-31T12:37:13.142841",
     "exception": false,
     "start_time": "2025-03-31T12:37:13.071485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "\n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a633ad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:13.157956Z",
     "iopub.status.busy": "2025-03-31T12:37:13.157671Z",
     "iopub.status.idle": "2025-03-31T12:37:20.458397Z",
     "shell.execute_reply": "2025-03-31T12:37:20.457424Z"
    },
    "papermill": {
     "duration": 7.310018,
     "end_time": "2025-03-31T12:37:20.460198",
     "exception": false,
     "start_time": "2025-03-31T12:37:13.150180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_comp = 600  #<--Update\n",
    "pca_g = PCA(n_components=n_comp, random_state=42)\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "gpca= (pca_g.fit(data[GENES]))\n",
    "train2= (gpca.transform(train_features[GENES]))\n",
    "test2 = (gpca.transform(test_features[GENES]))\n",
    "\n",
    "train_gpca = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test_gpca = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train_gpca), axis=1)\n",
    "test_features = pd.concat((test_features, test_gpca), axis=1)\n",
    "\n",
    "dump(gpca, open('gpca.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79e84b24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:20.476407Z",
     "iopub.status.busy": "2025-03-31T12:37:20.476127Z",
     "iopub.status.idle": "2025-03-31T12:37:21.056521Z",
     "shell.execute_reply": "2025-03-31T12:37:21.055785Z"
    },
    "papermill": {
     "duration": 0.590036,
     "end_time": "2025-03-31T12:37:21.058062",
     "exception": false,
     "start_time": "2025-03-31T12:37:20.468026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CELLS\n",
    "n_comp = 50  #<--Update\n",
    "\n",
    "pca_c = PCA(n_components=n_comp, random_state=42)\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "cpca= (pca_c.fit(data[CELLS]))\n",
    "train2= (cpca.transform(train_features[CELLS]))\n",
    "test2 = (cpca.transform(test_features[CELLS]))\n",
    "\n",
    "train_cpca = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test_cpca = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train_cpca), axis=1)\n",
    "test_features = pd.concat((test_features, test_cpca), axis=1)\n",
    "\n",
    "dump(cpca, open('cpca.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "991911ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:21.073469Z",
     "iopub.status.busy": "2025-03-31T12:37:21.073224Z",
     "iopub.status.idle": "2025-03-31T12:37:21.709162Z",
     "shell.execute_reply": "2025-03-31T12:37:21.708426Z"
    },
    "papermill": {
     "duration": 0.645095,
     "end_time": "2025-03-31T12:37:21.710648",
     "exception": false,
     "start_time": "2025-03-31T12:37:21.065553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#通过方差阈值（0.85）过滤低方差特征，保留信息量大的特征，提升模型效率并减少噪声。\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "#提取所有数值型特征列（排除ID和分类字段）\n",
    "c_n = [f for f in list(train_features.columns) if f not in ['sig_id', 'cp_type', 'cp_time', 'cp_dose']]\n",
    "#对训练集的数值特征计算方差（var()）生成布尔掩码mask，标记方差≥0.85的特征为True。\n",
    "mask = (train_features[c_n].var() >= 0.85).values\n",
    "#从训练集中选择高方差特征列（mask=True的列）,将非数值列（ID、类别）与筛选后的特征重新拼接。\n",
    "tmp = train_features[c_n].loc[:, mask]\n",
    "train_features = pd.concat([train_features[['sig_id', 'cp_type', 'cp_time', 'cp_dose']], tmp], axis=1)\n",
    "#测试集使用训练集计算的mask，避免数据泄漏。\n",
    "tmp = test_features[c_n].loc[:, mask]\n",
    "test_features = pd.concat([test_features[['sig_id', 'cp_type', 'cp_time', 'cp_dose']], tmp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d99070b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:21.726214Z",
     "iopub.status.busy": "2025-03-31T12:37:21.725973Z",
     "iopub.status.idle": "2025-03-31T12:37:44.234994Z",
     "shell.execute_reply": "2025-03-31T12:37:44.234101Z"
    },
    "papermill": {
     "duration": 22.518511,
     "end_time": "2025-03-31T12:37:44.236708",
     "exception": false,
     "start_time": "2025-03-31T12:37:21.718197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def fe_cluster_genes(train, test, n_clusters_g = 22, SEED = 42):\n",
    "    \n",
    "    features_g = GENES\n",
    "    #features_c = CELLS\n",
    "    \n",
    "    def create_cluster(train, test, features, kind = 'g', n_clusters = n_clusters_g):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans_genes = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_genes, open('kmeans_genes.pkl', 'wb'))\n",
    "        train[f'clusters_{kind}'] = kmeans_genes.predict(train_.values)\n",
    "        test[f'clusters_{kind}'] = kmeans_genes.predict(test_.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "    train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "   # train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features2 ,test_features2=fe_cluster_genes(train_features2,test_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8dc19f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:44.253316Z",
     "iopub.status.busy": "2025-03-31T12:37:44.253059Z",
     "iopub.status.idle": "2025-03-31T12:37:45.403289Z",
     "shell.execute_reply": "2025-03-31T12:37:45.402584Z"
    },
    "papermill": {
     "duration": 1.160105,
     "end_time": "2025-03-31T12:37:45.404780",
     "exception": false,
     "start_time": "2025-03-31T12:37:44.244675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_cluster_cells(train, test, n_clusters_c = 4, SEED = 42):\n",
    "    \n",
    "    #features_g = GENES\n",
    "    features_c = CELLS\n",
    "    \n",
    "    def create_cluster(train, test, features, kind = 'c', n_clusters = n_clusters_c):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans_cells = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_cells, open('kmeans_cells.pkl', 'wb'))\n",
    "        train[f'clusters_{kind}'] = kmeans_cells.predict(train_.values)\n",
    "        test[f'clusters_{kind}'] = kmeans_cells.predict(test_.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "   # train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "    train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features2 ,test_features2=fe_cluster_cells(train_features2,test_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e96097bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:45.420589Z",
     "iopub.status.busy": "2025-03-31T12:37:45.420339Z",
     "iopub.status.idle": "2025-03-31T12:37:45.519282Z",
     "shell.execute_reply": "2025-03-31T12:37:45.518561Z"
    },
    "papermill": {
     "duration": 0.108401,
     "end_time": "2025-03-31T12:37:45.520875",
     "exception": false,
     "start_time": "2025-03-31T12:37:45.412474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pca=pd.concat((train_gpca,train_cpca),axis=1)\n",
    "test_pca=pd.concat((test_gpca,test_cpca),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4ebda3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:45.536653Z",
     "iopub.status.busy": "2025-03-31T12:37:45.536402Z",
     "iopub.status.idle": "2025-03-31T12:37:53.491607Z",
     "shell.execute_reply": "2025-03-31T12:37:53.490893Z"
    },
    "papermill": {
     "duration": 7.964656,
     "end_time": "2025-03-31T12:37:53.493262",
     "exception": false,
     "start_time": "2025-03-31T12:37:45.528606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_cluster_pca(train, test,n_clusters=5,SEED = 42):\n",
    "        data=pd.concat([train,test],axis=0)\n",
    "        kmeans_pca = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        dump(kmeans_pca, open('kmeans_pca.pkl', 'wb'))\n",
    "        train[f'clusters_pca'] = kmeans_pca.predict(train.values)\n",
    "        test[f'clusters_pca'] = kmeans_pca.predict(test.values)\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_pca'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_pca'])\n",
    "        return train, test\n",
    "train_cluster_pca ,test_cluster_pca = fe_cluster_pca(train_pca,test_pca) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0954e0",
   "metadata": {
    "papermill": {
     "duration": 0.006965,
     "end_time": "2025-03-31T12:37:53.507888",
     "exception": false,
     "start_time": "2025-03-31T12:37:53.500923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "就是在pca特征后面又加了独热编码的pca簇特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccd46cea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:53.522967Z",
     "iopub.status.busy": "2025-03-31T12:37:53.522641Z",
     "iopub.status.idle": "2025-03-31T12:37:53.527452Z",
     "shell.execute_reply": "2025-03-31T12:37:53.526732Z"
    },
    "papermill": {
     "duration": 0.013635,
     "end_time": "2025-03-31T12:37:53.528578",
     "exception": false,
     "start_time": "2025-03-31T12:37:53.514943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_cluster_pca = train_cluster_pca.iloc[:,650:]\n",
    "test_cluster_pca = test_cluster_pca.iloc[:,650:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f56fb994",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:53.543730Z",
     "iopub.status.busy": "2025-03-31T12:37:53.543512Z",
     "iopub.status.idle": "2025-03-31T12:37:53.547556Z",
     "shell.execute_reply": "2025-03-31T12:37:53.546898Z"
    },
    "papermill": {
     "duration": 0.012986,
     "end_time": "2025-03-31T12:37:53.548833",
     "exception": false,
     "start_time": "2025-03-31T12:37:53.535847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features_cluster=train_features2.iloc[:,876:]\n",
    "test_features_cluster=test_features2.iloc[:,876:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3376d88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:53.563734Z",
     "iopub.status.busy": "2025-03-31T12:37:53.563522Z",
     "iopub.status.idle": "2025-03-31T12:37:53.567238Z",
     "shell.execute_reply": "2025-03-31T12:37:53.566610Z"
    },
    "papermill": {
     "duration": 0.012446,
     "end_time": "2025-03-31T12:37:53.568401",
     "exception": false,
     "start_time": "2025-03-31T12:37:53.555955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "gsquarecols=['g-574','g-211','g-216','g-0','g-255','g-577','g-153','g-389','g-60','g-370','g-248','g-167','g-203','g-177','g-301','g-332','g-517','g-6','g-744','g-224','g-162','g-3','g-736','g-486','g-283','g-22','g-359','g-361','g-440','g-335','g-106','g-307','g-745','g-146','g-416','g-298','g-666','g-91','g-17','g-549','g-145','g-157','g-768','g-568','g-396']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e1b9e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:53.583766Z",
     "iopub.status.busy": "2025-03-31T12:37:53.583542Z",
     "iopub.status.idle": "2025-03-31T12:37:56.762678Z",
     "shell.execute_reply": "2025-03-31T12:37:56.761973Z"
    },
    "papermill": {
     "duration": 3.188725,
     "end_time": "2025-03-31T12:37:56.764445",
     "exception": false,
     "start_time": "2025-03-31T12:37:53.575720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_stats(train, test):\n",
    "    \n",
    "    features_g = GENES\n",
    "    features_c = CELLS\n",
    "    \n",
    "    for df in train, test:\n",
    "        df['g_sum'] = df[features_g].sum(axis = 1)\n",
    "        df['g_mean'] = df[features_g].mean(axis = 1)\n",
    "        df['g_std'] = df[features_g].std(axis = 1)\n",
    "        df['g_kurt'] = df[features_g].kurtosis(axis = 1)\n",
    "        df['g_skew'] = df[features_g].skew(axis = 1)\n",
    "        df['c_sum'] = df[features_c].sum(axis = 1)\n",
    "        df['c_mean'] = df[features_c].mean(axis = 1)\n",
    "        df['c_std'] = df[features_c].std(axis = 1)\n",
    "        df['c_kurt'] = df[features_c].kurtosis(axis = 1)\n",
    "        df['c_skew'] = df[features_c].skew(axis = 1)\n",
    "        df['gc_sum'] = df[features_g + features_c].sum(axis = 1)\n",
    "        df['gc_mean'] = df[features_g + features_c].mean(axis = 1)\n",
    "        df['gc_std'] = df[features_g + features_c].std(axis = 1)\n",
    "        df['gc_kurt'] = df[features_g + features_c].kurtosis(axis = 1)\n",
    "        df['gc_skew'] = df[features_g + features_c].skew(axis = 1)\n",
    "        \n",
    "        df['c52_c42'] = df['c-52'] * df['c-42']\n",
    "        df['c13_c73'] = df['c-13'] * df['c-73']\n",
    "        df['c26_c13'] = df['c-26'] * df['c-13']\n",
    "        df['c33_c6'] = df['c-33'] * df['c-6']\n",
    "        df['c11_c55'] = df['c-11'] * df['c-55']\n",
    "        df['c38_c63'] = df['c-38'] * df['c-63']\n",
    "        df['c38_c94'] = df['c-38'] * df['c-94']\n",
    "        df['c13_c94'] = df['c-13'] * df['c-94']\n",
    "        df['c4_c52'] = df['c-4'] * df['c-52']\n",
    "        df['c4_c42'] = df['c-4'] * df['c-42']\n",
    "        df['c13_c38'] = df['c-13'] * df['c-38']\n",
    "        df['c55_c2'] = df['c-55'] * df['c-2']\n",
    "        df['c55_c4'] = df['c-55'] * df['c-4']\n",
    "        df['c4_c13'] = df['c-4'] * df['c-13']\n",
    "        df['c82_c42'] = df['c-82'] * df['c-42']\n",
    "        df['c66_c42'] = df['c-66'] * df['c-42']\n",
    "        df['c6_c38'] = df['c-6'] * df['c-38']\n",
    "        df['c2_c13'] = df['c-2'] * df['c-13']\n",
    "        df['c62_c42'] = df['c-62'] * df['c-42']\n",
    "        df['c90_c55'] = df['c-90'] * df['c-55']\n",
    "        df['c26_c38'] = df['c-26'] * df['c-38']\n",
    "        df['c90_c13'] = df['c-90'] * df['c-13']\n",
    "        df['c85_c31'] = df['c-85'] * df['c-31']\n",
    "        df['c63_c42'] = df['c-63'] * df['c-42']\n",
    "        df['c94_c11'] = df['c-94'] * df['c-11']\n",
    "        df['c94_c60'] = df['c-94'] * df['c-60']\n",
    "        df['c55_c42'] = df['c-55'] * df['c-42']\n",
    "        df['g37_c50'] = df['g-37'] * df['g-50']\n",
    "        \n",
    "        \n",
    "        for feature in features_c:\n",
    "             df[f'{feature}_squared'] = df[feature] ** 2     \n",
    "                \n",
    "        for feature in gsquarecols:\n",
    "            df[f'{feature}_squared'] = df[feature] ** 2        \n",
    "        \n",
    "    return train, test\n",
    "\n",
    "train_features2,test_features2=fe_stats(train_features2,test_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e21cc0b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:56.781640Z",
     "iopub.status.busy": "2025-03-31T12:37:56.781346Z",
     "iopub.status.idle": "2025-03-31T12:37:56.807518Z",
     "shell.execute_reply": "2025-03-31T12:37:56.806869Z"
    },
    "papermill": {
     "duration": 0.035695,
     "end_time": "2025-03-31T12:37:56.808740",
     "exception": false,
     "start_time": "2025-03-31T12:37:56.773045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features_stats=train_features2.iloc[:,902:]\n",
    "test_features_stats=test_features2.iloc[:,902:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e0612ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:56.824730Z",
     "iopub.status.busy": "2025-03-31T12:37:56.824481Z",
     "iopub.status.idle": "2025-03-31T12:37:56.939013Z",
     "shell.execute_reply": "2025-03-31T12:37:56.938227Z"
    },
    "papermill": {
     "duration": 0.124343,
     "end_time": "2025-03-31T12:37:56.940719",
     "exception": false,
     "start_time": "2025-03-31T12:37:56.816376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.concat((train_features, train_features_cluster,train_cluster_pca,train_features_stats), axis=1)\n",
    "test_features = pd.concat((test_features, test_features_cluster,test_cluster_pca,test_features_stats), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93375552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:56.957604Z",
     "iopub.status.busy": "2025-03-31T12:37:56.957339Z",
     "iopub.status.idle": "2025-03-31T12:37:57.052488Z",
     "shell.execute_reply": "2025-03-31T12:37:57.051379Z"
    },
    "papermill": {
     "duration": 0.104604,
     "end_time": "2025-03-31T12:37:57.053792",
     "exception": false,
     "start_time": "2025-03-31T12:37:56.949188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 targets without ANY mechanism of action in the nonscored dataset\n"
     ]
    }
   ],
   "source": [
    "#Extract unique elements per column\n",
    "cols2 = train_targets_nonscored.columns.to_list() # specify the columns whose unique values you want here\n",
    "uniques2 = {col: train_targets_nonscored[col].nunique() for col in cols2}\n",
    "uniques2=pd.DataFrame(uniques2, index=[0]).T\n",
    "uniques2=uniques2.rename(columns={0:'count'})\n",
    "uniques2= uniques2.drop('sig_id', axis=0)#行是moa标签，列是出现的次数的种类数\n",
    "print(f\"{len(uniques2[uniques2['count']==1])} targets without ANY mechanism of action in the nonscored dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78f60cf",
   "metadata": {
    "papermill": {
     "duration": 0.007437,
     "end_time": "2025-03-31T12:37:57.069133",
     "exception": false,
     "start_time": "2025-03-31T12:37:57.061696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "筛掉了那些只有0或者只有1的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3089c88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:57.085085Z",
     "iopub.status.busy": "2025-03-31T12:37:57.084796Z",
     "iopub.status.idle": "2025-03-31T12:37:57.110849Z",
     "shell.execute_reply": "2025-03-31T12:37:57.110073Z"
    },
    "papermill": {
     "duration": 0.035927,
     "end_time": "2025-03-31T12:37:57.112533",
     "exception": false,
     "start_time": "2025-03-31T12:37:57.076606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nonmoacols=uniques2[uniques2['count']==1].index\n",
    "train_targets_nonscored_columns = [col for col in list(train_targets_nonscored.columns) if col not in nonmoacols]\n",
    "train_targets_nonscored=train_targets_nonscored[train_targets_nonscored_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ada69d33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:57.132511Z",
     "iopub.status.busy": "2025-03-31T12:37:57.132193Z",
     "iopub.status.idle": "2025-03-31T12:37:57.707766Z",
     "shell.execute_reply": "2025-03-31T12:37:57.707052Z"
    },
    "papermill": {
     "duration": 0.58685,
     "end_time": "2025-03-31T12:37:57.709447",
     "exception": false,
     "start_time": "2025-03-31T12:37:57.122597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_nonscored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_nonscored.columns]  #有意义的非评分目标标签"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7e166",
   "metadata": {
    "papermill": {
     "duration": 0.007306,
     "end_time": "2025-03-31T12:37:57.724692",
     "exception": false,
     "start_time": "2025-03-31T12:37:57.717386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "先是删除了控制组样本，然后删除了cp_type这一列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6bbd49f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:57.740465Z",
     "iopub.status.busy": "2025-03-31T12:37:57.740200Z",
     "iopub.status.idle": "2025-03-31T12:37:57.837215Z",
     "shell.execute_reply": "2025-03-31T12:37:57.836395Z"
    },
    "papermill": {
     "duration": 0.106715,
     "end_time": "2025-03-31T12:37:57.838860",
     "exception": false,
     "start_time": "2025-03-31T12:37:57.732145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dea149ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:57.855262Z",
     "iopub.status.busy": "2025-03-31T12:37:57.855017Z",
     "iopub.status.idle": "2025-03-31T12:37:57.876528Z",
     "shell.execute_reply": "2025-03-31T12:37:57.875830Z"
    },
    "papermill": {
     "duration": 0.031166,
     "end_time": "2025-03-31T12:37:57.877973",
     "exception": false,
     "start_time": "2025-03-31T12:37:57.846807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist() #有意义的非评分标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f079c3e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:57.895023Z",
     "iopub.status.busy": "2025-03-31T12:37:57.894772Z",
     "iopub.status.idle": "2025-03-31T12:37:58.109260Z",
     "shell.execute_reply": "2025-03-31T12:37:58.108540Z"
    },
    "papermill": {
     "duration": 0.224624,
     "end_time": "2025-03-31T12:37:58.110836",
     "exception": false,
     "start_time": "2025-03-31T12:37:57.886212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=['cp_time','cp_dose'])\n",
    "test_ = pd.get_dummies(test, columns=['cp_time','cp_dose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a38dd581",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:58.127644Z",
     "iopub.status.busy": "2025-03-31T12:37:58.127378Z",
     "iopub.status.idle": "2025-03-31T12:37:58.136295Z",
     "shell.execute_reply": "2025-03-31T12:37:58.135609Z"
    },
    "papermill": {
     "duration": 0.018679,
     "end_time": "2025-03-31T12:37:58.137621",
     "exception": false,
     "start_time": "2025-03-31T12:37:58.118942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_cols = [c for c in train.columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['sig_id']]\n",
    "#所有特征组成的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "926809a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:58.154554Z",
     "iopub.status.busy": "2025-03-31T12:37:58.154298Z",
     "iopub.status.idle": "2025-03-31T12:37:58.158758Z",
     "shell.execute_reply": "2025-03-31T12:37:58.157981Z"
    },
    "papermill": {
     "duration": 0.014215,
     "end_time": "2025-03-31T12:37:58.159958",
     "exception": false,
     "start_time": "2025-03-31T12:37:58.145743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1248"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "922abf03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:58.176465Z",
     "iopub.status.busy": "2025-03-31T12:37:58.176228Z",
     "iopub.status.idle": "2025-03-31T12:37:58.181677Z",
     "shell.execute_reply": "2025-03-31T12:37:58.180881Z"
    },
    "papermill": {
     "duration": 0.015137,
     "end_time": "2025-03-31T12:37:58.182878",
     "exception": false,
     "start_time": "2025-03-31T12:37:58.167741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features.astype(np.float32)\n",
    "        self.targets = targets.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "    \n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60d14b0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:58.199675Z",
     "iopub.status.busy": "2025-03-31T12:37:58.199442Z",
     "iopub.status.idle": "2025-03-31T12:37:58.206514Z",
     "shell.execute_reply": "2025-03-31T12:37:58.205714Z"
    },
    "papermill": {
     "duration": 0.01663,
     "end_time": "2025-03-31T12:37:58.207711",
     "exception": false,
     "start_time": "2025-03-31T12:37:58.191081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    \n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b959664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:58.224042Z",
     "iopub.status.busy": "2025-03-31T12:37:58.223794Z",
     "iopub.status.idle": "2025-03-31T12:37:58.229399Z",
     "shell.execute_reply": "2025-03-31T12:37:58.228598Z"
    },
    "papermill": {
     "duration": 0.015021,
     "end_time": "2025-03-31T12:37:58.230562",
     "exception": false,
     "start_time": "2025-03-31T12:37:58.215541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e719f64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:58.247091Z",
     "iopub.status.busy": "2025-03-31T12:37:58.246857Z",
     "iopub.status.idle": "2025-03-31T12:37:58.252419Z",
     "shell.execute_reply": "2025-03-31T12:37:58.251611Z"
    },
    "papermill": {
     "duration": 0.0152,
     "end_time": "2025-03-31T12:37:58.253667",
     "exception": false,
     "start_time": "2025-03-31T12:37:58.238467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model1, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.leaky_relu(self.dense1(x), 1e-3)\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0445601",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:58.270116Z",
     "iopub.status.busy": "2025-03-31T12:37:58.269899Z",
     "iopub.status.idle": "2025-03-31T12:37:58.280619Z",
     "shell.execute_reply": "2025-03-31T12:37:58.279792Z"
    },
    "papermill": {
     "duration": 0.020546,
     "end_time": "2025-03-31T12:37:58.282009",
     "exception": false,
     "start_time": "2025-03-31T12:37:58.261463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "        def __init__(self, num_features, num_targets, hidden_size):\n",
    "            super(Model2, self).__init__()\n",
    "            cha_1 = 256\n",
    "            cha_2 = 512\n",
    "            cha_3 = 512\n",
    "\n",
    "            cha_1_reshape = int(hidden_size/cha_1)\n",
    "            cha_po_1 = int(hidden_size/cha_1/2)\n",
    "            cha_po_2 = int(hidden_size/cha_1/2/2) * cha_3\n",
    "\n",
    "            self.cha_1 = cha_1\n",
    "            self.cha_2 = cha_2\n",
    "            self.cha_3 = cha_3\n",
    "            self.cha_1_reshape = cha_1_reshape\n",
    "            self.cha_po_1 = cha_po_1\n",
    "            self.cha_po_2 = cha_po_2\n",
    "\n",
    "            self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "            self.dropout1 = nn.Dropout(0.1)\n",
    "            self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "\n",
    "            self.batch_norm_c1 = nn.BatchNorm1d(cha_1)\n",
    "            self.dropout_c1 = nn.Dropout(0.1)\n",
    "            self.conv1 = nn.utils.weight_norm(nn.Conv1d(cha_1,cha_2, kernel_size = 5, stride = 1, padding=2,  bias=False),dim=None)\n",
    "\n",
    "            self.ave_po_c1 = nn.AdaptiveAvgPool1d(output_size = cha_po_1)\n",
    "\n",
    "            self.batch_norm_c2 = nn.BatchNorm1d(cha_2)\n",
    "            self.dropout_c2 = nn.Dropout(0.1)\n",
    "            self.conv2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "\n",
    "            self.batch_norm_c2_1 = nn.BatchNorm1d(cha_2)\n",
    "            self.dropout_c2_1 = nn.Dropout(0.3)\n",
    "            self.conv2_1 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "\n",
    "            self.batch_norm_c2_2 = nn.BatchNorm1d(cha_2)\n",
    "            self.dropout_c2_2 = nn.Dropout(0.2)\n",
    "            self.conv2_2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_3, kernel_size = 5, stride = 1, padding=2, bias=True),dim=None)\n",
    "\n",
    "            self.max_po_c2 = nn.MaxPool1d(kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "            self.flt = nn.Flatten()\n",
    "\n",
    "            self.batch_norm3 = nn.BatchNorm1d(cha_po_2)\n",
    "            self.dropout3 = nn.Dropout(0.2)\n",
    "            self.dense3 = nn.utils.weight_norm(nn.Linear(cha_po_2, num_targets))\n",
    "\n",
    "        def forward(self, x):\n",
    "\n",
    "            x = self.batch_norm1(x)\n",
    "            x = self.dropout1(x)\n",
    "            x = F.celu(self.dense1(x), alpha=0.06)\n",
    "\n",
    "            x = x.reshape(x.shape[0],self.cha_1,\n",
    "                          self.cha_1_reshape)\n",
    "\n",
    "            x = self.batch_norm_c1(x)\n",
    "            x = self.dropout_c1(x)\n",
    "            x = F.relu(self.conv1(x))\n",
    "\n",
    "            x = self.ave_po_c1(x)\n",
    "\n",
    "            x = self.batch_norm_c2(x)\n",
    "            x = self.dropout_c2(x)\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x_s = x\n",
    "\n",
    "            x = self.batch_norm_c2_1(x)\n",
    "            x = self.dropout_c2_1(x)\n",
    "            x = F.relu(self.conv2_1(x))\n",
    "\n",
    "            x = self.batch_norm_c2_2(x)\n",
    "            x = self.dropout_c2_2(x)\n",
    "            x = F.relu(self.conv2_2(x))\n",
    "            x =  x * x_s\n",
    "\n",
    "            x = self.max_po_c2(x)\n",
    "\n",
    "            x = self.flt(x)\n",
    "\n",
    "            x = self.batch_norm3(x)\n",
    "            x = self.dropout3(x)\n",
    "            x = self.dense3(x)\n",
    "\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec827499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:58.298499Z",
     "iopub.status.busy": "2025-03-31T12:37:58.298282Z",
     "iopub.status.idle": "2025-03-31T12:37:58.302024Z",
     "shell.execute_reply": "2025-03-31T12:37:58.301360Z"
    },
    "papermill": {
     "duration": 0.013208,
     "end_time": "2025-03-31T12:37:58.303249",
     "exception": false,
     "start_time": "2025-03-31T12:37:58.290041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 26\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 6e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 7\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = True\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee98622e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:58.319638Z",
     "iopub.status.busy": "2025-03-31T12:37:58.319423Z",
     "iopub.status.idle": "2025-03-31T12:37:58.328680Z",
     "shell.execute_reply": "2025-03-31T12:37:58.327985Z"
    },
    "papermill": {
     "duration": 0.018928,
     "end_time": "2025-03-31T12:37:58.330004",
     "exception": false,
     "start_time": "2025-03-31T12:37:58.311076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    mskf = MultilabelStratifiedKFold(n_splits=7)\n",
    "    for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "         train.loc[v_idx, 'kfold'] = int(f)\n",
    "    train['kfold'] = train['kfold'].astype(int)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model1(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"SEED: {seed} ,FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"SEED{seed}_FOLD{fold}_nonscored.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model1(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "\n",
    "    )\n",
    "    model.load_state_dict(torch.load(f\"SEED{seed}_FOLD{fold}_nonscored.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2453519",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:58.347697Z",
     "iopub.status.busy": "2025-03-31T12:37:58.347473Z",
     "iopub.status.idle": "2025-03-31T12:37:58.351055Z",
     "shell.execute_reply": "2025-03-31T12:37:58.350437Z"
    },
    "papermill": {
     "duration": 0.013315,
     "end_time": "2025-03-31T12:37:58.352350",
     "exception": false,
     "start_time": "2025-03-31T12:37:58.339035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d2aebe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T12:37:58.368969Z",
     "iopub.status.busy": "2025-03-31T12:37:58.368717Z",
     "iopub.status.idle": "2025-03-31T13:01:01.749653Z",
     "shell.execute_reply": "2025-03-31T13:01:01.748900Z"
    },
    "papermill": {
     "duration": 1383.391081,
     "end_time": "2025-03-31T13:01:01.751341",
     "exception": false,
     "start_time": "2025-03-31T12:37:58.360260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 0, FOLD: 0, EPOCH: 0, train_loss: 0.5876662201575331\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08735949947283818\n",
      "SEED: 0, FOLD: 0, EPOCH: 1, train_loss: 0.01642236878743043\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 1, valid_loss: 0.006098045466037897\n",
      "SEED: 0, FOLD: 0, EPOCH: 2, train_loss: 0.009288513095344644\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 2, valid_loss: 0.00570342313641539\n",
      "SEED: 0, FOLD: 0, EPOCH: 3, train_loss: 0.009243685764738836\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 3, valid_loss: 0.005432544168657982\n",
      "SEED: 0, FOLD: 0, EPOCH: 4, train_loss: 0.009058085414958564\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 4, valid_loss: 0.0056814294881545584\n",
      "SEED: 0, FOLD: 0, EPOCH: 5, train_loss: 0.008968649123719818\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 5, valid_loss: 0.006163321578731904\n",
      "SEED: 0, FOLD: 0, EPOCH: 6, train_loss: 0.008935478729875507\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 6, valid_loss: 0.005566556042490097\n",
      "SEED: 0, FOLD: 0, EPOCH: 7, train_loss: 0.0089206681586802\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 7, valid_loss: 0.005454980696623142\n",
      "SEED: 0, FOLD: 0, EPOCH: 8, train_loss: 0.00891725074600529\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005343718346781456\n",
      "SEED: 0, FOLD: 0, EPOCH: 9, train_loss: 0.008920828975435044\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005449817515909672\n",
      "SEED: 0, FOLD: 0, EPOCH: 10, train_loss: 0.008921764665157409\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 10, valid_loss: 0.005380897281261591\n",
      "SEED: 0, FOLD: 0, EPOCH: 11, train_loss: 0.008907786570489407\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 11, valid_loss: 0.0054936249238940384\n",
      "SEED: 0, FOLD: 0, EPOCH: 12, train_loss: 0.008915787449458966\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 12, valid_loss: 0.005443041678518057\n",
      "SEED: 0, FOLD: 0, EPOCH: 13, train_loss: 0.008898159929526013\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 13, valid_loss: 0.0055284513017305964\n",
      "SEED: 0, FOLD: 0, EPOCH: 14, train_loss: 0.008907997414369035\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 14, valid_loss: 0.005464372905687644\n",
      "SEED: 0, FOLD: 1, EPOCH: 0, train_loss: 0.5898985481141387\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 0, valid_loss: 0.07304490816134673\n",
      "SEED: 0, FOLD: 1, EPOCH: 1, train_loss: 0.0165955687344477\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 1, valid_loss: 0.006285903581346457\n",
      "SEED: 0, FOLD: 1, EPOCH: 2, train_loss: 0.009306169933060536\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 2, valid_loss: 0.005721114217661894\n",
      "SEED: 0, FOLD: 1, EPOCH: 3, train_loss: 0.009267349941404286\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 3, valid_loss: 0.00664001706844339\n",
      "SEED: 0, FOLD: 1, EPOCH: 4, train_loss: 0.00906510852478646\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 4, valid_loss: 0.005669546958345633\n",
      "SEED: 0, FOLD: 1, EPOCH: 5, train_loss: 0.008982734691754386\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005806745889668281\n",
      "SEED: 0, FOLD: 1, EPOCH: 6, train_loss: 0.008945100072368577\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 6, valid_loss: 0.00539482868491457\n",
      "SEED: 0, FOLD: 1, EPOCH: 7, train_loss: 0.008915679220965988\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 7, valid_loss: 0.005617495017269483\n",
      "SEED: 0, FOLD: 1, EPOCH: 8, train_loss: 0.008907006650760368\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 8, valid_loss: 0.005553674991600788\n",
      "SEED: 0, FOLD: 1, EPOCH: 9, train_loss: 0.008922309778328683\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 9, valid_loss: 0.00549962822921001\n",
      "SEED: 0, FOLD: 1, EPOCH: 10, train_loss: 0.008921518676436029\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 10, valid_loss: 0.005609941955369253\n",
      "SEED: 0, FOLD: 1, EPOCH: 11, train_loss: 0.008923781337216496\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005465968691099148\n",
      "SEED: 0, FOLD: 1, EPOCH: 12, train_loss: 0.008917932952376636\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 12, valid_loss: 0.00555486035031768\n",
      "SEED: 0, FOLD: 1, EPOCH: 13, train_loss: 0.008911650489411643\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 13, valid_loss: 0.0054608829534397675\n",
      "SEED: 0, FOLD: 1, EPOCH: 14, train_loss: 0.008912083938264766\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 14, valid_loss: 0.005461962320483648\n",
      "SEED: 0, FOLD: 2, EPOCH: 0, train_loss: 0.5872873206799095\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 0, valid_loss: 0.07838250467410454\n",
      "SEED: 0, FOLD: 2, EPOCH: 1, train_loss: 0.01640476891770959\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 1, valid_loss: 0.005937647325201676\n",
      "SEED: 0, FOLD: 2, EPOCH: 2, train_loss: 0.009281511682815649\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 2, valid_loss: 0.005729350368850506\n",
      "SEED: 0, FOLD: 2, EPOCH: 3, train_loss: 0.00951878322489761\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 3, valid_loss: 0.005623035204525177\n",
      "SEED: 0, FOLD: 2, EPOCH: 4, train_loss: 0.009076970484661492\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 4, valid_loss: 0.005512142303184821\n",
      "SEED: 0, FOLD: 2, EPOCH: 5, train_loss: 0.008988389141253522\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 5, valid_loss: 0.00551372214865226\n",
      "SEED: 0, FOLD: 2, EPOCH: 6, train_loss: 0.00892183862978945\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 6, valid_loss: 0.0056115098727437165\n",
      "SEED: 0, FOLD: 2, EPOCH: 7, train_loss: 0.008915396092610585\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 7, valid_loss: 0.005602292788143341\n",
      "SEED: 0, FOLD: 2, EPOCH: 8, train_loss: 0.0088956841028522\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005507586201509604\n",
      "SEED: 0, FOLD: 2, EPOCH: 9, train_loss: 0.008890325323099623\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 9, valid_loss: 0.005385659061945402\n",
      "SEED: 0, FOLD: 2, EPOCH: 10, train_loss: 0.00888240577753734\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 10, valid_loss: 0.005505289058559216\n",
      "SEED: 0, FOLD: 2, EPOCH: 11, train_loss: 0.008886182762531412\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 11, valid_loss: 0.005564621470582027\n",
      "SEED: 0, FOLD: 2, EPOCH: 12, train_loss: 0.00888754625024425\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 12, valid_loss: 0.00549854373989197\n",
      "SEED: 0, FOLD: 2, EPOCH: 13, train_loss: 0.00887631912514366\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 13, valid_loss: 0.005515067247100747\n",
      "SEED: 0, FOLD: 2, EPOCH: 14, train_loss: 0.00886149046237807\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 14, valid_loss: 0.005470173648343637\n",
      "SEED: 0, FOLD: 2, EPOCH: 15, train_loss: 0.008846769845616576\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 15, valid_loss: 0.005418510247881596\n",
      "SEED: 0, FOLD: 2, EPOCH: 16, train_loss: 0.00880645723963106\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 16, valid_loss: 0.005428526335610793\n",
      "SEED: 0, FOLD: 3, EPOCH: 0, train_loss: 0.5886571423427479\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08341109408782078\n",
      "SEED: 0, FOLD: 3, EPOCH: 1, train_loss: 0.016732343850103585\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 1, valid_loss: 0.0061826631785012204\n",
      "SEED: 0, FOLD: 3, EPOCH: 2, train_loss: 0.009286166445629017\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 2, valid_loss: 0.005865958375999561\n",
      "SEED: 0, FOLD: 3, EPOCH: 3, train_loss: 0.009213193842033679\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 3, valid_loss: 0.005697771799392425\n",
      "SEED: 0, FOLD: 3, EPOCH: 4, train_loss: 0.009075647320699048\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 4, valid_loss: 0.005651852689110315\n",
      "SEED: 0, FOLD: 3, EPOCH: 5, train_loss: 0.008953778922708856\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 5, valid_loss: 0.005632614036305592\n",
      "SEED: 0, FOLD: 3, EPOCH: 6, train_loss: 0.008894730321559552\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 6, valid_loss: 0.0058202577683214955\n",
      "SEED: 0, FOLD: 3, EPOCH: 7, train_loss: 0.008892577342890404\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 7, valid_loss: 0.005803129779031644\n",
      "SEED: 0, FOLD: 3, EPOCH: 8, train_loss: 0.008892554217144041\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 8, valid_loss: 0.00566709188457865\n",
      "SEED: 0, FOLD: 3, EPOCH: 9, train_loss: 0.008889168872170755\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 9, valid_loss: 0.005661432846234395\n",
      "SEED: 0, FOLD: 3, EPOCH: 10, train_loss: 0.008879610557562194\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 10, valid_loss: 0.00566706398072151\n",
      "SEED: 0, FOLD: 3, EPOCH: 11, train_loss: 0.008886532688110665\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 11, valid_loss: 0.005689855736608689\n",
      "SEED: 0, FOLD: 3, EPOCH: 12, train_loss: 0.008895864905286077\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 12, valid_loss: 0.005723057493854027\n",
      "SEED: 0, FOLD: 3, EPOCH: 13, train_loss: 0.008885899401345366\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 13, valid_loss: 0.005659622999911125\n",
      "SEED: 0, FOLD: 3, EPOCH: 14, train_loss: 0.008857097973845698\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 14, valid_loss: 0.005701113348970046\n",
      "SEED: 0, FOLD: 3, EPOCH: 15, train_loss: 0.00885509223853414\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 15, valid_loss: 0.005684371177966778\n",
      "SEED: 0, FOLD: 4, EPOCH: 0, train_loss: 0.5894653625987671\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08442431344435765\n",
      "SEED: 0, FOLD: 4, EPOCH: 1, train_loss: 0.016757108761954145\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 1, valid_loss: 0.0061729466542601585\n",
      "SEED: 0, FOLD: 4, EPOCH: 2, train_loss: 0.009343262384268077\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 2, valid_loss: 0.006413396555357254\n",
      "SEED: 0, FOLD: 4, EPOCH: 3, train_loss: 0.009206576033721905\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 3, valid_loss: 0.0059522983546440415\n",
      "SEED: 0, FOLD: 4, EPOCH: 4, train_loss: 0.009188509244169737\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 4, valid_loss: 0.005589836456168156\n",
      "SEED: 0, FOLD: 4, EPOCH: 5, train_loss: 0.008995731512235629\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 5, valid_loss: 0.0057354455169003745\n",
      "SEED: 0, FOLD: 4, EPOCH: 6, train_loss: 0.008942337908052109\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 6, valid_loss: 0.00555793450285609\n",
      "SEED: 0, FOLD: 4, EPOCH: 7, train_loss: 0.008917107253108878\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 7, valid_loss: 0.005576268769800663\n",
      "SEED: 0, FOLD: 4, EPOCH: 8, train_loss: 0.008913805557263864\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 8, valid_loss: 0.005647500726179435\n",
      "SEED: 0, FOLD: 4, EPOCH: 9, train_loss: 0.008896282792242395\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 9, valid_loss: 0.005566018526084148\n",
      "SEED: 0, FOLD: 4, EPOCH: 10, train_loss: 0.008898993349961332\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 10, valid_loss: 0.00560589929899344\n",
      "SEED: 0, FOLD: 4, EPOCH: 11, train_loss: 0.008887103267920178\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005686640954361512\n",
      "SEED: 0, FOLD: 4, EPOCH: 12, train_loss: 0.00889037295269805\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 12, valid_loss: 0.005629724572197749\n",
      "SEED: 0, FOLD: 4, EPOCH: 13, train_loss: 0.008880058750258508\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 13, valid_loss: 0.005631906911730766\n",
      "SEED: 0, FOLD: 4, EPOCH: 14, train_loss: 0.008872469188645482\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005617973215591449\n",
      "SEED: 0, FOLD: 5, EPOCH: 0, train_loss: 0.5908610691895356\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 0, valid_loss: 0.08319659531116486\n",
      "SEED: 0, FOLD: 5, EPOCH: 1, train_loss: 0.01699509778739633\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 1, valid_loss: 0.006121026602788613\n",
      "SEED: 0, FOLD: 5, EPOCH: 2, train_loss: 0.009274371597613837\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 2, valid_loss: 0.00571313461002249\n",
      "SEED: 0, FOLD: 5, EPOCH: 3, train_loss: 0.009221957039994162\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 3, valid_loss: 0.005595686988761792\n",
      "SEED: 0, FOLD: 5, EPOCH: 4, train_loss: 0.009023354791507527\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 4, valid_loss: 0.005463069340643974\n",
      "SEED: 0, FOLD: 5, EPOCH: 5, train_loss: 0.00901474670909748\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 5, valid_loss: 0.005731737133688652\n",
      "SEED: 0, FOLD: 5, EPOCH: 6, train_loss: 0.008933025752068372\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 6, valid_loss: 0.005486289254174783\n",
      "SEED: 0, FOLD: 5, EPOCH: 7, train_loss: 0.008934671134763473\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 7, valid_loss: 0.005419546809907143\n",
      "SEED: 0, FOLD: 5, EPOCH: 8, train_loss: 0.00892342400510569\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 8, valid_loss: 0.005471997751066318\n",
      "SEED: 0, FOLD: 5, EPOCH: 9, train_loss: 0.008910915008871942\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 9, valid_loss: 0.005377137352927373\n",
      "SEED: 0, FOLD: 5, EPOCH: 10, train_loss: 0.008900095280763265\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005426479360231986\n",
      "SEED: 0, FOLD: 5, EPOCH: 11, train_loss: 0.008892842241235682\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005672360125642557\n",
      "SEED: 0, FOLD: 5, EPOCH: 12, train_loss: 0.008905006157284652\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 12, valid_loss: 0.005575537860680085\n",
      "SEED: 0, FOLD: 5, EPOCH: 13, train_loss: 0.008886259200202452\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 13, valid_loss: 0.005469336138608364\n",
      "SEED: 0, FOLD: 5, EPOCH: 14, train_loss: 0.008879602156780861\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 14, valid_loss: 0.005488681535308178\n",
      "SEED: 0, FOLD: 5, EPOCH: 15, train_loss: 0.008849629477874653\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 15, valid_loss: 0.005525730227908263\n",
      "SEED: 0, FOLD: 5, EPOCH: 16, train_loss: 0.00884063556991719\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 16, valid_loss: 0.005470185146595423\n",
      "SEED: 0, FOLD: 6, EPOCH: 0, train_loss: 0.5900932601778894\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 0, valid_loss: 0.08445440633938862\n",
      "SEED: 0, FOLD: 6, EPOCH: 1, train_loss: 0.01678675985769243\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 1, valid_loss: 0.006002930172074299\n",
      "SEED: 0, FOLD: 6, EPOCH: 2, train_loss: 0.00951976329088211\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 2, valid_loss: 0.00567622035025404\n",
      "SEED: 0, FOLD: 6, EPOCH: 3, train_loss: 0.00923579274299177\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 3, valid_loss: 0.0055347038074754756\n",
      "SEED: 0, FOLD: 6, EPOCH: 4, train_loss: 0.009026853776713079\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 4, valid_loss: 0.005570971263715854\n",
      "SEED: 0, FOLD: 6, EPOCH: 5, train_loss: 0.008934725849964732\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 5, valid_loss: 0.00561168549868923\n",
      "SEED: 0, FOLD: 6, EPOCH: 6, train_loss: 0.008919826696148596\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 6, valid_loss: 0.00555527163669467\n",
      "SEED: 0, FOLD: 6, EPOCH: 7, train_loss: 0.008910739756617192\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005487327213184192\n",
      "SEED: 0, FOLD: 6, EPOCH: 8, train_loss: 0.008892881262393014\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 8, valid_loss: 0.005550400282327945\n",
      "SEED: 0, FOLD: 6, EPOCH: 9, train_loss: 0.008891698426088772\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 9, valid_loss: 0.00547876817962298\n",
      "SEED: 0, FOLD: 6, EPOCH: 10, train_loss: 0.008890946244669927\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 10, valid_loss: 0.005557896246990332\n",
      "SEED: 0, FOLD: 6, EPOCH: 11, train_loss: 0.0088898638213003\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 11, valid_loss: 0.00548152095423295\n",
      "SEED: 0, FOLD: 6, EPOCH: 12, train_loss: 0.00889324676245451\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 12, valid_loss: 0.005531393278103609\n",
      "SEED: 0, FOLD: 6, EPOCH: 13, train_loss: 0.008883492756836317\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 13, valid_loss: 0.005611182512858739\n",
      "SEED: 0, FOLD: 6, EPOCH: 14, train_loss: 0.00888014620018972\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 14, valid_loss: 0.005449137614610104\n",
      "SEED: 0, FOLD: 6, EPOCH: 15, train_loss: 0.008868079833887718\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 15, valid_loss: 0.005584151161691317\n",
      "SEED: 0, FOLD: 6, EPOCH: 16, train_loss: 0.00886295349463015\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 16, valid_loss: 0.005513417534530163\n",
      "SEED: 1, FOLD: 0, EPOCH: 0, train_loss: 0.5881155934688207\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 0, valid_loss: 0.07895448001531455\n",
      "SEED: 1, FOLD: 0, EPOCH: 1, train_loss: 0.016467345324722497\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 1, valid_loss: 0.006176632327529101\n",
      "SEED: 1, FOLD: 0, EPOCH: 2, train_loss: 0.009319909986712643\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 2, valid_loss: 0.006108797334421139\n",
      "SEED: 1, FOLD: 0, EPOCH: 3, train_loss: 0.010355266012452744\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 3, valid_loss: 0.0055563613199270685\n",
      "SEED: 1, FOLD: 0, EPOCH: 4, train_loss: 0.00909313520517301\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 4, valid_loss: 0.005549571978358122\n",
      "SEED: 1, FOLD: 0, EPOCH: 5, train_loss: 0.009012423380202538\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 5, valid_loss: 0.0055406620869269734\n",
      "SEED: 1, FOLD: 0, EPOCH: 6, train_loss: 0.00897150582986305\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 6, valid_loss: 0.005627090469575846\n",
      "SEED: 1, FOLD: 0, EPOCH: 7, train_loss: 0.008952363155077438\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 7, valid_loss: 0.00560337881772564\n",
      "SEED: 1, FOLD: 0, EPOCH: 8, train_loss: 0.008951522674210169\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005573377443047671\n",
      "SEED: 1, FOLD: 0, EPOCH: 9, train_loss: 0.008936749305576086\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005555083151333607\n",
      "SEED: 1, FOLD: 0, EPOCH: 10, train_loss: 0.008940115998927\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 10, valid_loss: 0.005566306233119506\n",
      "SEED: 1, FOLD: 0, EPOCH: 11, train_loss: 0.008908712217030493\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 11, valid_loss: 0.0055299424566328526\n",
      "SEED: 1, FOLD: 0, EPOCH: 12, train_loss: 0.00891513071601858\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 12, valid_loss: 0.0054752346701346915\n",
      "SEED: 1, FOLD: 0, EPOCH: 13, train_loss: 0.008893715330978503\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 13, valid_loss: 0.005487573118163989\n",
      "SEED: 1, FOLD: 0, EPOCH: 14, train_loss: 0.008875281285695933\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 14, valid_loss: 0.0056426008231937885\n",
      "SEED: 1, FOLD: 0, EPOCH: 15, train_loss: 0.00887745216715376\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 15, valid_loss: 0.0055331742892471645\n",
      "SEED: 1, FOLD: 0, EPOCH: 16, train_loss: 0.008840240085044422\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 16, valid_loss: 0.005488872671356568\n",
      "SEED: 1, FOLD: 0, EPOCH: 17, train_loss: 0.008831705791070251\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 17, valid_loss: 0.005550670974816267\n",
      "SEED: 1, FOLD: 1, EPOCH: 0, train_loss: 0.5879643745720387\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 0, valid_loss: 0.08726315372265302\n",
      "SEED: 1, FOLD: 1, EPOCH: 1, train_loss: 0.01657429795611549\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 1, valid_loss: 0.0061585900302116685\n",
      "SEED: 1, FOLD: 1, EPOCH: 2, train_loss: 0.009347163644191381\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 2, valid_loss: 0.0057883885904000355\n",
      "SEED: 1, FOLD: 1, EPOCH: 3, train_loss: 0.009150076531679244\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 3, valid_loss: 0.006349267473874183\n",
      "SEED: 1, FOLD: 1, EPOCH: 4, train_loss: 0.009160139528732444\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 4, valid_loss: 0.0056581890497070094\n",
      "SEED: 1, FOLD: 1, EPOCH: 5, train_loss: 0.008970065073840119\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005607785083926641\n",
      "SEED: 1, FOLD: 1, EPOCH: 6, train_loss: 0.008957800203682604\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 6, valid_loss: 0.005963461079563086\n",
      "SEED: 1, FOLD: 1, EPOCH: 7, train_loss: 0.008922679941295772\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 7, valid_loss: 0.0056333667240463774\n",
      "SEED: 1, FOLD: 1, EPOCH: 8, train_loss: 0.008906111278495676\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 8, valid_loss: 0.005569510376797273\n",
      "SEED: 1, FOLD: 1, EPOCH: 9, train_loss: 0.008911331920456645\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 9, valid_loss: 0.005567500940882242\n",
      "SEED: 1, FOLD: 1, EPOCH: 10, train_loss: 0.00891301264936054\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 10, valid_loss: 0.005571326025976584\n",
      "SEED: 1, FOLD: 1, EPOCH: 11, train_loss: 0.008915565480050203\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005554138646962551\n",
      "SEED: 1, FOLD: 1, EPOCH: 12, train_loss: 0.008912599595213259\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 12, valid_loss: 0.005614089922836194\n",
      "SEED: 1, FOLD: 1, EPOCH: 13, train_loss: 0.008899102541240485\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 13, valid_loss: 0.005575902939129334\n",
      "SEED: 1, FOLD: 1, EPOCH: 14, train_loss: 0.008869887757542971\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 14, valid_loss: 0.005560458745234287\n",
      "SEED: 1, FOLD: 1, EPOCH: 15, train_loss: 0.008858350999149922\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 15, valid_loss: 0.005613536323205783\n",
      "SEED: 1, FOLD: 1, EPOCH: 16, train_loss: 0.00883810326608049\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 16, valid_loss: 0.005574341612653091\n",
      "SEED: 1, FOLD: 1, EPOCH: 17, train_loss: 0.00881756330538239\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 17, valid_loss: 0.0055262966869542235\n",
      "SEED: 1, FOLD: 1, EPOCH: 18, train_loss: 0.008781760314328445\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 18, valid_loss: 0.005509662728470106\n",
      "SEED: 1, FOLD: 1, EPOCH: 19, train_loss: 0.008741602641404481\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 19, valid_loss: 0.005510189176465456\n",
      "SEED: 1, FOLD: 2, EPOCH: 0, train_loss: 0.5883725091210894\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 0, valid_loss: 0.08447422832250595\n",
      "SEED: 1, FOLD: 2, EPOCH: 1, train_loss: 0.01660373463370913\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 1, valid_loss: 0.005993613543418737\n",
      "SEED: 1, FOLD: 2, EPOCH: 2, train_loss: 0.009311280880324744\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 2, valid_loss: 0.0065572680547260325\n",
      "SEED: 1, FOLD: 2, EPOCH: 3, train_loss: 0.00925738417316933\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 3, valid_loss: 0.005780413997574494\n",
      "SEED: 1, FOLD: 2, EPOCH: 4, train_loss: 0.009035551555555415\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 4, valid_loss: 0.005486656016168686\n",
      "SEED: 1, FOLD: 2, EPOCH: 5, train_loss: 0.009082218820883616\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 5, valid_loss: 0.005385379306972027\n",
      "SEED: 1, FOLD: 2, EPOCH: 6, train_loss: 0.008958398112775507\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 6, valid_loss: 0.0054870378942443775\n",
      "SEED: 1, FOLD: 2, EPOCH: 7, train_loss: 0.008937015298854661\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 7, valid_loss: 0.005647105343926411\n",
      "SEED: 1, FOLD: 2, EPOCH: 8, train_loss: 0.008935307970622907\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005458928573016937\n",
      "SEED: 1, FOLD: 2, EPOCH: 9, train_loss: 0.008931291465823716\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 9, valid_loss: 0.005524443569951332\n",
      "SEED: 1, FOLD: 2, EPOCH: 10, train_loss: 0.008928119544745297\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 10, valid_loss: 0.005546307083792412\n",
      "SEED: 1, FOLD: 2, EPOCH: 11, train_loss: 0.008918688003275846\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 11, valid_loss: 0.005487383665660253\n",
      "SEED: 1, FOLD: 2, EPOCH: 12, train_loss: 0.008918820295130482\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 12, valid_loss: 0.005455162555265885\n",
      "SEED: 1, FOLD: 2, EPOCH: 13, train_loss: 0.008899679596258982\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 13, valid_loss: 0.005489014841329593\n",
      "SEED: 1, FOLD: 2, EPOCH: 14, train_loss: 0.008915356781988128\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 14, valid_loss: 0.00543298411111419\n",
      "SEED: 1, FOLD: 3, EPOCH: 0, train_loss: 0.5872844787868293\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08597635019284028\n",
      "SEED: 1, FOLD: 3, EPOCH: 1, train_loss: 0.016513131219088227\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 1, valid_loss: 0.006052242377056525\n",
      "SEED: 1, FOLD: 3, EPOCH: 2, train_loss: 0.009423302750833131\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 2, valid_loss: 0.005749867906650672\n",
      "SEED: 1, FOLD: 3, EPOCH: 3, train_loss: 0.009161056459856194\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 3, valid_loss: 0.007670914467710715\n",
      "SEED: 1, FOLD: 3, EPOCH: 4, train_loss: 0.009039786719792598\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 4, valid_loss: 0.005569616046089392\n",
      "SEED: 1, FOLD: 3, EPOCH: 5, train_loss: 0.008975667287469716\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 5, valid_loss: 0.005734234081151394\n",
      "SEED: 1, FOLD: 3, EPOCH: 6, train_loss: 0.008923910986128691\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 6, valid_loss: 0.005477507849438832\n",
      "SEED: 1, FOLD: 3, EPOCH: 7, train_loss: 0.00890864827040885\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 7, valid_loss: 0.00555610921807014\n",
      "SEED: 1, FOLD: 3, EPOCH: 8, train_loss: 0.008910159970558173\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 8, valid_loss: 0.005517732387838455\n",
      "SEED: 1, FOLD: 3, EPOCH: 9, train_loss: 0.008909477902626669\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 9, valid_loss: 0.0055632906822630996\n",
      "SEED: 1, FOLD: 3, EPOCH: 10, train_loss: 0.008919064377157672\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 10, valid_loss: 0.005554613406555011\n",
      "SEED: 1, FOLD: 3, EPOCH: 11, train_loss: 0.00890859729308333\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 11, valid_loss: 0.005609000173325722\n",
      "SEED: 1, FOLD: 3, EPOCH: 12, train_loss: 0.00890226465196827\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 12, valid_loss: 0.005616048565850808\n",
      "SEED: 1, FOLD: 3, EPOCH: 13, train_loss: 0.00891764639448878\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 13, valid_loss: 0.0055657574692024635\n",
      "SEED: 1, FOLD: 3, EPOCH: 14, train_loss: 0.008882950324363805\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 14, valid_loss: 0.005583270058895533\n",
      "SEED: 1, FOLD: 4, EPOCH: 0, train_loss: 0.5873773328557208\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08033040051276867\n",
      "SEED: 1, FOLD: 4, EPOCH: 1, train_loss: 0.016765171599045798\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 1, valid_loss: 0.006060766521841288\n",
      "SEED: 1, FOLD: 4, EPOCH: 2, train_loss: 0.009279275539557676\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 2, valid_loss: 0.005712433252483606\n",
      "SEED: 1, FOLD: 4, EPOCH: 3, train_loss: 0.009226611563684168\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 3, valid_loss: 0.00739072564129646\n",
      "SEED: 1, FOLD: 4, EPOCH: 4, train_loss: 0.009134558885282761\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 4, valid_loss: 0.005515858101157041\n",
      "SEED: 1, FOLD: 4, EPOCH: 5, train_loss: 0.00895940830201112\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 5, valid_loss: 0.005460826321863211\n",
      "SEED: 1, FOLD: 4, EPOCH: 6, train_loss: 0.008918966676385419\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 6, valid_loss: 0.005440035405067297\n",
      "SEED: 1, FOLD: 4, EPOCH: 7, train_loss: 0.008901807441804055\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 7, valid_loss: 0.00562561837096627\n",
      "SEED: 1, FOLD: 4, EPOCH: 8, train_loss: 0.008894768178563666\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 8, valid_loss: 0.005384816788136959\n",
      "SEED: 1, FOLD: 4, EPOCH: 9, train_loss: 0.008915134705603123\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 9, valid_loss: 0.00543954660399602\n",
      "SEED: 1, FOLD: 4, EPOCH: 10, train_loss: 0.008898142756692864\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 10, valid_loss: 0.0054946132362462\n",
      "SEED: 1, FOLD: 4, EPOCH: 11, train_loss: 0.008894150894185578\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005532433493779256\n",
      "SEED: 1, FOLD: 4, EPOCH: 12, train_loss: 0.008886526571586728\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 12, valid_loss: 0.005470324522600724\n",
      "SEED: 1, FOLD: 4, EPOCH: 13, train_loss: 0.008900519063998316\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 13, valid_loss: 0.005521247020134559\n",
      "SEED: 1, FOLD: 4, EPOCH: 14, train_loss: 0.008884850505588425\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005539457421176708\n",
      "SEED: 1, FOLD: 4, EPOCH: 15, train_loss: 0.008852812008479156\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 15, valid_loss: 0.005477515300019429\n",
      "SEED: 1, FOLD: 4, EPOCH: 16, train_loss: 0.008828378427219955\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 16, valid_loss: 0.0054614577227487015\n",
      "SEED: 1, FOLD: 5, EPOCH: 0, train_loss: 0.588012109435088\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 0, valid_loss: 0.06784696590441924\n",
      "SEED: 1, FOLD: 5, EPOCH: 1, train_loss: 0.01658173612746838\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 1, valid_loss: 0.0062116292090370106\n",
      "SEED: 1, FOLD: 5, EPOCH: 2, train_loss: 0.009327097204387994\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 2, valid_loss: 0.005939299885470133\n",
      "SEED: 1, FOLD: 5, EPOCH: 3, train_loss: 0.00990927143878228\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 3, valid_loss: 0.005528412472743254\n",
      "SEED: 1, FOLD: 5, EPOCH: 4, train_loss: 0.00911886724517555\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 4, valid_loss: 0.005613170170153563\n",
      "SEED: 1, FOLD: 5, EPOCH: 5, train_loss: 0.009002291874305622\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 5, valid_loss: 0.005662117010125747\n",
      "SEED: 1, FOLD: 5, EPOCH: 6, train_loss: 0.008977903588045691\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 6, valid_loss: 0.005536567706328172\n",
      "SEED: 1, FOLD: 5, EPOCH: 7, train_loss: 0.008947383562052573\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 7, valid_loss: 0.00561618572100997\n",
      "SEED: 1, FOLD: 5, EPOCH: 8, train_loss: 0.008929106639698148\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 8, valid_loss: 0.0055559926952880164\n",
      "SEED: 1, FOLD: 5, EPOCH: 9, train_loss: 0.008927112520747894\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 9, valid_loss: 0.005600448733625503\n",
      "SEED: 1, FOLD: 5, EPOCH: 10, train_loss: 0.008922332815976965\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005527768176622116\n",
      "SEED: 1, FOLD: 5, EPOCH: 11, train_loss: 0.00890834297909326\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005575360658650215\n",
      "SEED: 1, FOLD: 5, EPOCH: 12, train_loss: 0.008910923887900001\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 12, valid_loss: 0.005532394199130626\n",
      "SEED: 1, FOLD: 5, EPOCH: 13, train_loss: 0.00888855309804549\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 13, valid_loss: 0.005467426461669115\n",
      "SEED: 1, FOLD: 5, EPOCH: 14, train_loss: 0.008880198247277656\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 14, valid_loss: 0.005545745030618631\n",
      "SEED: 1, FOLD: 5, EPOCH: 15, train_loss: 0.008854685735108482\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 15, valid_loss: 0.005524331202300696\n",
      "SEED: 1, FOLD: 6, EPOCH: 0, train_loss: 0.5864471917015475\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 0, valid_loss: 0.08721258147404744\n",
      "SEED: 1, FOLD: 6, EPOCH: 1, train_loss: 0.016458621953387518\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 1, valid_loss: 0.0061880419962108135\n",
      "SEED: 1, FOLD: 6, EPOCH: 2, train_loss: 0.010521568584482412\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 2, valid_loss: 0.005866353220951099\n",
      "SEED: 1, FOLD: 6, EPOCH: 3, train_loss: 0.009204671441300495\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 3, valid_loss: 0.005655646288337616\n",
      "SEED: 1, FOLD: 6, EPOCH: 4, train_loss: 0.009048482604526184\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 4, valid_loss: 0.005654988201478353\n",
      "SEED: 1, FOLD: 6, EPOCH: 5, train_loss: 0.00900477810913848\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 5, valid_loss: 0.005525394915961302\n",
      "SEED: 1, FOLD: 6, EPOCH: 6, train_loss: 0.008944232180412556\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 6, valid_loss: 0.005602850542905239\n",
      "SEED: 1, FOLD: 6, EPOCH: 7, train_loss: 0.00892748509382678\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005580145041816509\n",
      "SEED: 1, FOLD: 6, EPOCH: 8, train_loss: 0.008912723737995367\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 8, valid_loss: 0.005517668054940609\n",
      "SEED: 1, FOLD: 6, EPOCH: 9, train_loss: 0.008927092358872697\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 9, valid_loss: 0.005604358891455026\n",
      "SEED: 1, FOLD: 6, EPOCH: 10, train_loss: 0.008924954935807633\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 10, valid_loss: 0.005517085620130484\n",
      "SEED: 1, FOLD: 6, EPOCH: 11, train_loss: 0.008921916514786112\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 11, valid_loss: 0.005555381210377583\n",
      "SEED: 1, FOLD: 6, EPOCH: 12, train_loss: 0.008896081884567803\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 12, valid_loss: 0.00559855062657824\n",
      "SEED: 1, FOLD: 6, EPOCH: 13, train_loss: 0.008903185264333277\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 13, valid_loss: 0.005551216479104299\n",
      "SEED: 1, FOLD: 6, EPOCH: 14, train_loss: 0.008890331741674123\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 14, valid_loss: 0.0055441675492777275\n",
      "SEED: 1, FOLD: 6, EPOCH: 15, train_loss: 0.008867269174220998\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 15, valid_loss: 0.005534876281252274\n",
      "SEED: 1, FOLD: 6, EPOCH: 16, train_loss: 0.008846117781374502\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 16, valid_loss: 0.005518193105952098\n",
      "SEED: 1, FOLD: 6, EPOCH: 17, train_loss: 0.008796503484198774\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 17, valid_loss: 0.005461041600658343\n",
      "SEED: 1, FOLD: 6, EPOCH: 18, train_loss: 0.008776944420124227\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 18, valid_loss: 0.005505819196024766\n",
      "SEED: 2, FOLD: 0, EPOCH: 0, train_loss: 0.5873940748137396\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08106216788291931\n",
      "SEED: 2, FOLD: 0, EPOCH: 1, train_loss: 0.01680874443185088\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 1, valid_loss: 0.00616163806989789\n",
      "SEED: 2, FOLD: 0, EPOCH: 2, train_loss: 0.00923524536444126\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 2, valid_loss: 0.005997529325003807\n",
      "SEED: 2, FOLD: 0, EPOCH: 3, train_loss: 0.009209836845764437\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 3, valid_loss: 0.005594783999885504\n",
      "SEED: 2, FOLD: 0, EPOCH: 4, train_loss: 0.009025148355175514\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 4, valid_loss: 0.005928125841399798\n",
      "SEED: 2, FOLD: 0, EPOCH: 5, train_loss: 0.00912245999820329\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 5, valid_loss: 0.005494634979046308\n",
      "SEED: 2, FOLD: 0, EPOCH: 6, train_loss: 0.008919971044854941\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 6, valid_loss: 0.005535841238899873\n",
      "SEED: 2, FOLD: 0, EPOCH: 7, train_loss: 0.008928818911364352\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 7, valid_loss: 0.005604915965635043\n",
      "SEED: 2, FOLD: 0, EPOCH: 8, train_loss: 0.00891888073670703\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005539070456646956\n",
      "SEED: 2, FOLD: 0, EPOCH: 9, train_loss: 0.00889637166432835\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005637789682413523\n",
      "SEED: 2, FOLD: 0, EPOCH: 10, train_loss: 0.00889789402434552\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 10, valid_loss: 0.005559507470864516\n",
      "SEED: 2, FOLD: 0, EPOCH: 11, train_loss: 0.008897809349503872\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 11, valid_loss: 0.00562832887785939\n",
      "SEED: 2, FOLD: 0, EPOCH: 12, train_loss: 0.008903452019030983\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 12, valid_loss: 0.0056229142042306755\n",
      "SEED: 2, FOLD: 0, EPOCH: 13, train_loss: 0.008897488905318282\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 13, valid_loss: 0.005614744463505654\n",
      "SEED: 2, FOLD: 0, EPOCH: 14, train_loss: 0.008884326919812608\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 14, valid_loss: 0.005692636629996391\n",
      "SEED: 2, FOLD: 1, EPOCH: 0, train_loss: 0.5886654192330064\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 0, valid_loss: 0.08902096117918308\n",
      "SEED: 2, FOLD: 1, EPOCH: 1, train_loss: 0.017157139785185054\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 1, valid_loss: 0.006000684359325812\n",
      "SEED: 2, FOLD: 1, EPOCH: 2, train_loss: 0.009269461488804302\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 2, valid_loss: 0.005811915661279972\n",
      "SEED: 2, FOLD: 1, EPOCH: 3, train_loss: 0.009794269675842009\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 3, valid_loss: 0.005562068106463322\n",
      "SEED: 2, FOLD: 1, EPOCH: 4, train_loss: 0.009162404782113593\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 4, valid_loss: 0.005628257667502532\n",
      "SEED: 2, FOLD: 1, EPOCH: 5, train_loss: 0.00901133009559802\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005525841700056424\n",
      "SEED: 2, FOLD: 1, EPOCH: 6, train_loss: 0.00894808119188088\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 6, valid_loss: 0.005978752930576985\n",
      "SEED: 2, FOLD: 1, EPOCH: 7, train_loss: 0.008943183284655615\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 7, valid_loss: 0.005407736779978642\n",
      "SEED: 2, FOLD: 1, EPOCH: 8, train_loss: 0.00892804843700818\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 8, valid_loss: 0.00547136223086944\n",
      "SEED: 2, FOLD: 1, EPOCH: 9, train_loss: 0.008922055464338613\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 9, valid_loss: 0.005610978015913413\n",
      "SEED: 2, FOLD: 1, EPOCH: 10, train_loss: 0.008911147852101037\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 10, valid_loss: 0.005587091454519675\n",
      "SEED: 2, FOLD: 1, EPOCH: 11, train_loss: 0.00889888996057011\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005672046269934911\n",
      "SEED: 2, FOLD: 1, EPOCH: 12, train_loss: 0.008884162440694668\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 12, valid_loss: 0.005446669788887868\n",
      "SEED: 2, FOLD: 1, EPOCH: 13, train_loss: 0.008868907981023594\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 13, valid_loss: 0.005475883407948108\n",
      "SEED: 2, FOLD: 1, EPOCH: 14, train_loss: 0.008859398202165155\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 14, valid_loss: 0.005465608161802475\n",
      "SEED: 2, FOLD: 1, EPOCH: 15, train_loss: 0.008852200658136123\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 15, valid_loss: 0.0055239421243851\n",
      "SEED: 2, FOLD: 2, EPOCH: 0, train_loss: 0.5889658696345381\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 0, valid_loss: 0.07999937178996894\n",
      "SEED: 2, FOLD: 2, EPOCH: 1, train_loss: 0.01656684573941134\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 1, valid_loss: 0.006167388413674557\n",
      "SEED: 2, FOLD: 2, EPOCH: 2, train_loss: 0.00944235548377037\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 2, valid_loss: 0.005834147405739014\n",
      "SEED: 2, FOLD: 2, EPOCH: 3, train_loss: 0.009169220905499282\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 3, valid_loss: 0.005860041003101147\n",
      "SEED: 2, FOLD: 2, EPOCH: 4, train_loss: 0.009023148428044608\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 4, valid_loss: 0.0055205751783572714\n",
      "SEED: 2, FOLD: 2, EPOCH: 5, train_loss: 0.00894026574678719\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 5, valid_loss: 0.005647833494899364\n",
      "SEED: 2, FOLD: 2, EPOCH: 6, train_loss: 0.008912003762717988\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 6, valid_loss: 0.005607480362344246\n",
      "SEED: 2, FOLD: 2, EPOCH: 7, train_loss: 0.008896379039396305\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 7, valid_loss: 0.005580159441496317\n",
      "SEED: 2, FOLD: 2, EPOCH: 8, train_loss: 0.00889993886891249\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005679593636439397\n",
      "SEED: 2, FOLD: 2, EPOCH: 9, train_loss: 0.008893942636613911\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 9, valid_loss: 0.0055666671564372685\n",
      "SEED: 2, FOLD: 2, EPOCH: 10, train_loss: 0.008896261340359578\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 10, valid_loss: 0.0055414974832764035\n",
      "SEED: 2, FOLD: 2, EPOCH: 11, train_loss: 0.008899082756928495\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 11, valid_loss: 0.005608494859188795\n",
      "SEED: 2, FOLD: 2, EPOCH: 12, train_loss: 0.008901445025175408\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 12, valid_loss: 0.005590554398412888\n",
      "SEED: 2, FOLD: 2, EPOCH: 13, train_loss: 0.00891156169283833\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 13, valid_loss: 0.005713404872669623\n",
      "SEED: 2, FOLD: 3, EPOCH: 0, train_loss: 0.588565627465377\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08669564930292276\n",
      "SEED: 2, FOLD: 3, EPOCH: 1, train_loss: 0.01664444203866092\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 1, valid_loss: 0.006225092264895256\n",
      "SEED: 2, FOLD: 3, EPOCH: 2, train_loss: 0.009280550117428238\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 2, valid_loss: 0.005866130384115072\n",
      "SEED: 2, FOLD: 3, EPOCH: 3, train_loss: 0.009182843807581309\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 3, valid_loss: 0.005855337967379735\n",
      "SEED: 2, FOLD: 3, EPOCH: 4, train_loss: 0.00903477952689738\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 4, valid_loss: 0.005612568965611549\n",
      "SEED: 2, FOLD: 3, EPOCH: 5, train_loss: 0.008930964634527225\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 5, valid_loss: 0.005639818532822223\n",
      "SEED: 2, FOLD: 3, EPOCH: 6, train_loss: 0.008910525181154543\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 6, valid_loss: 0.005472176851561436\n",
      "SEED: 2, FOLD: 3, EPOCH: 7, train_loss: 0.00890657989106871\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 7, valid_loss: 0.005488111959913602\n",
      "SEED: 2, FOLD: 3, EPOCH: 8, train_loss: 0.00888864217779121\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 8, valid_loss: 0.005584446068566579\n",
      "SEED: 2, FOLD: 3, EPOCH: 9, train_loss: 0.008884200045989978\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 9, valid_loss: 0.005612645369882767\n",
      "SEED: 2, FOLD: 3, EPOCH: 10, train_loss: 0.00889519469283924\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 10, valid_loss: 0.005661384560740911\n",
      "SEED: 2, FOLD: 3, EPOCH: 11, train_loss: 0.008886775127737908\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 11, valid_loss: 0.005586762052889054\n",
      "SEED: 2, FOLD: 3, EPOCH: 12, train_loss: 0.008889916220780563\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 12, valid_loss: 0.005508342901101479\n",
      "SEED: 2, FOLD: 3, EPOCH: 13, train_loss: 0.008888944782115318\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 13, valid_loss: 0.005568003711792139\n",
      "SEED: 2, FOLD: 3, EPOCH: 14, train_loss: 0.008861774792643013\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 14, valid_loss: 0.005618117104929227\n",
      "SEED: 2, FOLD: 3, EPOCH: 15, train_loss: 0.008846979550513867\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 15, valid_loss: 0.005558471338680157\n",
      "SEED: 2, FOLD: 4, EPOCH: 0, train_loss: 0.5867371635662543\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08387443537895496\n",
      "SEED: 2, FOLD: 4, EPOCH: 1, train_loss: 0.01643751101014582\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 1, valid_loss: 0.005950860177668242\n",
      "SEED: 2, FOLD: 4, EPOCH: 2, train_loss: 0.00928509805502521\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 2, valid_loss: 0.005940639772094213\n",
      "SEED: 2, FOLD: 4, EPOCH: 3, train_loss: 0.009257800575043704\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 3, valid_loss: 0.0054849564241102105\n",
      "SEED: 2, FOLD: 4, EPOCH: 4, train_loss: 0.00906068248976324\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 4, valid_loss: 0.005750339227513625\n",
      "SEED: 2, FOLD: 4, EPOCH: 5, train_loss: 0.008966341425941602\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 5, valid_loss: 0.005497719985074722\n",
      "SEED: 2, FOLD: 4, EPOCH: 6, train_loss: 0.008914597181452287\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 6, valid_loss: 0.005590851024652903\n",
      "SEED: 2, FOLD: 4, EPOCH: 7, train_loss: 0.008896271213637414\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 7, valid_loss: 0.005398218842366567\n",
      "SEED: 2, FOLD: 4, EPOCH: 8, train_loss: 0.008901128174132994\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 8, valid_loss: 0.005586104216770484\n",
      "SEED: 2, FOLD: 4, EPOCH: 9, train_loss: 0.00890153315472039\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 9, valid_loss: 0.005373736915106957\n",
      "SEED: 2, FOLD: 4, EPOCH: 10, train_loss: 0.008886375835769483\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 10, valid_loss: 0.0054403269806733495\n",
      "SEED: 2, FOLD: 4, EPOCH: 11, train_loss: 0.008901300720518103\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005395512060763745\n",
      "SEED: 2, FOLD: 4, EPOCH: 12, train_loss: 0.008899032452924026\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 12, valid_loss: 0.0054731350392103195\n",
      "SEED: 2, FOLD: 4, EPOCH: 13, train_loss: 0.008896528931989058\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 13, valid_loss: 0.00552732153580739\n",
      "SEED: 2, FOLD: 4, EPOCH: 14, train_loss: 0.008873895188239781\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005431058315130381\n",
      "SEED: 2, FOLD: 4, EPOCH: 15, train_loss: 0.008865431485999678\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 15, valid_loss: 0.005492764560935589\n",
      "SEED: 2, FOLD: 5, EPOCH: 0, train_loss: 0.5872574179760508\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 0, valid_loss: 0.07367615057871892\n",
      "SEED: 2, FOLD: 5, EPOCH: 1, train_loss: 0.0167554782678348\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 1, valid_loss: 0.006005338966273344\n",
      "SEED: 2, FOLD: 5, EPOCH: 2, train_loss: 0.00949181425007614\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 2, valid_loss: 0.005670481576369359\n",
      "SEED: 2, FOLD: 5, EPOCH: 3, train_loss: 0.009216079740105448\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 3, valid_loss: 0.005712306126952171\n",
      "SEED: 2, FOLD: 5, EPOCH: 4, train_loss: 0.009066380283518418\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 4, valid_loss: 0.005489444431777184\n",
      "SEED: 2, FOLD: 5, EPOCH: 5, train_loss: 0.008955477183130948\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 5, valid_loss: 0.00558648226209558\n",
      "SEED: 2, FOLD: 5, EPOCH: 6, train_loss: 0.008930131522435191\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 6, valid_loss: 0.005490232330675309\n",
      "SEED: 2, FOLD: 5, EPOCH: 7, train_loss: 0.008890996171111191\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 7, valid_loss: 0.0055162015800865796\n",
      "SEED: 2, FOLD: 5, EPOCH: 8, train_loss: 0.008896466992745126\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 8, valid_loss: 0.005538505251304462\n",
      "SEED: 2, FOLD: 5, EPOCH: 9, train_loss: 0.008918306947610265\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 9, valid_loss: 0.0055923459048454575\n",
      "SEED: 2, FOLD: 5, EPOCH: 10, train_loss: 0.008891021971263596\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005527226970745967\n",
      "SEED: 2, FOLD: 5, EPOCH: 11, train_loss: 0.008896722571571937\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005553742154286458\n",
      "SEED: 2, FOLD: 5, EPOCH: 12, train_loss: 0.008902306983096374\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 12, valid_loss: 0.0055097790721517345\n",
      "SEED: 2, FOLD: 5, EPOCH: 13, train_loss: 0.008884295965922443\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 13, valid_loss: 0.005652530835225032\n",
      "SEED: 2, FOLD: 6, EPOCH: 0, train_loss: 0.5872166090317674\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 0, valid_loss: 0.07321341393085626\n",
      "SEED: 2, FOLD: 6, EPOCH: 1, train_loss: 0.016530762187431793\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 1, valid_loss: 0.006105216542402139\n",
      "SEED: 2, FOLD: 6, EPOCH: 2, train_loss: 0.009318799195760811\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 2, valid_loss: 0.006075729401065753\n",
      "SEED: 2, FOLD: 6, EPOCH: 3, train_loss: 0.009238922704212569\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 3, valid_loss: 0.006270637198422964\n",
      "SEED: 2, FOLD: 6, EPOCH: 4, train_loss: 0.009074449400744727\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 4, valid_loss: 0.005811879053138769\n",
      "SEED: 2, FOLD: 6, EPOCH: 5, train_loss: 0.008959563247658111\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 5, valid_loss: 0.006027977913618088\n",
      "SEED: 2, FOLD: 6, EPOCH: 6, train_loss: 0.008933461441129848\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 6, valid_loss: 0.005488205199631361\n",
      "SEED: 2, FOLD: 6, EPOCH: 7, train_loss: 0.008922778340559956\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005609554668458609\n",
      "SEED: 2, FOLD: 6, EPOCH: 8, train_loss: 0.00891978817840887\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 8, valid_loss: 0.005500164276991899\n",
      "SEED: 2, FOLD: 6, EPOCH: 9, train_loss: 0.008928859417603628\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 9, valid_loss: 0.005255331321117969\n",
      "SEED: 2, FOLD: 6, EPOCH: 10, train_loss: 0.008913071316390022\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 10, valid_loss: 0.00537034016675674\n",
      "SEED: 2, FOLD: 6, EPOCH: 11, train_loss: 0.008922552173906887\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 11, valid_loss: 0.005378772486717655\n",
      "SEED: 2, FOLD: 6, EPOCH: 12, train_loss: 0.008930994046700967\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 12, valid_loss: 0.005421200982080056\n",
      "SEED: 2, FOLD: 6, EPOCH: 13, train_loss: 0.008912300326030803\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 13, valid_loss: 0.005429839858641991\n",
      "SEED: 2, FOLD: 6, EPOCH: 14, train_loss: 0.008910023009505224\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 14, valid_loss: 0.005417084500480156\n",
      "SEED: 2, FOLD: 6, EPOCH: 15, train_loss: 0.008884432568290346\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 15, valid_loss: 0.005469599487976386\n",
      "SEED: 3, FOLD: 0, EPOCH: 0, train_loss: 0.5885433746954879\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 0, valid_loss: 0.07826988914838204\n",
      "SEED: 3, FOLD: 0, EPOCH: 1, train_loss: 0.01670195094334918\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 1, valid_loss: 0.006234562812516322\n",
      "SEED: 3, FOLD: 0, EPOCH: 2, train_loss: 0.009279434279714888\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 2, valid_loss: 0.0058000442357017444\n",
      "SEED: 3, FOLD: 0, EPOCH: 3, train_loss: 0.00919954280520009\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 3, valid_loss: 0.006283481390430377\n",
      "SEED: 3, FOLD: 0, EPOCH: 4, train_loss: 0.009105376521679195\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 4, valid_loss: 0.005635776628668492\n",
      "SEED: 3, FOLD: 0, EPOCH: 5, train_loss: 0.009029818547738565\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 5, valid_loss: 0.007371784653514624\n",
      "SEED: 3, FOLD: 0, EPOCH: 6, train_loss: 0.008960792801116366\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 6, valid_loss: 0.005572985105503064\n",
      "SEED: 3, FOLD: 0, EPOCH: 7, train_loss: 0.008936515971514824\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 7, valid_loss: 0.00552600109949708\n",
      "SEED: 3, FOLD: 0, EPOCH: 8, train_loss: 0.008898700920965624\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005548943443080554\n",
      "SEED: 3, FOLD: 0, EPOCH: 9, train_loss: 0.008917069276543083\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005572141004869571\n",
      "SEED: 3, FOLD: 0, EPOCH: 10, train_loss: 0.008899115869221656\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 10, valid_loss: 0.0056421087624935005\n",
      "SEED: 3, FOLD: 0, EPOCH: 11, train_loss: 0.008910509984235506\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 11, valid_loss: 0.005559365515812085\n",
      "SEED: 3, FOLD: 0, EPOCH: 12, train_loss: 0.008900974455566422\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 12, valid_loss: 0.005537639694431653\n",
      "SEED: 3, FOLD: 0, EPOCH: 13, train_loss: 0.008880827103968005\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 13, valid_loss: 0.005492571490601852\n",
      "SEED: 3, FOLD: 0, EPOCH: 14, train_loss: 0.008867796743288636\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 14, valid_loss: 0.005747197733189051\n",
      "SEED: 3, FOLD: 0, EPOCH: 15, train_loss: 0.008858326331687134\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 15, valid_loss: 0.005576427846860427\n",
      "SEED: 3, FOLD: 0, EPOCH: 16, train_loss: 0.008832943562820956\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 16, valid_loss: 0.005590360181835981\n",
      "SEED: 3, FOLD: 1, EPOCH: 0, train_loss: 0.5888906470625788\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 0, valid_loss: 0.07987237377808644\n",
      "SEED: 3, FOLD: 1, EPOCH: 1, train_loss: 0.016606862480575975\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 1, valid_loss: 0.006117401143106131\n",
      "SEED: 3, FOLD: 1, EPOCH: 2, train_loss: 0.009995614260284079\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 2, valid_loss: 0.005690853398006696\n",
      "SEED: 3, FOLD: 1, EPOCH: 3, train_loss: 0.009219648970945462\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 3, valid_loss: 0.005672165729965155\n",
      "SEED: 3, FOLD: 1, EPOCH: 4, train_loss: 0.009145919548196567\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 4, valid_loss: 0.005575039782203161\n",
      "SEED: 3, FOLD: 1, EPOCH: 5, train_loss: 0.008988052908633207\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005596765746863989\n",
      "SEED: 3, FOLD: 1, EPOCH: 6, train_loss: 0.008947346007099023\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 6, valid_loss: 0.005530080364014094\n",
      "SEED: 3, FOLD: 1, EPOCH: 7, train_loss: 0.00894069529415385\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 7, valid_loss: 0.00580941538254802\n",
      "SEED: 3, FOLD: 1, EPOCH: 8, train_loss: 0.008918295494859686\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 8, valid_loss: 0.005627419190624585\n",
      "SEED: 3, FOLD: 1, EPOCH: 9, train_loss: 0.008920728178644503\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 9, valid_loss: 0.005632843678960433\n",
      "SEED: 3, FOLD: 1, EPOCH: 10, train_loss: 0.008907992348729356\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 10, valid_loss: 0.005719446362211154\n",
      "SEED: 3, FOLD: 1, EPOCH: 11, train_loss: 0.008904656892441012\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005543247796595097\n",
      "SEED: 3, FOLD: 1, EPOCH: 12, train_loss: 0.008892701900992039\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 12, valid_loss: 0.005550881489538229\n",
      "SEED: 3, FOLD: 1, EPOCH: 13, train_loss: 0.008894180054650517\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 13, valid_loss: 0.005552891534394943\n",
      "SEED: 3, FOLD: 1, EPOCH: 14, train_loss: 0.00888342862143307\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 14, valid_loss: 0.0055970414899862726\n",
      "SEED: 3, FOLD: 1, EPOCH: 15, train_loss: 0.00886254320927971\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 15, valid_loss: 0.005533903299902494\n",
      "SEED: 3, FOLD: 2, EPOCH: 0, train_loss: 0.5890669468286875\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 0, valid_loss: 0.07664683747750062\n",
      "SEED: 3, FOLD: 2, EPOCH: 1, train_loss: 0.01698569507917037\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 1, valid_loss: 0.006164527713106229\n",
      "SEED: 3, FOLD: 2, EPOCH: 2, train_loss: 0.009279718899444954\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 2, valid_loss: 0.007239246311096044\n",
      "SEED: 3, FOLD: 2, EPOCH: 3, train_loss: 0.009408358975338775\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 3, valid_loss: 0.005672541411163716\n",
      "SEED: 3, FOLD: 2, EPOCH: 4, train_loss: 0.009059627716605729\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 4, valid_loss: 0.005556100191405186\n",
      "SEED: 3, FOLD: 2, EPOCH: 5, train_loss: 0.008953802671434509\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 5, valid_loss: 0.005634608248678537\n",
      "SEED: 3, FOLD: 2, EPOCH: 6, train_loss: 0.00891692831332015\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 6, valid_loss: 0.005500916570711594\n",
      "SEED: 3, FOLD: 2, EPOCH: 7, train_loss: 0.00892553958613929\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 7, valid_loss: 0.005717567598017363\n",
      "SEED: 3, FOLD: 2, EPOCH: 8, train_loss: 0.008920636028051376\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005562746073477543\n",
      "SEED: 3, FOLD: 2, EPOCH: 9, train_loss: 0.008899697366900541\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 9, valid_loss: 0.00555396989847605\n",
      "SEED: 3, FOLD: 2, EPOCH: 10, train_loss: 0.008897411957936915\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 10, valid_loss: 0.005527236677992802\n",
      "SEED: 3, FOLD: 2, EPOCH: 11, train_loss: 0.008915559092939302\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 11, valid_loss: 0.005535529066736882\n",
      "SEED: 3, FOLD: 2, EPOCH: 12, train_loss: 0.00890610391601316\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 12, valid_loss: 0.005519149574236228\n",
      "SEED: 3, FOLD: 2, EPOCH: 13, train_loss: 0.008917689531085056\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 13, valid_loss: 0.005637091620323749\n",
      "SEED: 3, FOLD: 2, EPOCH: 14, train_loss: 0.008880581014563103\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 14, valid_loss: 0.005490359062185654\n",
      "SEED: 3, FOLD: 2, EPOCH: 15, train_loss: 0.008866965342816469\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 15, valid_loss: 0.00558849133980962\n",
      "SEED: 3, FOLD: 3, EPOCH: 0, train_loss: 0.5875804273260606\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 0, valid_loss: 0.0774078695819928\n",
      "SEED: 3, FOLD: 3, EPOCH: 1, train_loss: 0.016592440346406924\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 1, valid_loss: 0.005919294575086007\n",
      "SEED: 3, FOLD: 3, EPOCH: 2, train_loss: 0.009378174496059483\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 2, valid_loss: 0.005796154746069358\n",
      "SEED: 3, FOLD: 3, EPOCH: 3, train_loss: 0.00920969938129388\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 3, valid_loss: 0.005663792387797282\n",
      "SEED: 3, FOLD: 3, EPOCH: 4, train_loss: 0.009027784350454001\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 4, valid_loss: 0.005546903775001948\n",
      "SEED: 3, FOLD: 3, EPOCH: 5, train_loss: 0.008936172848366\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 5, valid_loss: 0.0054154830554930065\n",
      "SEED: 3, FOLD: 3, EPOCH: 6, train_loss: 0.008946037763175933\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 6, valid_loss: 0.005596635254243245\n",
      "SEED: 3, FOLD: 3, EPOCH: 7, train_loss: 0.008907198226331053\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 7, valid_loss: 0.0054913858095040685\n",
      "SEED: 3, FOLD: 3, EPOCH: 8, train_loss: 0.008925606200874254\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 8, valid_loss: 0.005572783617446056\n",
      "SEED: 3, FOLD: 3, EPOCH: 9, train_loss: 0.008930935285280685\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 9, valid_loss: 0.005457333432367215\n",
      "SEED: 3, FOLD: 3, EPOCH: 10, train_loss: 0.008902670324754875\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 10, valid_loss: 0.005550127225713088\n",
      "SEED: 3, FOLD: 3, EPOCH: 11, train_loss: 0.008921318869987453\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 11, valid_loss: 0.005532883859884281\n",
      "SEED: 3, FOLD: 3, EPOCH: 12, train_loss: 0.00891299221689838\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 12, valid_loss: 0.005515367007599427\n",
      "SEED: 3, FOLD: 3, EPOCH: 13, train_loss: 0.00892463791486178\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 13, valid_loss: 0.005409786620965371\n",
      "SEED: 3, FOLD: 3, EPOCH: 14, train_loss: 0.00890483458627116\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 14, valid_loss: 0.0055632597695176415\n",
      "SEED: 3, FOLD: 3, EPOCH: 15, train_loss: 0.00888240201449072\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 15, valid_loss: 0.005452010171631208\n",
      "SEED: 3, FOLD: 3, EPOCH: 16, train_loss: 0.008861594739042827\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 16, valid_loss: 0.005465416022791312\n",
      "SEED: 3, FOLD: 4, EPOCH: 0, train_loss: 0.588463639991509\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08769323906073204\n",
      "SEED: 3, FOLD: 4, EPOCH: 1, train_loss: 0.01671478119552941\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 1, valid_loss: 0.006028920841904787\n",
      "SEED: 3, FOLD: 4, EPOCH: 2, train_loss: 0.009289387563193167\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 2, valid_loss: 0.005856464437853832\n",
      "SEED: 3, FOLD: 4, EPOCH: 3, train_loss: 0.009252369743645997\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 3, valid_loss: 0.006279826809007388\n",
      "SEED: 3, FOLD: 4, EPOCH: 4, train_loss: 0.009164833199434183\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 4, valid_loss: 0.0055104889906942844\n",
      "SEED: 3, FOLD: 4, EPOCH: 5, train_loss: 0.008972665936862296\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 5, valid_loss: 0.005681760501689636\n",
      "SEED: 3, FOLD: 4, EPOCH: 6, train_loss: 0.008965370459230366\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 6, valid_loss: 0.00561599347453851\n",
      "SEED: 3, FOLD: 4, EPOCH: 7, train_loss: 0.008919011436503482\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 7, valid_loss: 0.0055306971144790835\n",
      "SEED: 3, FOLD: 4, EPOCH: 8, train_loss: 0.008905647083412151\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 8, valid_loss: 0.005508047994226217\n",
      "SEED: 3, FOLD: 4, EPOCH: 9, train_loss: 0.008919543605549512\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 9, valid_loss: 0.005548469686450867\n",
      "SEED: 3, FOLD: 4, EPOCH: 10, train_loss: 0.008913842621385245\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 10, valid_loss: 0.005573477739324937\n",
      "SEED: 3, FOLD: 4, EPOCH: 11, train_loss: 0.008898809558485408\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005637496817283905\n",
      "SEED: 3, FOLD: 4, EPOCH: 12, train_loss: 0.008891067606069752\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 12, valid_loss: 0.005552864167839289\n",
      "SEED: 3, FOLD: 4, EPOCH: 13, train_loss: 0.008877130017641026\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 13, valid_loss: 0.0055505450313481\n",
      "SEED: 3, FOLD: 4, EPOCH: 14, train_loss: 0.008871113850005172\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005650980863720179\n",
      "SEED: 3, FOLD: 5, EPOCH: 0, train_loss: 0.5889076851308346\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 0, valid_loss: 0.07639590478860415\n",
      "SEED: 3, FOLD: 5, EPOCH: 1, train_loss: 0.016684242285083275\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 1, valid_loss: 0.00601208618340584\n",
      "SEED: 3, FOLD: 5, EPOCH: 2, train_loss: 0.009306797493450545\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 2, valid_loss: 0.005505352173573696\n",
      "SEED: 3, FOLD: 5, EPOCH: 3, train_loss: 0.009263028183045823\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 3, valid_loss: 0.007612886372953653\n",
      "SEED: 3, FOLD: 5, EPOCH: 4, train_loss: 0.009056680445634836\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 4, valid_loss: 0.00577192660421133\n",
      "SEED: 3, FOLD: 5, EPOCH: 5, train_loss: 0.008967379649245256\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 5, valid_loss: 0.005664196116133378\n",
      "SEED: 3, FOLD: 5, EPOCH: 6, train_loss: 0.008924863030630592\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 6, valid_loss: 0.005380353138137322\n",
      "SEED: 3, FOLD: 5, EPOCH: 7, train_loss: 0.008901863371500292\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 7, valid_loss: 0.005353266337456612\n",
      "SEED: 3, FOLD: 5, EPOCH: 8, train_loss: 0.008905768016907008\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 8, valid_loss: 0.005467000309951031\n",
      "SEED: 3, FOLD: 5, EPOCH: 9, train_loss: 0.00890699981686634\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 9, valid_loss: 0.005396533148506513\n",
      "SEED: 3, FOLD: 5, EPOCH: 10, train_loss: 0.008894928624048023\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 10, valid_loss: 0.0054139423972138995\n",
      "SEED: 3, FOLD: 5, EPOCH: 11, train_loss: 0.00889920478535665\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005542577280161472\n",
      "SEED: 3, FOLD: 5, EPOCH: 12, train_loss: 0.008907850019986162\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 12, valid_loss: 0.005474540476615612\n",
      "SEED: 3, FOLD: 5, EPOCH: 13, train_loss: 0.008895548287074308\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 13, valid_loss: 0.0054321462073578285\n",
      "SEED: 3, FOLD: 5, EPOCH: 14, train_loss: 0.008874714468933037\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 14, valid_loss: 0.0054572219602190535\n",
      "SEED: 3, FOLD: 6, EPOCH: 0, train_loss: 0.5883239604331352\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 0, valid_loss: 0.07978164920440087\n",
      "SEED: 3, FOLD: 6, EPOCH: 1, train_loss: 0.01688411212652116\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 1, valid_loss: 0.006193630289859497\n",
      "SEED: 3, FOLD: 6, EPOCH: 2, train_loss: 0.00934956844493344\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 2, valid_loss: 0.005836712232289406\n",
      "SEED: 3, FOLD: 6, EPOCH: 3, train_loss: 0.009193180550544246\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 3, valid_loss: 0.006003214153819359\n",
      "SEED: 3, FOLD: 6, EPOCH: 4, train_loss: 0.009071419909093026\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 4, valid_loss: 0.005587480783175964\n",
      "SEED: 3, FOLD: 6, EPOCH: 5, train_loss: 0.009007796349406644\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 5, valid_loss: 0.005654432739202793\n",
      "SEED: 3, FOLD: 6, EPOCH: 6, train_loss: 0.008958486475151134\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 6, valid_loss: 0.0054892001028817436\n",
      "SEED: 3, FOLD: 6, EPOCH: 7, train_loss: 0.008917895070201642\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005515687955686679\n",
      "SEED: 3, FOLD: 6, EPOCH: 8, train_loss: 0.008933728900612206\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 8, valid_loss: 0.005462738112188303\n",
      "SEED: 3, FOLD: 6, EPOCH: 9, train_loss: 0.008919606016747452\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 9, valid_loss: 0.005471821372898726\n",
      "SEED: 3, FOLD: 6, EPOCH: 10, train_loss: 0.008924234740285052\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 10, valid_loss: 0.005680571202761852\n",
      "SEED: 3, FOLD: 6, EPOCH: 11, train_loss: 0.0089119637536036\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 11, valid_loss: 0.005531286283467825\n",
      "SEED: 3, FOLD: 6, EPOCH: 12, train_loss: 0.008914142526132433\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 12, valid_loss: 0.005573987602614439\n",
      "SEED: 3, FOLD: 6, EPOCH: 13, train_loss: 0.008897200189027432\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 13, valid_loss: 0.005623683655777803\n",
      "SEED: 3, FOLD: 6, EPOCH: 14, train_loss: 0.008892135298181628\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 14, valid_loss: 0.005594818208080072\n",
      "SEED: 3, FOLD: 6, EPOCH: 15, train_loss: 0.008877138034566431\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 15, valid_loss: 0.005535216608013098\n",
      "SEED: 4, FOLD: 0, EPOCH: 0, train_loss: 0.5877427804107601\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 0, valid_loss: 0.07683941091482456\n",
      "SEED: 4, FOLD: 0, EPOCH: 1, train_loss: 0.01663507244272812\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 1, valid_loss: 0.006098823299488196\n",
      "SEED: 4, FOLD: 0, EPOCH: 2, train_loss: 0.009323356157118405\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 2, valid_loss: 0.0057836555374356415\n",
      "SEED: 4, FOLD: 0, EPOCH: 3, train_loss: 0.009222024258830258\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 3, valid_loss: 0.00567881168367771\n",
      "SEED: 4, FOLD: 0, EPOCH: 4, train_loss: 0.009063878858059243\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 4, valid_loss: 0.0058035645992136915\n",
      "SEED: 4, FOLD: 0, EPOCH: 5, train_loss: 0.009029502766458569\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 5, valid_loss: 0.005602536472277\n",
      "SEED: 4, FOLD: 0, EPOCH: 6, train_loss: 0.008949311110316901\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 6, valid_loss: 0.005544954230292485\n",
      "SEED: 4, FOLD: 0, EPOCH: 7, train_loss: 0.00893995021092328\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 7, valid_loss: 0.005630422240266433\n",
      "SEED: 4, FOLD: 0, EPOCH: 8, train_loss: 0.008931657941256827\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005590604761472115\n",
      "SEED: 4, FOLD: 0, EPOCH: 9, train_loss: 0.008933312775617515\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005538782140669914\n",
      "SEED: 4, FOLD: 0, EPOCH: 10, train_loss: 0.008878389323079909\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 10, valid_loss: 0.005539652891457081\n",
      "SEED: 4, FOLD: 0, EPOCH: 11, train_loss: 0.008885984447457501\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 11, valid_loss: 0.005557772452728107\n",
      "SEED: 4, FOLD: 0, EPOCH: 12, train_loss: 0.008884025095785791\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 12, valid_loss: 0.005695829490342965\n",
      "SEED: 4, FOLD: 0, EPOCH: 13, train_loss: 0.008892849754743479\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 13, valid_loss: 0.0055883466624296625\n",
      "SEED: 4, FOLD: 0, EPOCH: 14, train_loss: 0.008872257885397286\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 14, valid_loss: 0.00560997433673877\n",
      "SEED: 4, FOLD: 0, EPOCH: 15, train_loss: 0.008867781332417115\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 15, valid_loss: 0.005596973431798128\n",
      "SEED: 4, FOLD: 0, EPOCH: 16, train_loss: 0.008846540060649449\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 16, valid_loss: 0.005484525042657669\n",
      "SEED: 4, FOLD: 0, EPOCH: 17, train_loss: 0.008804745128932031\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 17, valid_loss: 0.005529823068242807\n",
      "SEED: 4, FOLD: 1, EPOCH: 0, train_loss: 0.5874308605451841\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 0, valid_loss: 0.07396995792022118\n",
      "SEED: 4, FOLD: 1, EPOCH: 1, train_loss: 0.016483482829219586\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 1, valid_loss: 0.006030681113211008\n",
      "SEED: 4, FOLD: 1, EPOCH: 2, train_loss: 0.009314493351691478\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 2, valid_loss: 0.006326656609487075\n",
      "SEED: 4, FOLD: 1, EPOCH: 3, train_loss: 0.009309242278136112\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 3, valid_loss: 0.005484375959405532\n",
      "SEED: 4, FOLD: 1, EPOCH: 4, train_loss: 0.009051629423944128\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 4, valid_loss: 0.005645072696587214\n",
      "SEED: 4, FOLD: 1, EPOCH: 5, train_loss: 0.009003805695101619\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005598224556216827\n",
      "SEED: 4, FOLD: 1, EPOCH: 6, train_loss: 0.008932040947665637\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 6, valid_loss: 0.005504932863494525\n",
      "SEED: 4, FOLD: 1, EPOCH: 7, train_loss: 0.00890944221661099\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 7, valid_loss: 0.00548797448237355\n",
      "SEED: 4, FOLD: 1, EPOCH: 8, train_loss: 0.008912944964863159\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 8, valid_loss: 0.005515977632827484\n",
      "SEED: 4, FOLD: 1, EPOCH: 9, train_loss: 0.00891605332317586\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 9, valid_loss: 0.005453067509314189\n",
      "SEED: 4, FOLD: 1, EPOCH: 10, train_loss: 0.008885651575149717\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 10, valid_loss: 0.00549549781359159\n",
      "SEED: 4, FOLD: 1, EPOCH: 11, train_loss: 0.008888212410179345\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005534558556973934\n",
      "SEED: 4, FOLD: 1, EPOCH: 12, train_loss: 0.008901094766081991\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 12, valid_loss: 0.005522807845129416\n",
      "SEED: 4, FOLD: 1, EPOCH: 13, train_loss: 0.008879946374862984\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 13, valid_loss: 0.005495533060569029\n",
      "SEED: 4, FOLD: 2, EPOCH: 0, train_loss: 0.5879494365606759\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 0, valid_loss: 0.07654604545006385\n",
      "SEED: 4, FOLD: 2, EPOCH: 1, train_loss: 0.01671503363428889\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 1, valid_loss: 0.006094575322304781\n",
      "SEED: 4, FOLD: 2, EPOCH: 2, train_loss: 0.009716890865584483\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 2, valid_loss: 0.023472063816510715\n",
      "SEED: 4, FOLD: 2, EPOCH: 3, train_loss: 0.009253411188822341\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 3, valid_loss: 0.0058741915899400525\n",
      "SEED: 4, FOLD: 2, EPOCH: 4, train_loss: 0.009049619529144588\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 4, valid_loss: 0.005716095571047985\n",
      "SEED: 4, FOLD: 2, EPOCH: 5, train_loss: 0.008979474024444416\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 5, valid_loss: 0.00587363512470172\n",
      "SEED: 4, FOLD: 2, EPOCH: 6, train_loss: 0.009333047430609932\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 6, valid_loss: 0.005584292042140777\n",
      "SEED: 4, FOLD: 2, EPOCH: 7, train_loss: 0.0089642792260526\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 7, valid_loss: 0.005537065104223215\n",
      "SEED: 4, FOLD: 2, EPOCH: 8, train_loss: 0.008937334773961353\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005514547121352875\n",
      "SEED: 4, FOLD: 2, EPOCH: 9, train_loss: 0.008931059371428313\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 9, valid_loss: 0.0056755122943566395\n",
      "SEED: 4, FOLD: 2, EPOCH: 10, train_loss: 0.008929944798551701\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 10, valid_loss: 0.005582719647253935\n",
      "SEED: 4, FOLD: 2, EPOCH: 11, train_loss: 0.008914409438148141\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 11, valid_loss: 0.005681064839546497\n",
      "SEED: 4, FOLD: 2, EPOCH: 12, train_loss: 0.008907432642740172\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 12, valid_loss: 0.005529400785095417\n",
      "SEED: 4, FOLD: 2, EPOCH: 13, train_loss: 0.008873022016691597\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 13, valid_loss: 0.0055902759687831765\n",
      "SEED: 4, FOLD: 2, EPOCH: 14, train_loss: 0.008878754231625714\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 14, valid_loss: 0.005498450141973221\n",
      "SEED: 4, FOLD: 2, EPOCH: 15, train_loss: nan\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 15, valid_loss: nan\n",
      "SEED: 4, FOLD: 2, EPOCH: 16, train_loss: nan\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 16, valid_loss: nan\n",
      "SEED: 4, FOLD: 2, EPOCH: 17, train_loss: nan\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 17, valid_loss: nan\n",
      "SEED: 4, FOLD: 3, EPOCH: 0, train_loss: 0.5882420477432173\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08104009410509697\n",
      "SEED: 4, FOLD: 3, EPOCH: 1, train_loss: 0.017282138654106372\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 1, valid_loss: 0.0061469649752745265\n",
      "SEED: 4, FOLD: 3, EPOCH: 2, train_loss: 0.009369968864563349\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 2, valid_loss: 0.005873522721230984\n",
      "SEED: 4, FOLD: 3, EPOCH: 3, train_loss: 0.009153361010642068\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 3, valid_loss: 0.005750618516825712\n",
      "SEED: 4, FOLD: 3, EPOCH: 4, train_loss: 0.009096317112798223\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 4, valid_loss: 0.005938389875854437\n",
      "SEED: 4, FOLD: 3, EPOCH: 5, train_loss: 0.009010928267663395\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 5, valid_loss: 0.0064591662600063365\n",
      "SEED: 4, FOLD: 3, EPOCH: 6, train_loss: 0.008953446629331322\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 6, valid_loss: 0.005599414858107383\n",
      "SEED: 4, FOLD: 3, EPOCH: 7, train_loss: 0.00892518857821218\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 7, valid_loss: 0.0057962188998667095\n",
      "SEED: 4, FOLD: 3, EPOCH: 8, train_loss: 0.008901459108282989\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 8, valid_loss: 0.005623019013840418\n",
      "SEED: 4, FOLD: 3, EPOCH: 9, train_loss: 0.008915416575414507\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 9, valid_loss: 0.005738961725280835\n",
      "SEED: 4, FOLD: 3, EPOCH: 10, train_loss: 0.008900024462491274\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 10, valid_loss: 0.005561250333602612\n",
      "SEED: 4, FOLD: 3, EPOCH: 11, train_loss: 0.008898878243525286\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 11, valid_loss: 0.0056853390012222985\n",
      "SEED: 4, FOLD: 3, EPOCH: 12, train_loss: 0.008888217431769983\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 12, valid_loss: 0.005636408244474576\n",
      "SEED: 4, FOLD: 3, EPOCH: 13, train_loss: 0.008883446266220228\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 13, valid_loss: 0.005724647870430579\n",
      "SEED: 4, FOLD: 3, EPOCH: 14, train_loss: 0.00886626007362596\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 14, valid_loss: 0.00564256446579328\n",
      "SEED: 4, FOLD: 3, EPOCH: 15, train_loss: 0.00885470087539304\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 15, valid_loss: 0.005668019660963462\n",
      "SEED: 4, FOLD: 4, EPOCH: 0, train_loss: 0.5877754687256104\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 0, valid_loss: 0.07531988792694531\n",
      "SEED: 4, FOLD: 4, EPOCH: 1, train_loss: 0.016643101487912842\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 1, valid_loss: 0.005996827931644825\n",
      "SEED: 4, FOLD: 4, EPOCH: 2, train_loss: 0.009277597497645262\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 2, valid_loss: 0.005527558951423719\n",
      "SEED: 4, FOLD: 4, EPOCH: 3, train_loss: 0.009169118566992315\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 3, valid_loss: 0.005631366314796301\n",
      "SEED: 4, FOLD: 4, EPOCH: 4, train_loss: 0.009038129116635065\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 4, valid_loss: 0.006216423084529547\n",
      "SEED: 4, FOLD: 4, EPOCH: 5, train_loss: 0.009013876293760699\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 5, valid_loss: 0.005438560655770393\n",
      "SEED: 4, FOLD: 4, EPOCH: 6, train_loss: 0.008910226780367462\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 6, valid_loss: 0.00555174181667658\n",
      "SEED: 4, FOLD: 4, EPOCH: 7, train_loss: 0.00891020829235581\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 7, valid_loss: 0.005545839631500153\n",
      "SEED: 4, FOLD: 4, EPOCH: 8, train_loss: 0.00890464087746836\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 8, valid_loss: 0.0053108339914335655\n",
      "SEED: 4, FOLD: 4, EPOCH: 9, train_loss: 0.008896700251293747\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 9, valid_loss: 0.005360097409440921\n",
      "SEED: 4, FOLD: 4, EPOCH: 10, train_loss: 0.008914513085540888\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 10, valid_loss: 0.005380715530079145\n",
      "SEED: 4, FOLD: 4, EPOCH: 11, train_loss: 0.008917256774431144\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005466793556339466\n",
      "SEED: 4, FOLD: 4, EPOCH: 12, train_loss: 0.008905313877590202\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 12, valid_loss: 0.005476851267023728\n",
      "SEED: 4, FOLD: 4, EPOCH: 13, train_loss: 0.00890345812296948\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 13, valid_loss: 0.005446511822251173\n",
      "SEED: 4, FOLD: 4, EPOCH: 14, train_loss: 0.008894652052706963\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005420839199079917\n",
      "SEED: 4, FOLD: 5, EPOCH: 0, train_loss: 0.5876216919639626\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 0, valid_loss: 0.07472669963653271\n",
      "SEED: 4, FOLD: 5, EPOCH: 1, train_loss: 0.016441668887194748\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 1, valid_loss: 0.006014209527235765\n",
      "SEED: 4, FOLD: 5, EPOCH: 2, train_loss: 0.009293824207742472\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 2, valid_loss: 0.006125454969990712\n",
      "SEED: 4, FOLD: 5, EPOCH: 3, train_loss: 0.009281480697461882\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 3, valid_loss: 0.005734363570809364\n",
      "SEED: 4, FOLD: 5, EPOCH: 4, train_loss: 0.009023220127297414\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 4, valid_loss: 0.0057050138353728335\n",
      "SEED: 4, FOLD: 5, EPOCH: 5, train_loss: 0.008940337905408564\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 5, valid_loss: 0.005555532084634671\n",
      "SEED: 4, FOLD: 5, EPOCH: 6, train_loss: 0.008914822769175107\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 6, valid_loss: 0.005686160571013506\n",
      "SEED: 4, FOLD: 5, EPOCH: 7, train_loss: 0.008892096969223506\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 7, valid_loss: 0.005396466200741438\n",
      "SEED: 4, FOLD: 5, EPOCH: 8, train_loss: 0.008892001747782971\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 8, valid_loss: 0.005495624509281837\n",
      "SEED: 4, FOLD: 5, EPOCH: 9, train_loss: 0.008919017993517825\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 9, valid_loss: 0.005459970185676446\n",
      "SEED: 4, FOLD: 5, EPOCH: 10, train_loss: 0.008911509526188712\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005556660847595105\n",
      "SEED: 4, FOLD: 5, EPOCH: 11, train_loss: 0.008910154294524644\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005609969895046491\n",
      "SEED: 4, FOLD: 5, EPOCH: 12, train_loss: 0.00890242407173925\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 12, valid_loss: 0.005547259719325946\n",
      "SEED: 4, FOLD: 5, EPOCH: 13, train_loss: 0.008894252704104056\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 13, valid_loss: 0.00555688407845222\n",
      "SEED: 4, FOLD: 5, EPOCH: 14, train_loss: 0.00889321941429296\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 14, valid_loss: 0.005493328154373627\n",
      "SEED: 4, FOLD: 5, EPOCH: 15, train_loss: 0.008873002093939765\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 15, valid_loss: 0.005450623862158794\n",
      "SEED: 4, FOLD: 6, EPOCH: 0, train_loss: 0.5878535785989182\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 0, valid_loss: 0.07484311495835964\n",
      "SEED: 4, FOLD: 6, EPOCH: 1, train_loss: 0.01654651538292701\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 1, valid_loss: 0.006093113718984218\n",
      "SEED: 4, FOLD: 6, EPOCH: 2, train_loss: 0.009783756780765346\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 2, valid_loss: 0.017666414881554935\n",
      "SEED: 4, FOLD: 6, EPOCH: 3, train_loss: 0.009282653559804769\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 3, valid_loss: 0.005669370687638338\n",
      "SEED: 4, FOLD: 6, EPOCH: 4, train_loss: 0.009030594087734416\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 4, valid_loss: 0.005626136257957954\n",
      "SEED: 4, FOLD: 6, EPOCH: 5, train_loss: 0.008964405508359542\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 5, valid_loss: 0.005929620542491858\n",
      "SEED: 4, FOLD: 6, EPOCH: 6, train_loss: 0.008930981404626288\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 6, valid_loss: 0.005364296026527882\n",
      "SEED: 4, FOLD: 6, EPOCH: 7, train_loss: 0.008911894539975235\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005468024227481622\n",
      "SEED: 4, FOLD: 6, EPOCH: 8, train_loss: 0.008900640142225736\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 8, valid_loss: 0.005509575112507894\n",
      "SEED: 4, FOLD: 6, EPOCH: 9, train_loss: 0.00888472086926167\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 9, valid_loss: 0.005470133279092037\n",
      "SEED: 4, FOLD: 6, EPOCH: 10, train_loss: 0.008913771041694123\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 10, valid_loss: 0.00542137768262854\n",
      "SEED: 4, FOLD: 6, EPOCH: 11, train_loss: 0.00890836663342811\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 11, valid_loss: 0.005526124929579405\n",
      "SEED: 4, FOLD: 6, EPOCH: 12, train_loss: 0.008897631743771804\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 12, valid_loss: 0.0055253459498859365\n",
      "SEED: 4, FOLD: 6, EPOCH: 13, train_loss: 0.008874155247483301\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 13, valid_loss: 0.00541647498567517\n",
      "SEED: 4, FOLD: 6, EPOCH: 14, train_loss: 0.008872531851552226\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 14, valid_loss: 0.005482633848889516\n",
      "SEED: 5, FOLD: 0, EPOCH: 0, train_loss: 0.5894418760530047\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08157596737146378\n",
      "SEED: 5, FOLD: 0, EPOCH: 1, train_loss: 0.01662522561948847\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 1, valid_loss: 0.006099872971669986\n",
      "SEED: 5, FOLD: 0, EPOCH: 2, train_loss: 0.009325025930396608\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 2, valid_loss: 0.005832186219497369\n",
      "SEED: 5, FOLD: 0, EPOCH: 3, train_loss: 0.009169133820545834\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 3, valid_loss: 0.005684141499491839\n",
      "SEED: 5, FOLD: 0, EPOCH: 4, train_loss: 0.009067072205849597\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 4, valid_loss: 0.005549469282134221\n",
      "SEED: 5, FOLD: 0, EPOCH: 5, train_loss: 0.008956086903659476\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 5, valid_loss: 0.005981058670351138\n",
      "SEED: 5, FOLD: 0, EPOCH: 6, train_loss: 0.008927016456082865\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 6, valid_loss: 0.005383976269513369\n",
      "SEED: 5, FOLD: 0, EPOCH: 7, train_loss: 0.008901593602589658\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 7, valid_loss: 0.005500300644108882\n",
      "SEED: 5, FOLD: 0, EPOCH: 8, train_loss: 0.008912626175662956\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005421587480948522\n",
      "SEED: 5, FOLD: 0, EPOCH: 9, train_loss: 0.008902024773478106\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005529798495654876\n",
      "SEED: 5, FOLD: 0, EPOCH: 10, train_loss: 0.008895788757080162\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 10, valid_loss: 0.005483865594634643\n",
      "SEED: 5, FOLD: 0, EPOCH: 11, train_loss: 0.008881221110051548\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 11, valid_loss: 0.005480775036490881\n",
      "SEED: 5, FOLD: 0, EPOCH: 12, train_loss: 0.008889672094704332\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 12, valid_loss: 0.005467778429962122\n",
      "SEED: 5, FOLD: 0, EPOCH: 13, train_loss: 0.008884479392420602\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 13, valid_loss: 0.005532222620856304\n",
      "SEED: 5, FOLD: 0, EPOCH: 14, train_loss: 0.008874825642419022\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 14, valid_loss: 0.0054535083830929715\n",
      "SEED: 5, FOLD: 0, EPOCH: 15, train_loss: 0.008852024159922794\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 15, valid_loss: 0.005562900493924434\n",
      "SEED: 5, FOLD: 1, EPOCH: 0, train_loss: 0.5880729419154089\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 0, valid_loss: 0.0890753108721513\n",
      "SEED: 5, FOLD: 1, EPOCH: 1, train_loss: 0.016779437887708883\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 1, valid_loss: 0.00599273587935246\n",
      "SEED: 5, FOLD: 1, EPOCH: 2, train_loss: 0.009303496231803217\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 2, valid_loss: 0.0057558544481603\n",
      "SEED: 5, FOLD: 1, EPOCH: 3, train_loss: 0.009432758462640483\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 3, valid_loss: 0.00550432435165231\n",
      "SEED: 5, FOLD: 1, EPOCH: 4, train_loss: 0.009095230139791965\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 4, valid_loss: 0.005620822059707\n",
      "SEED: 5, FOLD: 1, EPOCH: 5, train_loss: 0.00898942574103539\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005557323053765755\n",
      "SEED: 5, FOLD: 1, EPOCH: 6, train_loss: 0.0089624707863943\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 6, valid_loss: 0.0056173242270373385\n",
      "SEED: 5, FOLD: 1, EPOCH: 7, train_loss: 0.008939045248553157\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 7, valid_loss: 0.005743985780729697\n",
      "SEED: 5, FOLD: 1, EPOCH: 8, train_loss: 0.008909170666860568\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 8, valid_loss: 0.005537353097819365\n",
      "SEED: 5, FOLD: 1, EPOCH: 9, train_loss: 0.008928738685475814\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 9, valid_loss: 0.005535366658407908\n",
      "SEED: 5, FOLD: 1, EPOCH: 10, train_loss: 0.008900195825845003\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 10, valid_loss: 0.005476453986305457\n",
      "SEED: 5, FOLD: 1, EPOCH: 11, train_loss: 0.008882868607100603\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005456798280087801\n",
      "SEED: 5, FOLD: 1, EPOCH: 12, train_loss: 0.008885841577540379\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 12, valid_loss: 0.005454299864000999\n",
      "SEED: 5, FOLD: 1, EPOCH: 13, train_loss: 0.008880151725197965\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 13, valid_loss: 0.005471723225827401\n",
      "SEED: 5, FOLD: 1, EPOCH: 14, train_loss: 0.008864822287766918\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 14, valid_loss: 0.005523044186142774\n",
      "SEED: 5, FOLD: 1, EPOCH: 15, train_loss: 0.008849308542856897\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 15, valid_loss: 0.005499579478055239\n",
      "SEED: 5, FOLD: 1, EPOCH: 16, train_loss: 0.008828198065276485\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 16, valid_loss: 0.005475950678094075\n",
      "SEED: 5, FOLD: 2, EPOCH: 0, train_loss: 0.5873949182396\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 0, valid_loss: 0.07326280440275486\n",
      "SEED: 5, FOLD: 2, EPOCH: 1, train_loss: 0.016347088385373354\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 1, valid_loss: 0.006212316131075988\n",
      "SEED: 5, FOLD: 2, EPOCH: 2, train_loss: 0.009247263843143309\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 2, valid_loss: 0.006033803336322308\n",
      "SEED: 5, FOLD: 2, EPOCH: 3, train_loss: 0.009184694823783797\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 3, valid_loss: 0.0229732315414227\n",
      "SEED: 5, FOLD: 2, EPOCH: 4, train_loss: 0.009061492551621553\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 4, valid_loss: 0.009982359380676197\n",
      "SEED: 5, FOLD: 2, EPOCH: 5, train_loss: 0.00898847309243236\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 5, valid_loss: 0.005544371043260281\n",
      "SEED: 5, FOLD: 2, EPOCH: 6, train_loss: 0.008941918290597765\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 6, valid_loss: 0.0057448038401512\n",
      "SEED: 5, FOLD: 2, EPOCH: 7, train_loss: 0.008913876337779535\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 7, valid_loss: 0.0056104215148549815\n",
      "SEED: 5, FOLD: 2, EPOCH: 8, train_loss: 0.008913014197369685\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005627285545835128\n",
      "SEED: 5, FOLD: 2, EPOCH: 9, train_loss: 0.008916355543644042\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 9, valid_loss: 0.005776503087522892\n",
      "SEED: 5, FOLD: 2, EPOCH: 10, train_loss: 0.00891494649034497\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 10, valid_loss: 0.005767147020938305\n",
      "SEED: 5, FOLD: 2, EPOCH: 11, train_loss: 0.008913270411761227\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 11, valid_loss: 0.00569245469971345\n",
      "SEED: 5, FOLD: 2, EPOCH: 12, train_loss: 0.008904551986504245\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 12, valid_loss: 0.0056534749813950975\n",
      "SEED: 5, FOLD: 2, EPOCH: 13, train_loss: 0.008910994743928313\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 13, valid_loss: 0.005737633301088443\n",
      "SEED: 5, FOLD: 3, EPOCH: 0, train_loss: 0.5879552126736254\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 0, valid_loss: 0.07724373959578\n",
      "SEED: 5, FOLD: 3, EPOCH: 1, train_loss: 0.016880943704195118\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 1, valid_loss: 0.006033820816530631\n",
      "SEED: 5, FOLD: 3, EPOCH: 2, train_loss: 0.009332877256580302\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 2, valid_loss: 0.005781916399987845\n",
      "SEED: 5, FOLD: 3, EPOCH: 3, train_loss: 0.009212846074857423\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 3, valid_loss: 0.006709049885662703\n",
      "SEED: 5, FOLD: 3, EPOCH: 4, train_loss: 0.009045589299922859\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 4, valid_loss: 0.005663354021425431\n",
      "SEED: 5, FOLD: 3, EPOCH: 5, train_loss: 0.008941099387467713\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 5, valid_loss: 0.005624931771308184\n",
      "SEED: 5, FOLD: 3, EPOCH: 6, train_loss: 0.008912594353377417\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 6, valid_loss: 0.0056784613989293575\n",
      "SEED: 5, FOLD: 3, EPOCH: 7, train_loss: 0.008919023675844073\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 7, valid_loss: 0.00560231008925117\n",
      "SEED: 5, FOLD: 3, EPOCH: 8, train_loss: 0.008890567020185897\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 8, valid_loss: 0.005582628234361227\n",
      "SEED: 5, FOLD: 3, EPOCH: 9, train_loss: 0.008906240556137385\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 9, valid_loss: 0.005544035480572627\n",
      "SEED: 5, FOLD: 3, EPOCH: 10, train_loss: 0.008887653062875206\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 10, valid_loss: 0.005582719897994628\n",
      "SEED: 5, FOLD: 3, EPOCH: 11, train_loss: 0.008906465023756027\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 11, valid_loss: 0.005675146033844123\n",
      "SEED: 5, FOLD: 3, EPOCH: 12, train_loss: 0.008894082486025384\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 12, valid_loss: 0.0056527509139134334\n",
      "SEED: 5, FOLD: 3, EPOCH: 13, train_loss: 0.008878305126484987\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 13, valid_loss: 0.005590954974580269\n",
      "SEED: 5, FOLD: 3, EPOCH: 14, train_loss: 0.00885982544639626\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 14, valid_loss: 0.005575132735360127\n",
      "SEED: 5, FOLD: 3, EPOCH: 15, train_loss: nan\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 15, valid_loss: nan\n",
      "SEED: 5, FOLD: 3, EPOCH: 16, train_loss: nan\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 16, valid_loss: nan\n",
      "SEED: 5, FOLD: 3, EPOCH: 17, train_loss: nan\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 17, valid_loss: nan\n",
      "SEED: 5, FOLD: 4, EPOCH: 0, train_loss: 0.5900580600105427\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 0, valid_loss: 0.08844826485101993\n",
      "SEED: 5, FOLD: 4, EPOCH: 1, train_loss: 0.01672987374351234\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 1, valid_loss: 0.006092428838690886\n",
      "SEED: 5, FOLD: 4, EPOCH: 2, train_loss: 0.009478753696925737\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 2, valid_loss: 0.034168317197607115\n",
      "SEED: 5, FOLD: 4, EPOCH: 3, train_loss: 0.00944474047502956\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 3, valid_loss: 0.005536161255664551\n",
      "SEED: 5, FOLD: 4, EPOCH: 4, train_loss: 0.009094243202157118\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 4, valid_loss: 0.00566372092669973\n",
      "SEED: 5, FOLD: 4, EPOCH: 5, train_loss: 0.008994712657924439\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 5, valid_loss: 0.005506300080854159\n",
      "SEED: 5, FOLD: 4, EPOCH: 6, train_loss: 0.008958795762343987\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 6, valid_loss: 0.005499775987118483\n",
      "SEED: 5, FOLD: 4, EPOCH: 7, train_loss: 0.00894831253114987\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 7, valid_loss: 0.0058365159739668555\n",
      "SEED: 5, FOLD: 4, EPOCH: 8, train_loss: 0.00892847157209306\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 8, valid_loss: 0.005457179692502205\n",
      "SEED: 5, FOLD: 4, EPOCH: 9, train_loss: 0.008931294008082635\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 9, valid_loss: 0.005524231837346003\n",
      "SEED: 5, FOLD: 4, EPOCH: 10, train_loss: 0.008917472746877654\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 10, valid_loss: 0.005523632996930526\n",
      "SEED: 5, FOLD: 4, EPOCH: 11, train_loss: 0.008915865781238756\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005502138358469193\n",
      "SEED: 5, FOLD: 4, EPOCH: 12, train_loss: 0.008899284602218383\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 12, valid_loss: 0.00545665854588151\n",
      "SEED: 5, FOLD: 4, EPOCH: 13, train_loss: 0.008888194161291057\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 13, valid_loss: 0.005568097273890789\n",
      "SEED: 5, FOLD: 4, EPOCH: 14, train_loss: 0.008884630153408728\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005528224273942984\n",
      "SEED: 5, FOLD: 4, EPOCH: 15, train_loss: 0.008872295478107157\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 15, valid_loss: 0.005514717696664425\n",
      "SEED: 5, FOLD: 4, EPOCH: 16, train_loss: 0.008839746333054593\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 16, valid_loss: 0.005490957902601132\n",
      "SEED: 5, FOLD: 5, EPOCH: 0, train_loss: 0.5874968970546851\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 0, valid_loss: 0.07715854564538369\n",
      "SEED: 5, FOLD: 5, EPOCH: 1, train_loss: 0.01665157820979083\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 1, valid_loss: 0.006164985852172742\n",
      "SEED: 5, FOLD: 5, EPOCH: 2, train_loss: 0.009333543466857157\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 2, valid_loss: 0.0057740997737989975\n",
      "SEED: 5, FOLD: 5, EPOCH: 3, train_loss: 0.009332223682085404\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 3, valid_loss: 0.005929410565071381\n",
      "SEED: 5, FOLD: 5, EPOCH: 4, train_loss: 0.00908818861117234\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 4, valid_loss: 0.00580726728702967\n",
      "SEED: 5, FOLD: 5, EPOCH: 5, train_loss: 0.008995193044176779\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 5, valid_loss: 0.005575779646348495\n",
      "SEED: 5, FOLD: 5, EPOCH: 6, train_loss: 0.00896783101976522\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 6, valid_loss: 0.005706728615153294\n",
      "SEED: 5, FOLD: 5, EPOCH: 7, train_loss: 0.008936625647333425\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 7, valid_loss: 0.005535443205959522\n",
      "SEED: 5, FOLD: 5, EPOCH: 8, train_loss: 0.008920642698334681\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 8, valid_loss: 0.00542170275002718\n",
      "SEED: 5, FOLD: 5, EPOCH: 9, train_loss: 0.008915173808565817\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 9, valid_loss: 0.005566833003495748\n",
      "SEED: 5, FOLD: 5, EPOCH: 10, train_loss: 0.00891030126729527\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005699450365052774\n",
      "SEED: 5, FOLD: 5, EPOCH: 11, train_loss: 0.008890208322554827\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005586343136830972\n",
      "SEED: 5, FOLD: 5, EPOCH: 12, train_loss: 0.00889529231180613\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 12, valid_loss: 0.005654033810759966\n",
      "SEED: 5, FOLD: 5, EPOCH: 13, train_loss: 0.00887912224877525\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 13, valid_loss: 0.005545987998350308\n",
      "SEED: 5, FOLD: 5, EPOCH: 14, train_loss: 0.0088641291635262\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 14, valid_loss: 0.005549821680268416\n",
      "SEED: 5, FOLD: 5, EPOCH: 15, train_loss: 0.008849232444992743\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 15, valid_loss: 0.005592908602781021\n",
      "SEED: 5, FOLD: 6, EPOCH: 0, train_loss: 0.5888156642180842\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 0, valid_loss: 0.08270368896997891\n",
      "SEED: 5, FOLD: 6, EPOCH: 1, train_loss: 0.016576354014309676\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 1, valid_loss: 0.006004749259983118\n",
      "SEED: 5, FOLD: 6, EPOCH: 2, train_loss: 0.009304358831581634\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 2, valid_loss: 0.005614176392555237\n",
      "SEED: 5, FOLD: 6, EPOCH: 3, train_loss: 0.009239175457608056\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 3, valid_loss: 0.005613379861013248\n",
      "SEED: 5, FOLD: 6, EPOCH: 4, train_loss: 0.009094679325416282\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 4, valid_loss: 0.005992279853671789\n",
      "SEED: 5, FOLD: 6, EPOCH: 5, train_loss: 0.009020832323192342\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 5, valid_loss: 0.005501653533428907\n",
      "SEED: 5, FOLD: 6, EPOCH: 6, train_loss: 0.008946372410030785\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 6, valid_loss: 0.005556149551501641\n",
      "SEED: 5, FOLD: 6, EPOCH: 7, train_loss: 0.008925696042039105\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005640215240418911\n",
      "SEED: 5, FOLD: 6, EPOCH: 8, train_loss: 0.008933525356287891\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 8, valid_loss: 0.005364652472333266\n",
      "SEED: 5, FOLD: 6, EPOCH: 9, train_loss: 0.008902918987882298\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 9, valid_loss: 0.005568047412312948\n",
      "SEED: 5, FOLD: 6, EPOCH: 10, train_loss: 0.008901813457644469\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 10, valid_loss: 0.005403984373865219\n",
      "SEED: 5, FOLD: 6, EPOCH: 11, train_loss: 0.008892720483394491\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 11, valid_loss: 0.00534318509296729\n",
      "SEED: 5, FOLD: 6, EPOCH: 12, train_loss: 0.00888266253939553\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 12, valid_loss: 0.005476324425007288\n",
      "SEED: 5, FOLD: 6, EPOCH: 13, train_loss: 0.008892787683352426\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 13, valid_loss: 0.005408345220180659\n",
      "SEED: 5, FOLD: 6, EPOCH: 14, train_loss: 0.008874443435185665\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 14, valid_loss: 0.00535528168368798\n",
      "SEED: 5, FOLD: 6, EPOCH: 15, train_loss: 0.008845176818352696\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 15, valid_loss: 0.0054257981335887545\n",
      "SEED: 5, FOLD: 6, EPOCH: 16, train_loss: 0.008818153631747575\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 16, valid_loss: 0.00549909476047525\n",
      "SEED: 6, FOLD: 0, EPOCH: 0, train_loss: 0.5885158921214374\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 0, valid_loss: 0.08187056504763089\n",
      "SEED: 6, FOLD: 0, EPOCH: 1, train_loss: 0.016513696242425893\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 1, valid_loss: 0.006098264362663031\n",
      "SEED: 6, FOLD: 0, EPOCH: 2, train_loss: 0.009299343439272127\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 2, valid_loss: 0.006054559650902565\n",
      "SEED: 6, FOLD: 0, EPOCH: 3, train_loss: 0.009312786048630605\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 3, valid_loss: 0.00566192759344211\n",
      "SEED: 6, FOLD: 0, EPOCH: 4, train_loss: 0.009486752411199582\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 4, valid_loss: 0.005581970219142162\n",
      "SEED: 6, FOLD: 0, EPOCH: 5, train_loss: 0.008957721746048412\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 5, valid_loss: 0.00568782129826454\n",
      "SEED: 6, FOLD: 0, EPOCH: 6, train_loss: 0.008954539939106719\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 6, valid_loss: 0.005470836176895178\n",
      "SEED: 6, FOLD: 0, EPOCH: 7, train_loss: 0.00894101249758859\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 7, valid_loss: 0.005470204417808698\n",
      "SEED: 6, FOLD: 0, EPOCH: 8, train_loss: 0.008912690090821\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 8, valid_loss: 0.005521375865030747\n",
      "SEED: 6, FOLD: 0, EPOCH: 9, train_loss: 0.008914283992772972\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 9, valid_loss: 0.005557869704296956\n",
      "SEED: 6, FOLD: 0, EPOCH: 10, train_loss: 0.008914013103758162\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 10, valid_loss: 0.00547760882629798\n",
      "SEED: 6, FOLD: 0, EPOCH: 11, train_loss: 0.008912218797549203\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 11, valid_loss: 0.0055540047514324\n",
      "SEED: 6, FOLD: 0, EPOCH: 12, train_loss: 0.00890638872452483\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 12, valid_loss: 0.005569786764681339\n",
      "SEED: 6, FOLD: 0, EPOCH: 13, train_loss: 0.008895530327651146\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 13, valid_loss: 0.005557960400787683\n",
      "SEED: 6, FOLD: 0, EPOCH: 14, train_loss: 0.008884276861224222\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 14, valid_loss: 0.0056076635105105545\n",
      "SEED: 6, FOLD: 0, EPOCH: 15, train_loss: 0.00887577690033091\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 15, valid_loss: 0.005516431401841915\n",
      "SEED: 6, FOLD: 0, EPOCH: 16, train_loss: 0.008854268559229534\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 16, valid_loss: 0.0054570400299361116\n",
      "SEED: 6, FOLD: 0, EPOCH: 17, train_loss: 0.008829300512081466\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 17, valid_loss: 0.005499763879925013\n",
      "SEED: 6, FOLD: 1, EPOCH: 0, train_loss: 0.5895474939732939\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 0, valid_loss: 0.07322359486268117\n",
      "SEED: 6, FOLD: 1, EPOCH: 1, train_loss: 0.01670417466477768\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 1, valid_loss: 0.006008740048855543\n",
      "SEED: 6, FOLD: 1, EPOCH: 2, train_loss: 0.009303171728813165\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 2, valid_loss: 0.005686910142405675\n",
      "SEED: 6, FOLD: 1, EPOCH: 3, train_loss: 0.009244588342168042\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 3, valid_loss: 0.013346397676146947\n",
      "SEED: 6, FOLD: 1, EPOCH: 4, train_loss: 0.00956046675659112\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 4, valid_loss: 0.005455149874950831\n",
      "SEED: 6, FOLD: 1, EPOCH: 5, train_loss: 0.009027007545621411\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 5, valid_loss: 0.005501340394123242\n",
      "SEED: 6, FOLD: 1, EPOCH: 6, train_loss: 0.008993198119758352\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 6, valid_loss: 0.0054227614130538246\n",
      "SEED: 6, FOLD: 1, EPOCH: 7, train_loss: 0.008977144849612503\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 7, valid_loss: 0.005489656952424691\n",
      "SEED: 6, FOLD: 1, EPOCH: 8, train_loss: 0.008950970519485103\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 8, valid_loss: 0.00559236965357111\n",
      "SEED: 6, FOLD: 1, EPOCH: 9, train_loss: 0.008941290258253748\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 9, valid_loss: 0.005490246766175215\n",
      "SEED: 6, FOLD: 1, EPOCH: 10, train_loss: 0.008948232418530294\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 10, valid_loss: 0.00547272006336313\n",
      "SEED: 6, FOLD: 1, EPOCH: 11, train_loss: 0.00894751983090631\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 11, valid_loss: 0.005541621456639125\n",
      "SEED: 6, FOLD: 1, EPOCH: 12, train_loss: 0.00893080493787656\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 12, valid_loss: 0.0054989711094934205\n",
      "SEED: 6, FOLD: 1, EPOCH: 13, train_loss: 0.008897310198360198\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 13, valid_loss: 0.005589319034837759\n",
      "SEED: 6, FOLD: 1, EPOCH: 14, train_loss: 0.008881754745301363\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 14, valid_loss: 0.005587675787795048\n",
      "SEED: 6, FOLD: 2, EPOCH: 0, train_loss: 0.5884785358164761\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 0, valid_loss: 0.08063481690791938\n",
      "SEED: 6, FOLD: 2, EPOCH: 1, train_loss: 0.01716782886383904\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 1, valid_loss: 0.006351258283337722\n",
      "SEED: 6, FOLD: 2, EPOCH: 2, train_loss: 0.00948216555942152\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 2, valid_loss: 0.005678608619536345\n",
      "SEED: 6, FOLD: 2, EPOCH: 3, train_loss: 0.009384185793129978\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 3, valid_loss: 0.005669558313317024\n",
      "SEED: 6, FOLD: 2, EPOCH: 4, train_loss: 0.0091031427822403\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 4, valid_loss: 0.005638545343222527\n",
      "SEED: 6, FOLD: 2, EPOCH: 5, train_loss: 0.008987213208063229\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 5, valid_loss: 0.005421262592650377\n",
      "SEED: 6, FOLD: 2, EPOCH: 6, train_loss: 0.00898123883667427\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 6, valid_loss: 0.005501928381048716\n",
      "SEED: 6, FOLD: 2, EPOCH: 7, train_loss: 0.008947741020017781\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 7, valid_loss: 0.0058639826826178115\n",
      "SEED: 6, FOLD: 2, EPOCH: 8, train_loss: 0.008947588956436596\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 8, valid_loss: 0.005489911884069443\n",
      "SEED: 6, FOLD: 2, EPOCH: 9, train_loss: 0.008920559709942018\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 9, valid_loss: 0.005510564177082135\n",
      "SEED: 6, FOLD: 2, EPOCH: 10, train_loss: 0.008911171575655808\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 10, valid_loss: 0.005448810935307007\n",
      "SEED: 6, FOLD: 2, EPOCH: 11, train_loss: 0.008881488059823578\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 11, valid_loss: 0.0053835054859519005\n",
      "SEED: 6, FOLD: 2, EPOCH: 12, train_loss: 0.008878444434722533\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 12, valid_loss: 0.005502646251653249\n",
      "SEED: 6, FOLD: 2, EPOCH: 13, train_loss: 0.008851780637947691\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 13, valid_loss: 0.005527075595007493\n",
      "SEED: 6, FOLD: 2, EPOCH: 14, train_loss: 0.008863532802442441\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 14, valid_loss: 0.005441939708991692\n",
      "SEED: 6, FOLD: 2, EPOCH: 15, train_loss: 0.00882691134874885\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 15, valid_loss: 0.005529762926296546\n",
      "SEED: 6, FOLD: 2, EPOCH: 16, train_loss: 0.00880624951064788\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 16, valid_loss: 0.005450944129664164\n",
      "SEED: 6, FOLD: 3, EPOCH: 0, train_loss: 0.5889373662302623\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 0, valid_loss: 0.08678324692524396\n",
      "SEED: 6, FOLD: 3, EPOCH: 1, train_loss: 0.016689505742711795\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 1, valid_loss: 0.006105225640707291\n",
      "SEED: 6, FOLD: 3, EPOCH: 2, train_loss: 0.009283380941613703\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 2, valid_loss: 0.005772965530363413\n",
      "SEED: 6, FOLD: 3, EPOCH: 3, train_loss: 0.009369378506734565\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 3, valid_loss: 0.006906394739277088\n",
      "SEED: 6, FOLD: 3, EPOCH: 4, train_loss: 0.009111210162675864\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 4, valid_loss: 0.006000258458348421\n",
      "SEED: 6, FOLD: 3, EPOCH: 5, train_loss: 0.008976550086879649\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 5, valid_loss: 0.005649330954139049\n",
      "SEED: 6, FOLD: 3, EPOCH: 6, train_loss: 0.008948756350405715\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 6, valid_loss: 0.005524141964717553\n",
      "SEED: 6, FOLD: 3, EPOCH: 7, train_loss: 0.008917175642390912\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 7, valid_loss: 0.00554396090312646\n",
      "SEED: 6, FOLD: 3, EPOCH: 8, train_loss: 0.008922011100661915\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 8, valid_loss: 0.005562610709323333\n",
      "SEED: 6, FOLD: 3, EPOCH: 9, train_loss: 0.008918498063812385\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 9, valid_loss: 0.005561022911793911\n",
      "SEED: 6, FOLD: 3, EPOCH: 10, train_loss: 0.008912273745581106\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 10, valid_loss: 0.005604351655795024\n",
      "SEED: 6, FOLD: 3, EPOCH: 11, train_loss: 0.008910413479080071\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 11, valid_loss: 0.0056067085108504845\n",
      "SEED: 6, FOLD: 3, EPOCH: 12, train_loss: 0.008895351834645545\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 12, valid_loss: 0.00562866093017734\n",
      "SEED: 6, FOLD: 3, EPOCH: 13, train_loss: 0.008903357206617255\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 13, valid_loss: 0.005598255039121096\n",
      "SEED: 6, FOLD: 3, EPOCH: 14, train_loss: 0.008894967720717998\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 14, valid_loss: 0.005604471868047347\n",
      "SEED: 6, FOLD: 4, EPOCH: 0, train_loss: 0.5880625029472081\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 0, valid_loss: 0.0827487913461832\n",
      "SEED: 6, FOLD: 4, EPOCH: 1, train_loss: 0.016540492834472977\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 1, valid_loss: 0.006140368023457436\n",
      "SEED: 6, FOLD: 4, EPOCH: 2, train_loss: 0.009306119679397828\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 2, valid_loss: 0.005719778701089895\n",
      "SEED: 6, FOLD: 4, EPOCH: 3, train_loss: 0.009158100290979082\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 3, valid_loss: 0.010659750622625534\n",
      "SEED: 6, FOLD: 4, EPOCH: 4, train_loss: 0.009019354635195152\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 4, valid_loss: 0.005550227916011443\n",
      "SEED: 6, FOLD: 4, EPOCH: 5, train_loss: 0.008926482606880568\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 5, valid_loss: 0.005613643067100873\n",
      "SEED: 6, FOLD: 4, EPOCH: 6, train_loss: 0.008904460232352486\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 6, valid_loss: 0.005820636028567186\n",
      "SEED: 6, FOLD: 4, EPOCH: 7, train_loss: 0.008883920391216068\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 7, valid_loss: 0.005695662174660426\n",
      "SEED: 6, FOLD: 4, EPOCH: 8, train_loss: 0.008882167440763599\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 8, valid_loss: 0.005516051565511868\n",
      "SEED: 6, FOLD: 4, EPOCH: 9, train_loss: 0.008869295511898157\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 9, valid_loss: 0.005477706865909008\n",
      "SEED: 6, FOLD: 4, EPOCH: 10, train_loss: 0.008877824293449521\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 10, valid_loss: 0.005612579496720662\n",
      "SEED: 6, FOLD: 4, EPOCH: 11, train_loss: 0.008886619206719302\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 11, valid_loss: 0.005574344263340418\n",
      "SEED: 6, FOLD: 4, EPOCH: 12, train_loss: 0.008889227652469196\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 12, valid_loss: 0.005517907369022186\n",
      "SEED: 6, FOLD: 4, EPOCH: 13, train_loss: 0.008874098266902808\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 13, valid_loss: 0.005537513858423783\n",
      "SEED: 6, FOLD: 4, EPOCH: 14, train_loss: 0.00886219654962219\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 14, valid_loss: 0.005531142680690839\n",
      "SEED: 6, FOLD: 4, EPOCH: 15, train_loss: 0.008863159102966657\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 15, valid_loss: 0.005561474173401411\n",
      "SEED: 6, FOLD: 5, EPOCH: 0, train_loss: 0.5903458164350407\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 0, valid_loss: 0.0782708886724252\n",
      "SEED: 6, FOLD: 5, EPOCH: 1, train_loss: 0.01677500632767742\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 1, valid_loss: 0.0062032624219472594\n",
      "SEED: 6, FOLD: 5, EPOCH: 2, train_loss: 0.009340148998072019\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 2, valid_loss: 0.006065934108426938\n",
      "SEED: 6, FOLD: 5, EPOCH: 3, train_loss: 0.009288691525423044\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 3, valid_loss: 0.005685230323041861\n",
      "SEED: 6, FOLD: 5, EPOCH: 4, train_loss: 0.009146287735249545\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 4, valid_loss: 0.005669156590906473\n",
      "SEED: 6, FOLD: 5, EPOCH: 5, train_loss: 0.008994783035706024\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 5, valid_loss: 0.005540396301792218\n",
      "SEED: 6, FOLD: 5, EPOCH: 6, train_loss: 0.008937725942028133\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 6, valid_loss: 0.005483377474145248\n",
      "SEED: 6, FOLD: 5, EPOCH: 7, train_loss: 0.008928740881635127\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 7, valid_loss: 0.005593442967018256\n",
      "SEED: 6, FOLD: 5, EPOCH: 8, train_loss: 0.008917326145377514\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 8, valid_loss: 0.0055542392656207085\n",
      "SEED: 6, FOLD: 5, EPOCH: 9, train_loss: 0.008914290417640193\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 9, valid_loss: 0.005583098659721704\n",
      "SEED: 6, FOLD: 5, EPOCH: 10, train_loss: 0.008895262547240063\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 10, valid_loss: 0.005537877504069071\n",
      "SEED: 6, FOLD: 5, EPOCH: 11, train_loss: 0.008898828858257952\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 11, valid_loss: 0.005525160545053391\n",
      "SEED: 6, FOLD: 5, EPOCH: 12, train_loss: 0.008900822329058035\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 12, valid_loss: 0.005549026724810784\n",
      "SEED: 6, FOLD: 5, EPOCH: 13, train_loss: 0.008886853421761378\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 13, valid_loss: 0.005579329239061246\n",
      "SEED: 6, FOLD: 5, EPOCH: 14, train_loss: 0.008873358249311914\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 14, valid_loss: 0.005568771515614712\n",
      "SEED: 6, FOLD: 5, EPOCH: 15, train_loss: 0.008862353496354175\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 15, valid_loss: 0.005491802576356209\n",
      "SEED: 6, FOLD: 5, EPOCH: 16, train_loss: 0.0088322428810234\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 16, valid_loss: 0.005560007698547382\n",
      "SEED: 6, FOLD: 6, EPOCH: 0, train_loss: 0.5887958752746517\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 0, valid_loss: 0.07661628092710789\n",
      "SEED: 6, FOLD: 6, EPOCH: 1, train_loss: 0.016547790288019018\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 1, valid_loss: 0.006083485813668141\n",
      "SEED: 6, FOLD: 6, EPOCH: 2, train_loss: 0.009765720762614463\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 2, valid_loss: 0.006353903991671709\n",
      "SEED: 6, FOLD: 6, EPOCH: 3, train_loss: 0.009242784508780853\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 3, valid_loss: 0.005525230215145991\n",
      "SEED: 6, FOLD: 6, EPOCH: 4, train_loss: 0.00906308342677516\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 4, valid_loss: 0.0055767054884479595\n",
      "SEED: 6, FOLD: 6, EPOCH: 5, train_loss: 0.009016373729635332\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 5, valid_loss: 0.0054158220569101665\n",
      "SEED: 6, FOLD: 6, EPOCH: 6, train_loss: 0.008934263687429798\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 6, valid_loss: 0.005501306329209071\n",
      "SEED: 6, FOLD: 6, EPOCH: 7, train_loss: 0.00895272263929852\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 7, valid_loss: 0.005416053347289562\n",
      "SEED: 6, FOLD: 6, EPOCH: 8, train_loss: 0.008932225802611257\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 8, valid_loss: 0.005356608782536709\n",
      "SEED: 6, FOLD: 6, EPOCH: 9, train_loss: 0.00893523162734267\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 9, valid_loss: 0.0054189500828775074\n",
      "SEED: 6, FOLD: 6, EPOCH: 10, train_loss: 0.008937191992142313\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 10, valid_loss: 0.0055258411985750384\n",
      "SEED: 6, FOLD: 6, EPOCH: 11, train_loss: 0.008910943263185185\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 11, valid_loss: 0.005449883818912964\n",
      "SEED: 6, FOLD: 6, EPOCH: 12, train_loss: 0.00892011501599808\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 12, valid_loss: 0.005397213443827171\n",
      "SEED: 6, FOLD: 6, EPOCH: 13, train_loss: 0.008906210810449478\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 13, valid_loss: 0.005405882086891394\n",
      "SEED: 6, FOLD: 6, EPOCH: 14, train_loss: 0.008882841416257056\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 14, valid_loss: 0.005402063055393787\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [0,1,2,3,4,5,6]  #<-- Update\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test_[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05e21e56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T13:01:01.838060Z",
     "iopub.status.busy": "2025-03-31T13:01:01.837545Z",
     "iopub.status.idle": "2025-03-31T13:01:02.172629Z",
     "shell.execute_reply": "2025-03-31T13:01:02.171879Z"
    },
    "papermill": {
     "duration": 0.379951,
     "end_time": "2025-03-31T13:01:02.174190",
     "exception": false,
     "start_time": "2025-03-31T13:01:01.794239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.merge(train_targets_scored, on='sig_id')\n",
    "target = train[train_targets_scored.columns]\n",
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f96ca54e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T13:01:02.260907Z",
     "iopub.status.busy": "2025-03-31T13:01:02.260546Z",
     "iopub.status.idle": "2025-03-31T13:01:02.268858Z",
     "shell.execute_reply": "2025-03-31T13:01:02.268177Z"
    },
    "papermill": {
     "duration": 0.052671,
     "end_time": "2025-03-31T13:01:02.270105",
     "exception": false,
     "start_time": "2025-03-31T13:01:02.217434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_cols = [c for c in train.columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['sig_id','kfold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7a29f32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T13:01:02.357287Z",
     "iopub.status.busy": "2025-03-31T13:01:02.356961Z",
     "iopub.status.idle": "2025-03-31T13:01:02.361838Z",
     "shell.execute_reply": "2025-03-31T13:01:02.361015Z"
    },
    "papermill": {
     "duration": 0.050288,
     "end_time": "2025-03-31T13:01:02.363205",
     "exception": false,
     "start_time": "2025-03-31T13:01:02.312917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1579"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd410a74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T13:01:02.450330Z",
     "iopub.status.busy": "2025-03-31T13:01:02.450011Z",
     "iopub.status.idle": "2025-03-31T13:01:02.454370Z",
     "shell.execute_reply": "2025-03-31T13:01:02.453513Z"
    },
    "papermill": {
     "duration": 0.049341,
     "end_time": "2025-03-31T13:01:02.455739",
     "exception": false,
     "start_time": "2025-03-31T13:01:02.406398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 26\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 6e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 7\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = True\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd09a537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T13:01:02.545560Z",
     "iopub.status.busy": "2025-03-31T13:01:02.545266Z",
     "iopub.status.idle": "2025-03-31T13:01:02.555627Z",
     "shell.execute_reply": "2025-03-31T13:01:02.554925Z"
    },
    "papermill": {
     "duration": 0.056815,
     "end_time": "2025-03-31T13:01:02.556882",
     "exception": false,
     "start_time": "2025-03-31T13:01:02.500067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    mskf = MultilabelStratifiedKFold(n_splits=7)\n",
    "    for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "         train.loc[v_idx, 'kfold'] = int(f)\n",
    "    train['kfold'] = train['kfold'].astype(int)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "    \n",
    "    train_dataset = MoADataset(x_train, y_train)\n",
    "    valid_dataset = MoADataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model2(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "    \n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n",
    "    \n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "        print(f\"SEED: {seed} ,FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            \n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), f\"SEED{seed}_FOLD{fold}_scored.pth\")\n",
    "        \n",
    "        elif(EARLY_STOP == True):\n",
    "            \n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "            \n",
    "    \n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = Model2(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(torch.load(f\"SEED{seed}_FOLD{fold}_scored.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27fa1a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T13:01:02.645365Z",
     "iopub.status.busy": "2025-03-31T13:01:02.645070Z",
     "iopub.status.idle": "2025-03-31T13:01:02.649343Z",
     "shell.execute_reply": "2025-03-31T13:01:02.648536Z"
    },
    "papermill": {
     "duration": 0.049392,
     "end_time": "2025-03-31T13:01:02.650655",
     "exception": false,
     "start_time": "2025-03-31T13:01:02.601263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "369b919b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T13:01:02.737767Z",
     "iopub.status.busy": "2025-03-31T13:01:02.737465Z",
     "iopub.status.idle": "2025-03-31T13:46:15.942893Z",
     "shell.execute_reply": "2025-03-31T13:46:15.941901Z"
    },
    "papermill": {
     "duration": 2713.25109,
     "end_time": "2025-03-31T13:46:15.944619",
     "exception": false,
     "start_time": "2025-03-31T13:01:02.693529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 0, FOLD: 0, EPOCH: 0, train_loss: 0.6211328566879839\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 0, valid_loss: 0.21571865677833557\n",
      "SEED: 0, FOLD: 0, EPOCH: 1, train_loss: 0.039302716937822266\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 1, valid_loss: 0.02012624305028182\n",
      "SEED: 0, FOLD: 0, EPOCH: 2, train_loss: 0.022131782226465845\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 2, valid_loss: 0.018541380046651915\n",
      "SEED: 0, FOLD: 0, EPOCH: 3, train_loss: 0.021178668868300075\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 3, valid_loss: 0.018058534425038558\n",
      "SEED: 0, FOLD: 0, EPOCH: 4, train_loss: 0.020661215222365147\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017873199370044928\n",
      "SEED: 0, FOLD: 0, EPOCH: 5, train_loss: 0.02036178414080594\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 5, valid_loss: 0.01745407827771627\n",
      "SEED: 0, FOLD: 0, EPOCH: 6, train_loss: 0.020212833920644747\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01782311599415082\n",
      "SEED: 0, FOLD: 0, EPOCH: 7, train_loss: 0.020119885561635364\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017191582431013767\n",
      "SEED: 0, FOLD: 0, EPOCH: 8, train_loss: 0.01983814568233651\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017378445714712143\n",
      "SEED: 0, FOLD: 0, EPOCH: 9, train_loss: 0.01974723070255808\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 9, valid_loss: 0.016904019535734102\n",
      "SEED: 0, FOLD: 0, EPOCH: 10, train_loss: 0.019616346378382797\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 10, valid_loss: 0.01754419505596161\n",
      "SEED: 0, FOLD: 0, EPOCH: 11, train_loss: 0.019539579421885916\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01678255580079097\n",
      "SEED: 0, FOLD: 0, EPOCH: 12, train_loss: 0.019323744936972052\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01690737881626074\n",
      "SEED: 0, FOLD: 0, EPOCH: 13, train_loss: 0.019174401170095882\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016685020751678027\n",
      "SEED: 0, FOLD: 0, EPOCH: 14, train_loss: 0.019008192988867696\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 14, valid_loss: 0.01656819650760064\n",
      "SEED: 0, FOLD: 0, EPOCH: 15, train_loss: 0.018729628340618032\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 15, valid_loss: 0.01666885442458666\n",
      "SEED: 0, FOLD: 0, EPOCH: 16, train_loss: 0.01848533674067742\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01635805438630856\n",
      "SEED: 0, FOLD: 0, EPOCH: 17, train_loss: 0.01811021420399885\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01632335216093522\n",
      "SEED: 0, FOLD: 0, EPOCH: 18, train_loss: 0.017771534772740828\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016191610779899817\n",
      "SEED: 0, FOLD: 0, EPOCH: 19, train_loss: 0.017316998976811365\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 19, valid_loss: 0.01624119281768799\n",
      "SEED: 0, FOLD: 0, EPOCH: 20, train_loss: 0.01672516021927869\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01599311764137103\n",
      "SEED: 0, FOLD: 0, EPOCH: 21, train_loss: 0.016019365939034802\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016170325689017773\n",
      "SEED: 0, FOLD: 0, EPOCH: 22, train_loss: 0.0153091915857953\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 22, valid_loss: 0.016015454482000608\n",
      "SEED: 0, FOLD: 0, EPOCH: 23, train_loss: 0.014619744521238515\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01598454560511387\n",
      "SEED: 0, FOLD: 0, EPOCH: 24, train_loss: 0.014163510420837917\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 24, valid_loss: 0.016017874846091636\n",
      "SEED: 0, FOLD: 0, EPOCH: 25, train_loss: 0.013920938822667341\n",
      "SEED: 0 ,FOLD: 0, EPOCH: 25, valid_loss: 0.016012801717107113\n",
      "SEED: 0, FOLD: 1, EPOCH: 0, train_loss: 0.6218746002461459\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 0, valid_loss: 0.16361708022080934\n",
      "SEED: 0, FOLD: 1, EPOCH: 1, train_loss: 0.03925792243633721\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 1, valid_loss: 0.020131208145847686\n",
      "SEED: 0, FOLD: 1, EPOCH: 2, train_loss: 0.022112231852637755\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 2, valid_loss: 0.018567226254023038\n",
      "SEED: 0, FOLD: 1, EPOCH: 3, train_loss: 0.0213969105955314\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 3, valid_loss: 0.017973122688440177\n",
      "SEED: 0, FOLD: 1, EPOCH: 4, train_loss: 0.020548592799821415\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01760694241294494\n",
      "SEED: 0, FOLD: 1, EPOCH: 5, train_loss: 0.020194271025625436\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017431286808389884\n",
      "SEED: 0, FOLD: 1, EPOCH: 6, train_loss: 0.02000598584276599\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017344290677171487\n",
      "SEED: 0, FOLD: 1, EPOCH: 7, train_loss: 0.019881986459163396\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01789512442281613\n",
      "SEED: 0, FOLD: 1, EPOCH: 8, train_loss: 0.01977510835874725\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017037293802087124\n",
      "SEED: 0, FOLD: 1, EPOCH: 9, train_loss: 0.019753338341173286\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 9, valid_loss: 0.018533419674405686\n",
      "SEED: 0, FOLD: 1, EPOCH: 10, train_loss: 0.019580432792773116\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 10, valid_loss: 0.016960143828048155\n",
      "SEED: 0, FOLD: 1, EPOCH: 11, train_loss: 0.019490632580945622\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01700949310683287\n",
      "SEED: 0, FOLD: 1, EPOCH: 12, train_loss: 0.019328215159475803\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016819412390199993\n",
      "SEED: 0, FOLD: 1, EPOCH: 13, train_loss: 0.019151785989870895\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016825794958724424\n",
      "SEED: 0, FOLD: 1, EPOCH: 14, train_loss: 0.018960107948530366\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016854656000549976\n",
      "SEED: 0, FOLD: 1, EPOCH: 15, train_loss: 0.018787505885435117\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016540206825503938\n",
      "SEED: 0, FOLD: 1, EPOCH: 16, train_loss: 0.01846645729666626\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016646145699689023\n",
      "SEED: 0, FOLD: 1, EPOCH: 17, train_loss: 0.018199143125801474\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016593329536800202\n",
      "SEED: 0, FOLD: 1, EPOCH: 18, train_loss: 0.01778317059113367\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016217580208411582\n",
      "SEED: 0, FOLD: 1, EPOCH: 19, train_loss: 0.01726919601394518\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016230082640854213\n",
      "SEED: 0, FOLD: 1, EPOCH: 20, train_loss: 0.016720856313367147\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016186436638236046\n",
      "SEED: 0, FOLD: 1, EPOCH: 21, train_loss: 0.016037879662739264\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01613608869509055\n",
      "SEED: 0, FOLD: 1, EPOCH: 22, train_loss: 0.015350035026770186\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 22, valid_loss: 0.016156135843350336\n",
      "SEED: 0, FOLD: 1, EPOCH: 23, train_loss: 0.014607200499724698\n",
      "SEED: 0 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01622581847298604\n",
      "SEED: 0, FOLD: 2, EPOCH: 0, train_loss: 0.622710724134703\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 0, valid_loss: 0.1642428762637652\n",
      "SEED: 0, FOLD: 2, EPOCH: 1, train_loss: 0.03951169560487206\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 1, valid_loss: 0.019853872891802054\n",
      "SEED: 0, FOLD: 2, EPOCH: 2, train_loss: 0.022107213785922206\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 2, valid_loss: 0.01826479020886696\n",
      "SEED: 0, FOLD: 2, EPOCH: 3, train_loss: 0.021108474381066656\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 3, valid_loss: 0.01753873356546347\n",
      "SEED: 0, FOLD: 2, EPOCH: 4, train_loss: 0.020618169744675223\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017350253649055958\n",
      "SEED: 0, FOLD: 2, EPOCH: 5, train_loss: 0.02021029669590093\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017279247753322124\n",
      "SEED: 0, FOLD: 2, EPOCH: 6, train_loss: 0.020049842653443683\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01692347787320614\n",
      "SEED: 0, FOLD: 2, EPOCH: 7, train_loss: 0.01992340906951073\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017153899973401658\n",
      "SEED: 0, FOLD: 2, EPOCH: 8, train_loss: 0.01972374667388362\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 8, valid_loss: 0.016976262227847025\n",
      "SEED: 0, FOLD: 2, EPOCH: 9, train_loss: 0.01965814333006337\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 9, valid_loss: 0.016898812582859628\n",
      "SEED: 0, FOLD: 2, EPOCH: 10, train_loss: 0.019590167580424128\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 10, valid_loss: 0.016990859992802143\n",
      "SEED: 0, FOLD: 2, EPOCH: 11, train_loss: 0.019446354762122437\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016840330110146448\n",
      "SEED: 0, FOLD: 2, EPOCH: 12, train_loss: 0.01931909685702743\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016466585990901176\n",
      "SEED: 0, FOLD: 2, EPOCH: 13, train_loss: 0.019154591813079408\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016515603074087545\n",
      "SEED: 0, FOLD: 2, EPOCH: 14, train_loss: 0.01888118626398815\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01707738322707323\n",
      "SEED: 0, FOLD: 2, EPOCH: 15, train_loss: 0.018688556713026924\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01641509882532633\n",
      "SEED: 0, FOLD: 2, EPOCH: 16, train_loss: 0.0183180303539376\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01636370400396677\n",
      "SEED: 0, FOLD: 2, EPOCH: 17, train_loss: 0.018086309293033304\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016014988175951518\n",
      "SEED: 0, FOLD: 2, EPOCH: 18, train_loss: 0.017642161657882703\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 18, valid_loss: 0.01611259364737914\n",
      "SEED: 0, FOLD: 2, EPOCH: 19, train_loss: 0.01708546668492459\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 19, valid_loss: 0.016097065562812183\n",
      "SEED: 0, FOLD: 2, EPOCH: 20, train_loss: 0.01647000211114819\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 20, valid_loss: 0.015966520358163577\n",
      "SEED: 0, FOLD: 2, EPOCH: 21, train_loss: 0.0157000820051778\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016058889862436514\n",
      "SEED: 0, FOLD: 2, EPOCH: 22, train_loss: 0.014891502774647764\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 22, valid_loss: 0.016040583785909873\n",
      "SEED: 0, FOLD: 2, EPOCH: 23, train_loss: 0.014132741171665289\n",
      "SEED: 0 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01608848922814314\n",
      "SEED: 0, FOLD: 3, EPOCH: 0, train_loss: 0.6225667005857906\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 0, valid_loss: 0.16712859043708214\n",
      "SEED: 0, FOLD: 3, EPOCH: 1, train_loss: 0.03919102339627775\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 1, valid_loss: 0.02037683716760232\n",
      "SEED: 0, FOLD: 3, EPOCH: 2, train_loss: 0.022177350682181282\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018466966226696968\n",
      "SEED: 0, FOLD: 3, EPOCH: 3, train_loss: 0.021084862383636268\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 3, valid_loss: 0.01801866378921729\n",
      "SEED: 0, FOLD: 3, EPOCH: 4, train_loss: 0.020542103142754453\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 4, valid_loss: 0.018021497159050062\n",
      "SEED: 0, FOLD: 3, EPOCH: 5, train_loss: 0.02028616880242889\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 5, valid_loss: 0.01815458917273925\n",
      "SEED: 0, FOLD: 3, EPOCH: 6, train_loss: 0.02007308043539524\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01750418242926781\n",
      "SEED: 0, FOLD: 3, EPOCH: 7, train_loss: 0.019943618568012845\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017163235407609206\n",
      "SEED: 0, FOLD: 3, EPOCH: 8, train_loss: 0.019825536858391116\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017600366702446572\n",
      "SEED: 0, FOLD: 3, EPOCH: 9, train_loss: 0.019761580571129516\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 9, valid_loss: 0.017230395800792254\n",
      "SEED: 0, FOLD: 3, EPOCH: 10, train_loss: 0.019601338366801675\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017312011466576502\n",
      "SEED: 0, FOLD: 3, EPOCH: 11, train_loss: 0.01947415479131647\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 11, valid_loss: 0.017084292494333707\n",
      "SEED: 0, FOLD: 3, EPOCH: 12, train_loss: 0.01931498572230339\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016797883149523\n",
      "SEED: 0, FOLD: 3, EPOCH: 13, train_loss: 0.019185402027859882\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016820365706315406\n",
      "SEED: 0, FOLD: 3, EPOCH: 14, train_loss: 0.018988514344233112\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016689071861597207\n",
      "SEED: 0, FOLD: 3, EPOCH: 15, train_loss: 0.01878723268069931\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01663103599387866\n",
      "SEED: 0, FOLD: 3, EPOCH: 16, train_loss: 0.018597107305115945\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016547109573506392\n",
      "SEED: 0, FOLD: 3, EPOCH: 17, train_loss: 0.018205457492857367\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016450486217553798\n",
      "SEED: 0, FOLD: 3, EPOCH: 18, train_loss: 0.017769331565579853\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016415902341787632\n",
      "SEED: 0, FOLD: 3, EPOCH: 19, train_loss: 0.01727468052224533\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01624963253449935\n",
      "SEED: 0, FOLD: 3, EPOCH: 20, train_loss: 0.01666390912204578\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 20, valid_loss: 0.01622817120873011\n",
      "SEED: 0, FOLD: 3, EPOCH: 21, train_loss: 0.0160306713392807\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01625764534737055\n",
      "SEED: 0, FOLD: 3, EPOCH: 22, train_loss: 0.015240376387294885\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 22, valid_loss: 0.016409954915826138\n",
      "SEED: 0, FOLD: 3, EPOCH: 23, train_loss: 0.01452790992334485\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016292544296727732\n",
      "SEED: 0, FOLD: 3, EPOCH: 24, train_loss: 0.014004584124966248\n",
      "SEED: 0 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016375092073128775\n",
      "SEED: 0, FOLD: 4, EPOCH: 0, train_loss: 0.6226616012486251\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 0, valid_loss: 0.16725887816685897\n",
      "SEED: 0, FOLD: 4, EPOCH: 1, train_loss: 0.03923331976339624\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 1, valid_loss: 0.020184870809316635\n",
      "SEED: 0, FOLD: 4, EPOCH: 2, train_loss: 0.022429661800128384\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018520885362074926\n",
      "SEED: 0, FOLD: 4, EPOCH: 3, train_loss: 0.021251057173956086\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 3, valid_loss: 0.017861429530267533\n",
      "SEED: 0, FOLD: 4, EPOCH: 4, train_loss: 0.020643569252176863\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017513511702418327\n",
      "SEED: 0, FOLD: 4, EPOCH: 5, train_loss: 0.020324468335791213\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017217012838675425\n",
      "SEED: 0, FOLD: 4, EPOCH: 6, train_loss: 0.020206957426224206\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017010285304142878\n",
      "SEED: 0, FOLD: 4, EPOCH: 7, train_loss: 0.02006842603755964\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 7, valid_loss: 0.018014977757747356\n",
      "SEED: 0, FOLD: 4, EPOCH: 8, train_loss: 0.019885147795886605\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 8, valid_loss: 0.01690959593710991\n",
      "SEED: 0, FOLD: 4, EPOCH: 9, train_loss: 0.019750296641644592\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 9, valid_loss: 0.016891720991295118\n",
      "SEED: 0, FOLD: 4, EPOCH: 10, train_loss: 0.01962583970177818\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 10, valid_loss: 0.016896724700927734\n",
      "SEED: 0, FOLD: 4, EPOCH: 11, train_loss: 0.019543266855180264\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016849038907541677\n",
      "SEED: 0, FOLD: 4, EPOCH: 12, train_loss: 0.019334584097000392\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 12, valid_loss: 0.01669948261517745\n",
      "SEED: 0, FOLD: 4, EPOCH: 13, train_loss: 0.01917264467054928\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016504285642160818\n",
      "SEED: 0, FOLD: 4, EPOCH: 14, train_loss: 0.018940313366820682\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016379161666219052\n",
      "SEED: 0, FOLD: 4, EPOCH: 15, train_loss: 0.018794359110698506\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01647586841136217\n",
      "SEED: 0, FOLD: 4, EPOCH: 16, train_loss: 0.01848966218027714\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01633662572846963\n",
      "SEED: 0, FOLD: 4, EPOCH: 17, train_loss: 0.018231745154873746\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016090034077373836\n",
      "SEED: 0, FOLD: 4, EPOCH: 18, train_loss: 0.01775251593239404\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 18, valid_loss: 0.0159230030929813\n",
      "SEED: 0, FOLD: 4, EPOCH: 19, train_loss: 0.01716403293146475\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 19, valid_loss: 0.015826557834561054\n",
      "SEED: 0, FOLD: 4, EPOCH: 20, train_loss: 0.01657491481888133\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01592220588085743\n",
      "SEED: 0, FOLD: 4, EPOCH: 21, train_loss: 0.015867630447688942\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 21, valid_loss: 0.015952966964015595\n",
      "SEED: 0, FOLD: 4, EPOCH: 22, train_loss: 0.015080764512153896\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015919175930321217\n",
      "SEED: 0, FOLD: 4, EPOCH: 23, train_loss: 0.01430831032779974\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 23, valid_loss: 0.015995527760913737\n",
      "SEED: 0, FOLD: 4, EPOCH: 24, train_loss: 0.013786204662677404\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01602582368426598\n",
      "SEED: 0, FOLD: 4, EPOCH: 25, train_loss: 0.013557617049160841\n",
      "SEED: 0 ,FOLD: 4, EPOCH: 25, valid_loss: 0.016032919001120787\n",
      "SEED: 0, FOLD: 5, EPOCH: 0, train_loss: 0.6204680645385304\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 0, valid_loss: 0.17930130316660955\n",
      "SEED: 0, FOLD: 5, EPOCH: 1, train_loss: 0.03886413262099833\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 1, valid_loss: 0.020237147664794557\n",
      "SEED: 0, FOLD: 5, EPOCH: 2, train_loss: 0.02225660693806571\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 2, valid_loss: 0.01835395610676362\n",
      "SEED: 0, FOLD: 5, EPOCH: 3, train_loss: 0.021103806642664445\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 3, valid_loss: 0.017568974684064206\n",
      "SEED: 0, FOLD: 5, EPOCH: 4, train_loss: 0.020779680460691452\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 4, valid_loss: 0.017218675607672103\n",
      "SEED: 0, FOLD: 5, EPOCH: 5, train_loss: 0.0202894256626432\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 5, valid_loss: 0.01733930394626581\n",
      "SEED: 0, FOLD: 5, EPOCH: 6, train_loss: 0.020132890575238177\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 6, valid_loss: 0.016863741697027132\n",
      "SEED: 0, FOLD: 5, EPOCH: 7, train_loss: 0.01993388496339321\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 7, valid_loss: 0.016870623526091758\n",
      "SEED: 0, FOLD: 5, EPOCH: 8, train_loss: 0.019784416978222294\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 8, valid_loss: 0.016707609837444928\n",
      "SEED: 0, FOLD: 5, EPOCH: 9, train_loss: 0.019643336735867167\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 9, valid_loss: 0.016679510832406007\n",
      "SEED: 0, FOLD: 5, EPOCH: 10, train_loss: 0.019536454205376072\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 10, valid_loss: 0.01661528217104765\n",
      "SEED: 0, FOLD: 5, EPOCH: 11, train_loss: 0.01945214459320178\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 11, valid_loss: 0.016420640123005096\n",
      "SEED: 0, FOLD: 5, EPOCH: 12, train_loss: 0.019326628387175703\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 12, valid_loss: 0.016718651096408185\n",
      "SEED: 0, FOLD: 5, EPOCH: 13, train_loss: 0.01908341936163\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 13, valid_loss: 0.01647464121476962\n",
      "SEED: 0, FOLD: 5, EPOCH: 14, train_loss: 0.018853959350569827\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 14, valid_loss: 0.016174009571281765\n",
      "SEED: 0, FOLD: 5, EPOCH: 15, train_loss: 0.018674859122650045\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 15, valid_loss: 0.016267685792767085\n",
      "SEED: 0, FOLD: 5, EPOCH: 16, train_loss: 0.018476972155071592\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 16, valid_loss: 0.016054277809766624\n",
      "SEED: 0, FOLD: 5, EPOCH: 17, train_loss: 0.018082923205519044\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 17, valid_loss: 0.01594745496717783\n",
      "SEED: 0, FOLD: 5, EPOCH: 18, train_loss: 0.017609486054327037\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 18, valid_loss: 0.015938592286637195\n",
      "SEED: 0, FOLD: 5, EPOCH: 19, train_loss: 0.01709071738091675\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 19, valid_loss: 0.015778253929546245\n",
      "SEED: 0, FOLD: 5, EPOCH: 20, train_loss: 0.01648445862873986\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 20, valid_loss: 0.015838412639613334\n",
      "SEED: 0, FOLD: 5, EPOCH: 21, train_loss: 0.015736555856828753\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 21, valid_loss: 0.015771941281855106\n",
      "SEED: 0, FOLD: 5, EPOCH: 22, train_loss: 0.014949923897212421\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 22, valid_loss: 0.015806986807057492\n",
      "SEED: 0, FOLD: 5, EPOCH: 23, train_loss: 0.014206252148928674\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 23, valid_loss: 0.0158399217403852\n",
      "SEED: 0, FOLD: 5, EPOCH: 24, train_loss: 0.013723195278765383\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 24, valid_loss: 0.015825057545533545\n",
      "SEED: 0, FOLD: 5, EPOCH: 25, train_loss: 0.013466872010581396\n",
      "SEED: 0 ,FOLD: 5, EPOCH: 25, valid_loss: 0.015831580958687343\n",
      "SEED: 0, FOLD: 6, EPOCH: 0, train_loss: 0.6208117912347252\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 0, valid_loss: 0.1504900466937285\n",
      "SEED: 0, FOLD: 6, EPOCH: 1, train_loss: 0.03941944520920515\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 1, valid_loss: 0.02059754987175648\n",
      "SEED: 0, FOLD: 6, EPOCH: 2, train_loss: 0.02237204497529043\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 2, valid_loss: 0.01858312521989529\n",
      "SEED: 0, FOLD: 6, EPOCH: 3, train_loss: 0.021139111445360893\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 3, valid_loss: 0.017950092227413103\n",
      "SEED: 0, FOLD: 6, EPOCH: 4, train_loss: 0.020583290959129464\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 4, valid_loss: 0.01796074627110591\n",
      "SEED: 0, FOLD: 6, EPOCH: 5, train_loss: 0.020375522432496417\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 5, valid_loss: 0.018748128643402688\n",
      "SEED: 0, FOLD: 6, EPOCH: 6, train_loss: 0.02034858244194372\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 6, valid_loss: 0.017377346610793702\n",
      "SEED: 0, FOLD: 6, EPOCH: 7, train_loss: 0.020110307563398336\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 7, valid_loss: 0.017312349178470098\n",
      "SEED: 0, FOLD: 6, EPOCH: 8, train_loss: 0.019864662474877125\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 8, valid_loss: 0.017074977835783593\n",
      "SEED: 0, FOLD: 6, EPOCH: 9, train_loss: 0.019684009656712815\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 9, valid_loss: 0.017277320560354453\n",
      "SEED: 0, FOLD: 6, EPOCH: 10, train_loss: 0.019624872812749567\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 10, valid_loss: 0.01702450645657686\n",
      "SEED: 0, FOLD: 6, EPOCH: 11, train_loss: 0.019410995917545783\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 11, valid_loss: 0.016878913801449996\n",
      "SEED: 0, FOLD: 6, EPOCH: 12, train_loss: 0.019287142776758283\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 12, valid_loss: 0.01700702080359826\n",
      "SEED: 0, FOLD: 6, EPOCH: 13, train_loss: 0.01914674312983816\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 13, valid_loss: 0.016846598054354008\n",
      "SEED: 0, FOLD: 6, EPOCH: 14, train_loss: 0.018975530348315433\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 14, valid_loss: 0.016832328616426542\n",
      "SEED: 0, FOLD: 6, EPOCH: 15, train_loss: 0.018715640806869882\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 15, valid_loss: 0.016771296325784463\n",
      "SEED: 0, FOLD: 6, EPOCH: 16, train_loss: 0.018484745199817257\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 16, valid_loss: 0.01649171472168886\n",
      "SEED: 0, FOLD: 6, EPOCH: 17, train_loss: 0.018139791549057573\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 17, valid_loss: 0.01638949805727372\n",
      "SEED: 0, FOLD: 6, EPOCH: 18, train_loss: 0.01770159013166621\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 18, valid_loss: 0.01622463332918974\n",
      "SEED: 0, FOLD: 6, EPOCH: 19, train_loss: 0.017282321067476594\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 19, valid_loss: 0.016211510850833014\n",
      "SEED: 0, FOLD: 6, EPOCH: 20, train_loss: 0.016695133133514506\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 20, valid_loss: 0.01618260395928071\n",
      "SEED: 0, FOLD: 6, EPOCH: 21, train_loss: 0.01605119587652184\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 21, valid_loss: 0.016225381181217156\n",
      "SEED: 0, FOLD: 6, EPOCH: 22, train_loss: 0.015252686231522946\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 22, valid_loss: 0.016266721229140576\n",
      "SEED: 0, FOLD: 6, EPOCH: 23, train_loss: 0.014548904677802647\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 23, valid_loss: 0.016321357769461777\n",
      "SEED: 0, FOLD: 6, EPOCH: 24, train_loss: 0.01403399374386346\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 24, valid_loss: 0.016285414162736673\n",
      "SEED: 0, FOLD: 6, EPOCH: 25, train_loss: 0.013790948870214256\n",
      "SEED: 0 ,FOLD: 6, EPOCH: 25, valid_loss: 0.01631248341156886\n",
      "SEED: 1, FOLD: 0, EPOCH: 0, train_loss: 0.6243507262017276\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 0, valid_loss: 0.17335508190668547\n",
      "SEED: 1, FOLD: 0, EPOCH: 1, train_loss: 0.03893567302037735\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 1, valid_loss: 0.020097352850895662\n",
      "SEED: 1, FOLD: 0, EPOCH: 2, train_loss: 0.02216740936745663\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 2, valid_loss: 0.018463479928099193\n",
      "SEED: 1, FOLD: 0, EPOCH: 3, train_loss: 0.021051860892692127\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 3, valid_loss: 0.01767466038178939\n",
      "SEED: 1, FOLD: 0, EPOCH: 4, train_loss: 0.02050762064754963\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 4, valid_loss: 0.01779450669598121\n",
      "SEED: 1, FOLD: 0, EPOCH: 5, train_loss: 0.020242766477167606\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017424309268020667\n",
      "SEED: 1, FOLD: 0, EPOCH: 6, train_loss: 0.0199689619444512\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017243282941098396\n",
      "SEED: 1, FOLD: 0, EPOCH: 7, train_loss: 0.019837182745136118\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017343037403546847\n",
      "SEED: 1, FOLD: 0, EPOCH: 8, train_loss: 0.019752846023923642\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01701755005006607\n",
      "SEED: 1, FOLD: 0, EPOCH: 9, train_loss: 0.019615589691376365\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01715100656908292\n",
      "SEED: 1, FOLD: 0, EPOCH: 10, train_loss: 0.019577905812577623\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017009229900745246\n",
      "SEED: 1, FOLD: 0, EPOCH: 11, train_loss: 0.019434875858997978\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 11, valid_loss: 0.017027685705285806\n",
      "SEED: 1, FOLD: 0, EPOCH: 12, train_loss: 0.019268565559508028\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01670924796221348\n",
      "SEED: 1, FOLD: 0, EPOCH: 13, train_loss: 0.01910643496022031\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016578467276233893\n",
      "SEED: 1, FOLD: 0, EPOCH: 14, train_loss: 0.018849452756143904\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016517343357778512\n",
      "SEED: 1, FOLD: 0, EPOCH: 15, train_loss: 0.0186517318660343\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016476409867979012\n",
      "SEED: 1, FOLD: 0, EPOCH: 16, train_loss: 0.01846197760991148\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016381603235808704\n",
      "SEED: 1, FOLD: 0, EPOCH: 17, train_loss: 0.01804323499468533\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01636291818263439\n",
      "SEED: 1, FOLD: 0, EPOCH: 18, train_loss: 0.01754788017353496\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016345245190537892\n",
      "SEED: 1, FOLD: 0, EPOCH: 19, train_loss: 0.017063522031782446\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016265506068101294\n",
      "SEED: 1, FOLD: 0, EPOCH: 20, train_loss: 0.016497344068075355\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 20, valid_loss: 0.01621430066342537\n",
      "SEED: 1, FOLD: 0, EPOCH: 21, train_loss: 0.01574876402328546\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 21, valid_loss: 0.01620651974987525\n",
      "SEED: 1, FOLD: 0, EPOCH: 22, train_loss: 0.014879902359098196\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 22, valid_loss: 0.016239064244123604\n",
      "SEED: 1, FOLD: 0, EPOCH: 23, train_loss: 0.014096996293881454\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01624538255139039\n",
      "SEED: 1, FOLD: 0, EPOCH: 24, train_loss: 0.013577008292683074\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 24, valid_loss: 0.0162793449484385\n",
      "SEED: 1, FOLD: 0, EPOCH: 25, train_loss: 0.013367507543817565\n",
      "SEED: 1 ,FOLD: 0, EPOCH: 25, valid_loss: 0.016275348499990426\n",
      "SEED: 1, FOLD: 1, EPOCH: 0, train_loss: 0.6242181342598554\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 0, valid_loss: 0.19538556497830611\n",
      "SEED: 1, FOLD: 1, EPOCH: 1, train_loss: 0.039907347788480485\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 1, valid_loss: 0.020231383494459666\n",
      "SEED: 1, FOLD: 1, EPOCH: 2, train_loss: 0.022477328299066505\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 2, valid_loss: 0.01850153634754511\n",
      "SEED: 1, FOLD: 1, EPOCH: 3, train_loss: 0.021503336803131812\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 3, valid_loss: 0.017723245474581536\n",
      "SEED: 1, FOLD: 1, EPOCH: 4, train_loss: 0.020553495634246518\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017666896876807395\n",
      "SEED: 1, FOLD: 1, EPOCH: 5, train_loss: 0.02041635403057208\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017324563044194993\n",
      "SEED: 1, FOLD: 1, EPOCH: 6, train_loss: 0.020211901037475548\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017128864159950845\n",
      "SEED: 1, FOLD: 1, EPOCH: 7, train_loss: 0.019932372420019395\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 7, valid_loss: 0.016945444907133397\n",
      "SEED: 1, FOLD: 1, EPOCH: 8, train_loss: 0.01975512856969962\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 8, valid_loss: 0.016855186854417507\n",
      "SEED: 1, FOLD: 1, EPOCH: 9, train_loss: 0.0196870111835164\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 9, valid_loss: 0.016699580045846794\n",
      "SEED: 1, FOLD: 1, EPOCH: 10, train_loss: 0.019515797369987577\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01669502595009712\n",
      "SEED: 1, FOLD: 1, EPOCH: 11, train_loss: 0.019363810912378737\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 11, valid_loss: 0.016567378018337946\n",
      "SEED: 1, FOLD: 1, EPOCH: 12, train_loss: 0.01933077712719505\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016587715810881212\n",
      "SEED: 1, FOLD: 1, EPOCH: 13, train_loss: 0.019114688366047433\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016288316235519372\n",
      "SEED: 1, FOLD: 1, EPOCH: 14, train_loss: 0.018872598387502337\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016337250502636798\n",
      "SEED: 1, FOLD: 1, EPOCH: 15, train_loss: 0.018700655272884947\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016224383018337764\n",
      "SEED: 1, FOLD: 1, EPOCH: 16, train_loss: 0.01841722829015674\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016082313914711658\n",
      "SEED: 1, FOLD: 1, EPOCH: 17, train_loss: 0.018048333834756066\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016033836998618566\n",
      "SEED: 1, FOLD: 1, EPOCH: 18, train_loss: 0.01765582330424238\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 18, valid_loss: 0.015940099453123715\n",
      "SEED: 1, FOLD: 1, EPOCH: 19, train_loss: 0.01719581680624066\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016042207869199607\n",
      "SEED: 1, FOLD: 1, EPOCH: 20, train_loss: 0.016542494510980072\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 20, valid_loss: 0.01599841543401663\n",
      "SEED: 1, FOLD: 1, EPOCH: 21, train_loss: 0.01579721166274032\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 21, valid_loss: 0.016016176615196925\n",
      "SEED: 1, FOLD: 1, EPOCH: 22, train_loss: 0.01497602486680891\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 22, valid_loss: 0.015987450901705485\n",
      "SEED: 1, FOLD: 1, EPOCH: 23, train_loss: 0.014258468309669075\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 23, valid_loss: 0.016065540365301646\n",
      "SEED: 1, FOLD: 1, EPOCH: 24, train_loss: 0.013693335730381109\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 24, valid_loss: 0.016113704142089073\n",
      "SEED: 1, FOLD: 1, EPOCH: 25, train_loss: 0.013471858928332458\n",
      "SEED: 1 ,FOLD: 1, EPOCH: 25, valid_loss: 0.016118186597640697\n",
      "SEED: 1, FOLD: 2, EPOCH: 0, train_loss: 0.6248180499753436\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 0, valid_loss: 0.15154147606629592\n",
      "SEED: 1, FOLD: 2, EPOCH: 1, train_loss: 0.039804291735227045\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 1, valid_loss: 0.02064978302671359\n",
      "SEED: 1, FOLD: 2, EPOCH: 2, train_loss: 0.022370900505700626\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018796187324019577\n",
      "SEED: 1, FOLD: 2, EPOCH: 3, train_loss: 0.021176346879754518\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017890124653394405\n",
      "SEED: 1, FOLD: 2, EPOCH: 4, train_loss: 0.020486886764096247\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017864084874208156\n",
      "SEED: 1, FOLD: 2, EPOCH: 5, train_loss: 0.020212862539935757\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01747026466406309\n",
      "SEED: 1, FOLD: 2, EPOCH: 6, train_loss: 0.020034702368886083\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017834422250206653\n",
      "SEED: 1, FOLD: 2, EPOCH: 7, train_loss: 0.019858654563290043\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017754176201728675\n",
      "SEED: 1, FOLD: 2, EPOCH: 8, train_loss: 0.019719728847613204\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017603344642199002\n",
      "SEED: 1, FOLD: 2, EPOCH: 9, train_loss: 0.019627743501316856\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 9, valid_loss: 0.0168875318307143\n",
      "SEED: 1, FOLD: 2, EPOCH: 10, train_loss: 0.019475274593443483\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 10, valid_loss: 0.016966804575461607\n",
      "SEED: 1, FOLD: 2, EPOCH: 11, train_loss: 0.019312008409886748\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016817398082751494\n",
      "SEED: 1, FOLD: 2, EPOCH: 12, train_loss: 0.019282957639645885\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 12, valid_loss: 0.017043322468033202\n",
      "SEED: 1, FOLD: 2, EPOCH: 13, train_loss: 0.01898637446700721\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016732469057807557\n",
      "SEED: 1, FOLD: 2, EPOCH: 14, train_loss: 0.018790685546559258\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016560637248823278\n",
      "SEED: 1, FOLD: 2, EPOCH: 15, train_loss: 0.018590551750684105\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01712767966091633\n",
      "SEED: 1, FOLD: 2, EPOCH: 16, train_loss: 0.01826348717047556\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 16, valid_loss: 0.01646198869611208\n",
      "SEED: 1, FOLD: 2, EPOCH: 17, train_loss: 0.017878823410216217\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016276602418376848\n",
      "SEED: 1, FOLD: 2, EPOCH: 18, train_loss: 0.01741728633390488\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 18, valid_loss: 0.01623901087217606\n",
      "SEED: 1, FOLD: 2, EPOCH: 19, train_loss: 0.016852324778163754\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01627543418166729\n",
      "SEED: 1, FOLD: 2, EPOCH: 20, train_loss: 0.016191885668180278\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01612454796066651\n",
      "SEED: 1, FOLD: 2, EPOCH: 21, train_loss: 0.015368318827067679\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 21, valid_loss: 0.01620451733469963\n",
      "SEED: 1, FOLD: 2, EPOCH: 22, train_loss: 0.014496972230640618\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 22, valid_loss: 0.016210630536079407\n",
      "SEED: 1, FOLD: 2, EPOCH: 23, train_loss: 0.013709898559829674\n",
      "SEED: 1 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01624611156204572\n",
      "SEED: 1, FOLD: 3, EPOCH: 0, train_loss: 0.624589601078549\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 0, valid_loss: 0.1886053429200099\n",
      "SEED: 1, FOLD: 3, EPOCH: 1, train_loss: 0.03962811709356469\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 1, valid_loss: 0.020215388674002428\n",
      "SEED: 1, FOLD: 3, EPOCH: 2, train_loss: 0.022089370903936593\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 2, valid_loss: 0.01862669736146927\n",
      "SEED: 1, FOLD: 3, EPOCH: 3, train_loss: 0.021065309241011337\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018117163330316544\n",
      "SEED: 1, FOLD: 3, EPOCH: 4, train_loss: 0.02057807892560959\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 4, valid_loss: 0.01853383117570327\n",
      "SEED: 1, FOLD: 3, EPOCH: 5, train_loss: 0.02022616648291414\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 5, valid_loss: 0.018025161555180184\n",
      "SEED: 1, FOLD: 3, EPOCH: 6, train_loss: 0.02004560619290616\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 6, valid_loss: 0.03954259048287685\n",
      "SEED: 1, FOLD: 3, EPOCH: 7, train_loss: 0.019836377805551968\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017367364265597783\n",
      "SEED: 1, FOLD: 3, EPOCH: 8, train_loss: 0.019783242756651866\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017286622896790504\n",
      "SEED: 1, FOLD: 3, EPOCH: 9, train_loss: 0.01962804061838904\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 9, valid_loss: 0.017300528689072683\n",
      "SEED: 1, FOLD: 3, EPOCH: 10, train_loss: 0.019525949893569625\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017211952461646154\n",
      "SEED: 1, FOLD: 3, EPOCH: 11, train_loss: 0.01935188122395728\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01692144852131605\n",
      "SEED: 1, FOLD: 3, EPOCH: 12, train_loss: 0.019248905214103492\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 12, valid_loss: 0.01694878197919864\n",
      "SEED: 1, FOLD: 3, EPOCH: 13, train_loss: 0.019093988337428182\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016963793752858274\n",
      "SEED: 1, FOLD: 3, EPOCH: 14, train_loss: 0.01895933474942639\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01681628407767186\n",
      "SEED: 1, FOLD: 3, EPOCH: 15, train_loss: 0.018676670847108234\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016729561182168815\n",
      "SEED: 1, FOLD: 3, EPOCH: 16, train_loss: 0.018323425102878262\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016707192103450116\n",
      "SEED: 1, FOLD: 3, EPOCH: 17, train_loss: 0.01805467259239506\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016480141319334507\n",
      "SEED: 1, FOLD: 3, EPOCH: 18, train_loss: 0.017537058595366573\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016473598276766446\n",
      "SEED: 1, FOLD: 3, EPOCH: 19, train_loss: 0.017097790876554476\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016420927758400258\n",
      "SEED: 1, FOLD: 3, EPOCH: 20, train_loss: 0.016478968859725707\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016503054075516187\n",
      "SEED: 1, FOLD: 3, EPOCH: 21, train_loss: 0.015759263577795512\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 21, valid_loss: 0.0163855033998306\n",
      "SEED: 1, FOLD: 3, EPOCH: 22, train_loss: 0.0149181394560917\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 22, valid_loss: 0.016430642169255476\n",
      "SEED: 1, FOLD: 3, EPOCH: 23, train_loss: 0.014150682069059159\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01650989456818654\n",
      "SEED: 1, FOLD: 3, EPOCH: 24, train_loss: 0.013597367469825455\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 24, valid_loss: 0.01650890664985547\n",
      "SEED: 1, FOLD: 3, EPOCH: 25, train_loss: 0.013350170483258931\n",
      "SEED: 1 ,FOLD: 3, EPOCH: 25, valid_loss: 0.016520391003443644\n",
      "SEED: 1, FOLD: 4, EPOCH: 0, train_loss: 0.6242359463830252\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 0, valid_loss: 0.1756128382224303\n",
      "SEED: 1, FOLD: 4, EPOCH: 1, train_loss: 0.03923105078472479\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 1, valid_loss: 0.020708700068868123\n",
      "SEED: 1, FOLD: 4, EPOCH: 2, train_loss: 0.022313168951989832\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018576111644506454\n",
      "SEED: 1, FOLD: 4, EPOCH: 3, train_loss: 0.021106833516544587\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 3, valid_loss: 0.018577666523364875\n",
      "SEED: 1, FOLD: 4, EPOCH: 4, train_loss: 0.02061421804230761\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017699567314523917\n",
      "SEED: 1, FOLD: 4, EPOCH: 5, train_loss: 0.020218374534837297\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017263509476414092\n",
      "SEED: 1, FOLD: 4, EPOCH: 6, train_loss: 0.019969411370520655\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017304741992400244\n",
      "SEED: 1, FOLD: 4, EPOCH: 7, train_loss: 0.01985331637331763\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017384193551081877\n",
      "SEED: 1, FOLD: 4, EPOCH: 8, train_loss: 0.01968336324333339\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 8, valid_loss: 0.01704562412431607\n",
      "SEED: 1, FOLD: 4, EPOCH: 9, train_loss: 0.0196576062338175\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 9, valid_loss: 0.016923868025724705\n",
      "SEED: 1, FOLD: 4, EPOCH: 10, train_loss: 0.019482809748198535\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017238129790012654\n",
      "SEED: 1, FOLD: 4, EPOCH: 11, train_loss: 0.019350704434957053\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016879509991178147\n",
      "SEED: 1, FOLD: 4, EPOCH: 12, train_loss: 0.019265648883742256\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016721006482839584\n",
      "SEED: 1, FOLD: 4, EPOCH: 13, train_loss: 0.01908862208192413\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 13, valid_loss: 0.01677989873748559\n",
      "SEED: 1, FOLD: 4, EPOCH: 14, train_loss: 0.018852609964842733\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016429777901906233\n",
      "SEED: 1, FOLD: 4, EPOCH: 15, train_loss: 0.018615698819426266\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016387528811509792\n",
      "SEED: 1, FOLD: 4, EPOCH: 16, train_loss: 0.018345759099198354\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 16, valid_loss: 0.0162597787208282\n",
      "SEED: 1, FOLD: 4, EPOCH: 17, train_loss: 0.01803279444071892\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01640513797218983\n",
      "SEED: 1, FOLD: 4, EPOCH: 18, train_loss: 0.017609419225639588\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016212152102245733\n",
      "SEED: 1, FOLD: 4, EPOCH: 19, train_loss: 0.017128725057920895\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016098415335783593\n",
      "SEED: 1, FOLD: 4, EPOCH: 20, train_loss: 0.01649879479176692\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016135096764908388\n",
      "SEED: 1, FOLD: 4, EPOCH: 21, train_loss: 0.01575381974563808\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 21, valid_loss: 0.016117676304510005\n",
      "SEED: 1, FOLD: 4, EPOCH: 22, train_loss: 0.014991286500180894\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 22, valid_loss: 0.016134160499160107\n",
      "SEED: 1, FOLD: 4, EPOCH: 23, train_loss: 0.01421709343589641\n",
      "SEED: 1 ,FOLD: 4, EPOCH: 23, valid_loss: 0.016134641634730194\n",
      "SEED: 1, FOLD: 5, EPOCH: 0, train_loss: 0.6237041752886128\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 0, valid_loss: 0.2583075142823733\n",
      "SEED: 1, FOLD: 5, EPOCH: 1, train_loss: 0.03984304386618975\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 1, valid_loss: 0.020389329498777024\n",
      "SEED: 1, FOLD: 5, EPOCH: 2, train_loss: 0.022576987315472717\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 2, valid_loss: 0.01843739214998025\n",
      "SEED: 1, FOLD: 5, EPOCH: 3, train_loss: 0.02106857267082543\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 3, valid_loss: 0.018091322710880868\n",
      "SEED: 1, FOLD: 5, EPOCH: 4, train_loss: 0.020530487637262087\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 4, valid_loss: 0.017329109116242483\n",
      "SEED: 1, FOLD: 5, EPOCH: 5, train_loss: 0.020106421859079116\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 5, valid_loss: 0.017216923001867074\n",
      "SEED: 1, FOLD: 5, EPOCH: 6, train_loss: 0.019920787169925264\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 6, valid_loss: 0.01725610402914194\n",
      "SEED: 1, FOLD: 5, EPOCH: 7, train_loss: 0.019801079773822346\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 7, valid_loss: 0.017658689704078894\n",
      "SEED: 1, FOLD: 5, EPOCH: 8, train_loss: 0.019716970849077444\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 8, valid_loss: 0.0169889832345339\n",
      "SEED: 1, FOLD: 5, EPOCH: 9, train_loss: 0.01959501380553922\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 9, valid_loss: 0.017056333975723155\n",
      "SEED: 1, FOLD: 5, EPOCH: 10, train_loss: 0.019528402544155315\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 10, valid_loss: 0.01699400471093563\n",
      "SEED: 1, FOLD: 5, EPOCH: 11, train_loss: 0.019385485230265436\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 11, valid_loss: 0.016879598108621743\n",
      "SEED: 1, FOLD: 5, EPOCH: 12, train_loss: 0.019235138177267602\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 12, valid_loss: 0.016707225129581414\n",
      "SEED: 1, FOLD: 5, EPOCH: 13, train_loss: 0.019083610005878115\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 13, valid_loss: 0.016489480837033346\n",
      "SEED: 1, FOLD: 5, EPOCH: 14, train_loss: 0.018863900438756555\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 14, valid_loss: 0.016447277882924445\n",
      "SEED: 1, FOLD: 5, EPOCH: 15, train_loss: 0.01865476412648285\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 15, valid_loss: 0.01636285435121793\n",
      "SEED: 1, FOLD: 5, EPOCH: 16, train_loss: 0.01832237230563486\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 16, valid_loss: 0.016210761709282033\n",
      "SEED: 1, FOLD: 5, EPOCH: 17, train_loss: 0.018047295737306814\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 17, valid_loss: 0.016095055267214775\n",
      "SEED: 1, FOLD: 5, EPOCH: 18, train_loss: 0.017556517460458988\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 18, valid_loss: 0.016089900969885863\n",
      "SEED: 1, FOLD: 5, EPOCH: 19, train_loss: 0.017040562702695262\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 19, valid_loss: 0.01599216017012413\n",
      "SEED: 1, FOLD: 5, EPOCH: 20, train_loss: 0.016357668574798753\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 20, valid_loss: 0.015973352970412143\n",
      "SEED: 1, FOLD: 5, EPOCH: 21, train_loss: 0.015692480890130676\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 21, valid_loss: 0.016059140030008096\n",
      "SEED: 1, FOLD: 5, EPOCH: 22, train_loss: 0.014857441224661228\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 22, valid_loss: 0.015998345943024524\n",
      "SEED: 1, FOLD: 5, EPOCH: 23, train_loss: 0.014046668779809732\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 23, valid_loss: 0.01607346276824291\n",
      "SEED: 1, FOLD: 5, EPOCH: 24, train_loss: 0.013528459579557986\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 24, valid_loss: 0.016105217787508782\n",
      "SEED: 1, FOLD: 5, EPOCH: 25, train_loss: 0.013252321265738559\n",
      "SEED: 1 ,FOLD: 5, EPOCH: 25, valid_loss: 0.016111876242435895\n",
      "SEED: 1, FOLD: 6, EPOCH: 0, train_loss: 0.6246891355997807\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 0, valid_loss: 0.19468719913409308\n",
      "SEED: 1, FOLD: 6, EPOCH: 1, train_loss: 0.0394841091254273\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 1, valid_loss: 0.02148883531873043\n",
      "SEED: 1, FOLD: 6, EPOCH: 2, train_loss: 0.02259000249811121\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 2, valid_loss: 0.018370416301947374\n",
      "SEED: 1, FOLD: 6, EPOCH: 3, train_loss: 0.02120749549185102\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 3, valid_loss: 0.01787728200165125\n",
      "SEED: 1, FOLD: 6, EPOCH: 4, train_loss: 0.020688689313828945\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 4, valid_loss: 0.01765918072599631\n",
      "SEED: 1, FOLD: 6, EPOCH: 5, train_loss: 0.020370956334109243\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 5, valid_loss: 0.017582858841006573\n",
      "SEED: 1, FOLD: 6, EPOCH: 6, train_loss: 0.02015984428392069\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 6, valid_loss: 0.01726726184670742\n",
      "SEED: 1, FOLD: 6, EPOCH: 7, train_loss: 0.019899041014345916\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 7, valid_loss: 0.017231034616438243\n",
      "SEED: 1, FOLD: 6, EPOCH: 8, train_loss: 0.01982124539947993\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 8, valid_loss: 0.017454781784461096\n",
      "SEED: 1, FOLD: 6, EPOCH: 9, train_loss: 0.0197206650785095\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 9, valid_loss: 0.016739479481027678\n",
      "SEED: 1, FOLD: 6, EPOCH: 10, train_loss: 0.019636355441164325\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 10, valid_loss: 0.01684365622126139\n",
      "SEED: 1, FOLD: 6, EPOCH: 11, train_loss: 0.0195133940039857\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 11, valid_loss: 0.016893081940137424\n",
      "SEED: 1, FOLD: 6, EPOCH: 12, train_loss: 0.01940307635310534\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 12, valid_loss: 0.016759259124787953\n",
      "SEED: 1, FOLD: 6, EPOCH: 13, train_loss: 0.019148676832382742\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 13, valid_loss: 0.016694596753670618\n",
      "SEED: 1, FOLD: 6, EPOCH: 14, train_loss: 0.01902596023235772\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 14, valid_loss: 0.01644805045082019\n",
      "SEED: 1, FOLD: 6, EPOCH: 15, train_loss: 0.0186865428160574\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 15, valid_loss: 0.01648002153692337\n",
      "SEED: 1, FOLD: 6, EPOCH: 16, train_loss: 0.01850081469259552\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 16, valid_loss: 0.01644837548239873\n",
      "SEED: 1, FOLD: 6, EPOCH: 17, train_loss: 0.018221548959814215\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 17, valid_loss: 0.016261217900766775\n",
      "SEED: 1, FOLD: 6, EPOCH: 18, train_loss: 0.017823079198196128\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 18, valid_loss: 0.01608768026702679\n",
      "SEED: 1, FOLD: 6, EPOCH: 19, train_loss: 0.017297021088165207\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 19, valid_loss: 0.016280899540736124\n",
      "SEED: 1, FOLD: 6, EPOCH: 20, train_loss: 0.016741922477612626\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 20, valid_loss: 0.016012517735362053\n",
      "SEED: 1, FOLD: 6, EPOCH: 21, train_loss: 0.016134762142256304\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 21, valid_loss: 0.01596813820875608\n",
      "SEED: 1, FOLD: 6, EPOCH: 22, train_loss: 0.015346500733112162\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 22, valid_loss: 0.01595666316839365\n",
      "SEED: 1, FOLD: 6, EPOCH: 23, train_loss: 0.014662607560387335\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 23, valid_loss: 0.015974002388807442\n",
      "SEED: 1, FOLD: 6, EPOCH: 24, train_loss: 0.01414119204304911\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 24, valid_loss: 0.016010356637147758\n",
      "SEED: 1, FOLD: 6, EPOCH: 25, train_loss: 0.01389258969071749\n",
      "SEED: 1 ,FOLD: 6, EPOCH: 25, valid_loss: 0.015995323084867917\n",
      "SEED: 2, FOLD: 0, EPOCH: 0, train_loss: 0.6217971200475821\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 0, valid_loss: 0.19257173056785876\n",
      "SEED: 2, FOLD: 0, EPOCH: 1, train_loss: 0.03914084544757734\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 1, valid_loss: 0.020060663326428488\n",
      "SEED: 2, FOLD: 0, EPOCH: 2, train_loss: 0.022229096801901185\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 2, valid_loss: 0.018448740530472536\n",
      "SEED: 2, FOLD: 0, EPOCH: 3, train_loss: 0.021082147452476864\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017618539958046034\n",
      "SEED: 2, FOLD: 0, EPOCH: 4, train_loss: 0.020550340036484035\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017590529930133086\n",
      "SEED: 2, FOLD: 0, EPOCH: 5, train_loss: 0.020251430042490765\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 5, valid_loss: 0.01754806864147003\n",
      "SEED: 2, FOLD: 0, EPOCH: 6, train_loss: 0.019993850759960508\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 6, valid_loss: 0.01726736042361993\n",
      "SEED: 2, FOLD: 0, EPOCH: 7, train_loss: 0.019801146627680677\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017053809948265553\n",
      "SEED: 2, FOLD: 0, EPOCH: 8, train_loss: 0.019831675809581537\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017325672894143142\n",
      "SEED: 2, FOLD: 0, EPOCH: 9, train_loss: 0.019623925733203824\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01684827644091386\n",
      "SEED: 2, FOLD: 0, EPOCH: 10, train_loss: 0.019608368593696003\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 10, valid_loss: 0.0169530906356298\n",
      "SEED: 2, FOLD: 0, EPOCH: 11, train_loss: 0.019352255414265232\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 11, valid_loss: 0.016967054169911604\n",
      "SEED: 2, FOLD: 0, EPOCH: 12, train_loss: 0.019392305985093117\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016702477748577412\n",
      "SEED: 2, FOLD: 0, EPOCH: 13, train_loss: 0.01907989679760224\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 13, valid_loss: 0.01655262830452277\n",
      "SEED: 2, FOLD: 0, EPOCH: 14, train_loss: 0.018901928680369984\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 14, valid_loss: 0.01672003876704436\n",
      "SEED: 2, FOLD: 0, EPOCH: 15, train_loss: 0.018734258725433738\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016421246127440378\n",
      "SEED: 2, FOLD: 0, EPOCH: 16, train_loss: 0.01840690676928372\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016366677502026923\n",
      "SEED: 2, FOLD: 0, EPOCH: 17, train_loss: 0.01811773533857352\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016327128244134095\n",
      "SEED: 2, FOLD: 0, EPOCH: 18, train_loss: 0.017697638693592838\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016174201638652727\n",
      "SEED: 2, FOLD: 0, EPOCH: 19, train_loss: 0.017194202257874044\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 19, valid_loss: 0.016069618698496085\n",
      "SEED: 2, FOLD: 0, EPOCH: 20, train_loss: 0.016620290037747974\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016055524850694034\n",
      "SEED: 2, FOLD: 0, EPOCH: 21, train_loss: 0.015904451028217335\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 21, valid_loss: 0.015975240976191483\n",
      "SEED: 2, FOLD: 0, EPOCH: 22, train_loss: 0.015119035149345527\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 22, valid_loss: 0.016088641965045378\n",
      "SEED: 2, FOLD: 0, EPOCH: 23, train_loss: 0.01440803801036767\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 23, valid_loss: 0.016089860278253373\n",
      "SEED: 2, FOLD: 0, EPOCH: 24, train_loss: 0.013849055495213819\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 24, valid_loss: 0.016091882537763853\n",
      "SEED: 2, FOLD: 0, EPOCH: 25, train_loss: 0.01365280320012086\n",
      "SEED: 2 ,FOLD: 0, EPOCH: 25, valid_loss: 0.01609414493521819\n",
      "SEED: 2, FOLD: 1, EPOCH: 0, train_loss: 0.6225883348568065\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 0, valid_loss: 0.17963615289101234\n",
      "SEED: 2, FOLD: 1, EPOCH: 1, train_loss: 0.03942338399891112\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 1, valid_loss: 0.020170404217564143\n",
      "SEED: 2, FOLD: 1, EPOCH: 2, train_loss: 0.02209696505923529\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 2, valid_loss: 0.018251550168945238\n",
      "SEED: 2, FOLD: 1, EPOCH: 3, train_loss: 0.020936248446437152\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 3, valid_loss: 0.017760804925973598\n",
      "SEED: 2, FOLD: 1, EPOCH: 4, train_loss: 0.020393744161402858\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017548695779763736\n",
      "SEED: 2, FOLD: 1, EPOCH: 5, train_loss: 0.020097309094224428\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017557969603400964\n",
      "SEED: 2, FOLD: 1, EPOCH: 6, train_loss: 0.01995230491298276\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 6, valid_loss: 0.01739778405485245\n",
      "SEED: 2, FOLD: 1, EPOCH: 7, train_loss: 0.01978951634688152\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017329282628802154\n",
      "SEED: 2, FOLD: 1, EPOCH: 8, train_loss: 0.019671780812377866\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 8, valid_loss: 0.017006685455831196\n",
      "SEED: 2, FOLD: 1, EPOCH: 9, train_loss: 0.019584711313851783\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 9, valid_loss: 0.017134568725640956\n",
      "SEED: 2, FOLD: 1, EPOCH: 10, train_loss: 0.019452398743581126\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 10, valid_loss: 0.017143560716739066\n",
      "SEED: 2, FOLD: 1, EPOCH: 11, train_loss: 0.01931449501599009\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01668583766485636\n",
      "SEED: 2, FOLD: 1, EPOCH: 12, train_loss: 0.01920324204036513\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 12, valid_loss: 0.017172693131634824\n",
      "SEED: 2, FOLD: 1, EPOCH: 13, train_loss: 0.01903481300718881\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01679635986399192\n",
      "SEED: 2, FOLD: 1, EPOCH: 14, train_loss: 0.018839949238541966\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 14, valid_loss: 0.01648062324294677\n",
      "SEED: 2, FOLD: 1, EPOCH: 15, train_loss: 0.018595295983391838\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01647995004000572\n",
      "SEED: 2, FOLD: 1, EPOCH: 16, train_loss: 0.018334278308257863\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016388203017413616\n",
      "SEED: 2, FOLD: 1, EPOCH: 17, train_loss: 0.017947563649834814\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016283763715854056\n",
      "SEED: 2, FOLD: 1, EPOCH: 18, train_loss: 0.01756435411201941\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016177334177952547\n",
      "SEED: 2, FOLD: 1, EPOCH: 19, train_loss: 0.01702615978649339\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01614369351703387\n",
      "SEED: 2, FOLD: 1, EPOCH: 20, train_loss: 0.016352598416946224\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016185704332131606\n",
      "SEED: 2, FOLD: 1, EPOCH: 21, train_loss: 0.01567056296846351\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 21, valid_loss: 0.016216636778643496\n",
      "SEED: 2, FOLD: 1, EPOCH: 22, train_loss: 0.014810357028870163\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 22, valid_loss: 0.016202685781396352\n",
      "SEED: 2, FOLD: 1, EPOCH: 23, train_loss: 0.014027186216333427\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 23, valid_loss: 0.016235267385267295\n",
      "SEED: 2, FOLD: 1, EPOCH: 24, train_loss: 0.013458663748728263\n",
      "SEED: 2 ,FOLD: 1, EPOCH: 24, valid_loss: 0.016272684989067223\n",
      "SEED: 2, FOLD: 2, EPOCH: 0, train_loss: 0.6222079790927268\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 0, valid_loss: 0.1922846000928145\n",
      "SEED: 2, FOLD: 2, EPOCH: 1, train_loss: 0.03924291573364187\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 1, valid_loss: 0.020033534759512313\n",
      "SEED: 2, FOLD: 2, EPOCH: 2, train_loss: 0.022225843113217805\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018390682740853384\n",
      "SEED: 2, FOLD: 2, EPOCH: 3, train_loss: 0.02118333731148694\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017843108194378707\n",
      "SEED: 2, FOLD: 2, EPOCH: 4, train_loss: 0.020461166126502527\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017161329778341148\n",
      "SEED: 2, FOLD: 2, EPOCH: 5, train_loss: 0.02015430900595478\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017076644903192155\n",
      "SEED: 2, FOLD: 2, EPOCH: 6, train_loss: 0.019952739815454226\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017226621580238525\n",
      "SEED: 2, FOLD: 2, EPOCH: 7, train_loss: 0.019855123365650307\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 7, valid_loss: 0.016940994976231687\n",
      "SEED: 2, FOLD: 2, EPOCH: 8, train_loss: 0.019683053213599568\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 8, valid_loss: 0.016704686129322417\n",
      "SEED: 2, FOLD: 2, EPOCH: 9, train_loss: 0.019603113719337695\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 9, valid_loss: 0.0170496293128683\n",
      "SEED: 2, FOLD: 2, EPOCH: 10, train_loss: 0.01950642987582329\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 10, valid_loss: 0.016802312519687872\n",
      "SEED: 2, FOLD: 2, EPOCH: 11, train_loss: 0.019410293675153643\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016479216014536526\n",
      "SEED: 2, FOLD: 2, EPOCH: 12, train_loss: 0.01922927107158545\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016540340362833097\n",
      "SEED: 2, FOLD: 2, EPOCH: 13, train_loss: 0.019083717913442367\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 13, valid_loss: 0.01648644759104802\n",
      "SEED: 2, FOLD: 2, EPOCH: 14, train_loss: 0.018830479550603275\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016229138279763553\n",
      "SEED: 2, FOLD: 2, EPOCH: 15, train_loss: 0.018563410091037687\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016216926706524994\n",
      "SEED: 2, FOLD: 2, EPOCH: 16, train_loss: 0.018298661109764833\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016112521935540896\n",
      "SEED: 2, FOLD: 2, EPOCH: 17, train_loss: 0.017899040913058294\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01611184271482321\n",
      "SEED: 2, FOLD: 2, EPOCH: 18, train_loss: 0.017514138457340164\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 18, valid_loss: 0.015971007613608472\n",
      "SEED: 2, FOLD: 2, EPOCH: 19, train_loss: 0.017008783711070143\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 19, valid_loss: 0.015986272563728\n",
      "SEED: 2, FOLD: 2, EPOCH: 20, train_loss: 0.01629893920963278\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 20, valid_loss: 0.015919291987442054\n",
      "SEED: 2, FOLD: 2, EPOCH: 21, train_loss: 0.015505016038848742\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016104565002024174\n",
      "SEED: 2, FOLD: 2, EPOCH: 22, train_loss: 0.014707905982897894\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01606009814601678\n",
      "SEED: 2, FOLD: 2, EPOCH: 23, train_loss: 0.013945080641959165\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 23, valid_loss: 0.016079395722884398\n",
      "SEED: 2, FOLD: 2, EPOCH: 24, train_loss: 0.013392491618523726\n",
      "SEED: 2 ,FOLD: 2, EPOCH: 24, valid_loss: 0.01607877517548891\n",
      "SEED: 2, FOLD: 3, EPOCH: 0, train_loss: 0.622233668694625\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 0, valid_loss: 0.17679804448898023\n",
      "SEED: 2, FOLD: 3, EPOCH: 1, train_loss: 0.03967290127498878\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 1, valid_loss: 0.020714704090586074\n",
      "SEED: 2, FOLD: 3, EPOCH: 2, train_loss: 0.022690520193931217\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018793462990568235\n",
      "SEED: 2, FOLD: 3, EPOCH: 3, train_loss: 0.021334184912612308\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018146687258894626\n",
      "SEED: 2, FOLD: 3, EPOCH: 4, train_loss: 0.02074725500534515\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017758612019511368\n",
      "SEED: 2, FOLD: 3, EPOCH: 5, train_loss: 0.020477332074094464\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017923098630630054\n",
      "SEED: 2, FOLD: 3, EPOCH: 6, train_loss: 0.02010919216617539\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017250889912247658\n",
      "SEED: 2, FOLD: 3, EPOCH: 7, train_loss: 0.01994622400584253\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01725749384898406\n",
      "SEED: 2, FOLD: 3, EPOCH: 8, train_loss: 0.01981382887508418\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 8, valid_loss: 0.016925426486593027\n",
      "SEED: 2, FOLD: 3, EPOCH: 9, train_loss: 0.019669127776413352\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01713789741580303\n",
      "SEED: 2, FOLD: 3, EPOCH: 10, train_loss: 0.019490358948304847\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 10, valid_loss: 0.0170960955035228\n",
      "SEED: 2, FOLD: 3, EPOCH: 11, train_loss: 0.01938654965645558\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 11, valid_loss: 0.016919642973404665\n",
      "SEED: 2, FOLD: 3, EPOCH: 12, train_loss: 0.019210874279205863\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016775202937424183\n",
      "SEED: 2, FOLD: 3, EPOCH: 13, train_loss: 0.01898692691749012\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016592965962795112\n",
      "SEED: 2, FOLD: 3, EPOCH: 14, train_loss: 0.018758288106402836\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01662124922642341\n",
      "SEED: 2, FOLD: 3, EPOCH: 15, train_loss: 0.01846327431298591\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01648117960072481\n",
      "SEED: 2, FOLD: 3, EPOCH: 16, train_loss: 0.018191088595100352\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016463090880559042\n",
      "SEED: 2, FOLD: 3, EPOCH: 17, train_loss: 0.01777515880058746\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016348790663939256\n",
      "SEED: 2, FOLD: 3, EPOCH: 18, train_loss: 0.01728856618944052\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 18, valid_loss: 0.0163733631802293\n",
      "SEED: 2, FOLD: 3, EPOCH: 19, train_loss: 0.016682599583086936\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01627989815404782\n",
      "SEED: 2, FOLD: 3, EPOCH: 20, train_loss: 0.01595207250903587\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016342427151707504\n",
      "SEED: 2, FOLD: 3, EPOCH: 21, train_loss: 0.015115351151876353\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01636597363708111\n",
      "SEED: 2, FOLD: 3, EPOCH: 22, train_loss: 0.014224947631560467\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 22, valid_loss: 0.016426693576459702\n",
      "SEED: 2, FOLD: 3, EPOCH: 23, train_loss: 0.013447694279052116\n",
      "SEED: 2 ,FOLD: 3, EPOCH: 23, valid_loss: 0.01646324433386326\n",
      "SEED: 2, FOLD: 4, EPOCH: 0, train_loss: 0.6224946756217931\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 0, valid_loss: 0.18009862303733826\n",
      "SEED: 2, FOLD: 4, EPOCH: 1, train_loss: 0.03929031021087556\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 1, valid_loss: 0.02056471759883257\n",
      "SEED: 2, FOLD: 4, EPOCH: 2, train_loss: 0.022174209406649745\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 2, valid_loss: 0.01896298934633915\n",
      "SEED: 2, FOLD: 4, EPOCH: 3, train_loss: 0.021125528055268364\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01802863710774825\n",
      "SEED: 2, FOLD: 4, EPOCH: 4, train_loss: 0.02052808827343019\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017676003993703768\n",
      "SEED: 2, FOLD: 4, EPOCH: 5, train_loss: 0.02016137303734148\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017384582557357274\n",
      "SEED: 2, FOLD: 4, EPOCH: 6, train_loss: 0.019938058194679184\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017916201112362053\n",
      "SEED: 2, FOLD: 4, EPOCH: 7, train_loss: 0.019897991539658728\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017532100327886067\n",
      "SEED: 2, FOLD: 4, EPOCH: 8, train_loss: 0.019712049790934938\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 8, valid_loss: 0.01735347552368274\n",
      "SEED: 2, FOLD: 4, EPOCH: 9, train_loss: 0.019675656322490524\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 9, valid_loss: 0.01760296494914935\n",
      "SEED: 2, FOLD: 4, EPOCH: 10, train_loss: 0.01953941402403084\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01732994458423211\n",
      "SEED: 2, FOLD: 4, EPOCH: 11, train_loss: 0.0194720194951908\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 11, valid_loss: 0.017197849228978157\n",
      "SEED: 2, FOLD: 4, EPOCH: 12, train_loss: 0.019280457063703925\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 12, valid_loss: 0.017129317928965274\n",
      "SEED: 2, FOLD: 4, EPOCH: 13, train_loss: 0.019133446914320056\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016828034789516375\n",
      "SEED: 2, FOLD: 4, EPOCH: 14, train_loss: 0.018904138557814264\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016687932495887462\n",
      "SEED: 2, FOLD: 4, EPOCH: 15, train_loss: 0.018738641328102833\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016882677419254415\n",
      "SEED: 2, FOLD: 4, EPOCH: 16, train_loss: 0.018523377467047523\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 16, valid_loss: 0.01652054374034588\n",
      "SEED: 2, FOLD: 4, EPOCH: 17, train_loss: 0.018171835866932932\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016355355986608908\n",
      "SEED: 2, FOLD: 4, EPOCH: 18, train_loss: 0.01770350490570874\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01617282270812071\n",
      "SEED: 2, FOLD: 4, EPOCH: 19, train_loss: 0.01722856394543841\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016222058580471918\n",
      "SEED: 2, FOLD: 4, EPOCH: 20, train_loss: 0.01668467728823826\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01610835433865969\n",
      "SEED: 2, FOLD: 4, EPOCH: 21, train_loss: 0.01597511996137532\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 21, valid_loss: 0.016153884263565906\n",
      "SEED: 2, FOLD: 4, EPOCH: 22, train_loss: 0.015193054528051132\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 22, valid_loss: 0.01616637917378774\n",
      "SEED: 2, FOLD: 4, EPOCH: 23, train_loss: 0.01450131818450786\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01615965459495783\n",
      "SEED: 2, FOLD: 4, EPOCH: 24, train_loss: 0.01396233806185223\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 24, valid_loss: 0.01618154325450842\n",
      "SEED: 2, FOLD: 4, EPOCH: 25, train_loss: 0.013747647404670715\n",
      "SEED: 2 ,FOLD: 4, EPOCH: 25, valid_loss: 0.016202682485947244\n",
      "SEED: 2, FOLD: 5, EPOCH: 0, train_loss: 0.6224753047163422\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 0, valid_loss: 0.17820298786346728\n",
      "SEED: 2, FOLD: 5, EPOCH: 1, train_loss: 0.03976206713028856\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 1, valid_loss: 0.02094811716905007\n",
      "SEED: 2, FOLD: 5, EPOCH: 2, train_loss: 0.023183811858699128\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 2, valid_loss: 0.019070386026914302\n",
      "SEED: 2, FOLD: 5, EPOCH: 3, train_loss: 0.021814031098541374\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 3, valid_loss: 0.018337624290814765\n",
      "SEED: 2, FOLD: 5, EPOCH: 4, train_loss: 0.021092253762322502\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 4, valid_loss: 0.0179093093253099\n",
      "SEED: 2, FOLD: 5, EPOCH: 5, train_loss: 0.02065536523288166\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 5, valid_loss: 0.017545448831067637\n",
      "SEED: 2, FOLD: 5, EPOCH: 6, train_loss: 0.0203622723300312\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 6, valid_loss: 0.017494455338097535\n",
      "SEED: 2, FOLD: 5, EPOCH: 7, train_loss: 0.02015490339112443\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 7, valid_loss: 0.01721016217309695\n",
      "SEED: 2, FOLD: 5, EPOCH: 8, train_loss: 0.020008131182072935\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 8, valid_loss: 0.017206483520567417\n",
      "SEED: 2, FOLD: 5, EPOCH: 9, train_loss: 0.019778684184357926\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 9, valid_loss: 0.01712955147601091\n",
      "SEED: 2, FOLD: 5, EPOCH: 10, train_loss: 0.019585795524353918\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 10, valid_loss: 0.017071479501632545\n",
      "SEED: 2, FOLD: 5, EPOCH: 11, train_loss: 0.019460367718459787\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 11, valid_loss: 0.016593259401046313\n",
      "SEED: 2, FOLD: 5, EPOCH: 12, train_loss: 0.01927794752692854\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 12, valid_loss: 0.016909771383954927\n",
      "SEED: 2, FOLD: 5, EPOCH: 13, train_loss: 0.019119410498722178\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 13, valid_loss: 0.01652233933026974\n",
      "SEED: 2, FOLD: 5, EPOCH: 14, train_loss: 0.0188150617822602\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 14, valid_loss: 0.016506355470762804\n",
      "SEED: 2, FOLD: 5, EPOCH: 15, train_loss: 0.018609389134154126\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 15, valid_loss: 0.016504326548713904\n",
      "SEED: 2, FOLD: 5, EPOCH: 16, train_loss: 0.01824691632410159\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 16, valid_loss: 0.016584511559743147\n",
      "SEED: 2, FOLD: 5, EPOCH: 17, train_loss: 0.01787774471213689\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 17, valid_loss: 0.016233690512868073\n",
      "SEED: 2, FOLD: 5, EPOCH: 18, train_loss: 0.01732619447834991\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 18, valid_loss: 0.016259833955420896\n",
      "SEED: 2, FOLD: 5, EPOCH: 19, train_loss: 0.016740830275355965\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 19, valid_loss: 0.01634869337655031\n",
      "SEED: 2, FOLD: 5, EPOCH: 20, train_loss: 0.01605855765425273\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 20, valid_loss: 0.016359122613301642\n",
      "SEED: 2, FOLD: 5, EPOCH: 21, train_loss: 0.015240635269799747\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 21, valid_loss: 0.016286932720014684\n",
      "SEED: 2, FOLD: 5, EPOCH: 22, train_loss: 0.01439218026762073\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 22, valid_loss: 0.016316877033274908\n",
      "SEED: 2, FOLD: 5, EPOCH: 23, train_loss: 0.013632002878128676\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 23, valid_loss: 0.016328781126783445\n",
      "SEED: 2, FOLD: 5, EPOCH: 24, train_loss: 0.013092641555074905\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 24, valid_loss: 0.016326927078457978\n",
      "SEED: 2, FOLD: 5, EPOCH: 25, train_loss: 0.01288903650601168\n",
      "SEED: 2 ,FOLD: 5, EPOCH: 25, valid_loss: 0.016341996020995654\n",
      "SEED: 2, FOLD: 6, EPOCH: 0, train_loss: 0.6226102238571322\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 0, valid_loss: 0.15725171680633837\n",
      "SEED: 2, FOLD: 6, EPOCH: 1, train_loss: 0.03906173437733103\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 1, valid_loss: 0.020344766286703255\n",
      "SEED: 2, FOLD: 6, EPOCH: 2, train_loss: 0.022626618502309192\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 2, valid_loss: 0.018545221967192795\n",
      "SEED: 2, FOLD: 6, EPOCH: 3, train_loss: 0.021278660140327504\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 3, valid_loss: 0.01777017331467225\n",
      "SEED: 2, FOLD: 6, EPOCH: 4, train_loss: 0.02058309321669308\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 4, valid_loss: 0.01753330187728772\n",
      "SEED: 2, FOLD: 6, EPOCH: 5, train_loss: 0.02028183196042035\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 5, valid_loss: 0.01734857461773432\n",
      "SEED: 2, FOLD: 6, EPOCH: 6, train_loss: 0.02002813943938629\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 6, valid_loss: 0.017038598083532773\n",
      "SEED: 2, FOLD: 6, EPOCH: 7, train_loss: 0.019945628412470624\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 7, valid_loss: 0.01731613650918007\n",
      "SEED: 2, FOLD: 6, EPOCH: 8, train_loss: 0.019803035198836715\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 8, valid_loss: 0.01707740371616987\n",
      "SEED: 2, FOLD: 6, EPOCH: 9, train_loss: 0.01961144485284348\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 9, valid_loss: 0.016758222992603596\n",
      "SEED: 2, FOLD: 6, EPOCH: 10, train_loss: 0.019611924634994688\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 10, valid_loss: 0.016869626366175137\n",
      "SEED: 2, FOLD: 6, EPOCH: 11, train_loss: 0.019408393827443186\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 11, valid_loss: 0.016768405500512857\n",
      "SEED: 2, FOLD: 6, EPOCH: 12, train_loss: 0.019317276952033106\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 12, valid_loss: 0.016736274155286644\n",
      "SEED: 2, FOLD: 6, EPOCH: 13, train_loss: 0.019190669361803983\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 13, valid_loss: 0.016574701724144127\n",
      "SEED: 2, FOLD: 6, EPOCH: 14, train_loss: 0.019003070790219952\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 14, valid_loss: 0.016412946323935803\n",
      "SEED: 2, FOLD: 6, EPOCH: 15, train_loss: 0.01868285482900368\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 15, valid_loss: 0.01660319324582815\n",
      "SEED: 2, FOLD: 6, EPOCH: 16, train_loss: 0.01843150445839038\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 16, valid_loss: 0.016249758406327322\n",
      "SEED: 2, FOLD: 6, EPOCH: 17, train_loss: 0.018102996466631018\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 17, valid_loss: 0.016199920039910536\n",
      "SEED: 2, FOLD: 6, EPOCH: 18, train_loss: 0.01766030183313666\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 18, valid_loss: 0.01607444868064844\n",
      "SEED: 2, FOLD: 6, EPOCH: 19, train_loss: 0.01718124861803812\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 19, valid_loss: 0.016047334011930686\n",
      "SEED: 2, FOLD: 6, EPOCH: 20, train_loss: 0.016515974056076358\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 20, valid_loss: 0.01602105373659959\n",
      "SEED: 2, FOLD: 6, EPOCH: 21, train_loss: 0.01579785320555439\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 21, valid_loss: 0.015995553121543847\n",
      "SEED: 2, FOLD: 6, EPOCH: 22, train_loss: 0.014974188902792899\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 22, valid_loss: 0.016092009699115388\n",
      "SEED: 2, FOLD: 6, EPOCH: 23, train_loss: 0.014238222904906079\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 23, valid_loss: 0.016090114457676045\n",
      "SEED: 2, FOLD: 6, EPOCH: 24, train_loss: 0.013689010769028115\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 24, valid_loss: 0.016088834748818323\n",
      "SEED: 2, FOLD: 6, EPOCH: 25, train_loss: 0.013435325761501854\n",
      "SEED: 2 ,FOLD: 6, EPOCH: 25, valid_loss: 0.016094569188471023\n",
      "SEED: 3, FOLD: 0, EPOCH: 0, train_loss: 0.6216532215476036\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 0, valid_loss: 0.1638318391946646\n",
      "SEED: 3, FOLD: 0, EPOCH: 1, train_loss: 0.03924724812040458\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 1, valid_loss: 0.020515417393583518\n",
      "SEED: 3, FOLD: 0, EPOCH: 2, train_loss: 0.022592415278022353\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 2, valid_loss: 0.018765192908736374\n",
      "SEED: 3, FOLD: 0, EPOCH: 3, train_loss: 0.021100369684800908\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017872014584449623\n",
      "SEED: 3, FOLD: 0, EPOCH: 4, train_loss: 0.02046985546680721\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017786406267147798\n",
      "SEED: 3, FOLD: 0, EPOCH: 5, train_loss: 0.020205321570707334\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 5, valid_loss: 0.01739730700277365\n",
      "SEED: 3, FOLD: 0, EPOCH: 6, train_loss: 0.020072917982533172\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017748948043355577\n",
      "SEED: 3, FOLD: 0, EPOCH: 7, train_loss: 0.019894326181226486\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017291932581708983\n",
      "SEED: 3, FOLD: 0, EPOCH: 8, train_loss: 0.01978795260593698\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017300555625787147\n",
      "SEED: 3, FOLD: 0, EPOCH: 9, train_loss: 0.019698622133079415\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 9, valid_loss: 0.017063932493329048\n",
      "SEED: 3, FOLD: 0, EPOCH: 10, train_loss: 0.019566831329988467\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 10, valid_loss: 0.01702873007609294\n",
      "SEED: 3, FOLD: 0, EPOCH: 11, train_loss: 0.019464522902224515\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01701563410460949\n",
      "SEED: 3, FOLD: 0, EPOCH: 12, train_loss: 0.019291233548240083\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01689285856599991\n",
      "SEED: 3, FOLD: 0, EPOCH: 13, train_loss: 0.01913054131374166\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016870465846015856\n",
      "SEED: 3, FOLD: 0, EPOCH: 14, train_loss: 0.018971836949522432\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 14, valid_loss: 0.01684695969407375\n",
      "SEED: 3, FOLD: 0, EPOCH: 15, train_loss: 0.018720537071695197\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016651079130287353\n",
      "SEED: 3, FOLD: 0, EPOCH: 16, train_loss: 0.018427143225798737\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016658971229424842\n",
      "SEED: 3, FOLD: 0, EPOCH: 17, train_loss: 0.018114769894226983\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016355946516761415\n",
      "SEED: 3, FOLD: 0, EPOCH: 18, train_loss: 0.0176967583042947\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016275062798880614\n",
      "SEED: 3, FOLD: 0, EPOCH: 19, train_loss: 0.017214623279869556\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 19, valid_loss: 0.01621584207392656\n",
      "SEED: 3, FOLD: 0, EPOCH: 20, train_loss: 0.016566132874907675\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016285884767197646\n",
      "SEED: 3, FOLD: 0, EPOCH: 21, train_loss: 0.015898542831072938\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016215461664474927\n",
      "SEED: 3, FOLD: 0, EPOCH: 22, train_loss: 0.015090997720993048\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01626806935438743\n",
      "SEED: 3, FOLD: 0, EPOCH: 23, train_loss: 0.014326183452598146\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 23, valid_loss: 0.016252798959612846\n",
      "SEED: 3, FOLD: 0, EPOCH: 24, train_loss: 0.013820018380175571\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 24, valid_loss: 0.01629891346853513\n",
      "SEED: 3, FOLD: 0, EPOCH: 25, train_loss: 0.013581900593094729\n",
      "SEED: 3 ,FOLD: 0, EPOCH: 25, valid_loss: 0.016303163809845082\n",
      "SEED: 3, FOLD: 1, EPOCH: 0, train_loss: 0.6211496430474359\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 0, valid_loss: 0.17538883823614854\n",
      "SEED: 3, FOLD: 1, EPOCH: 1, train_loss: 0.03924703411757946\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 1, valid_loss: 0.020069763494225647\n",
      "SEED: 3, FOLD: 1, EPOCH: 2, train_loss: 0.022272403301620804\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 2, valid_loss: 0.018367715609761383\n",
      "SEED: 3, FOLD: 1, EPOCH: 3, train_loss: 0.021216743751554877\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 3, valid_loss: 0.017575626261532307\n",
      "SEED: 3, FOLD: 1, EPOCH: 4, train_loss: 0.020595401424813916\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 4, valid_loss: 0.01731240305189903\n",
      "SEED: 3, FOLD: 1, EPOCH: 5, train_loss: 0.020236958170662057\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 5, valid_loss: 0.016896481124254372\n",
      "SEED: 3, FOLD: 1, EPOCH: 6, train_loss: 0.02004069190573048\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 6, valid_loss: 0.016949166758702353\n",
      "SEED: 3, FOLD: 1, EPOCH: 7, train_loss: 0.019921613731295675\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 7, valid_loss: 0.01680840666477497\n",
      "SEED: 3, FOLD: 1, EPOCH: 8, train_loss: 0.019833047647733946\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 8, valid_loss: 0.01689608323459442\n",
      "SEED: 3, FOLD: 1, EPOCH: 9, train_loss: 0.019717919086483685\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 9, valid_loss: 0.016822823968071204\n",
      "SEED: 3, FOLD: 1, EPOCH: 10, train_loss: 0.01961196000008164\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 10, valid_loss: 0.016559663945092604\n",
      "SEED: 3, FOLD: 1, EPOCH: 11, train_loss: 0.01944649060936393\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 11, valid_loss: 0.016836054981327973\n",
      "SEED: 3, FOLD: 1, EPOCH: 12, train_loss: 0.01932855063696971\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016706853961715333\n",
      "SEED: 3, FOLD: 1, EPOCH: 13, train_loss: 0.019195702128313685\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016443597009548776\n",
      "SEED: 3, FOLD: 1, EPOCH: 14, train_loss: 0.019004337112041744\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016297544854191635\n",
      "SEED: 3, FOLD: 1, EPOCH: 15, train_loss: 0.018758147803915513\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016362581975184955\n",
      "SEED: 3, FOLD: 1, EPOCH: 16, train_loss: 0.018452069143185746\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016162513110500116\n",
      "SEED: 3, FOLD: 1, EPOCH: 17, train_loss: 0.018151808026674633\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 17, valid_loss: 0.01632887375755952\n",
      "SEED: 3, FOLD: 1, EPOCH: 18, train_loss: 0.017768252968184045\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 18, valid_loss: 0.01600156667140814\n",
      "SEED: 3, FOLD: 1, EPOCH: 19, train_loss: 0.017224381489024776\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01592661075007457\n",
      "SEED: 3, FOLD: 1, EPOCH: 20, train_loss: 0.01656278723699821\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 20, valid_loss: 0.015915558530161016\n",
      "SEED: 3, FOLD: 1, EPOCH: 21, train_loss: 0.015922986474391575\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01589026631644139\n",
      "SEED: 3, FOLD: 1, EPOCH: 22, train_loss: 0.015112434463525141\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 22, valid_loss: 0.0159267820417881\n",
      "SEED: 3, FOLD: 1, EPOCH: 23, train_loss: 0.014387095296705092\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01596152359763017\n",
      "SEED: 3, FOLD: 1, EPOCH: 24, train_loss: 0.013821285494880096\n",
      "SEED: 3 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015944889603325955\n",
      "SEED: 3, FOLD: 2, EPOCH: 0, train_loss: 0.62149255460984\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 0, valid_loss: 0.1826486954322228\n",
      "SEED: 3, FOLD: 2, EPOCH: 1, train_loss: 0.03941945668712661\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 1, valid_loss: 0.02053388050542428\n",
      "SEED: 3, FOLD: 2, EPOCH: 2, train_loss: 0.02243404571168326\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 2, valid_loss: 0.01849947626201006\n",
      "SEED: 3, FOLD: 2, EPOCH: 3, train_loss: 0.021206383819918375\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 3, valid_loss: 0.018003771511407998\n",
      "SEED: 3, FOLD: 2, EPOCH: 4, train_loss: 0.020712075830512756\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017560380439345654\n",
      "SEED: 3, FOLD: 2, EPOCH: 5, train_loss: 0.020365264845659602\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017203494906425476\n",
      "SEED: 3, FOLD: 2, EPOCH: 6, train_loss: 0.020153850115634298\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 6, valid_loss: 0.01735168580825512\n",
      "SEED: 3, FOLD: 2, EPOCH: 7, train_loss: 0.02004949383538317\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 7, valid_loss: 0.01723131838326271\n",
      "SEED: 3, FOLD: 2, EPOCH: 8, train_loss: 0.0199554029197709\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 8, valid_loss: 0.016966733938226335\n",
      "SEED: 3, FOLD: 2, EPOCH: 9, train_loss: 0.019773075784984474\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 9, valid_loss: 0.016911859695728008\n",
      "SEED: 3, FOLD: 2, EPOCH: 10, train_loss: 0.01972078695591237\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017259442175810154\n",
      "SEED: 3, FOLD: 2, EPOCH: 11, train_loss: 0.01960696347963971\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016789020182421573\n",
      "SEED: 3, FOLD: 2, EPOCH: 12, train_loss: 0.01938583789947065\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 12, valid_loss: 0.016818869715699784\n",
      "SEED: 3, FOLD: 2, EPOCH: 13, train_loss: 0.01921292014319349\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 13, valid_loss: 0.01679753168271138\n",
      "SEED: 3, FOLD: 2, EPOCH: 14, train_loss: 0.019028308549644175\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016399062166993435\n",
      "SEED: 3, FOLD: 2, EPOCH: 15, train_loss: 0.01881178133693096\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016441134592661492\n",
      "SEED: 3, FOLD: 2, EPOCH: 16, train_loss: 0.018587238960773557\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016195088195113037\n",
      "SEED: 3, FOLD: 2, EPOCH: 17, train_loss: 0.01828077490869406\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01624601620894212\n",
      "SEED: 3, FOLD: 2, EPOCH: 18, train_loss: 0.017860470188630594\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016001588808229335\n",
      "SEED: 3, FOLD: 2, EPOCH: 19, train_loss: 0.017393293702421157\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01600475523334283\n",
      "SEED: 3, FOLD: 2, EPOCH: 20, train_loss: 0.016791165290350043\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 20, valid_loss: 0.015853797372144002\n",
      "SEED: 3, FOLD: 2, EPOCH: 21, train_loss: 0.01608811745520782\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 21, valid_loss: 0.015973154097222365\n",
      "SEED: 3, FOLD: 2, EPOCH: 22, train_loss: 0.015374417416751385\n",
      "SEED: 3 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01593437884002924\n",
      "SEED: 3, FOLD: 3, EPOCH: 0, train_loss: 0.6201422530654315\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 0, valid_loss: 0.1577103493305353\n",
      "SEED: 3, FOLD: 3, EPOCH: 1, train_loss: 0.03911027752769154\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 1, valid_loss: 0.020855239664132778\n",
      "SEED: 3, FOLD: 3, EPOCH: 2, train_loss: 0.02250732043506326\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018581927539064333\n",
      "SEED: 3, FOLD: 3, EPOCH: 3, train_loss: 0.021299505933515123\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 3, valid_loss: 0.017852941241401892\n",
      "SEED: 3, FOLD: 3, EPOCH: 4, train_loss: 0.020665880267483158\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017650484179074947\n",
      "SEED: 3, FOLD: 3, EPOCH: 5, train_loss: 0.020330782048404217\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 5, valid_loss: 0.0177829794299144\n",
      "SEED: 3, FOLD: 3, EPOCH: 6, train_loss: 0.020147432975873753\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017490065871522978\n",
      "SEED: 3, FOLD: 3, EPOCH: 7, train_loss: 0.019967152485372248\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017365255034886874\n",
      "SEED: 3, FOLD: 3, EPOCH: 8, train_loss: 0.019867900683469063\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 8, valid_loss: 0.01703256368637085\n",
      "SEED: 3, FOLD: 3, EPOCH: 9, train_loss: 0.019806258556609217\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 9, valid_loss: 0.016893748552180253\n",
      "SEED: 3, FOLD: 3, EPOCH: 10, train_loss: 0.019652804510818946\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 10, valid_loss: 0.016962896172816936\n",
      "SEED: 3, FOLD: 3, EPOCH: 11, train_loss: 0.019518614822142833\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 11, valid_loss: 0.016864974338274736\n",
      "SEED: 3, FOLD: 3, EPOCH: 12, train_loss: 0.019345335536510556\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016823153799543016\n",
      "SEED: 3, FOLD: 3, EPOCH: 13, train_loss: 0.01921415897841389\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01677228739628425\n",
      "SEED: 3, FOLD: 3, EPOCH: 14, train_loss: 0.019039602622993895\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 14, valid_loss: 0.01637651864439249\n",
      "SEED: 3, FOLD: 3, EPOCH: 15, train_loss: 0.018814581849083706\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016610080662828226\n",
      "SEED: 3, FOLD: 3, EPOCH: 16, train_loss: 0.018611374185294717\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016603939736691806\n",
      "SEED: 3, FOLD: 3, EPOCH: 17, train_loss: 0.018280949292553438\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016211920202924654\n",
      "SEED: 3, FOLD: 3, EPOCH: 18, train_loss: 0.01786329491517028\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 18, valid_loss: 0.01616850423698242\n",
      "SEED: 3, FOLD: 3, EPOCH: 19, train_loss: 0.01735618101382578\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01608996630574648\n",
      "SEED: 3, FOLD: 3, EPOCH: 20, train_loss: 0.01677234806875522\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016127567953215197\n",
      "SEED: 3, FOLD: 3, EPOCH: 21, train_loss: 0.016166786625477915\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016030394543821994\n",
      "SEED: 3, FOLD: 3, EPOCH: 22, train_loss: 0.015439837969638206\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 22, valid_loss: 0.015984356260070436\n",
      "SEED: 3, FOLD: 3, EPOCH: 23, train_loss: 0.014763457927148085\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016022547864570066\n",
      "SEED: 3, FOLD: 3, EPOCH: 24, train_loss: 0.01429877824124855\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 24, valid_loss: 0.01604069325213249\n",
      "SEED: 3, FOLD: 3, EPOCH: 25, train_loss: 0.014084837009274476\n",
      "SEED: 3 ,FOLD: 3, EPOCH: 25, valid_loss: 0.016034798624996956\n",
      "SEED: 3, FOLD: 4, EPOCH: 0, train_loss: 0.6213608796934824\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 0, valid_loss: 0.21716134020915398\n",
      "SEED: 3, FOLD: 4, EPOCH: 1, train_loss: 0.039331117242171955\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 1, valid_loss: 0.020372487461337678\n",
      "SEED: 3, FOLD: 4, EPOCH: 2, train_loss: 0.022178129418878943\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018602347144713767\n",
      "SEED: 3, FOLD: 4, EPOCH: 3, train_loss: 0.021062849391553853\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 3, valid_loss: 0.018006004966222323\n",
      "SEED: 3, FOLD: 4, EPOCH: 4, train_loss: 0.020443138037178968\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017567888332101014\n",
      "SEED: 3, FOLD: 4, EPOCH: 5, train_loss: 0.02013418627147739\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017702144499008473\n",
      "SEED: 3, FOLD: 4, EPOCH: 6, train_loss: 0.020078881920592206\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017473244896301858\n",
      "SEED: 3, FOLD: 4, EPOCH: 7, train_loss: 0.01992101310374769\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017501648802023668\n",
      "SEED: 3, FOLD: 4, EPOCH: 8, train_loss: 0.0198481773353509\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017085622566250656\n",
      "SEED: 3, FOLD: 4, EPOCH: 9, train_loss: 0.01966050815944736\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017177361708420973\n",
      "SEED: 3, FOLD: 4, EPOCH: 10, train_loss: 0.019625423476099968\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01704613635173211\n",
      "SEED: 3, FOLD: 4, EPOCH: 11, train_loss: 0.01937790202429971\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 11, valid_loss: 0.017200686324101228\n",
      "SEED: 3, FOLD: 4, EPOCH: 12, train_loss: 0.019364646862487536\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 12, valid_loss: 0.017189864785625383\n",
      "SEED: 3, FOLD: 4, EPOCH: 13, train_loss: 0.01923338545335306\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016892795092784442\n",
      "SEED: 3, FOLD: 4, EPOCH: 14, train_loss: 0.01901842004342659\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016675814986228943\n",
      "SEED: 3, FOLD: 4, EPOCH: 15, train_loss: 0.018896315095795167\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016607023847217742\n",
      "SEED: 3, FOLD: 4, EPOCH: 16, train_loss: 0.0185823310670015\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016613071497816306\n",
      "SEED: 3, FOLD: 4, EPOCH: 17, train_loss: 0.018261624374301046\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 17, valid_loss: 0.01639027879215204\n",
      "SEED: 3, FOLD: 4, EPOCH: 18, train_loss: 0.01787695608328323\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016326268776678123\n",
      "SEED: 3, FOLD: 4, EPOCH: 19, train_loss: 0.017410085158976348\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016402006794053774\n",
      "SEED: 3, FOLD: 4, EPOCH: 20, train_loss: 0.016835122331473475\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 20, valid_loss: 0.0162988448372254\n",
      "SEED: 3, FOLD: 4, EPOCH: 21, train_loss: 0.016113242939920037\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 21, valid_loss: 0.016434692419492282\n",
      "SEED: 3, FOLD: 4, EPOCH: 22, train_loss: 0.015340517526744184\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 22, valid_loss: 0.016400935916373365\n",
      "SEED: 3, FOLD: 4, EPOCH: 23, train_loss: 0.014725239167140948\n",
      "SEED: 3 ,FOLD: 4, EPOCH: 23, valid_loss: 0.016418360316982634\n",
      "SEED: 3, FOLD: 5, EPOCH: 0, train_loss: 0.6207291413400624\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 0, valid_loss: 0.17718925498999083\n",
      "SEED: 3, FOLD: 5, EPOCH: 1, train_loss: 0.03899091827003537\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 1, valid_loss: 0.020102117067346208\n",
      "SEED: 3, FOLD: 5, EPOCH: 2, train_loss: 0.022138476824840984\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 2, valid_loss: 0.018382020796147678\n",
      "SEED: 3, FOLD: 5, EPOCH: 3, train_loss: 0.021041879933830852\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 3, valid_loss: 0.01783450463643441\n",
      "SEED: 3, FOLD: 5, EPOCH: 4, train_loss: 0.020541710703558213\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 4, valid_loss: 0.017738008226912755\n",
      "SEED: 3, FOLD: 5, EPOCH: 5, train_loss: 0.020263641040671517\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 5, valid_loss: 0.01757698327016372\n",
      "SEED: 3, FOLD: 5, EPOCH: 6, train_loss: 0.020040896192595765\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 6, valid_loss: 0.017110236418934967\n",
      "SEED: 3, FOLD: 5, EPOCH: 7, train_loss: 0.01987126298450135\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 7, valid_loss: 0.017077761200758126\n",
      "SEED: 3, FOLD: 5, EPOCH: 8, train_loss: 0.019768564408091275\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 8, valid_loss: 0.017133165938922994\n",
      "SEED: 3, FOLD: 5, EPOCH: 9, train_loss: 0.01975610580396008\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 9, valid_loss: 0.01717787479551939\n",
      "SEED: 3, FOLD: 5, EPOCH: 10, train_loss: 0.019660433225736424\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 10, valid_loss: 0.01688019186258316\n",
      "SEED: 3, FOLD: 5, EPOCH: 11, train_loss: 0.019525285785061283\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 11, valid_loss: 0.016721100618059818\n",
      "SEED: 3, FOLD: 5, EPOCH: 12, train_loss: 0.019375463368723523\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 12, valid_loss: 0.016594364092900202\n",
      "SEED: 3, FOLD: 5, EPOCH: 13, train_loss: 0.019214046439407644\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 13, valid_loss: 0.016684041931652106\n",
      "SEED: 3, FOLD: 5, EPOCH: 14, train_loss: 0.019052365517898184\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 14, valid_loss: 0.016589515985777743\n",
      "SEED: 3, FOLD: 5, EPOCH: 15, train_loss: 0.018851159669056133\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 15, valid_loss: 0.016383025651940934\n",
      "SEED: 3, FOLD: 5, EPOCH: 16, train_loss: 0.018546469031354866\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 16, valid_loss: 0.016219296134435214\n",
      "SEED: 3, FOLD: 5, EPOCH: 17, train_loss: 0.018271513937695605\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 17, valid_loss: 0.016267119620281916\n",
      "SEED: 3, FOLD: 5, EPOCH: 18, train_loss: 0.017883035530512396\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 18, valid_loss: 0.016096183600334022\n",
      "SEED: 3, FOLD: 5, EPOCH: 19, train_loss: 0.01738550395679635\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 19, valid_loss: 0.016028406743246775\n",
      "SEED: 3, FOLD: 5, EPOCH: 20, train_loss: 0.01684954099206103\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 20, valid_loss: 0.01600386596356447\n",
      "SEED: 3, FOLD: 5, EPOCH: 21, train_loss: 0.016172414834334237\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 21, valid_loss: 0.01592153697632826\n",
      "SEED: 3, FOLD: 5, EPOCH: 22, train_loss: 0.015480068310893871\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 22, valid_loss: 0.015875865848591693\n",
      "SEED: 3, FOLD: 5, EPOCH: 23, train_loss: 0.01474539452307933\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 23, valid_loss: 0.015862185651293166\n",
      "SEED: 3, FOLD: 5, EPOCH: 24, train_loss: 0.014248801156173687\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 24, valid_loss: 0.015899230654423054\n",
      "SEED: 3, FOLD: 5, EPOCH: 25, train_loss: 0.014003855767785697\n",
      "SEED: 3 ,FOLD: 5, EPOCH: 25, valid_loss: 0.015902065528699987\n",
      "SEED: 3, FOLD: 6, EPOCH: 0, train_loss: 0.6204928574529854\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 0, valid_loss: 0.21559565800886887\n",
      "SEED: 3, FOLD: 6, EPOCH: 1, train_loss: 0.03897582354477128\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 1, valid_loss: 0.02027255525955787\n",
      "SEED: 3, FOLD: 6, EPOCH: 2, train_loss: 0.022279438613032974\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 2, valid_loss: 0.018524248009690873\n",
      "SEED: 3, FOLD: 6, EPOCH: 3, train_loss: 0.021231461568055925\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 3, valid_loss: 0.018126313073130753\n",
      "SEED: 3, FOLD: 6, EPOCH: 4, train_loss: 0.02065245283616556\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 4, valid_loss: 0.0179234015253874\n",
      "SEED: 3, FOLD: 6, EPOCH: 5, train_loss: 0.020354334843923915\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 5, valid_loss: 0.01734550053683611\n",
      "SEED: 3, FOLD: 6, EPOCH: 6, train_loss: 0.020231877101232875\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 6, valid_loss: 0.017184242606163025\n",
      "SEED: 3, FOLD: 6, EPOCH: 7, train_loss: 0.020016348215977888\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 7, valid_loss: 0.017134170835981004\n",
      "SEED: 3, FOLD: 6, EPOCH: 8, train_loss: 0.019784585774146223\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 8, valid_loss: 0.01702174558662451\n",
      "SEED: 3, FOLD: 6, EPOCH: 9, train_loss: 0.019742189302436403\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 9, valid_loss: 0.017108530809099857\n",
      "SEED: 3, FOLD: 6, EPOCH: 10, train_loss: 0.019588821416569722\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 10, valid_loss: 0.017059268429875374\n",
      "SEED: 3, FOLD: 6, EPOCH: 11, train_loss: 0.019462951056256488\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 11, valid_loss: 0.017026675291932546\n",
      "SEED: 3, FOLD: 6, EPOCH: 12, train_loss: 0.019406650039191183\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 12, valid_loss: 0.016914206198774852\n",
      "SEED: 3, FOLD: 6, EPOCH: 13, train_loss: 0.01918159251579562\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 13, valid_loss: 0.016641584368279345\n",
      "SEED: 3, FOLD: 6, EPOCH: 14, train_loss: 0.01906075741390924\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 14, valid_loss: 0.0166440186305688\n",
      "SEED: 3, FOLD: 6, EPOCH: 15, train_loss: 0.0187551188408523\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 15, valid_loss: 0.01667488566957987\n",
      "SEED: 3, FOLD: 6, EPOCH: 16, train_loss: 0.018579464909192676\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 16, valid_loss: 0.016431740914972928\n",
      "SEED: 3, FOLD: 6, EPOCH: 17, train_loss: 0.01825053967233445\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 17, valid_loss: 0.016318286984012678\n",
      "SEED: 3, FOLD: 6, EPOCH: 18, train_loss: 0.017860523274017347\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 18, valid_loss: 0.016243628727701995\n",
      "SEED: 3, FOLD: 6, EPOCH: 19, train_loss: 0.017407186002143332\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 19, valid_loss: 0.01616410932575281\n",
      "SEED: 3, FOLD: 6, EPOCH: 20, train_loss: 0.016806797753717448\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 20, valid_loss: 0.016173681172613915\n",
      "SEED: 3, FOLD: 6, EPOCH: 21, train_loss: 0.016157878978127562\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 21, valid_loss: 0.0160580465856653\n",
      "SEED: 3, FOLD: 6, EPOCH: 22, train_loss: 0.01538316999889306\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 22, valid_loss: 0.0161423789193997\n",
      "SEED: 3, FOLD: 6, EPOCH: 23, train_loss: 0.014699263787652189\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 23, valid_loss: 0.016184053025566615\n",
      "SEED: 3, FOLD: 6, EPOCH: 24, train_loss: 0.014179452045543774\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 24, valid_loss: 0.016163255732793074\n",
      "SEED: 3, FOLD: 6, EPOCH: 25, train_loss: 0.013909043744206429\n",
      "SEED: 3 ,FOLD: 6, EPOCH: 25, valid_loss: 0.01614800410775038\n",
      "SEED: 4, FOLD: 0, EPOCH: 0, train_loss: 0.6227057660753662\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 0, valid_loss: 0.20347106227507958\n",
      "SEED: 4, FOLD: 0, EPOCH: 1, train_loss: 0.03910808859241975\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 1, valid_loss: 0.020458063397269983\n",
      "SEED: 4, FOLD: 0, EPOCH: 2, train_loss: 0.022183279003444557\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 2, valid_loss: 0.018441467474286374\n",
      "SEED: 4, FOLD: 0, EPOCH: 3, train_loss: 0.021086750828937906\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017860500141978264\n",
      "SEED: 4, FOLD: 0, EPOCH: 4, train_loss: 0.020409068294070864\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017575524317530487\n",
      "SEED: 4, FOLD: 0, EPOCH: 5, train_loss: 0.02004220160479481\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 5, valid_loss: 0.0173847100769098\n",
      "SEED: 4, FOLD: 0, EPOCH: 6, train_loss: 0.019908445484533504\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017708364301002942\n",
      "SEED: 4, FOLD: 0, EPOCH: 7, train_loss: 0.019834660346040856\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017097635194659233\n",
      "SEED: 4, FOLD: 0, EPOCH: 8, train_loss: 0.019652540115891275\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 8, valid_loss: 0.01701935609945884\n",
      "SEED: 4, FOLD: 0, EPOCH: 9, train_loss: 0.019528373950035184\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 9, valid_loss: 0.016977721108840063\n",
      "SEED: 4, FOLD: 0, EPOCH: 10, train_loss: 0.01948374295858918\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017056932816138633\n",
      "SEED: 4, FOLD: 0, EPOCH: 11, train_loss: 0.019391138861710962\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01712298164000878\n",
      "SEED: 4, FOLD: 0, EPOCH: 12, train_loss: 0.019202025280006835\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 12, valid_loss: 0.01689461389413247\n",
      "SEED: 4, FOLD: 0, EPOCH: 13, train_loss: 0.01894132760227532\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016816529230429575\n",
      "SEED: 4, FOLD: 0, EPOCH: 14, train_loss: 0.018778602491963555\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 14, valid_loss: 0.016913776787427757\n",
      "SEED: 4, FOLD: 0, EPOCH: 15, train_loss: 0.018624300640579815\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016440852903402768\n",
      "SEED: 4, FOLD: 0, EPOCH: 16, train_loss: 0.018229059774327924\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01646306817061626\n",
      "SEED: 4, FOLD: 0, EPOCH: 17, train_loss: 0.017898198544374994\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 17, valid_loss: 0.016460304363415793\n",
      "SEED: 4, FOLD: 0, EPOCH: 18, train_loss: 0.017492000567349227\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016406286794405717\n",
      "SEED: 4, FOLD: 0, EPOCH: 19, train_loss: 0.016815296147723455\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 19, valid_loss: 0.01633722335100174\n",
      "SEED: 4, FOLD: 0, EPOCH: 20, train_loss: 0.016140589314336713\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016299749008164957\n",
      "SEED: 4, FOLD: 0, EPOCH: 21, train_loss: 0.015380638689306137\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 21, valid_loss: 0.01631796245391552\n",
      "SEED: 4, FOLD: 0, EPOCH: 22, train_loss: 0.014588702595918565\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 22, valid_loss: 0.016282943865427606\n",
      "SEED: 4, FOLD: 0, EPOCH: 23, train_loss: 0.013739968952093576\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01642244953948718\n",
      "SEED: 4, FOLD: 0, EPOCH: 24, train_loss: 0.01317239594268235\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 24, valid_loss: 0.016408455844681997\n",
      "SEED: 4, FOLD: 0, EPOCH: 25, train_loss: 0.012958142969354585\n",
      "SEED: 4 ,FOLD: 0, EPOCH: 25, valid_loss: 0.01639948470088152\n",
      "SEED: 4, FOLD: 1, EPOCH: 0, train_loss: 0.6244328166987445\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 0, valid_loss: 0.1876950768324045\n",
      "SEED: 4, FOLD: 1, EPOCH: 1, train_loss: 0.03955484395595016\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 1, valid_loss: 0.020303077422655545\n",
      "SEED: 4, FOLD: 1, EPOCH: 2, train_loss: 0.022365650942398084\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 2, valid_loss: 0.018667502185473077\n",
      "SEED: 4, FOLD: 1, EPOCH: 3, train_loss: 0.02126353739987354\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 3, valid_loss: 0.01807354476589423\n",
      "SEED: 4, FOLD: 1, EPOCH: 4, train_loss: 0.02065452721876067\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017776909212653454\n",
      "SEED: 4, FOLD: 1, EPOCH: 5, train_loss: 0.020434924904760475\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 5, valid_loss: 0.018267610253622897\n",
      "SEED: 4, FOLD: 1, EPOCH: 6, train_loss: 0.02075410375019183\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017399869715938203\n",
      "SEED: 4, FOLD: 1, EPOCH: 7, train_loss: 0.02023357988612072\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017399894288526133\n",
      "SEED: 4, FOLD: 1, EPOCH: 8, train_loss: 0.020048537165731996\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 8, valid_loss: 0.0171348789276985\n",
      "SEED: 4, FOLD: 1, EPOCH: 9, train_loss: 0.019937311022265536\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01766592672524544\n",
      "SEED: 4, FOLD: 1, EPOCH: 10, train_loss: 0.019827049099714368\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01720257640744631\n",
      "SEED: 4, FOLD: 1, EPOCH: 11, train_loss: 0.019678411023640954\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 11, valid_loss: 0.01685634097800805\n",
      "SEED: 4, FOLD: 1, EPOCH: 12, train_loss: 0.019591436142454278\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01678322212627301\n",
      "SEED: 4, FOLD: 1, EPOCH: 13, train_loss: 0.01938793292218769\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01676810274903591\n",
      "SEED: 4, FOLD: 1, EPOCH: 14, train_loss: 0.019218005642697617\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016761082940949842\n",
      "SEED: 4, FOLD: 1, EPOCH: 15, train_loss: 0.019008466193603503\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01644575008406089\n",
      "SEED: 4, FOLD: 1, EPOCH: 16, train_loss: 0.0186554773937206\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016541446272570353\n",
      "SEED: 4, FOLD: 1, EPOCH: 17, train_loss: 0.01840427439861201\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016301077002516158\n",
      "SEED: 4, FOLD: 1, EPOCH: 18, train_loss: 0.018032087441030388\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016322802035854414\n",
      "SEED: 4, FOLD: 1, EPOCH: 19, train_loss: 0.017567813270599454\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016116356763702173\n",
      "SEED: 4, FOLD: 1, EPOCH: 20, train_loss: 0.016996656922069756\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 20, valid_loss: 0.0160663491831376\n",
      "SEED: 4, FOLD: 1, EPOCH: 21, train_loss: 0.0163749503475186\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01606074211975703\n",
      "SEED: 4, FOLD: 1, EPOCH: 22, train_loss: 0.015698467519738385\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 22, valid_loss: 0.01618350390344858\n",
      "SEED: 4, FOLD: 1, EPOCH: 23, train_loss: 0.015057614513647717\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 23, valid_loss: 0.01613121537061838\n",
      "SEED: 4, FOLD: 1, EPOCH: 24, train_loss: 0.014638424599291506\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 24, valid_loss: 0.01614042830008727\n",
      "SEED: 4, FOLD: 1, EPOCH: 25, train_loss: 0.014424936732629666\n",
      "SEED: 4 ,FOLD: 1, EPOCH: 25, valid_loss: 0.01613059940819557\n",
      "SEED: 4, FOLD: 2, EPOCH: 0, train_loss: 0.6233454278192004\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 0, valid_loss: 0.18985813626876244\n",
      "SEED: 4, FOLD: 2, EPOCH: 1, train_loss: 0.03955105213901481\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 1, valid_loss: 0.020326152587166198\n",
      "SEED: 4, FOLD: 2, EPOCH: 2, train_loss: 0.02218024812739443\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 2, valid_loss: 0.01832455747689192\n",
      "SEED: 4, FOLD: 2, EPOCH: 3, train_loss: 0.021126607986720832\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 3, valid_loss: 0.01817338175785083\n",
      "SEED: 4, FOLD: 2, EPOCH: 4, train_loss: 0.020608520915580762\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 4, valid_loss: 0.01740480916431317\n",
      "SEED: 4, FOLD: 2, EPOCH: 5, train_loss: 0.020275794447877922\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 5, valid_loss: 0.01721036469993683\n",
      "SEED: 4, FOLD: 2, EPOCH: 6, train_loss: 0.02004891790046885\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 6, valid_loss: 0.016955281106325295\n",
      "SEED: 4, FOLD: 2, EPOCH: 7, train_loss: 0.01995591220219393\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017235773902099866\n",
      "SEED: 4, FOLD: 2, EPOCH: 8, train_loss: 0.0198846528608654\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 8, valid_loss: 0.016944823714976128\n",
      "SEED: 4, FOLD: 2, EPOCH: 9, train_loss: 0.019691712248164253\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 9, valid_loss: 0.016866264578241568\n",
      "SEED: 4, FOLD: 2, EPOCH: 10, train_loss: 0.019652863561704353\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 10, valid_loss: 0.01660210223725209\n",
      "SEED: 4, FOLD: 2, EPOCH: 11, train_loss: 0.019518579809448204\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016698977050299827\n",
      "SEED: 4, FOLD: 2, EPOCH: 12, train_loss: 0.019368520560296806\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01641511222204337\n",
      "SEED: 4, FOLD: 2, EPOCH: 13, train_loss: 0.019154615045802015\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016307502841720216\n",
      "SEED: 4, FOLD: 2, EPOCH: 14, train_loss: 0.018968257197254413\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 14, valid_loss: 0.016583282715426043\n",
      "SEED: 4, FOLD: 2, EPOCH: 15, train_loss: 0.0187774012116967\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016181777876157027\n",
      "SEED: 4, FOLD: 2, EPOCH: 16, train_loss: 0.01846398873808416\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 16, valid_loss: 0.0162600906422505\n",
      "SEED: 4, FOLD: 2, EPOCH: 17, train_loss: 0.0182041852307078\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01608741648781758\n",
      "SEED: 4, FOLD: 2, EPOCH: 18, train_loss: 0.01782496595704878\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 18, valid_loss: 0.015990588240898572\n",
      "SEED: 4, FOLD: 2, EPOCH: 19, train_loss: 0.017314461739482107\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01602315057355624\n",
      "SEED: 4, FOLD: 2, EPOCH: 20, train_loss: 0.016756995430065168\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 20, valid_loss: 0.015935066227729503\n",
      "SEED: 4, FOLD: 2, EPOCH: 21, train_loss: 0.01602985503504405\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 21, valid_loss: 0.015859840222849295\n",
      "SEED: 4, FOLD: 2, EPOCH: 22, train_loss: 0.015244539449545177\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01589905721350358\n",
      "SEED: 4, FOLD: 2, EPOCH: 23, train_loss: 0.014579860770420448\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01586609211965249\n",
      "SEED: 4, FOLD: 2, EPOCH: 24, train_loss: 0.014033521626245332\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 24, valid_loss: 0.015880688953285035\n",
      "SEED: 4, FOLD: 2, EPOCH: 25, train_loss: 0.01382408498761219\n",
      "SEED: 4 ,FOLD: 2, EPOCH: 25, valid_loss: 0.015865029623875253\n",
      "SEED: 4, FOLD: 3, EPOCH: 0, train_loss: 0.6206869694429475\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 0, valid_loss: 0.18015922491367048\n",
      "SEED: 4, FOLD: 3, EPOCH: 1, train_loss: 0.039418376151573016\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 1, valid_loss: 0.02082043900512732\n",
      "SEED: 4, FOLD: 3, EPOCH: 2, train_loss: 0.022387148988609377\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018905617439976104\n",
      "SEED: 4, FOLD: 3, EPOCH: 3, train_loss: 0.02112265573059385\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018310647601118453\n",
      "SEED: 4, FOLD: 3, EPOCH: 4, train_loss: 0.020493459132676188\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017724973651079032\n",
      "SEED: 4, FOLD: 3, EPOCH: 5, train_loss: 0.02020062121084413\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017343453203256313\n",
      "SEED: 4, FOLD: 3, EPOCH: 6, train_loss: 0.01994635587608492\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017632261348458435\n",
      "SEED: 4, FOLD: 3, EPOCH: 7, train_loss: 0.019859211594873184\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017266523379545946\n",
      "SEED: 4, FOLD: 3, EPOCH: 8, train_loss: 0.01972564616920175\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017287168436898634\n",
      "SEED: 4, FOLD: 3, EPOCH: 9, train_loss: 0.01961242898392516\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 9, valid_loss: 0.01712422137363599\n",
      "SEED: 4, FOLD: 3, EPOCH: 10, train_loss: 0.01957539438798621\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 10, valid_loss: 0.017175429357359044\n",
      "SEED: 4, FOLD: 3, EPOCH: 11, train_loss: 0.019400506179679085\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 11, valid_loss: 0.016822843310924675\n",
      "SEED: 4, FOLD: 3, EPOCH: 12, train_loss: 0.019305118787530308\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016817781142890453\n",
      "SEED: 4, FOLD: 3, EPOCH: 13, train_loss: 0.019109154673846992\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 13, valid_loss: 0.01674933760212018\n",
      "SEED: 4, FOLD: 3, EPOCH: 14, train_loss: 0.018935407612573455\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016715832126255218\n",
      "SEED: 4, FOLD: 3, EPOCH: 15, train_loss: 0.018661554298690847\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01648492065186684\n",
      "SEED: 4, FOLD: 3, EPOCH: 16, train_loss: 0.01834575638074327\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016289144181288205\n",
      "SEED: 4, FOLD: 3, EPOCH: 17, train_loss: 0.018044531571905355\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01631858844596606\n",
      "SEED: 4, FOLD: 3, EPOCH: 18, train_loss: 0.017621630802750587\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016435737291780803\n",
      "SEED: 4, FOLD: 3, EPOCH: 19, train_loss: 0.017176544960789585\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01637267801337517\n",
      "SEED: 4, FOLD: 3, EPOCH: 20, train_loss: 0.016543934801341715\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016293488657818392\n",
      "SEED: 4, FOLD: 3, EPOCH: 21, train_loss: 0.015810358375814314\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01621347164305357\n",
      "SEED: 4, FOLD: 3, EPOCH: 22, train_loss: 0.015075482579099166\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01628376034876475\n",
      "SEED: 4, FOLD: 3, EPOCH: 23, train_loss: 0.014318100302606015\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016256387488773234\n",
      "SEED: 4, FOLD: 3, EPOCH: 24, train_loss: 0.013787519325174996\n",
      "SEED: 4 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016275325288566258\n",
      "SEED: 4, FOLD: 4, EPOCH: 0, train_loss: 0.6239486747496837\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 0, valid_loss: 0.1912820258965859\n",
      "SEED: 4, FOLD: 4, EPOCH: 1, train_loss: 0.03977752711019806\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 1, valid_loss: 0.02112666044670802\n",
      "SEED: 4, FOLD: 4, EPOCH: 2, train_loss: 0.022664720922507143\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 2, valid_loss: 0.018426944215137225\n",
      "SEED: 4, FOLD: 4, EPOCH: 3, train_loss: 0.021473091397736524\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 3, valid_loss: 0.017918681582579248\n",
      "SEED: 4, FOLD: 4, EPOCH: 4, train_loss: 0.020737700617393932\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 4, valid_loss: 0.017705432784098845\n",
      "SEED: 4, FOLD: 4, EPOCH: 5, train_loss: 0.020322695022096503\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 5, valid_loss: 0.01726376680800548\n",
      "SEED: 4, FOLD: 4, EPOCH: 6, train_loss: 0.020095375769243046\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01731748370310435\n",
      "SEED: 4, FOLD: 4, EPOCH: 7, train_loss: 0.01995147955981461\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 7, valid_loss: 0.016915983377167813\n",
      "SEED: 4, FOLD: 4, EPOCH: 8, train_loss: 0.019803951796446298\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017313646152615547\n",
      "SEED: 4, FOLD: 4, EPOCH: 9, train_loss: 0.01975092525921158\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 9, valid_loss: 0.016492145995681103\n",
      "SEED: 4, FOLD: 4, EPOCH: 10, train_loss: 0.01957969896092608\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01742480745395789\n",
      "SEED: 4, FOLD: 4, EPOCH: 11, train_loss: 0.019611246531476844\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016612630050915938\n",
      "SEED: 4, FOLD: 4, EPOCH: 12, train_loss: 0.01937012988570574\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016747498956437293\n",
      "SEED: 4, FOLD: 4, EPOCH: 13, train_loss: 0.019193463052648144\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016671582196767513\n",
      "SEED: 4, FOLD: 4, EPOCH: 14, train_loss: 0.01900866099104688\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016255511042590324\n",
      "SEED: 4, FOLD: 4, EPOCH: 15, train_loss: 0.018737553090259835\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 15, valid_loss: 0.016158738531745397\n",
      "SEED: 4, FOLD: 4, EPOCH: 16, train_loss: 0.018632232337384612\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016047095163510397\n",
      "SEED: 4, FOLD: 4, EPOCH: 17, train_loss: 0.018258193860182893\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 17, valid_loss: 0.015941504603968218\n",
      "SEED: 4, FOLD: 4, EPOCH: 18, train_loss: 0.01777579850592726\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 18, valid_loss: 0.0164554575458169\n",
      "SEED: 4, FOLD: 4, EPOCH: 19, train_loss: 0.017354823044828466\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 19, valid_loss: 0.015891767106950283\n",
      "SEED: 4, FOLD: 4, EPOCH: 20, train_loss: 0.016841612164736598\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01571102547817505\n",
      "SEED: 4, FOLD: 4, EPOCH: 21, train_loss: 0.016100476156114728\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 21, valid_loss: 0.016009819837143786\n",
      "SEED: 4, FOLD: 4, EPOCH: 22, train_loss: 0.015412816450603911\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 22, valid_loss: 0.015796711023610372\n",
      "SEED: 4, FOLD: 4, EPOCH: 23, train_loss: 0.014679449333532437\n",
      "SEED: 4 ,FOLD: 4, EPOCH: 23, valid_loss: 0.01576589735654684\n",
      "SEED: 4, FOLD: 5, EPOCH: 0, train_loss: 0.6252732699787295\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 0, valid_loss: 0.19603395691284767\n",
      "SEED: 4, FOLD: 5, EPOCH: 1, train_loss: 0.03969084028456662\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 1, valid_loss: 0.020169253675983503\n",
      "SEED: 4, FOLD: 5, EPOCH: 2, train_loss: 0.02219542765335457\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 2, valid_loss: 0.018380343770751588\n",
      "SEED: 4, FOLD: 5, EPOCH: 3, train_loss: 0.020995081704411958\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 3, valid_loss: 0.01767677254974842\n",
      "SEED: 4, FOLD: 5, EPOCH: 4, train_loss: 0.02051540360962217\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 4, valid_loss: 0.01767511723133234\n",
      "SEED: 4, FOLD: 5, EPOCH: 5, train_loss: 0.020232869740072136\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 5, valid_loss: 0.017332354847055215\n",
      "SEED: 4, FOLD: 5, EPOCH: 6, train_loss: 0.020141866284649115\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 6, valid_loss: 0.017451502239474885\n",
      "SEED: 4, FOLD: 5, EPOCH: 7, train_loss: 0.019970123907802877\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 7, valid_loss: 0.017011571102417432\n",
      "SEED: 4, FOLD: 5, EPOCH: 8, train_loss: 0.01979861400920797\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 8, valid_loss: 0.017028447097310655\n",
      "SEED: 4, FOLD: 5, EPOCH: 9, train_loss: 0.01963673539560389\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 9, valid_loss: 0.01726213111900366\n",
      "SEED: 4, FOLD: 5, EPOCH: 10, train_loss: 0.019541152929132048\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 10, valid_loss: 0.016863891281760655\n",
      "SEED: 4, FOLD: 5, EPOCH: 11, train_loss: 0.019435846926392737\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 11, valid_loss: 0.016885561725268\n",
      "SEED: 4, FOLD: 5, EPOCH: 12, train_loss: 0.019272079791974376\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 12, valid_loss: 0.016765391883941796\n",
      "SEED: 4, FOLD: 5, EPOCH: 13, train_loss: 0.019052306794234225\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 13, valid_loss: 0.016644244010631856\n",
      "SEED: 4, FOLD: 5, EPOCH: 14, train_loss: 0.018980089449197858\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 14, valid_loss: 0.016570064454124525\n",
      "SEED: 4, FOLD: 5, EPOCH: 15, train_loss: 0.018699260151668173\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 15, valid_loss: 0.016391939411942776\n",
      "SEED: 4, FOLD: 5, EPOCH: 16, train_loss: 0.018431701294675067\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 16, valid_loss: 0.016394092343174495\n",
      "SEED: 4, FOLD: 5, EPOCH: 17, train_loss: 0.018083742140112696\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 17, valid_loss: 0.01632422996828189\n",
      "SEED: 4, FOLD: 5, EPOCH: 18, train_loss: 0.01764469128102064\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 18, valid_loss: 0.016160325935253732\n",
      "SEED: 4, FOLD: 5, EPOCH: 19, train_loss: 0.017108694625061913\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 19, valid_loss: 0.016100862278388098\n",
      "SEED: 4, FOLD: 5, EPOCH: 20, train_loss: 0.0165454376287557\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 20, valid_loss: 0.016160753197394885\n",
      "SEED: 4, FOLD: 5, EPOCH: 21, train_loss: 0.015783185567203407\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 21, valid_loss: 0.01615889721478407\n",
      "SEED: 4, FOLD: 5, EPOCH: 22, train_loss: 0.014970527886337525\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 22, valid_loss: 0.01618303294078662\n",
      "SEED: 4, FOLD: 5, EPOCH: 23, train_loss: 0.014235667909520704\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 23, valid_loss: 0.016152465214522984\n",
      "SEED: 4, FOLD: 5, EPOCH: 24, train_loss: 0.013652986582569979\n",
      "SEED: 4 ,FOLD: 5, EPOCH: 24, valid_loss: 0.016130542167677328\n",
      "SEED: 4, FOLD: 6, EPOCH: 0, train_loss: 0.6234063367183144\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 0, valid_loss: 0.20742201461241797\n",
      "SEED: 4, FOLD: 6, EPOCH: 1, train_loss: 0.03929641903252215\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 1, valid_loss: 0.020399998157070234\n",
      "SEED: 4, FOLD: 6, EPOCH: 2, train_loss: 0.022191415490532242\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 2, valid_loss: 0.01862327568233013\n",
      "SEED: 4, FOLD: 6, EPOCH: 3, train_loss: 0.021203165873885155\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 3, valid_loss: 0.01826092701118726\n",
      "SEED: 4, FOLD: 6, EPOCH: 4, train_loss: 0.020622349721757142\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 4, valid_loss: 0.017780851429471604\n",
      "SEED: 4, FOLD: 6, EPOCH: 5, train_loss: 0.02034843886724195\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 5, valid_loss: 0.01758722344843241\n",
      "SEED: 4, FOLD: 6, EPOCH: 6, train_loss: 0.020003785454743617\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 6, valid_loss: 0.017871968161601286\n",
      "SEED: 4, FOLD: 6, EPOCH: 7, train_loss: 0.01993273339561514\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 7, valid_loss: 0.017577924837286655\n",
      "SEED: 4, FOLD: 6, EPOCH: 8, train_loss: 0.019882215942079957\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 8, valid_loss: 0.017639388258640584\n",
      "SEED: 4, FOLD: 6, EPOCH: 9, train_loss: 0.019731741675452608\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 9, valid_loss: 0.017309776292397425\n",
      "SEED: 4, FOLD: 6, EPOCH: 10, train_loss: 0.01967267707191609\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 10, valid_loss: 0.017295171578343097\n",
      "SEED: 4, FOLD: 6, EPOCH: 11, train_loss: 0.019576279874387627\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 11, valid_loss: 0.017305128562908906\n",
      "SEED: 4, FOLD: 6, EPOCH: 12, train_loss: 0.01936218807020703\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 12, valid_loss: 0.01722532496429407\n",
      "SEED: 4, FOLD: 6, EPOCH: 13, train_loss: 0.01922377241725052\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 13, valid_loss: 0.01697614387823985\n",
      "SEED: 4, FOLD: 6, EPOCH: 14, train_loss: 0.01905260406233169\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 14, valid_loss: 0.017025146060265027\n",
      "SEED: 4, FOLD: 6, EPOCH: 15, train_loss: 0.01883315229536714\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 15, valid_loss: 0.01672780277350774\n",
      "SEED: 4, FOLD: 6, EPOCH: 16, train_loss: 0.018539218030668592\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 16, valid_loss: 0.016625312730096854\n",
      "SEED: 4, FOLD: 6, EPOCH: 17, train_loss: 0.01825726548260128\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 17, valid_loss: 0.01659743724247584\n",
      "SEED: 4, FOLD: 6, EPOCH: 18, train_loss: 0.017835150925895653\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 18, valid_loss: 0.0167236878321721\n",
      "SEED: 4, FOLD: 6, EPOCH: 19, train_loss: 0.017364573702719564\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 19, valid_loss: 0.016307167279032562\n",
      "SEED: 4, FOLD: 6, EPOCH: 20, train_loss: 0.016743535402457457\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 20, valid_loss: 0.016354633351931207\n",
      "SEED: 4, FOLD: 6, EPOCH: 21, train_loss: 0.016092621859767148\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 21, valid_loss: 0.0163720275920171\n",
      "SEED: 4, FOLD: 6, EPOCH: 22, train_loss: 0.015363955769587207\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 22, valid_loss: 0.016272788652433798\n",
      "SEED: 4, FOLD: 6, EPOCH: 23, train_loss: 0.014672706318968857\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 23, valid_loss: 0.016294696726478063\n",
      "SEED: 4, FOLD: 6, EPOCH: 24, train_loss: 0.014157485619590088\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 24, valid_loss: 0.016320103636154763\n",
      "SEED: 4, FOLD: 6, EPOCH: 25, train_loss: 0.013965454418212175\n",
      "SEED: 4 ,FOLD: 6, EPOCH: 25, valid_loss: 0.016309433688337985\n",
      "SEED: 5, FOLD: 0, EPOCH: 0, train_loss: 0.622527796473052\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 0, valid_loss: 0.1622013128720797\n",
      "SEED: 5, FOLD: 0, EPOCH: 1, train_loss: 0.04034143354038935\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 1, valid_loss: 0.020858158715642415\n",
      "SEED: 5, FOLD: 0, EPOCH: 2, train_loss: 0.02263037918286549\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 2, valid_loss: 0.018735135690524027\n",
      "SEED: 5, FOLD: 0, EPOCH: 3, train_loss: 0.02128694883572894\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 3, valid_loss: 0.018023160501168325\n",
      "SEED: 5, FOLD: 0, EPOCH: 4, train_loss: 0.020581106705641426\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017606691242410585\n",
      "SEED: 5, FOLD: 0, EPOCH: 5, train_loss: 0.0202277750028549\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 5, valid_loss: 0.01776598823758272\n",
      "SEED: 5, FOLD: 0, EPOCH: 6, train_loss: 0.020171701304010442\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017469682515813753\n",
      "SEED: 5, FOLD: 0, EPOCH: 7, train_loss: 0.019936207329501975\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017204014011300527\n",
      "SEED: 5, FOLD: 0, EPOCH: 8, train_loss: 0.019771083333605045\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017256885337141845\n",
      "SEED: 5, FOLD: 0, EPOCH: 9, train_loss: 0.019678928587283637\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 9, valid_loss: 0.01776065118610859\n",
      "SEED: 5, FOLD: 0, EPOCH: 10, train_loss: 0.019636317735185493\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 10, valid_loss: 0.017148043387211286\n",
      "SEED: 5, FOLD: 0, EPOCH: 11, train_loss: 0.019422886012172378\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 11, valid_loss: 0.01678372912395459\n",
      "SEED: 5, FOLD: 0, EPOCH: 12, train_loss: 0.019361798676687317\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016904527608018655\n",
      "SEED: 5, FOLD: 0, EPOCH: 13, train_loss: 0.019151920905789814\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016740860847326424\n",
      "SEED: 5, FOLD: 0, EPOCH: 14, train_loss: 0.018889554071466665\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 14, valid_loss: 0.01675437082751439\n",
      "SEED: 5, FOLD: 0, EPOCH: 15, train_loss: 0.01872477524385259\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 15, valid_loss: 0.016430387273430824\n",
      "SEED: 5, FOLD: 0, EPOCH: 16, train_loss: 0.018382695881096093\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 16, valid_loss: 0.016546962567819998\n",
      "SEED: 5, FOLD: 0, EPOCH: 17, train_loss: 0.018065422748190327\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 17, valid_loss: 0.01650965091987298\n",
      "SEED: 5, FOLD: 0, EPOCH: 18, train_loss: 0.017786584517641646\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 18, valid_loss: 0.016324696560891774\n",
      "SEED: 5, FOLD: 0, EPOCH: 19, train_loss: 0.017261628514608822\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 19, valid_loss: 0.01625283506627266\n",
      "SEED: 5, FOLD: 0, EPOCH: 20, train_loss: 0.016665046367592907\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016121777419287425\n",
      "SEED: 5, FOLD: 0, EPOCH: 21, train_loss: 0.016030095517635345\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016106150184686367\n",
      "SEED: 5, FOLD: 0, EPOCH: 22, train_loss: 0.015246196297576299\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 22, valid_loss: 0.01618282525585248\n",
      "SEED: 5, FOLD: 0, EPOCH: 23, train_loss: 0.014555574696813081\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 23, valid_loss: 0.016186334336033233\n",
      "SEED: 5, FOLD: 0, EPOCH: 24, train_loss: 0.014015284870323297\n",
      "SEED: 5 ,FOLD: 0, EPOCH: 24, valid_loss: 0.016166026775653545\n",
      "SEED: 5, FOLD: 1, EPOCH: 0, train_loss: 0.6228983575427854\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 0, valid_loss: 0.219049055988972\n",
      "SEED: 5, FOLD: 1, EPOCH: 1, train_loss: 0.039402788655983435\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 1, valid_loss: 0.02055700682103634\n",
      "SEED: 5, FOLD: 1, EPOCH: 2, train_loss: 0.023090295619457156\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 2, valid_loss: 0.018637049943208694\n",
      "SEED: 5, FOLD: 1, EPOCH: 3, train_loss: 0.021487758872476784\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 3, valid_loss: 0.01795288619513695\n",
      "SEED: 5, FOLD: 1, EPOCH: 4, train_loss: 0.02079738651377124\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017271604890433643\n",
      "SEED: 5, FOLD: 1, EPOCH: 5, train_loss: 0.020463783520500402\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017450233133366473\n",
      "SEED: 5, FOLD: 1, EPOCH: 6, train_loss: 0.020217389950679766\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 6, valid_loss: 0.017252408039684478\n",
      "SEED: 5, FOLD: 1, EPOCH: 7, train_loss: 0.02009397455667322\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017087007944400493\n",
      "SEED: 5, FOLD: 1, EPOCH: 8, train_loss: 0.01994623299184683\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 8, valid_loss: 0.016929734426622208\n",
      "SEED: 5, FOLD: 1, EPOCH: 9, train_loss: 0.019734626359029395\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 9, valid_loss: 0.016947377902957108\n",
      "SEED: 5, FOLD: 1, EPOCH: 10, train_loss: 0.019744870932521048\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 10, valid_loss: 0.016925941722897384\n",
      "SEED: 5, FOLD: 1, EPOCH: 11, train_loss: 0.019559734928849583\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 11, valid_loss: 0.0166681962660872\n",
      "SEED: 5, FOLD: 1, EPOCH: 12, train_loss: 0.019441416059192772\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 12, valid_loss: 0.01682406971947505\n",
      "SEED: 5, FOLD: 1, EPOCH: 13, train_loss: 0.019203077825541433\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 13, valid_loss: 0.01649295037182478\n",
      "SEED: 5, FOLD: 1, EPOCH: 14, train_loss: 0.018997350783162826\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016270395654898424\n",
      "SEED: 5, FOLD: 1, EPOCH: 15, train_loss: 0.01883964562738264\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 15, valid_loss: 0.01627586459597716\n",
      "SEED: 5, FOLD: 1, EPOCH: 16, train_loss: 0.018595971091574914\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 16, valid_loss: 0.016194458262851603\n",
      "SEED: 5, FOLD: 1, EPOCH: 17, train_loss: 0.01824001275707741\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 17, valid_loss: 0.01613644539163663\n",
      "SEED: 5, FOLD: 1, EPOCH: 18, train_loss: 0.017865282105835708\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 18, valid_loss: 0.016125574636344727\n",
      "SEED: 5, FOLD: 1, EPOCH: 19, train_loss: 0.0173735835690152\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 19, valid_loss: 0.016011807064597424\n",
      "SEED: 5, FOLD: 1, EPOCH: 20, train_loss: 0.016750143413004036\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 20, valid_loss: 0.015925000063501872\n",
      "SEED: 5, FOLD: 1, EPOCH: 21, train_loss: 0.016121904630012607\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 21, valid_loss: 0.01597070686805707\n",
      "SEED: 5, FOLD: 1, EPOCH: 22, train_loss: 0.015334773015834996\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 22, valid_loss: 0.01593082333700015\n",
      "SEED: 5, FOLD: 1, EPOCH: 23, train_loss: 0.014638186797398972\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 23, valid_loss: 0.016003369496992\n",
      "SEED: 5, FOLD: 1, EPOCH: 24, train_loss: 0.01414212438504438\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 24, valid_loss: 0.015982133121444628\n",
      "SEED: 5, FOLD: 1, EPOCH: 25, train_loss: 0.013917142512729845\n",
      "SEED: 5 ,FOLD: 1, EPOCH: 25, valid_loss: 0.015996265225112438\n",
      "SEED: 5, FOLD: 2, EPOCH: 0, train_loss: 0.6235239316482801\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 0, valid_loss: 0.18512388032216293\n",
      "SEED: 5, FOLD: 2, EPOCH: 1, train_loss: 0.039320917246309484\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 1, valid_loss: 0.020176362819396533\n",
      "SEED: 5, FOLD: 2, EPOCH: 2, train_loss: 0.02233221218291972\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018580428396279994\n",
      "SEED: 5, FOLD: 2, EPOCH: 3, train_loss: 0.02127172430423466\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 3, valid_loss: 0.017820956615301278\n",
      "SEED: 5, FOLD: 2, EPOCH: 4, train_loss: 0.02070078983701564\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017652902752161026\n",
      "SEED: 5, FOLD: 2, EPOCH: 5, train_loss: 0.020254654784661694\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 5, valid_loss: 0.017405127819914084\n",
      "SEED: 5, FOLD: 2, EPOCH: 6, train_loss: 0.020015085468421113\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017200601788667533\n",
      "SEED: 5, FOLD: 2, EPOCH: 7, train_loss: 0.019855960624644887\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017204308452514503\n",
      "SEED: 5, FOLD: 2, EPOCH: 8, train_loss: 0.019780958222376334\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 8, valid_loss: 0.01701466438288872\n",
      "SEED: 5, FOLD: 2, EPOCH: 9, train_loss: 0.01963582126474058\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 9, valid_loss: 0.01691215055493208\n",
      "SEED: 5, FOLD: 2, EPOCH: 10, train_loss: 0.019528254136644507\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 10, valid_loss: 0.017045222795926608\n",
      "SEED: 5, FOLD: 2, EPOCH: 11, train_loss: 0.019408841088816926\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 11, valid_loss: 0.017042613659913722\n",
      "SEED: 5, FOLD: 2, EPOCH: 12, train_loss: 0.019247370268646126\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01695468878516784\n",
      "SEED: 5, FOLD: 2, EPOCH: 13, train_loss: 0.019118667756383483\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016704396488001712\n",
      "SEED: 5, FOLD: 2, EPOCH: 14, train_loss: 0.018884478665485576\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01634255789506894\n",
      "SEED: 5, FOLD: 2, EPOCH: 15, train_loss: 0.018661500407835922\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 15, valid_loss: 0.016411283626579322\n",
      "SEED: 5, FOLD: 2, EPOCH: 16, train_loss: 0.01834244009208035\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 16, valid_loss: 0.0164422276788033\n",
      "SEED: 5, FOLD: 2, EPOCH: 17, train_loss: 0.01802740668928301\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 17, valid_loss: 0.01621830012076176\n",
      "SEED: 5, FOLD: 2, EPOCH: 18, train_loss: 0.017584664369555743\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 18, valid_loss: 0.01630033402202221\n",
      "SEED: 5, FOLD: 2, EPOCH: 19, train_loss: 0.017056521305159944\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01624149062599127\n",
      "SEED: 5, FOLD: 2, EPOCH: 20, train_loss: 0.01642993580852006\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 20, valid_loss: 0.0161976063480744\n",
      "SEED: 5, FOLD: 2, EPOCH: 21, train_loss: 0.015709071583743836\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016218252050188873\n",
      "SEED: 5, FOLD: 2, EPOCH: 22, train_loss: 0.01490097667870892\n",
      "SEED: 5 ,FOLD: 2, EPOCH: 22, valid_loss: 0.01621574364029444\n",
      "SEED: 5, FOLD: 3, EPOCH: 0, train_loss: 0.6228153703583253\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 0, valid_loss: 0.24727226564517388\n",
      "SEED: 5, FOLD: 3, EPOCH: 1, train_loss: 0.039249902817647196\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 1, valid_loss: 0.01997833584363644\n",
      "SEED: 5, FOLD: 3, EPOCH: 2, train_loss: 0.022129901131061284\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018354705176674403\n",
      "SEED: 5, FOLD: 3, EPOCH: 3, train_loss: 0.02108052372932434\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 3, valid_loss: 0.01774870052647132\n",
      "SEED: 5, FOLD: 3, EPOCH: 4, train_loss: 0.02052994558235278\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 4, valid_loss: 0.017568289660490476\n",
      "SEED: 5, FOLD: 3, EPOCH: 5, train_loss: 0.020174732003864403\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017271634836036425\n",
      "SEED: 5, FOLD: 3, EPOCH: 6, train_loss: 0.019960493730330788\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 6, valid_loss: 0.017123366706073284\n",
      "SEED: 5, FOLD: 3, EPOCH: 7, train_loss: 0.019814841751311277\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 7, valid_loss: 0.01718653982075361\n",
      "SEED: 5, FOLD: 3, EPOCH: 8, train_loss: 0.019700044363334373\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017030029056163933\n",
      "SEED: 5, FOLD: 3, EPOCH: 9, train_loss: 0.019623931069430466\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 9, valid_loss: 0.016658096717527278\n",
      "SEED: 5, FOLD: 3, EPOCH: 10, train_loss: 0.019542514321369095\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 10, valid_loss: 0.016987303486810282\n",
      "SEED: 5, FOLD: 3, EPOCH: 11, train_loss: 0.01936119293945061\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 11, valid_loss: 0.016888779731324084\n",
      "SEED: 5, FOLD: 3, EPOCH: 12, train_loss: 0.019224498571979033\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016828057499459155\n",
      "SEED: 5, FOLD: 3, EPOCH: 13, train_loss: 0.019061434586104507\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016504111198278573\n",
      "SEED: 5, FOLD: 3, EPOCH: 14, train_loss: 0.018869961762951838\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016412836141311206\n",
      "SEED: 5, FOLD: 3, EPOCH: 15, train_loss: 0.018622176318958\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 15, valid_loss: 0.01647624932229519\n",
      "SEED: 5, FOLD: 3, EPOCH: 16, train_loss: 0.018291813019361045\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 16, valid_loss: 0.016405502190956704\n",
      "SEED: 5, FOLD: 3, EPOCH: 17, train_loss: 0.018013948197099002\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 17, valid_loss: 0.016189540449816447\n",
      "SEED: 5, FOLD: 3, EPOCH: 18, train_loss: 0.017529252639694792\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 18, valid_loss: 0.016174617366721995\n",
      "SEED: 5, FOLD: 3, EPOCH: 19, train_loss: 0.01698378330046261\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 19, valid_loss: 0.01609576729914317\n",
      "SEED: 5, FOLD: 3, EPOCH: 20, train_loss: 0.016328650086211996\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 20, valid_loss: 0.016122923232614994\n",
      "SEED: 5, FOLD: 3, EPOCH: 21, train_loss: 0.015578221366111492\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 21, valid_loss: 0.01608254058429828\n",
      "SEED: 5, FOLD: 3, EPOCH: 22, train_loss: 0.014779603687693944\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 22, valid_loss: 0.01605853022864232\n",
      "SEED: 5, FOLD: 3, EPOCH: 23, train_loss: 0.014033628967464776\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016065846125666913\n",
      "SEED: 5, FOLD: 3, EPOCH: 24, train_loss: 0.013470374211366917\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016151082415420275\n",
      "SEED: 5, FOLD: 3, EPOCH: 25, train_loss: 0.013229046960839548\n",
      "SEED: 5 ,FOLD: 3, EPOCH: 25, valid_loss: 0.01613564918247553\n",
      "SEED: 5, FOLD: 4, EPOCH: 0, train_loss: 0.6228233873844147\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 0, valid_loss: 0.15746931043954995\n",
      "SEED: 5, FOLD: 4, EPOCH: 1, train_loss: 0.03920486823630494\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 1, valid_loss: 0.020188653411773536\n",
      "SEED: 5, FOLD: 4, EPOCH: 2, train_loss: 0.022292866195375856\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 2, valid_loss: 0.01895821338089613\n",
      "SEED: 5, FOLD: 4, EPOCH: 3, train_loss: 0.02134478328799879\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 3, valid_loss: 0.01827771761096441\n",
      "SEED: 5, FOLD: 4, EPOCH: 4, train_loss: 0.02066797634737717\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 4, valid_loss: 0.01760082906828477\n",
      "SEED: 5, FOLD: 4, EPOCH: 5, train_loss: 0.020298579607058217\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 5, valid_loss: 0.01744438922749116\n",
      "SEED: 5, FOLD: 4, EPOCH: 6, train_loss: 0.020129233573538227\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 6, valid_loss: 0.01740440110174509\n",
      "SEED: 5, FOLD: 4, EPOCH: 7, train_loss: 0.020004704116365395\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 7, valid_loss: 0.017180157108948782\n",
      "SEED: 5, FOLD: 4, EPOCH: 8, train_loss: 0.01994698278203204\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017201306871496715\n",
      "SEED: 5, FOLD: 4, EPOCH: 9, train_loss: 0.019781128453040444\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017141544761566017\n",
      "SEED: 5, FOLD: 4, EPOCH: 10, train_loss: 0.01961733106322385\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 10, valid_loss: 0.01690183336345049\n",
      "SEED: 5, FOLD: 4, EPOCH: 11, train_loss: 0.01953590215762725\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 11, valid_loss: 0.0170652807618563\n",
      "SEED: 5, FOLD: 4, EPOCH: 12, train_loss: 0.01929146718435191\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 12, valid_loss: 0.01713519672361704\n",
      "SEED: 5, FOLD: 4, EPOCH: 13, train_loss: 0.019219812609859416\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016819096671847198\n",
      "SEED: 5, FOLD: 4, EPOCH: 14, train_loss: 0.019041441582344675\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 14, valid_loss: 0.01687525141124542\n",
      "SEED: 5, FOLD: 4, EPOCH: 15, train_loss: 0.018822168125896842\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01657251397577616\n",
      "SEED: 5, FOLD: 4, EPOCH: 16, train_loss: 0.018563189694808947\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016438291049920596\n",
      "SEED: 5, FOLD: 4, EPOCH: 17, train_loss: 0.018229985685163253\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016601340128825262\n",
      "SEED: 5, FOLD: 4, EPOCH: 18, train_loss: 0.017760494346352847\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 18, valid_loss: 0.016377704719511364\n",
      "SEED: 5, FOLD: 4, EPOCH: 19, train_loss: 0.01733387095501294\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016304818770060174\n",
      "SEED: 5, FOLD: 4, EPOCH: 20, train_loss: 0.016697948723024613\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 20, valid_loss: 0.016239514431128137\n",
      "SEED: 5, FOLD: 4, EPOCH: 21, train_loss: 0.016060211796414207\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 21, valid_loss: 0.0161619854088013\n",
      "SEED: 5, FOLD: 4, EPOCH: 22, train_loss: 0.015343362163450266\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 22, valid_loss: 0.01626772154122591\n",
      "SEED: 5, FOLD: 4, EPOCH: 23, train_loss: 0.01465767848531942\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 23, valid_loss: 0.016225122631742403\n",
      "SEED: 5, FOLD: 4, EPOCH: 24, train_loss: 0.014158612519905373\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 24, valid_loss: 0.0162765087129978\n",
      "SEED: 5, FOLD: 4, EPOCH: 25, train_loss: 0.013980456778930651\n",
      "SEED: 5 ,FOLD: 4, EPOCH: 25, valid_loss: 0.016276925014188655\n",
      "SEED: 5, FOLD: 5, EPOCH: 0, train_loss: 0.6218323030987302\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 0, valid_loss: 0.17091237008571625\n",
      "SEED: 5, FOLD: 5, EPOCH: 1, train_loss: 0.03909678721951472\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 1, valid_loss: 0.020083532883570746\n",
      "SEED: 5, FOLD: 5, EPOCH: 2, train_loss: 0.022333381068263505\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 2, valid_loss: 0.01852211757348134\n",
      "SEED: 5, FOLD: 5, EPOCH: 3, train_loss: 0.021071470418089145\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 3, valid_loss: 0.017777447660381977\n",
      "SEED: 5, FOLD: 5, EPOCH: 4, train_loss: 0.02055345566288845\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 4, valid_loss: 0.017502329097344324\n",
      "SEED: 5, FOLD: 5, EPOCH: 5, train_loss: 0.020143581101217785\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 5, valid_loss: 0.01724745039469921\n",
      "SEED: 5, FOLD: 5, EPOCH: 6, train_loss: 0.019960996216616116\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 6, valid_loss: 0.017232072038146164\n",
      "SEED: 5, FOLD: 5, EPOCH: 7, train_loss: 0.019876737147569656\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 7, valid_loss: 0.017281404338203944\n",
      "SEED: 5, FOLD: 5, EPOCH: 8, train_loss: 0.019781946632507687\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 8, valid_loss: 0.016867131209717348\n",
      "SEED: 5, FOLD: 5, EPOCH: 9, train_loss: 0.019688293790897808\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 9, valid_loss: 0.016989867847699385\n",
      "SEED: 5, FOLD: 5, EPOCH: 10, train_loss: 0.019535451699551697\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 10, valid_loss: 0.016829189128027514\n",
      "SEED: 5, FOLD: 5, EPOCH: 11, train_loss: 0.019369069637881743\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 11, valid_loss: 0.016864232575664155\n",
      "SEED: 5, FOLD: 5, EPOCH: 12, train_loss: 0.019223955208183947\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 12, valid_loss: 0.016994238687822454\n",
      "SEED: 5, FOLD: 5, EPOCH: 13, train_loss: 0.019178931349636736\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 13, valid_loss: 0.016753273657881297\n",
      "SEED: 5, FOLD: 5, EPOCH: 14, train_loss: 0.018953439628554357\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 14, valid_loss: 0.016612316410128888\n",
      "SEED: 5, FOLD: 5, EPOCH: 15, train_loss: 0.018740785660574567\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 15, valid_loss: 0.01645693999643509\n",
      "SEED: 5, FOLD: 5, EPOCH: 16, train_loss: 0.01837028145185999\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 16, valid_loss: 0.01615204533132223\n",
      "SEED: 5, FOLD: 5, EPOCH: 17, train_loss: 0.01805283665354993\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 17, valid_loss: 0.016377257326474555\n",
      "SEED: 5, FOLD: 5, EPOCH: 18, train_loss: 0.017658975478765125\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 18, valid_loss: 0.01613581753694094\n",
      "SEED: 5, FOLD: 5, EPOCH: 19, train_loss: 0.017137100781641296\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 19, valid_loss: 0.01620278199418233\n",
      "SEED: 5, FOLD: 5, EPOCH: 20, train_loss: 0.01651790550582715\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 20, valid_loss: 0.016208193766383026\n",
      "SEED: 5, FOLD: 5, EPOCH: 21, train_loss: 0.015776458863370323\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 21, valid_loss: 0.016113504910698302\n",
      "SEED: 5, FOLD: 5, EPOCH: 22, train_loss: 0.014989444344128305\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 22, valid_loss: 0.016190937648598965\n",
      "SEED: 5, FOLD: 5, EPOCH: 23, train_loss: 0.01421679080640142\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 23, valid_loss: 0.01623036640767868\n",
      "SEED: 5, FOLD: 5, EPOCH: 24, train_loss: 0.013648644429505677\n",
      "SEED: 5 ,FOLD: 5, EPOCH: 24, valid_loss: 0.016299883763377484\n",
      "SEED: 5, FOLD: 6, EPOCH: 0, train_loss: 0.622965348532071\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 0, valid_loss: 0.17693192798357743\n",
      "SEED: 5, FOLD: 6, EPOCH: 1, train_loss: 0.03946203086525202\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 1, valid_loss: 0.020454678827753432\n",
      "SEED: 5, FOLD: 6, EPOCH: 2, train_loss: 0.022711109772727296\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 2, valid_loss: 0.018826292254603826\n",
      "SEED: 5, FOLD: 6, EPOCH: 3, train_loss: 0.021298598674302165\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 3, valid_loss: 0.01796769379423215\n",
      "SEED: 5, FOLD: 6, EPOCH: 4, train_loss: 0.02082123700529337\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 4, valid_loss: 0.01769662075317823\n",
      "SEED: 5, FOLD: 6, EPOCH: 5, train_loss: 0.02028067915926914\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 5, valid_loss: 0.01774479434467279\n",
      "SEED: 5, FOLD: 6, EPOCH: 6, train_loss: 0.020022209179965226\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 6, valid_loss: 0.017357811618309755\n",
      "SEED: 5, FOLD: 6, EPOCH: 7, train_loss: 0.019843173565695416\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 7, valid_loss: 0.017164570494340017\n",
      "SEED: 5, FOLD: 6, EPOCH: 8, train_loss: 0.01979186536895262\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 8, valid_loss: 0.017439916873207457\n",
      "SEED: 5, FOLD: 6, EPOCH: 9, train_loss: 0.019643305020557868\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 9, valid_loss: 0.017045902876326673\n",
      "SEED: 5, FOLD: 6, EPOCH: 10, train_loss: 0.01954327362614709\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 10, valid_loss: 0.017332814633846283\n",
      "SEED: 5, FOLD: 6, EPOCH: 11, train_loss: 0.019435891478851035\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 11, valid_loss: 0.0167790106855906\n",
      "SEED: 5, FOLD: 6, EPOCH: 12, train_loss: 0.01923021495442938\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 12, valid_loss: 0.016660175357873622\n",
      "SEED: 5, FOLD: 6, EPOCH: 13, train_loss: 0.01905598400815113\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 13, valid_loss: 0.016738012003210876\n",
      "SEED: 5, FOLD: 6, EPOCH: 14, train_loss: 0.01891880646045949\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 14, valid_loss: 0.016471534680861693\n",
      "SEED: 5, FOLD: 6, EPOCH: 15, train_loss: 0.018685428878745518\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 15, valid_loss: 0.016394643041376885\n",
      "SEED: 5, FOLD: 6, EPOCH: 16, train_loss: 0.018319662232455368\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 16, valid_loss: 0.01636676827015785\n",
      "SEED: 5, FOLD: 6, EPOCH: 17, train_loss: 0.018035272941798776\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 17, valid_loss: 0.01628864062233613\n",
      "SEED: 5, FOLD: 6, EPOCH: 18, train_loss: 0.01762589473730406\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 18, valid_loss: 0.016241938520509463\n",
      "SEED: 5, FOLD: 6, EPOCH: 19, train_loss: 0.017143567331840057\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 19, valid_loss: 0.01617057234621965\n",
      "SEED: 5, FOLD: 6, EPOCH: 20, train_loss: 0.016539153252803796\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 20, valid_loss: 0.01625613710628106\n",
      "SEED: 5, FOLD: 6, EPOCH: 21, train_loss: 0.01580493523412057\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 21, valid_loss: 0.01607999327377631\n",
      "SEED: 5, FOLD: 6, EPOCH: 22, train_loss: 0.014993479638989712\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 22, valid_loss: 0.016170958916728314\n",
      "SEED: 5, FOLD: 6, EPOCH: 23, train_loss: 0.014254195275842338\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 23, valid_loss: 0.016100988436776858\n",
      "SEED: 5, FOLD: 6, EPOCH: 24, train_loss: 0.013711420781407002\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 24, valid_loss: 0.016230896545144227\n",
      "SEED: 5, FOLD: 6, EPOCH: 25, train_loss: 0.013492825705356695\n",
      "SEED: 5 ,FOLD: 6, EPOCH: 25, valid_loss: 0.016217977739870548\n",
      "SEED: 6, FOLD: 0, EPOCH: 0, train_loss: 0.6230731628633834\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 0, valid_loss: 0.16070848932633033\n",
      "SEED: 6, FOLD: 0, EPOCH: 1, train_loss: 0.03922109504708567\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 1, valid_loss: 0.020069780544592783\n",
      "SEED: 6, FOLD: 0, EPOCH: 2, train_loss: 0.02223187289829995\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 2, valid_loss: 0.020200281905440185\n",
      "SEED: 6, FOLD: 0, EPOCH: 3, train_loss: 0.021259117770839383\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 3, valid_loss: 0.017971283111434717\n",
      "SEED: 6, FOLD: 0, EPOCH: 4, train_loss: 0.02061814271114968\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 4, valid_loss: 0.017617171057141744\n",
      "SEED: 6, FOLD: 0, EPOCH: 5, train_loss: 0.02028274702260623\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 5, valid_loss: 0.017289067403628275\n",
      "SEED: 6, FOLD: 0, EPOCH: 6, train_loss: 0.020044663618948008\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 6, valid_loss: 0.017135431416905843\n",
      "SEED: 6, FOLD: 0, EPOCH: 7, train_loss: 0.019956375245709677\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 7, valid_loss: 0.017212027468933508\n",
      "SEED: 6, FOLD: 0, EPOCH: 8, train_loss: 0.019889385766676954\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 8, valid_loss: 0.017057439383979026\n",
      "SEED: 6, FOLD: 0, EPOCH: 9, train_loss: 0.019712487034298277\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 9, valid_loss: 0.016860979036069833\n",
      "SEED: 6, FOLD: 0, EPOCH: 10, train_loss: 0.01966327874342332\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 10, valid_loss: 0.016532817640556738\n",
      "SEED: 6, FOLD: 0, EPOCH: 11, train_loss: 0.019495716091950197\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 11, valid_loss: 0.016627614458019916\n",
      "SEED: 6, FOLD: 0, EPOCH: 12, train_loss: 0.019307362922542804\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 12, valid_loss: 0.016534430619615775\n",
      "SEED: 6, FOLD: 0, EPOCH: 13, train_loss: 0.019167095120694186\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 13, valid_loss: 0.016491138376295567\n",
      "SEED: 6, FOLD: 0, EPOCH: 14, train_loss: 0.01892535572217123\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 14, valid_loss: 0.01624805286813241\n",
      "SEED: 6, FOLD: 0, EPOCH: 15, train_loss: 0.018658673063524672\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 15, valid_loss: 0.0161973090412525\n",
      "SEED: 6, FOLD: 0, EPOCH: 16, train_loss: 0.018393939235121816\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 16, valid_loss: 0.01615228332006014\n",
      "SEED: 6, FOLD: 0, EPOCH: 17, train_loss: 0.018084892927593476\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 17, valid_loss: 0.015987286988932353\n",
      "SEED: 6, FOLD: 0, EPOCH: 18, train_loss: 0.01763177660570757\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 18, valid_loss: 0.015984311484946653\n",
      "SEED: 6, FOLD: 0, EPOCH: 19, train_loss: 0.01706099379304293\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 19, valid_loss: 0.01596223906828807\n",
      "SEED: 6, FOLD: 0, EPOCH: 20, train_loss: 0.016414751663703372\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 20, valid_loss: 0.016002211934671953\n",
      "SEED: 6, FOLD: 0, EPOCH: 21, train_loss: 0.015719321229167887\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 21, valid_loss: 0.016021207691385195\n",
      "SEED: 6, FOLD: 0, EPOCH: 22, train_loss: 0.01488648625594136\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 22, valid_loss: 0.016069279052317142\n",
      "SEED: 6, FOLD: 0, EPOCH: 23, train_loss: 0.014106827737713183\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 23, valid_loss: 0.01606982874755676\n",
      "SEED: 6, FOLD: 0, EPOCH: 24, train_loss: 0.013543931200999665\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 24, valid_loss: 0.016144518883755572\n",
      "SEED: 6, FOLD: 0, EPOCH: 25, train_loss: 0.013323055202695163\n",
      "SEED: 6 ,FOLD: 0, EPOCH: 25, valid_loss: 0.01615308217990857\n",
      "SEED: 6, FOLD: 1, EPOCH: 0, train_loss: 0.6233869406419832\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 0, valid_loss: 0.19396688502568465\n",
      "SEED: 6, FOLD: 1, EPOCH: 1, train_loss: 0.03989157312222429\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 1, valid_loss: 0.020389915229036257\n",
      "SEED: 6, FOLD: 1, EPOCH: 2, train_loss: 0.02213755781082688\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 2, valid_loss: 0.018171281912005864\n",
      "SEED: 6, FOLD: 1, EPOCH: 3, train_loss: 0.02095620598442651\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 3, valid_loss: 0.018172330151383694\n",
      "SEED: 6, FOLD: 1, EPOCH: 4, train_loss: 0.02051445096731186\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 4, valid_loss: 0.017768790658849936\n",
      "SEED: 6, FOLD: 1, EPOCH: 5, train_loss: 0.02012295723968261\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 5, valid_loss: 0.017583532258868217\n",
      "SEED: 6, FOLD: 1, EPOCH: 6, train_loss: 0.020019555162336375\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 6, valid_loss: 0.01737171210921728\n",
      "SEED: 6, FOLD: 1, EPOCH: 7, train_loss: 0.01985846001755547\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 7, valid_loss: 0.017183674356112115\n",
      "SEED: 6, FOLD: 1, EPOCH: 8, train_loss: 0.01977546973707708\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 8, valid_loss: 0.01702074405665581\n",
      "SEED: 6, FOLD: 1, EPOCH: 9, train_loss: 0.019636529296435213\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 9, valid_loss: 0.01688895646769267\n",
      "SEED: 6, FOLD: 1, EPOCH: 10, train_loss: 0.019472756574081408\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 10, valid_loss: 0.01714079024700018\n",
      "SEED: 6, FOLD: 1, EPOCH: 11, train_loss: 0.019368265428253123\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 11, valid_loss: 0.016932681776010074\n",
      "SEED: 6, FOLD: 1, EPOCH: 12, train_loss: 0.01921735341484482\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 12, valid_loss: 0.016974450160677616\n",
      "SEED: 6, FOLD: 1, EPOCH: 13, train_loss: 0.01902343312630782\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 13, valid_loss: 0.016753359626118954\n",
      "SEED: 6, FOLD: 1, EPOCH: 14, train_loss: 0.018863895832485444\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 14, valid_loss: 0.016474320624883357\n",
      "SEED: 6, FOLD: 1, EPOCH: 15, train_loss: 0.01863736822899129\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 15, valid_loss: 0.016434450275622882\n",
      "SEED: 6, FOLD: 1, EPOCH: 16, train_loss: 0.018307102617581148\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 16, valid_loss: 0.01647771794635516\n",
      "SEED: 6, FOLD: 1, EPOCH: 17, train_loss: 0.01796366858321267\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 17, valid_loss: 0.016293236699241858\n",
      "SEED: 6, FOLD: 1, EPOCH: 18, train_loss: 0.017614978164233065\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 18, valid_loss: 0.0163134432469423\n",
      "SEED: 6, FOLD: 1, EPOCH: 19, train_loss: 0.0170252517343977\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 19, valid_loss: 0.01629094535914751\n",
      "SEED: 6, FOLD: 1, EPOCH: 20, train_loss: 0.01634831985811124\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 20, valid_loss: 0.016137475291123755\n",
      "SEED: 6, FOLD: 1, EPOCH: 21, train_loss: 0.015535995754337794\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 21, valid_loss: 0.016153542539821222\n",
      "SEED: 6, FOLD: 1, EPOCH: 22, train_loss: 0.014722496610940309\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 22, valid_loss: 0.016207879409193993\n",
      "SEED: 6, FOLD: 1, EPOCH: 23, train_loss: 0.013942493629213926\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 23, valid_loss: 0.016232095372218352\n",
      "SEED: 6, FOLD: 1, EPOCH: 24, train_loss: 0.013394370121327607\n",
      "SEED: 6 ,FOLD: 1, EPOCH: 24, valid_loss: 0.01625547744333744\n",
      "SEED: 6, FOLD: 2, EPOCH: 0, train_loss: 0.6242354957235826\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 0, valid_loss: 0.21919915080070496\n",
      "SEED: 6, FOLD: 2, EPOCH: 1, train_loss: 0.0398903653478703\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 1, valid_loss: 0.02061314207430069\n",
      "SEED: 6, FOLD: 2, EPOCH: 2, train_loss: 0.02267241837909898\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 2, valid_loss: 0.018745865672826767\n",
      "SEED: 6, FOLD: 2, EPOCH: 3, train_loss: 0.021472005148393078\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 3, valid_loss: 0.018246151220339995\n",
      "SEED: 6, FOLD: 2, EPOCH: 4, train_loss: 0.020989924493069585\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 4, valid_loss: 0.017721642525150225\n",
      "SEED: 6, FOLD: 2, EPOCH: 5, train_loss: 0.020481516028175484\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 5, valid_loss: 0.0174239338017427\n",
      "SEED: 6, FOLD: 2, EPOCH: 6, train_loss: 0.02029486811040221\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 6, valid_loss: 0.017525078012393072\n",
      "SEED: 6, FOLD: 2, EPOCH: 7, train_loss: 0.020131099314705747\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 7, valid_loss: 0.017091974186209533\n",
      "SEED: 6, FOLD: 2, EPOCH: 8, train_loss: 0.019926088308361737\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 8, valid_loss: 0.017232043811908133\n",
      "SEED: 6, FOLD: 2, EPOCH: 9, train_loss: 0.019779367749956814\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 9, valid_loss: 0.016888763325718734\n",
      "SEED: 6, FOLD: 2, EPOCH: 10, train_loss: 0.019636177105476726\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 10, valid_loss: 0.01690975447686819\n",
      "SEED: 6, FOLD: 2, EPOCH: 11, train_loss: 0.019458519244516217\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 11, valid_loss: 0.016885514156176493\n",
      "SEED: 6, FOLD: 2, EPOCH: 12, train_loss: 0.01935030658402153\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 12, valid_loss: 0.01688517529803973\n",
      "SEED: 6, FOLD: 2, EPOCH: 13, train_loss: 0.019123449619557406\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 13, valid_loss: 0.016567319631576538\n",
      "SEED: 6, FOLD: 2, EPOCH: 14, train_loss: 0.01891795704392968\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 14, valid_loss: 0.01672520373876278\n",
      "SEED: 6, FOLD: 2, EPOCH: 15, train_loss: 0.018580713460372912\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 15, valid_loss: 0.01619349978864193\n",
      "SEED: 6, FOLD: 2, EPOCH: 16, train_loss: 0.018258430441287724\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 16, valid_loss: 0.016545111385102455\n",
      "SEED: 6, FOLD: 2, EPOCH: 17, train_loss: 0.017868078792014637\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 17, valid_loss: 0.016261894828998126\n",
      "SEED: 6, FOLD: 2, EPOCH: 18, train_loss: 0.017341384550908934\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 18, valid_loss: 0.016178282694174692\n",
      "SEED: 6, FOLD: 2, EPOCH: 19, train_loss: 0.01672867710727292\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 19, valid_loss: 0.01615828139564166\n",
      "SEED: 6, FOLD: 2, EPOCH: 20, train_loss: 0.01596680496240387\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 20, valid_loss: 0.01634422467591671\n",
      "SEED: 6, FOLD: 2, EPOCH: 21, train_loss: 0.015144586248474347\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 21, valid_loss: 0.016283630680006284\n",
      "SEED: 6, FOLD: 2, EPOCH: 22, train_loss: 0.014263181204630717\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 22, valid_loss: 0.016324113982801255\n",
      "SEED: 6, FOLD: 2, EPOCH: 23, train_loss: 0.013485522651289767\n",
      "SEED: 6 ,FOLD: 2, EPOCH: 23, valid_loss: 0.01631384572157493\n",
      "SEED: 6, FOLD: 3, EPOCH: 0, train_loss: 0.6232411168717049\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 0, valid_loss: 0.21672323231513685\n",
      "SEED: 6, FOLD: 3, EPOCH: 1, train_loss: 0.038805368255723165\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 1, valid_loss: 0.020516530682261173\n",
      "SEED: 6, FOLD: 3, EPOCH: 2, train_loss: 0.022497382770116266\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 2, valid_loss: 0.018715340357560378\n",
      "SEED: 6, FOLD: 3, EPOCH: 3, train_loss: 0.021756793850579777\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 3, valid_loss: 0.018328578139726933\n",
      "SEED: 6, FOLD: 3, EPOCH: 4, train_loss: 0.0209817361287974\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 4, valid_loss: 0.01773137140732545\n",
      "SEED: 6, FOLD: 3, EPOCH: 5, train_loss: 0.020360237994306796\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 5, valid_loss: 0.017496803775429726\n",
      "SEED: 6, FOLD: 3, EPOCH: 6, train_loss: 0.020156809078479134\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 6, valid_loss: 0.01730251484192335\n",
      "SEED: 6, FOLD: 3, EPOCH: 7, train_loss: 0.020011017577269592\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 7, valid_loss: 0.017174186041721932\n",
      "SEED: 6, FOLD: 3, EPOCH: 8, train_loss: 0.01987285479097753\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 8, valid_loss: 0.017015319174298875\n",
      "SEED: 6, FOLD: 3, EPOCH: 9, train_loss: 0.019795992764065396\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 9, valid_loss: 0.017319565925460596\n",
      "SEED: 6, FOLD: 3, EPOCH: 10, train_loss: 0.019604635173203173\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 10, valid_loss: 0.01753328124491068\n",
      "SEED: 6, FOLD: 3, EPOCH: 11, train_loss: 0.019619872415992053\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 11, valid_loss: 0.01751255215360568\n",
      "SEED: 6, FOLD: 3, EPOCH: 12, train_loss: 0.01939881406724453\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 12, valid_loss: 0.016638179667867146\n",
      "SEED: 6, FOLD: 3, EPOCH: 13, train_loss: 0.019224696893345664\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 13, valid_loss: 0.016999238170683384\n",
      "SEED: 6, FOLD: 3, EPOCH: 14, train_loss: 0.0190645244375274\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 14, valid_loss: 0.016710116599614803\n",
      "SEED: 6, FOLD: 3, EPOCH: 15, train_loss: 0.01884787607736684\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 15, valid_loss: 0.016952342855242584\n",
      "SEED: 6, FOLD: 3, EPOCH: 16, train_loss: 0.018580924392350623\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 16, valid_loss: 0.01652765668068941\n",
      "SEED: 6, FOLD: 3, EPOCH: 17, train_loss: 0.018272843010522222\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 17, valid_loss: 0.01627657297425545\n",
      "SEED: 6, FOLD: 3, EPOCH: 18, train_loss: 0.017785003962549003\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 18, valid_loss: 0.0162457711278246\n",
      "SEED: 6, FOLD: 3, EPOCH: 19, train_loss: 0.017361355542733863\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 19, valid_loss: 0.016236302586129077\n",
      "SEED: 6, FOLD: 3, EPOCH: 20, train_loss: 0.01680499585848805\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 20, valid_loss: 0.01610182813153817\n",
      "SEED: 6, FOLD: 3, EPOCH: 21, train_loss: 0.016091892810387386\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 21, valid_loss: 0.016097697500999156\n",
      "SEED: 6, FOLD: 3, EPOCH: 22, train_loss: 0.015310762135462987\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 22, valid_loss: 0.016088493168354034\n",
      "SEED: 6, FOLD: 3, EPOCH: 23, train_loss: 0.01462095697737626\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 23, valid_loss: 0.016182817232150298\n",
      "SEED: 6, FOLD: 3, EPOCH: 24, train_loss: 0.014092257321887725\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 24, valid_loss: 0.016167982624700435\n",
      "SEED: 6, FOLD: 3, EPOCH: 25, train_loss: 0.013877409623583426\n",
      "SEED: 6 ,FOLD: 3, EPOCH: 25, valid_loss: 0.016170568979130343\n",
      "SEED: 6, FOLD: 4, EPOCH: 0, train_loss: 0.6229405747474851\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 0, valid_loss: 0.17456892476632044\n",
      "SEED: 6, FOLD: 4, EPOCH: 1, train_loss: 0.03955085988383036\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 1, valid_loss: 0.02042654572198024\n",
      "SEED: 6, FOLD: 4, EPOCH: 2, train_loss: 0.022233851656720444\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 2, valid_loss: 0.01862031493622523\n",
      "SEED: 6, FOLD: 4, EPOCH: 3, train_loss: 0.021063946615401154\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 3, valid_loss: 0.017884366787396945\n",
      "SEED: 6, FOLD: 4, EPOCH: 4, train_loss: 0.020556106886549574\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 4, valid_loss: 0.0179833616488255\n",
      "SEED: 6, FOLD: 4, EPOCH: 5, train_loss: 0.020223247692794412\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 5, valid_loss: 0.017501712418519534\n",
      "SEED: 6, FOLD: 4, EPOCH: 6, train_loss: 0.02000852845407821\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 6, valid_loss: 0.017210021041906796\n",
      "SEED: 6, FOLD: 4, EPOCH: 7, train_loss: 0.01990119674922647\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 7, valid_loss: 0.01749680692759844\n",
      "SEED: 6, FOLD: 4, EPOCH: 8, train_loss: 0.019847962124323524\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 8, valid_loss: 0.017094112646121245\n",
      "SEED: 6, FOLD: 4, EPOCH: 9, train_loss: 0.019692536770693353\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 9, valid_loss: 0.017183253828149576\n",
      "SEED: 6, FOLD: 4, EPOCH: 10, train_loss: 0.019610795972717775\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 10, valid_loss: 0.017165498091624334\n",
      "SEED: 6, FOLD: 4, EPOCH: 11, train_loss: 0.019434024579823017\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 11, valid_loss: 0.016864867307818852\n",
      "SEED: 6, FOLD: 4, EPOCH: 12, train_loss: 0.019318385427263943\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 12, valid_loss: 0.016702262254861686\n",
      "SEED: 6, FOLD: 4, EPOCH: 13, train_loss: 0.019133981946553733\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 13, valid_loss: 0.016926778910251763\n",
      "SEED: 6, FOLD: 4, EPOCH: 14, train_loss: 0.01894391589873546\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 14, valid_loss: 0.016843854879530575\n",
      "SEED: 6, FOLD: 4, EPOCH: 15, train_loss: 0.01871760154294001\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 15, valid_loss: 0.01662202408680549\n",
      "SEED: 6, FOLD: 4, EPOCH: 16, train_loss: 0.01843741402734776\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 16, valid_loss: 0.016493193948498137\n",
      "SEED: 6, FOLD: 4, EPOCH: 17, train_loss: 0.018144913722534437\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 17, valid_loss: 0.016322126755347617\n",
      "SEED: 6, FOLD: 4, EPOCH: 18, train_loss: 0.017711960408534552\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 18, valid_loss: 0.01632768173630421\n",
      "SEED: 6, FOLD: 4, EPOCH: 19, train_loss: 0.017237375389683892\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 19, valid_loss: 0.016182664925089248\n",
      "SEED: 6, FOLD: 4, EPOCH: 20, train_loss: 0.016606035239591792\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 20, valid_loss: 0.01613155981669059\n",
      "SEED: 6, FOLD: 4, EPOCH: 21, train_loss: 0.0158716169487987\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 21, valid_loss: 0.016119625132817488\n",
      "SEED: 6, FOLD: 4, EPOCH: 22, train_loss: 0.015125789541147044\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 22, valid_loss: 0.016167542395683434\n",
      "SEED: 6, FOLD: 4, EPOCH: 23, train_loss: 0.014355013461632503\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 23, valid_loss: 0.016190287155600693\n",
      "SEED: 6, FOLD: 4, EPOCH: 24, train_loss: 0.013844487823646617\n",
      "SEED: 6 ,FOLD: 4, EPOCH: 24, valid_loss: 0.016196256790023584\n",
      "SEED: 6, FOLD: 5, EPOCH: 0, train_loss: 0.6236024112314791\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 0, valid_loss: 0.17222980352548453\n",
      "SEED: 6, FOLD: 5, EPOCH: 1, train_loss: 0.03916570043342339\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 1, valid_loss: 0.021517128182145264\n",
      "SEED: 6, FOLD: 5, EPOCH: 2, train_loss: 0.022641120050605888\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 2, valid_loss: 0.01871556989275492\n",
      "SEED: 6, FOLD: 5, EPOCH: 3, train_loss: 0.021140038639911124\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 3, valid_loss: 0.018048931199770708\n",
      "SEED: 6, FOLD: 5, EPOCH: 4, train_loss: 0.020536555229006586\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 4, valid_loss: 0.017511947223773368\n",
      "SEED: 6, FOLD: 5, EPOCH: 5, train_loss: 0.020201195736189146\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 5, valid_loss: 0.017670024186372757\n",
      "SEED: 6, FOLD: 5, EPOCH: 6, train_loss: 0.020060210413223988\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 6, valid_loss: 0.01726593865224948\n",
      "SEED: 6, FOLD: 5, EPOCH: 7, train_loss: 0.019822881557047367\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 7, valid_loss: 0.017099120654165745\n",
      "SEED: 6, FOLD: 5, EPOCH: 8, train_loss: 0.019701726105366205\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 8, valid_loss: 0.017382537874464806\n",
      "SEED: 6, FOLD: 5, EPOCH: 9, train_loss: 0.019608268715642595\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 9, valid_loss: 0.016944096710246343\n",
      "SEED: 6, FOLD: 5, EPOCH: 10, train_loss: 0.01958529824844083\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 10, valid_loss: 0.01705430097018297\n",
      "SEED: 6, FOLD: 5, EPOCH: 11, train_loss: 0.01942409373618461\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 11, valid_loss: 0.016745703294873238\n",
      "SEED: 6, FOLD: 5, EPOCH: 12, train_loss: 0.01922056295380399\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 12, valid_loss: 0.016803634711183034\n",
      "SEED: 6, FOLD: 5, EPOCH: 13, train_loss: 0.019100697761451877\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 13, valid_loss: 0.016688284392540272\n",
      "SEED: 6, FOLD: 5, EPOCH: 14, train_loss: 0.018938670614482584\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 14, valid_loss: 0.01660910850534072\n",
      "SEED: 6, FOLD: 5, EPOCH: 15, train_loss: 0.01868046014695554\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 15, valid_loss: 0.016422442590387967\n",
      "SEED: 6, FOLD: 5, EPOCH: 16, train_loss: 0.018408398999757058\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 16, valid_loss: 0.016384166880295828\n",
      "SEED: 6, FOLD: 5, EPOCH: 17, train_loss: 0.018072505406028515\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 17, valid_loss: 0.01624900919313614\n",
      "SEED: 6, FOLD: 5, EPOCH: 18, train_loss: 0.017634498647640686\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 18, valid_loss: 0.016259364712123688\n",
      "SEED: 6, FOLD: 5, EPOCH: 19, train_loss: 0.017112928958660043\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 19, valid_loss: 0.016018787685495157\n",
      "SEED: 6, FOLD: 5, EPOCH: 20, train_loss: 0.016521791562538694\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 20, valid_loss: 0.016137141161240064\n",
      "SEED: 6, FOLD: 5, EPOCH: 21, train_loss: 0.01580590647771149\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 21, valid_loss: 0.01617401659202117\n",
      "SEED: 6, FOLD: 5, EPOCH: 22, train_loss: 0.01499474626286207\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 22, valid_loss: 0.016147120855748653\n",
      "SEED: 6, FOLD: 5, EPOCH: 23, train_loss: 0.014246131633282514\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 23, valid_loss: 0.01626268673974734\n",
      "SEED: 6, FOLD: 5, EPOCH: 24, train_loss: 0.013729857469632014\n",
      "SEED: 6 ,FOLD: 5, EPOCH: 24, valid_loss: 0.01624706373191797\n",
      "SEED: 6, FOLD: 6, EPOCH: 0, train_loss: 0.6236213798055777\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 0, valid_loss: 0.18131015850947454\n",
      "SEED: 6, FOLD: 6, EPOCH: 1, train_loss: 0.039286653561567936\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 1, valid_loss: 0.019883326183144864\n",
      "SEED: 6, FOLD: 6, EPOCH: 2, train_loss: 0.022162325957135576\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 2, valid_loss: 0.01840359803575736\n",
      "SEED: 6, FOLD: 6, EPOCH: 3, train_loss: 0.020991373354116\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 3, valid_loss: 0.017706070811702654\n",
      "SEED: 6, FOLD: 6, EPOCH: 4, train_loss: 0.020427549106849206\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 4, valid_loss: 0.01759410076416456\n",
      "SEED: 6, FOLD: 6, EPOCH: 5, train_loss: 0.020060946208399696\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 5, valid_loss: 0.017520816423572026\n",
      "SEED: 6, FOLD: 6, EPOCH: 6, train_loss: 0.01988498478926517\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 6, valid_loss: 0.01721032694555246\n",
      "SEED: 6, FOLD: 6, EPOCH: 7, train_loss: 0.019865576328860747\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 7, valid_loss: 0.017286689952015877\n",
      "SEED: 6, FOLD: 6, EPOCH: 8, train_loss: 0.019687470526912727\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 8, valid_loss: 0.01709229714022233\n",
      "SEED: 6, FOLD: 6, EPOCH: 9, train_loss: 0.019670147524290794\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 9, valid_loss: 0.017119694501161575\n",
      "SEED: 6, FOLD: 6, EPOCH: 10, train_loss: 0.01951693740950243\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 10, valid_loss: 0.017032570420549467\n",
      "SEED: 6, FOLD: 6, EPOCH: 11, train_loss: 0.01936205687957841\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 11, valid_loss: 0.01705687865614891\n",
      "SEED: 6, FOLD: 6, EPOCH: 12, train_loss: 0.0192570746750445\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 12, valid_loss: 0.016844330785366204\n",
      "SEED: 6, FOLD: 6, EPOCH: 13, train_loss: 0.01906274284261304\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 13, valid_loss: 0.01666969906252164\n",
      "SEED: 6, FOLD: 6, EPOCH: 14, train_loss: 0.018874227673419425\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 14, valid_loss: 0.016750484346770324\n",
      "SEED: 6, FOLD: 6, EPOCH: 15, train_loss: 0.018631912591690954\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 15, valid_loss: 0.016557208119103543\n",
      "SEED: 6, FOLD: 6, EPOCH: 16, train_loss: 0.018302322692565015\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 16, valid_loss: 0.016404210446545713\n",
      "SEED: 6, FOLD: 6, EPOCH: 17, train_loss: 0.01797255808235826\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 17, valid_loss: 0.016407449944661215\n",
      "SEED: 6, FOLD: 6, EPOCH: 18, train_loss: 0.01753819182615828\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 18, valid_loss: 0.016366791195021227\n",
      "SEED: 6, FOLD: 6, EPOCH: 19, train_loss: 0.016950679036813812\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 19, valid_loss: 0.016243251542059276\n",
      "SEED: 6, FOLD: 6, EPOCH: 20, train_loss: 0.016321378936235968\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 20, valid_loss: 0.01630349249507372\n",
      "SEED: 6, FOLD: 6, EPOCH: 21, train_loss: 0.015566949707430762\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 21, valid_loss: 0.01628677461009759\n",
      "SEED: 6, FOLD: 6, EPOCH: 22, train_loss: 0.014750548789428698\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 22, valid_loss: 0.016312956236875974\n",
      "SEED: 6, FOLD: 6, EPOCH: 23, train_loss: 0.013978224260279455\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 23, valid_loss: 0.01629230659455061\n",
      "SEED: 6, FOLD: 6, EPOCH: 24, train_loss: 0.013481606125227502\n",
      "SEED: 6 ,FOLD: 6, EPOCH: 24, valid_loss: 0.01628833063519918\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "SEED = [0,1,2,3,4,5,6]  #<-- Update\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    \n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8d77673",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T13:46:16.146105Z",
     "iopub.status.busy": "2025-03-31T13:46:16.145736Z",
     "iopub.status.idle": "2025-03-31T13:46:19.048671Z",
     "shell.execute_reply": "2025-03-31T13:46:19.047618Z"
    },
    "papermill": {
     "duration": 3.005114,
     "end_time": "2025-03-31T13:46:19.050143",
     "exception": false,
     "start_time": "2025-03-31T13:46:16.045029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.01435779884264557\n",
      "Overall AUC:  0.8280635780769898\n"
     ]
    }
   ],
   "source": [
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "cv_score = 0\n",
    "roc_score = 0\n",
    "\n",
    "for i in range(len(target_cols)):\n",
    "    cv_score += log_loss(y_true[:, i], y_pred[:, i])\n",
    "    roc_score +=roc_auc_score(y_true[:, i], y_pred[:, i], average='micro')\n",
    "\n",
    "print(\"CV log_loss: \", cv_score / y_pred.shape[1])\n",
    "print(\"Overall AUC: \", roc_score / y_pred.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c997973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T13:46:19.300037Z",
     "iopub.status.busy": "2025-03-31T13:46:19.299683Z",
     "iopub.status.idle": "2025-03-31T13:46:26.351518Z",
     "shell.execute_reply": "2025-03-31T13:46:26.350829Z"
    },
    "papermill": {
     "duration": 7.153533,
     "end_time": "2025-03-31T13:46:26.353038",
     "exception": false,
     "start_time": "2025-03-31T13:46:19.199505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "oof_pretrain= valid_results[target_cols]\n",
    "oof_pretrain.to_csv('off_pretrain_last.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0634f4ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T13:46:26.548299Z",
     "iopub.status.busy": "2025-03-31T13:46:26.547999Z",
     "iopub.status.idle": "2025-03-31T13:46:27.536309Z",
     "shell.execute_reply": "2025-03-31T13:46:27.535578Z"
    },
    "papermill": {
     "duration": 1.086764,
     "end_time": "2025-03-31T13:46:27.537841",
     "exception": false,
     "start_time": "2025-03-31T13:46:26.451077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "public_id = list(df['sig_id'].values)\n",
    "test_id = list(test_features['sig_id'].values)\n",
    "private_id = list(set(test_id)-set(public_id))\n",
    "df_submit = pd.DataFrame(index = public_id+private_id, columns=target_cols)\n",
    "df_submit.index.name = 'sig_id'\n",
    "df_submit[:] = 0\n",
    "df_submit.loc[test.sig_id,:] = test[target_cols].values\n",
    "df_submit.loc[test_features[test_features.cp_type=='ctl_vehicle'].sig_id]= 0\n",
    "df_submit.to_csv('submission.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec26dcb",
   "metadata": {
    "papermill": {
     "duration": 0.096908,
     "end_time": "2025-03-31T13:46:27.733036",
     "exception": false,
     "start_time": "2025-03-31T13:46:27.636128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Your support motivates me to share kernels like these ... so please \" Do UPVOTE \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d14b775",
   "metadata": {
    "papermill": {
     "duration": 0.09892,
     "end_time": "2025-03-31T13:46:27.929491",
     "exception": false,
     "start_time": "2025-03-31T13:46:27.830571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1651354,
     "sourceId": 19988,
     "sourceType": "competition"
    },
    {
     "datasetId": 877310,
     "sourceId": 1494119,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4178.663644,
   "end_time": "2025-03-31T13:46:29.755108",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-31T12:36:51.091464",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
